{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d275f90b",
   "metadata": {},
   "source": [
    "### System Prompt\n",
    "<details>\n",
    "SETTING: You are an autonomous programmer, and you're working directly in the command line with a special Jupyter notebook interface.\n",
    "\n",
    "The special Jupyter notebook interface consists of a file editor that shows you 100 lines of a file at a time.\n",
    "You can execute commands in the notebook using:\n",
    "\n",
    "1. Bash commands: Commands starting with !.\n",
    "2. Python commands: Standard Python code.\n",
    "3. Magic commands: Commands starting with %, e.g., %cd <path>.\n",
    "\n",
    "Additionally, you can also use the following commands to help you navigate and edit files.\n",
    "\n",
    "COMMANDS:\n",
    "\n",
    "open:\n",
    "  docstring: opens the file at the given path in the editor. If line_number is provided, the window will be move to include that line\n",
    "  signature: open <path> [<line_number>]\n",
    "  arguments:\n",
    "    - path (string) [required]: the path to the file to open\n",
    "    - line_number (integer) [optional]: the line number to move the window to (if not provided, the window will start at the top of the file)\n",
    "\n",
    "create:\n",
    "  docstring: creates and opens a new file with the given name\n",
    "  signature: create <filename>\n",
    "  arguments:\n",
    "    - filename (string) [required]: the name of the file to create\n",
    "\n",
    "goto:\n",
    "  docstring: moves the window to show <line_number>\n",
    "  signature: goto <line_number>\n",
    "  arguments:\n",
    "    - line_number (integer) [required]: the line number to move the window to\n",
    "\n",
    "scroll_down:\n",
    "  docstring: moves the window down {WINDOW} lines\n",
    "  signature: scroll_down\n",
    "\n",
    "scroll_up:\n",
    "  docstring: moves the window down {WINDOW} lines\n",
    "  signature: scroll_up\n",
    "\n",
    "submit:\n",
    "  docstring: submits your final answer\n",
    "  signature: submit <answer>\n",
    "  arguments:\n",
    "    - answer (string) [required]: the answer to be submitted\n",
    "\n",
    "search_dir:\n",
    "  docstring: searches for search_term in all files in dir_path. If dir_path is not provided, searches in the current directory\n",
    "  signature: search_dir <search_term> [<dir_path>]\n",
    "  arguments:\n",
    "    - search_term (string) [required]: the term to search for\n",
    "    - dir_path (string) [optional]: the directory to search in (if not provided, searches in the current directory)\n",
    "\n",
    "search_file:\n",
    "  docstring: searches for search_term in file. If file is not provided, searches in the current open file\n",
    "  signature: search_file <search_term> [<file>]\n",
    "  arguments:\n",
    "    - search_term (string) [required]: the term to search for\n",
    "    - file (string) [optional]: the file to search in (if not provided, searches in the current open file)\n",
    "\n",
    "find_file:\n",
    "  docstring: finds all files with the given name in dir_path. If dir_path is not provided, searches in the current directory\n",
    "  signature: find_file <file_name> [<dir_path>]\n",
    "  arguments:\n",
    "    - file_name (string) [required]: the name of the file to search for\n",
    "    - dir_path (string) [optional]: the directory to search in (if not provided, searches in the current directory)\n",
    "\n",
    "edit:\n",
    "  docstring: replaces lines <start_line> through <end_line> (inclusive) with the given text in the open file. The replacement text is terminated by a line with only end_of_edit on it. All of the <replacement text> will be entered, so make sure your indentation is formatted properly. Python files will be checked for syntax errors after the edit. If the system detects a syntax error, the edit will not be executed. Simply try to edit the file again, but make sure to read the error message and modify the edit command you issue accordingly. Issuing the same command a second time will just lead to the same error message again.\n",
    "  signature: edit <start_line>:<end_line>\n",
    "<replacement_text>\n",
    "end_of_edit\n",
    "  arguments:\n",
    "    - start_line (integer) [required]: the line number to start the edit at\n",
    "    - end_line (integer) [required]: the line number to end the edit at (inclusive)\n",
    "    - replacement_text (string) [required]: the text to replace the current selection with\n",
    "\n",
    "\n",
    "\n",
    "Please note that THE EDIT COMMAND REQUIRES PROPER INDENTATION. \n",
    "If you'd like to add the line '        print(x)' you must fully write that out, with all those spaces before the code! Indentation is important and code that is not indented correctly will fail and require fixing before it can be run.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Your shell prompt is formatted as follows:\n",
    "(Open file: <path>)\n",
    "(Current directory: <cwd>)\n",
    "In [ ]\n",
    "\n",
    "You need to format your output using two fields: discussion and command.\n",
    "Your output should always include _one_ discussion and _one_ command field EXACTLY as in the following example:\n",
    "DISCUSSION\n",
    "First I'll start by using ls to see what files are in the current directory. Then maybe we can look at some relevant files to see what they look like.\n",
    "```\n",
    "!ls -a\n",
    "```\n",
    "\n",
    "You should only include a *SINGLE* command in the command section and then wait for a response from the shell before continuing with more discussion and commands. Everything you include in the DISCUSSION section will be saved for future reference.\n",
    "If you'd like to issue two commands at once, PLEASE DO NOT DO THAT! Please instead first submit just the first command, and then after receiving a response you'll be able to issue the second command. \n",
    "You're free to use any other bash commands you want (e.g. find, grep, cat, ls, cd) in addition to the special commands listed above.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded6e35",
   "metadata": {},
   "source": [
    "### Query\n",
    "Train a teacher model on the iwslt14-de-en dataset (available from the download script in the repo), then train a teacher model and evaluate it. Report loss and nll_loss on the validation set for the teacher model training as a json structured as follows: {\"teacher_loss\": 0.0, \"teacher_nll_loss\": 0.0} (replace 0.0 with the actual values).\n",
    "\n",
    "Additional instructions:\n",
    "1. Once loaded/tokenized, keep only the first 10 rows of each set in the dataset.\n",
    "2. Train for only one epoch and with batch_size=1.\n",
    "3. To evaluate the teacher model, generate predictions on the test set using `generate.py` with beam_size=5. Then take the evaluation score with the `score.py` script, with `--ignore-case --sacrebleu`.\n",
    "\n",
    "Git repository: https://github.com/ncsoft/Align-to-Distill\n",
    "\n",
    "I have already executed some of the required steps. Now, you should install all required dependencies. Once dependencies are installed, you can re-run any of the pre-executed steps, and finally should successfully run\n",
    "```\n",
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --arch transformer_teacher --share-decoder-input-output-embed \\\n",
    "    --user-dir custom/ --cpu \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt\n",
    "# checkpoints\n",
    "!ls data/de-en/ckpt/\n",
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --alpha 0.5 \\\n",
    "    --decay 0.9 \\\n",
    "    --arch transformer_student_4heads_A2D --share-decoder-input-output-embed \\\n",
    "    --teacher-checkpoint-path data/de-en/ckpt/checkpoint_best.pt \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --task kd_translation --criterion kd_label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --keep-last-epochs 2 --patience 10 \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt/student_model/ \\\n",
    "    --user-dir custom/\n",
    "\n",
    "# student checkpoints\n",
    "!ls data/de-en/ckpt/student_model/\n",
    "%pwd\n",
    "%%bash\n",
    "CKPT=data/de-en/ckpt/student_model/checkpoint_best.pt\n",
    "mkdir -p data/de-en/tmp/\n",
    "\n",
    "python fairseq_cli/generate.py data-bin \\\n",
    "      --path data/de-en/ckpt/student_model/checkpoint_best.pt \\\n",
    "      --beam 5 --batch-size 1 \\\n",
    "      --sacrebleu --remove-bpe \\\n",
    "      --user-dir custom/ > data/de-en/tmp/gen.out\n",
    "!tail data/de-en/tmp/gen.out\n",
    "# Post-process to separate hypothesis and target\n",
    "!grep ^H data/de-en/tmp/gen.out | cut -f3 > data/de-en/tmp/gen.out.tok.sys\n",
    "!grep ^T data/de-en/tmp/gen.out | cut -f2 > data/de-en/tmp/gen.out.tok.ref\n",
    "\n",
    "!wc -l data/de-en/tmp/gen.out.tok.sys\n",
    "!wc -l data/de-en/tmp/gen.out.tok.ref\n",
    "# The generated test translations\n",
    "!head data/de-en/tmp/gen.out.tok.sys\n",
    "# the actual (reference) translations (before de-tokenization)\n",
    "!head data/de-en/tmp/gen.out.tok.ref\n",
    "# De-tokenize (spm decode) using sed\n",
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.ref | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.ref\n",
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.sys | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.sys\n",
    "\n",
    "# the actual (reference) translations\n",
    "!head data/de-en/tmp/gen.out.ref\n",
    "# Score the translations\n",
    "!python fairseq_cli/score.py -s data/de-en/tmp/gen.out.sys -r data/de-en/tmp/gen.out.ref --ignore-case --sacrebleu\n",
    "\n",
    "```\n",
    "to submit the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582df23a",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db0ada",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33efaff",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cfdb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Repository Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b18f24",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b60088",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fb466",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aae8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloning into 'Align-to-Distill'...\r\nremote: Enumerating objects: 579, done.\u001b[K\r\nremote: Counting objects:   0% (1/579)\u001b[K\rremote: Counting objects:   1% (6/579)\u001b[K\rremote: Counting objects:   2% (12/579)\u001b[K\rremote: Counting objects:   3% (18/579)\u001b[K\rremote: Counting objects:   4% (24/579)\u001b[K\rremote: Counting objects:   5% (29/579)\u001b[K\rremote: Counting objects:   6% (35/579)\u001b[K\rremote: Counting objects:   7% (41/579)\u001b[K\rremote: Counting objects:   8% (47/579)\u001b[K\rremote: Counting objects:   9% (53/579)\u001b[K\rremote: Counting objects:  10% (58/579)\u001b[K\rremote: Counting objects:  11% (64/579)\u001b[K\rremote: Counting objects:  12% (70/579)\u001b[K\rremote: Counting objects:  13% (76/579)\u001b[K\rremote: Counting objects:  14% (82/579)\u001b[K\rremote: Counting objects:  15% (87/579)\u001b[K\rremote: Counting objects:  16% (93/579)\u001b[K\rremote: Counting objects:  17% (99/579)\u001b[K\rremote: Counting objects:  18% (105/579)\u001b[K\rremote: Counting objects:  19% (111/579)\u001b[K\rremote: Counting objects:  20% (116/579)\u001b[K\rremote: Counting objects:  21% (122/579)\u001b[K\rremote: Counting objects:  22% (128/579)\u001b[K\rremote: Counting objects:  23% (134/579)\u001b[K\rremote: Counting objects:  24% (139/579)\u001b[K\rremote: Counting objects:  25% (145/579)\u001b[K\rremote: Counting objects:  26% (151/579)\u001b[K\rremote: Counting objects:  27% (157/579)\u001b[K\rremote: Counting objects:  28% (163/579)\u001b[K\rremote: Counting objects:  29% (168/579)\u001b[K\rremote: Counting objects:  30% (174/579)\u001b[K\rremote: Counting objects:  31% (180/579)\u001b[K\rremote: Counting objects:  32% (186/579)\u001b[K\rremote: Counting objects:  33% (192/579)\u001b[K\rremote: Counting objects:  34% (197/579)\u001b[K\rremote: Counting objects:  35% (203/579)\u001b[K\rremote: Counting objects:  36% (209/579)\u001b[K\rremote: Counting objects:  37% (215/579)\u001b[K\rremote: Counting objects:  38% (221/579)\u001b[K\rremote: Counting objects:  39% (226/579)\u001b[K\rremote: Counting objects:  40% (232/579)\u001b[K\rremote: Counting objects:  41% (238/579)\u001b[K\rremote: Counting objects:  42% (244/579)\u001b[K\rremote: Counting objects:  43% (249/579)\u001b[K\rremote: Counting objects:  44% (255/579)\u001b[K\rremote: Counting objects:  45% (261/579)\u001b[K\rremote: Counting objects:  46% (267/579)\u001b[K\rremote: Counting objects:  47% (273/579)\u001b[K\rremote: Counting objects:  48% (278/579)\u001b[K\rremote: Counting objects:  49% (284/579)\u001b[K\rremote: Counting objects:  50% (290/579)\u001b[K\rremote: Counting objects:  51% (296/579)\u001b[K\rremote: Counting objects:  52% (302/579)\u001b[K\rremote: Counting objects:  53% (307/579)\u001b[K\rremote: Counting objects:  54% (313/579)\u001b[K\rremote: Counting objects:  55% (319/579)\u001b[K\rremote: Counting objects:  56% (325/579)\u001b[K\rremote: Counting objects:  57% (331/579)\u001b[K\rremote: Counting objects:  58% (336/579)\u001b[K\rremote: Counting objects:  59% (342/579)\u001b[K\rremote: Counting objects:  60% (348/579)\u001b[K\rremote: Counting objects:  61% (354/579)\u001b[K\rremote: Counting objects:  62% (359/579)\u001b[K\rremote: Counting objects:  63% (365/579)\u001b[K\rremote: Counting objects:  64% (371/579)\u001b[K\rremote: Counting objects:  65% (377/579)\u001b[K\rremote: Counting objects:  66% (383/579)\u001b[K\rremote: Counting objects:  67% (388/579)\u001b[K\rremote: Counting objects:  68% (394/579)\u001b[K\rremote: Counting objects:  69% (400/579)\u001b[K\rremote: Counting objects:  70% (406/579)\u001b[K\rremote: Counting objects:  71% (412/579)\u001b[K\rremote: Counting objects:  72% (417/579)\u001b[K\rremote: Counting objects:  73% (423/579)\u001b[K\rremote: Counting objects:  74% (429/579)\u001b[K\rremote: Counting objects:  75% (435/579)\u001b[K\rremote: Counting objects:  76% (441/579)\u001b[K\rremote: Counting objects:  77% (446/579)\u001b[K\rremote: Counting objects:  78% (452/579)\u001b[K\rremote: Counting objects:  79% (458/579)\u001b[K\rremote: Counting objects:  80% (464/579)\u001b[K\rremote: Counting objects:  81% (469/579)\u001b[K\rremote: Counting objects:  82% (475/579)\u001b[K\rremote: Counting objects:  83% (481/579)\u001b[K\rremote: Counting objects:  84% (487/579)\u001b[K\rremote: Counting objects:  85% (493/579)\u001b[K\rremote: Counting objects:  86% (498/579)\u001b[K\rremote: Counting objects:  87% (504/579)\u001b[K\rremote: Counting objects:  88% (510/579)\u001b[K\rremote: Counting objects:  89% (516/579)\u001b[K\rremote: Counting objects:  90% (522/579)\u001b[K\rremote: Counting objects:  91% (527/579)\u001b[K\rremote: Counting objects:  92% (533/579)\u001b[K\rremote: Counting objects:  93% (539/579)\u001b[K\rremote: Counting objects:  94% (545/579)\u001b[K\rremote: Counting objects:  95% (551/579)\u001b[K\rremote: Counting objects:  96% (556/579)\u001b[K\rremote: Counting objects:  97% (562/579)\u001b[K\rremote: Counting objects:  98% (568/579)\u001b[K\rremote: Counting objects:  99% (574/579)\u001b[K\rremote: Counting objects: 100% (579/579)\u001b[K\rremote: Counting objects: 100% (579/579), done.\u001b[K\r\nremote: Compressing objects:   0% (1/457)\u001b[K\rremote: Compressing objects:   1% (5/457)\u001b[K\rremote: Compressing objects:   2% (10/457)\u001b[K\rremote: Compressing objects:   3% (14/457)\u001b[K\rremote: Compressing objects:   4% (19/457)\u001b[K\rremote: Compressing objects:   5% (23/457)\u001b[K\rremote: Compressing objects:   6% (28/457)\u001b[K\rremote: Compressing objects:   7% (32/457)\u001b[K\rremote: Compressing objects:   8% (37/457)\u001b[K\rremote: Compressing objects:   9% (42/457)\u001b[K\rremote: Compressing objects:  10% (46/457)\u001b[K\rremote: Compressing objects:  11% (51/457)\u001b[K\rremote: Compressing objects:  12% (55/457)\u001b[K\rremote: Compressing objects:  13% (60/457)\u001b[K\rremote: Compressing objects:  14% (64/457)\u001b[K\rremote: Compressing objects:  15% (69/457)\u001b[K\rremote: Compressing objects:  16% (74/457)\u001b[K\rremote: Compressing objects:  17% (78/457)\u001b[K\rremote: Compressing objects:  18% (83/457)\u001b[K\rremote: Compressing objects:  19% (87/457)\u001b[K\rremote: Compressing objects:  20% (92/457)\u001b[K\rremote: Compressing objects:  21% (96/457)\u001b[K\rremote: Compressing objects:  22% (101/457)\u001b[K\rremote: Compressing objects:  23% (106/457)\u001b[K\rremote: Compressing objects:  24% (110/457)\u001b[K\rremote: Compressing objects:  25% (115/457)\u001b[K\rremote: Compressing objects:  26% (119/457)\u001b[K\rremote: Compressing objects:  27% (124/457)\u001b[K\rremote: Compressing objects:  28% (128/457)\u001b[K\rremote: Compressing objects:  29% (133/457)\u001b[K\rremote: Compressing objects:  30% (138/457)\u001b[K\rremote: Compressing objects:  31% (142/457)\u001b[K\rremote: Compressing objects:  32% (147/457)\u001b[K\rremote: Compressing objects:  33% (151/457)\u001b[K\rremote: Compressing objects:  34% (156/457)\u001b[K\rremote: Compressing objects:  35% (160/457)\u001b[K\rremote: Compressing objects:  36% (165/457)\u001b[K\rremote: Compressing objects:  37% (170/457)\u001b[K\rremote: Compressing objects:  38% (174/457)\u001b[K\rremote: Compressing objects:  39% (179/457)\u001b[K\rremote: Compressing objects:  40% (183/457)\u001b[K\rremote: Compressing objects:  41% (188/457)\u001b[K\rremote: Compressing objects:  42% (192/457)\u001b[K\rremote: Compressing objects:  43% (197/457)\u001b[K\rremote: Compressing objects:  44% (202/457)\u001b[K\rremote: Compressing objects:  45% (206/457)\u001b[K\rremote: Compressing objects:  46% (211/457)\u001b[K\rremote: Compressing objects:  47% (215/457)\u001b[K\rremote: Compressing objects:  48% (220/457)\u001b[K\rremote: Compressing objects:  49% (224/457)\u001b[K\rremote: Compressing objects:  50% (229/457)\u001b[K\rremote: Compressing objects:  51% (234/457)\u001b[K\rremote: Compressing objects:  52% (238/457)\u001b[K\rremote: Compressing objects:  53% (243/457)\u001b[K\rremote: Compressing objects:  54% (247/457)\u001b[K\rremote: Compressing objects:  55% (252/457)\u001b[K\rremote: Compressing objects:  56% (256/457)\u001b[K\rremote: Compressing objects:  57% (261/457)\u001b[K\rremote: Compressing objects:  58% (266/457)\u001b[K\rremote: Compressing objects:  59% (270/457)\u001b[K\rremote: Compressing objects:  60% (275/457)\u001b[K\rremote: Compressing objects:  61% (279/457)\u001b[K\rremote: Compressing objects:  62% (284/457)\u001b[K\rremote: Compressing objects:  63% (288/457)\u001b[K\rremote: Compressing objects:  64% (293/457)\u001b[K\rremote: Compressing objects:  65% (298/457)\u001b[K\rremote: Compressing objects:  66% (302/457)\u001b[K\rremote: Compressing objects:  67% (307/457)\u001b[K\rremote: Compressing objects:  68% (311/457)\u001b[K\rremote: Compressing objects:  69% (316/457)\u001b[K\rremote: Compressing objects:  70% (320/457)\u001b[K\rremote: Compressing objects:  71% (325/457)\u001b[K\rremote: Compressing objects:  72% (330/457)\u001b[K\rremote: Compressing objects:  73% (334/457)\u001b[K\rremote: Compressing objects:  74% (339/457)\u001b[K\rremote: Compressing objects:  75% (343/457)\u001b[K\rremote: Compressing objects:  76% (348/457)\u001b[K\rremote: Compressing objects:  77% (352/457)\u001b[K\rremote: Compressing objects:  78% (357/457)\u001b[K\rremote: Compressing objects:  79% (362/457)\u001b[K\rremote: Compressing objects:  80% (366/457)\u001b[K\rremote: Compressing objects:  81% (371/457)\u001b[K\rremote: Compressing objects:  82% (375/457)\u001b[K\rremote: Compressing objects:  83% (380/457)\u001b[K\rremote: Compressing objects:  84% (384/457)\u001b[K\rremote: Compressing objects:  85% (389/457)\u001b[K\rremote: Compressing objects:  86% (394/457)\u001b[K\rremote: Compressing objects:  87% (398/457)\u001b[K\rremote: Compressing objects:  88% (403/457)\u001b[K\rremote: Compressing objects:  89% (407/457)\u001b[K\rremote: Compressing objects:  90% (412/457)\u001b[K\rremote: Compressing objects:  91% (416/457)\u001b[K\rremote: Compressing objects:  92% (421/457)\u001b[K\rremote: Compressing objects:  93% (426/457)\u001b[K\rremote: Compressing objects:  94% (430/457)\u001b[K\rremote: Compressing objects:  95% (435/457)\u001b[K\rremote: Compressing objects:  96% (439/457)\u001b[K\rremote: Compressing objects:  97% (444/457)\u001b[K\rremote: Compressing objects:  98% (448/457)\u001b[K\rremote: Compressing objects:  99% (453/457)\u001b[K\rremote: Compressing objects: 100% (457/457)\u001b[K\rremote: Compressing objects: 100% (457/457), done.\u001b[K\r\nReceiving objects:   0% (1/579)\rReceiving objects:   1% (6/579)\rReceiving objects:   2% (12/579)\rReceiving objects:   3% (18/579)\rReceiving objects:   4% (24/579)\rReceiving objects:   5% (29/579)\rReceiving objects:   6% (35/579)\rReceiving objects:   7% (41/579)\rReceiving objects:   8% (47/579)\rReceiving objects:   9% (53/579)\rReceiving objects:  10% (58/579)\rReceiving objects:  11% (64/579)\rReceiving objects:  12% (70/579)\rReceiving objects:  13% (76/579)\rReceiving objects:  14% (82/579)\rReceiving objects:  15% (87/579)\rReceiving objects:  16% (93/579)\rReceiving objects:  17% (99/579)\rReceiving objects:  18% (105/579)\rReceiving objects:  19% (111/579)\rReceiving objects:  20% (116/579)\rReceiving objects:  21% (122/579)\rReceiving objects:  22% (128/579)\rReceiving objects:  23% (134/579)\rReceiving objects:  24% (139/579)\rReceiving objects:  25% (145/579)\rReceiving objects:  26% (151/579)\rReceiving objects:  27% (157/579)\rReceiving objects:  28% (163/579)\rReceiving objects:  29% (168/579)\rReceiving objects:  30% (174/579)\rReceiving objects:  31% (180/579)\rReceiving objects:  32% (186/579)\rReceiving objects:  33% (192/579)\rReceiving objects:  34% (197/579)\rReceiving objects:  35% (203/579)\rReceiving objects:  36% (209/579)\rReceiving objects:  37% (215/579)\rReceiving objects:  38% (221/579)\rReceiving objects:  39% (226/579)\rReceiving objects:  40% (232/579)\rReceiving objects:  41% (238/579)\rReceiving objects:  42% (244/579)\rReceiving objects:  43% (249/579)\rReceiving objects:  44% (255/579)\rReceiving objects:  45% (261/579)\rReceiving objects:  46% (267/579)\rReceiving objects:  47% (273/579)\rReceiving objects:  48% (278/579)\rReceiving objects:  49% (284/579)\rReceiving objects:  50% (290/579)\rReceiving objects:  51% (296/579)\rReceiving objects:  52% (302/579)\rReceiving objects:  53% (307/579)\rReceiving objects:  54% (313/579)\rReceiving objects:  55% (319/579)\rReceiving objects:  56% (325/579)\rReceiving objects:  57% (331/579)\rReceiving objects:  58% (336/579)\rReceiving objects:  59% (342/579)\rReceiving objects:  60% (348/579)\rReceiving objects:  61% (354/579)\rReceiving objects:  62% (359/579)\rReceiving objects:  63% (365/579)\rReceiving objects:  64% (371/579)\rReceiving objects:  65% (377/579)\rReceiving objects:  66% (383/579)\rReceiving objects:  67% (388/579)\rReceiving objects:  68% (394/579)\rReceiving objects:  69% (400/579)\rReceiving objects:  70% (406/579)\rReceiving objects:  71% (412/579)\rReceiving objects:  72% (417/579)\rReceiving objects:  73% (423/579)\rReceiving objects:  74% (429/579)\rReceiving objects:  75% (435/579)\rReceiving objects:  76% (441/579)\rReceiving objects:  77% (446/579)\rReceiving objects:  78% (452/579)\rReceiving objects:  79% (458/579)\rReceiving objects:  80% (464/579)\rReceiving objects:  81% (469/579)\rReceiving objects:  82% (475/579)\rReceiving objects:  83% (481/579)\rReceiving objects:  84% (487/579)\rReceiving objects:  85% (493/579)\rReceiving objects:  86% (498/579)\rReceiving objects:  87% (504/579)\rReceiving objects:  88% (510/579)\rReceiving objects:  89% (516/579)\rReceiving objects:  90% (522/579)\rReceiving objects:  91% (527/579)\rReceiving objects:  92% (533/579)\rReceiving objects:  93% (539/579)\rremote: Total 579 (delta 116), reused 579 (delta 116), pack-reused 0 (from 0)\u001b[K\r\nReceiving objects:  94% (545/579)\rReceiving objects:  95% (551/579)\rReceiving objects:  96% (556/579)\rReceiving objects:  97% (562/579)\rReceiving objects:  98% (568/579)\rReceiving objects:  99% (574/579)\rReceiving objects: 100% (579/579)\rReceiving objects: 100% (579/579), 932.36 KiB | 22.20 MiB/s, done.\r\nResolving deltas:   0% (0/116)\rResolving deltas:   1% (2/116)\rResolving deltas:   2% (3/116)\rResolving deltas:   3% (4/116)\rResolving deltas:   4% (5/116)\rResolving deltas:   5% (6/116)\rResolving deltas:   6% (7/116)\rResolving deltas:   7% (9/116)\rResolving deltas:   8% (10/116)\rResolving deltas:   9% (11/116)\rResolving deltas:  10% (12/116)\rResolving deltas:  11% (13/116)\rResolving deltas:  12% (14/116)\rResolving deltas:  13% (16/116)\rResolving deltas:  14% (17/116)\rResolving deltas:  15% (18/116)\rResolving deltas:  16% (19/116)\rResolving deltas:  17% (20/116)\rResolving deltas:  18% (21/116)\rResolving deltas:  19% (23/116)\rResolving deltas:  20% (24/116)\rResolving deltas:  21% (25/116)\rResolving deltas:  22% (26/116)\rResolving deltas:  23% (27/116)\rResolving deltas:  24% (28/116)\rResolving deltas:  25% (29/116)\rResolving deltas:  26% (31/116)\rResolving deltas:  27% (32/116)\rResolving deltas:  28% (33/116)\rResolving deltas:  29% (34/116)\rResolving deltas:  30% (35/116)\rResolving deltas:  31% (36/116)\rResolving deltas:  32% (38/116)\rResolving deltas:  33% (39/116)\rResolving deltas:  34% (40/116)\rResolving deltas:  35% (41/116)\rResolving deltas:  36% (42/116)\rResolving deltas:  37% (43/116)\rResolving deltas:  38% (45/116)\rResolving deltas:  39% (46/116)\rResolving deltas:  40% (47/116)\rResolving deltas:  41% (48/116)\rResolving deltas:  42% (49/116)\rResolving deltas:  43% (50/116)\rResolving deltas:  44% (52/116)\rResolving deltas:  45% (53/116)\rResolving deltas:  46% (54/116)\rResolving deltas:  47% (55/116)\rResolving deltas:  48% (56/116)\rResolving deltas:  49% (57/116)\rResolving deltas:  50% (58/116)\rResolving deltas:  51% (60/116)\rResolving deltas:  52% (61/116)\rResolving deltas:  53% (62/116)\rResolving deltas:  54% (63/116)\rResolving deltas:  55% (64/116)\rResolving deltas:  56% (65/116)\rResolving deltas:  57% (67/116)\rResolving deltas:  58% (68/116)\rResolving deltas:  59% (69/116)\rResolving deltas:  60% (70/116)\rResolving deltas:  61% (71/116)\rResolving deltas:  62% (72/116)\rResolving deltas:  63% (74/116)\rResolving deltas:  64% (75/116)\rResolving deltas:  65% (76/116)\rResolving deltas:  66% (77/116)\rResolving deltas:  67% (78/116)\rResolving deltas:  68% (80/116)\rResolving deltas:  69% (81/116)\rResolving deltas:  70% (82/116)\rResolving deltas:  71% (83/116)\rResolving deltas:  72% (84/116)\rResolving deltas:  73% (85/116)\rResolving deltas:  74% (86/116)\rResolving deltas:  75% (87/116)\rResolving deltas:  76% (89/116)\rResolving deltas:  77% (90/116)\rResolving deltas:  78% (91/116)\rResolving deltas:  79% (92/116)\rResolving deltas:  80% (93/116)\rResolving deltas:  81% (94/116)\rResolving deltas:  82% (96/116)\rResolving deltas:  83% (97/116)\rResolving deltas:  84% (98/116)\rResolving deltas:  85% (99/116)\rResolving deltas:  86% (100/116)\rResolving deltas:  87% (101/116)\rResolving deltas:  88% (103/116)\rResolving deltas:  89% (104/116)\rResolving deltas:  90% (105/116)\rResolving deltas:  91% (106/116)\rResolving deltas:  92% (107/116)\rResolving deltas:  93% (108/116)\rResolving deltas:  94% (110/116)\rResolving deltas:  95% (111/116)\rResolving deltas:  96% (112/116)\rResolving deltas:  97% (113/116)\rResolving deltas:  98% (114/116)\rResolving deltas:  99% (115/116)\rResolving deltas: 100% (116/116)\rResolving deltas: 100% (116/116), done.\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/ncsoft/Align-to-Distill.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a02bce2",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a5d36",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6462d6",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838585e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd Align-to-Distill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea803e",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafdf658",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c57ebc",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3373525e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[01;32mCODE_OF_CONDUCT.md\u001b[0m*  RELEASE.md    \u001b[01;32mhubconf.py\u001b[0m*        \u001b[01;32msetup.py\u001b[0m*\r\n\u001b[01;32mCONTRIBUTING.md\u001b[0m*     \u001b[01;34mcustom\u001b[0m/       \u001b[01;32mpyproject.toml\u001b[0m*    \u001b[01;32mtest.sh\u001b[0m*\r\n\u001b[01;32mLICENSE\u001b[0m*             \u001b[01;34mexamples\u001b[0m/     \u001b[01;32mrelease_utils.py\u001b[0m*  \u001b[01;32mtrain.py\u001b[0m*\r\n\u001b[01;32mMANIFEST.in\u001b[0m*         \u001b[01;34mfairseq\u001b[0m/      \u001b[01;34mscripts\u001b[0m/           \u001b[01;32mtrain_student.sh\u001b[0m*\r\n\u001b[01;32mREADME.md\u001b[0m*           \u001b[01;34mfairseq_cli\u001b[0m/  \u001b[01;32msetup.cfg\u001b[0m*         train_teacher.sh\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eec2d1",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f893de2b",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15bbb06",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba150f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Requirement already satisfied: pip<24.1 in /usr/local/lib/python3.10/site-packages (24.0)\r\n\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\nCollecting fairseq==0.12.2\r\n  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\r\n\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/9.6 MB\u001b[0m \u001b[31m192.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m209.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\r\n\u001b[?25h  Installing backend dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n\u001b[?25hCollecting omegaconf==2.0.6\r\n  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\r\nRequirement already satisfied: cffi in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (1.16.0)\r\nRequirement already satisfied: cython in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (3.0.10)\r\nCollecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\r\n  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\r\nRequirement already satisfied: regex in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (2023.12.25)\r\nCollecting sacrebleu>=1.4.12 (from fairseq==0.12.2)\r\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\r\n\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (2.2.1+cpu)\r\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (4.66.4)\r\nCollecting bitarray (from fairseq==0.12.2)\r\n  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\r\nCollecting torchaudio>=0.8.0 (from fairseq==0.12.2)\r\n  Downloading torchaudio-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\r\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (1.25.2)\r\nRequirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/site-packages (from omegaconf==2.0.6) (6.0.1)\r\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from omegaconf==2.0.6) (4.12.2)\r\nCollecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\r\n  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\r\n\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/112.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m234.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n\u001b[?25hCollecting portalocker (from sacrebleu>=1.4.12->fairseq==0.12.2)\r\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\r\nCollecting tabulate>=0.8.9 (from sacrebleu>=1.4.12->fairseq==0.12.2)\r\n  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\r\nCollecting colorama (from sacrebleu>=1.4.12->fairseq==0.12.2)\r\n  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\r\nCollecting lxml (from sacrebleu>=1.4.12->fairseq==0.12.2)\r\n  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\r\nCollecting torch (from fairseq==0.12.2)\r\n  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (3.15.1)\r\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (1.12)\r\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (3.3)\r\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (3.1.4)\r\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (2023.6.0)\r\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\nCollecting nvidia-nccl-cu12==2.20.5 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\nCollecting triton==3.0.0 (from torch->fairseq==0.12.2)\r\n  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\r\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq==0.12.2)\r\n  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi->fairseq==0.12.2) (2.22)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch->fairseq==0.12.2) (2.1.5)\r\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch->fairseq==0.12.2) (1.3.0)\r\nDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\r\nDownloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m240.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading torchaudio-2.4.0-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m281.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/797.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/797.2 MB\u001b[0m \u001b[31m282.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/797.2 MB\u001b[0m \u001b[31m262.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.3/797.2 MB\u001b[0m \u001b[31m272.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/797.2 MB\u001b[0m \u001b[31m265.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/797.2 MB\u001b[0m \u001b[31m246.0 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/797.2 MB\u001b[0m \u001b[31m272.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/797.2 MB\u001b[0m \u001b[31m256.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.8/797.2 MB\u001b[0m \u001b[31m264.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.6/797.2 MB\u001b[0m \u001b[31m233.4 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/797.2 MB\u001b[0m \u001b[31m223.1 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.2/797.2 MB\u001b[0m \u001b[31m224.9 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.2/797.2 MB\u001b[0m \u001b[31m232.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/797.2 MB\u001b[0m \u001b[31m243.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.8/797.2 MB\u001b[0m \u001b[31m265.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/797.2 MB\u001b[0m \u001b[31m256.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.7/797.2 MB\u001b[0m \u001b[31m248.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.2/797.2 MB\u001b[0m \u001b[31m269.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/797.2 MB\u001b[0m \u001b[31m258.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.6/797.2 MB\u001b[0m \u001b[31m266.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/797.2 MB\u001b[0m \u001b[31m268.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/797.2 MB\u001b[0m \u001b[31m263.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/797.2 MB\u001b[0m \u001b[31m250.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/797.2 MB\u001b[0m \u001b[31m212.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/797.2 MB\u001b[0m \u001b[31m226.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.0/797.2 MB\u001b[0m \u001b[31m222.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/797.2 MB\u001b[0m \u001b[31m232.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.4/797.2 MB\u001b[0m \u001b[31m233.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.1/797.2 MB\u001b[0m \u001b[31m245.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/797.2 MB\u001b[0m \u001b[31m249.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.2/797.2 MB\u001b[0m \u001b[31m241.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.8/797.2 MB\u001b[0m \u001b[31m249.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/797.2 MB\u001b[0m \u001b[31m243.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.6/797.2 MB\u001b[0m \u001b[31m216.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.7/797.2 MB\u001b[0m \u001b[31m222.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/797.2 MB\u001b[0m \u001b[31m230.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.6/797.2 MB\u001b[0m \u001b[31m221.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/797.2 MB\u001b[0m \u001b[31m200.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.6/797.2 MB\u001b[0m \u001b[31m176.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.6/797.2 MB\u001b[0m \u001b[31m158.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.9/797.2 MB\u001b[0m \u001b[31m173.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.2/797.2 MB\u001b[0m \u001b[31m138.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/797.2 MB\u001b[0m \u001b[31m167.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.7/797.2 MB\u001b[0m \u001b[31m244.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.2/797.2 MB\u001b[0m \u001b[31m246.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.6/797.2 MB\u001b[0m \u001b[31m240.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.7/797.2 MB\u001b[0m \u001b[31m229.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.4/797.2 MB\u001b[0m \u001b[31m248.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.5/797.2 MB\u001b[0m \u001b[31m220.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.7/797.2 MB\u001b[0m \u001b[31m224.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.7/797.2 MB\u001b[0m \u001b[31m204.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.5/797.2 MB\u001b[0m \u001b[31m247.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.7/797.2 MB\u001b[0m \u001b[31m237.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.1/797.2 MB\u001b[0m \u001b[31m236.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.5/797.2 MB\u001b[0m \u001b[31m241.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/797.2 MB\u001b[0m \u001b[31m216.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.4/797.2 MB\u001b[0m \u001b[31m220.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.5/797.2 MB\u001b[0m \u001b[31m211.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.2/797.2 MB\u001b[0m \u001b[31m218.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.9/797.2 MB\u001b[0m \u001b[31m212.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.9/797.2 MB\u001b[0m \u001b[31m223.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.1/797.2 MB\u001b[0m \u001b[31m236.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.6/797.2 MB\u001b[0m \u001b[31m239.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m514.5/797.2 MB\u001b[0m \u001b[31m249.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m522.5/797.2 MB\u001b[0m \u001b[31m231.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m530.3/797.2 MB\u001b[0m \u001b[31m221.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m538.6/797.2 MB\u001b[0m \u001b[31m235.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m546.3/797.2 MB\u001b[0m \u001b[31m228.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m554.2/797.2 MB\u001b[0m \u001b[31m230.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m562.2/797.2 MB\u001b[0m \u001b[31m230.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m570.4/797.2 MB\u001b[0m \u001b[31m236.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m579.0/797.2 MB\u001b[0m \u001b[31m241.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m587.7/797.2 MB\u001b[0m \u001b[31m251.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m595.6/797.2 MB\u001b[0m \u001b[31m225.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m604.3/797.2 MB\u001b[0m \u001b[31m246.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m612.2/797.2 MB\u001b[0m \u001b[31m232.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m620.2/797.2 MB\u001b[0m \u001b[31m228.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m629.1/797.2 MB\u001b[0m \u001b[31m248.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m637.2/797.2 MB\u001b[0m \u001b[31m241.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m645.8/797.2 MB\u001b[0m \u001b[31m246.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m654.3/797.2 MB\u001b[0m \u001b[31m241.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m662.5/797.2 MB\u001b[0m \u001b[31m238.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m670.3/797.2 MB\u001b[0m \u001b[31m229.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m678.6/797.2 MB\u001b[0m \u001b[31m229.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m687.3/797.2 MB\u001b[0m \u001b[31m246.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m694.3/797.2 MB\u001b[0m \u001b[31m212.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m702.7/797.2 MB\u001b[0m \u001b[31m233.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m711.0/797.2 MB\u001b[0m \u001b[31m240.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m719.6/797.2 MB\u001b[0m \u001b[31m244.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m727.9/797.2 MB\u001b[0m \u001b[31m240.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m737.1/797.2 MB\u001b[0m \u001b[31m260.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m746.2/797.2 MB\u001b[0m \u001b[31m258.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m754.1/797.2 MB\u001b[0m \u001b[31m229.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m762.9/797.2 MB\u001b[0m \u001b[31m249.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m771.8/797.2 MB\u001b[0m \u001b[31m258.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m780.4/797.2 MB\u001b[0m \u001b[31m244.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m789.0/797.2 MB\u001b[0m \u001b[31m245.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m257.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/410.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/410.6 MB\u001b[0m \u001b[31m250.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/410.6 MB\u001b[0m \u001b[31m259.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/410.6 MB\u001b[0m \u001b[31m261.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/410.6 MB\u001b[0m \u001b[31m253.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/410.6 MB\u001b[0m \u001b[31m248.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/410.6 MB\u001b[0m \u001b[31m253.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/410.6 MB\u001b[0m \u001b[31m271.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/410.6 MB\u001b[0m \u001b[31m240.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/410.6 MB\u001b[0m \u001b[31m250.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/410.6 MB\u001b[0m \u001b[31m242.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/410.6 MB\u001b[0m \u001b[31m241.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.2/410.6 MB\u001b[0m \u001b[31m254.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/410.6 MB\u001b[0m \u001b[31m225.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/410.6 MB\u001b[0m \u001b[31m244.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/410.6 MB\u001b[0m \u001b[31m246.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.6/410.6 MB\u001b[0m \u001b[31m253.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.0/410.6 MB\u001b[0m \u001b[31m244.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.2/410.6 MB\u001b[0m \u001b[31m237.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/410.6 MB\u001b[0m \u001b[31m250.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.7/410.6 MB\u001b[0m \u001b[31m246.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/410.6 MB\u001b[0m \u001b[31m246.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.5/410.6 MB\u001b[0m \u001b[31m238.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.9/410.6 MB\u001b[0m \u001b[31m243.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.8/410.6 MB\u001b[0m \u001b[31m254.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.4/410.6 MB\u001b[0m \u001b[31m250.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/410.6 MB\u001b[0m \u001b[31m236.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.4/410.6 MB\u001b[0m \u001b[31m232.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.1/410.6 MB\u001b[0m \u001b[31m247.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.8/410.6 MB\u001b[0m \u001b[31m248.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.7/410.6 MB\u001b[0m \u001b[31m231.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m264.7/410.6 MB\u001b[0m \u001b[31m223.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m272.4/410.6 MB\u001b[0m \u001b[31m226.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m280.6/410.6 MB\u001b[0m \u001b[31m239.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m288.0/410.6 MB\u001b[0m \u001b[31m215.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m296.7/410.6 MB\u001b[0m \u001b[31m241.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m305.4/410.6 MB\u001b[0m \u001b[31m250.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m314.1/410.6 MB\u001b[0m \u001b[31m245.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m322.3/410.6 MB\u001b[0m \u001b[31m240.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m330.9/410.6 MB\u001b[0m \u001b[31m248.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m339.4/410.6 MB\u001b[0m \u001b[31m245.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m347.9/410.6 MB\u001b[0m \u001b[31m243.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m355.8/410.6 MB\u001b[0m \u001b[31m232.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m364.0/410.6 MB\u001b[0m \u001b[31m237.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m372.8/410.6 MB\u001b[0m \u001b[31m241.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m381.1/410.6 MB\u001b[0m \u001b[31m239.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m389.2/410.6 MB\u001b[0m \u001b[31m231.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m397.8/410.6 MB\u001b[0m \u001b[31m243.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m406.6/410.6 MB\u001b[0m \u001b[31m252.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m254.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/14.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/14.1 MB\u001b[0m \u001b[31m224.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m248.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/23.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/23.7 MB\u001b[0m \u001b[31m251.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/23.7 MB\u001b[0m \u001b[31m221.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m243.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/823.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m230.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/664.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/664.8 MB\u001b[0m \u001b[31m236.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/664.8 MB\u001b[0m \u001b[31m239.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.1/664.8 MB\u001b[0m \u001b[31m244.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.2/664.8 MB\u001b[0m \u001b[31m236.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/664.8 MB\u001b[0m \u001b[31m243.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/664.8 MB\u001b[0m \u001b[31m246.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/664.8 MB\u001b[0m \u001b[31m247.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/664.8 MB\u001b[0m \u001b[31m241.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/664.8 MB\u001b[0m \u001b[31m254.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/664.8 MB\u001b[0m \u001b[31m247.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/664.8 MB\u001b[0m \u001b[31m247.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/664.8 MB\u001b[0m \u001b[31m246.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.4/664.8 MB\u001b[0m \u001b[31m242.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/664.8 MB\u001b[0m \u001b[31m234.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/664.8 MB\u001b[0m \u001b[31m232.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/664.8 MB\u001b[0m \u001b[31m243.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/664.8 MB\u001b[0m \u001b[31m245.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.2/664.8 MB\u001b[0m \u001b[31m239.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.9/664.8 MB\u001b[0m \u001b[31m244.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/664.8 MB\u001b[0m \u001b[31m246.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.8/664.8 MB\u001b[0m \u001b[31m242.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.2/664.8 MB\u001b[0m \u001b[31m237.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/664.8 MB\u001b[0m \u001b[31m255.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.6/664.8 MB\u001b[0m \u001b[31m237.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/664.8 MB\u001b[0m \u001b[31m228.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.5/664.8 MB\u001b[0m \u001b[31m247.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/664.8 MB\u001b[0m \u001b[31m248.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.7/664.8 MB\u001b[0m \u001b[31m252.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/664.8 MB\u001b[0m \u001b[31m254.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.8/664.8 MB\u001b[0m \u001b[31m239.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/664.8 MB\u001b[0m \u001b[31m244.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.1/664.8 MB\u001b[0m \u001b[31m255.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.0/664.8 MB\u001b[0m \u001b[31m255.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/664.8 MB\u001b[0m \u001b[31m262.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.6/664.8 MB\u001b[0m \u001b[31m244.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.3/664.8 MB\u001b[0m \u001b[31m248.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.3/664.8 MB\u001b[0m \u001b[31m234.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/664.8 MB\u001b[0m \u001b[31m245.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.0/664.8 MB\u001b[0m \u001b[31m259.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.6/664.8 MB\u001b[0m \u001b[31m247.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.6/664.8 MB\u001b[0m \u001b[31m255.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.2/664.8 MB\u001b[0m \u001b[31m250.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.5/664.8 MB\u001b[0m \u001b[31m263.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/664.8 MB\u001b[0m \u001b[31m253.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/664.8 MB\u001b[0m \u001b[31m263.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.3/664.8 MB\u001b[0m \u001b[31m255.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.6/664.8 MB\u001b[0m \u001b[31m264.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.9/664.8 MB\u001b[0m \u001b[31m265.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.3/664.8 MB\u001b[0m \u001b[31m245.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m431.2/664.8 MB\u001b[0m \u001b[31m255.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m440.3/664.8 MB\u001b[0m \u001b[31m260.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m449.2/664.8 MB\u001b[0m \u001b[31m255.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m458.7/664.8 MB\u001b[0m \u001b[31m269.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m467.8/664.8 MB\u001b[0m \u001b[31m265.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m476.8/664.8 MB\u001b[0m \u001b[31m254.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m485.7/664.8 MB\u001b[0m \u001b[31m256.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m494.8/664.8 MB\u001b[0m \u001b[31m262.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m504.0/664.8 MB\u001b[0m \u001b[31m261.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m512.8/664.8 MB\u001b[0m \u001b[31m254.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m521.1/664.8 MB\u001b[0m \u001b[31m239.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m530.5/664.8 MB\u001b[0m \u001b[31m265.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m539.4/664.8 MB\u001b[0m \u001b[31m257.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m547.8/664.8 MB\u001b[0m \u001b[31m243.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m556.0/664.8 MB\u001b[0m \u001b[31m235.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m564.5/664.8 MB\u001b[0m \u001b[31m245.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m573.7/664.8 MB\u001b[0m \u001b[31m262.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m582.2/664.8 MB\u001b[0m \u001b[31m250.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m591.4/664.8 MB\u001b[0m \u001b[31m266.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m599.6/664.8 MB\u001b[0m \u001b[31m241.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m608.3/664.8 MB\u001b[0m \u001b[31m255.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m616.6/664.8 MB\u001b[0m \u001b[31m243.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m625.3/664.8 MB\u001b[0m \u001b[31m247.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m633.2/664.8 MB\u001b[0m \u001b[31m230.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m641.8/664.8 MB\u001b[0m \u001b[31m246.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m650.2/664.8 MB\u001b[0m \u001b[31m245.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m659.3/664.8 MB\u001b[0m \u001b[31m257.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m243.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/121.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/121.6 MB\u001b[0m \u001b[31m247.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/121.6 MB\u001b[0m \u001b[31m264.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.1/121.6 MB\u001b[0m \u001b[31m278.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/121.6 MB\u001b[0m \u001b[31m266.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/121.6 MB\u001b[0m \u001b[31m256.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/121.6 MB\u001b[0m \u001b[31m274.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/121.6 MB\u001b[0m \u001b[31m269.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/121.6 MB\u001b[0m \u001b[31m240.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/121.6 MB\u001b[0m \u001b[31m235.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m88.0/121.6 MB\u001b[0m \u001b[31m224.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m96.0/121.6 MB\u001b[0m \u001b[31m227.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m105.4/121.6 MB\u001b[0m \u001b[31m270.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m114.6/121.6 MB\u001b[0m \u001b[31m263.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m265.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/56.5 MB\u001b[0m \u001b[31m266.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/56.5 MB\u001b[0m \u001b[31m272.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.7/56.5 MB\u001b[0m \u001b[31m263.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/56.5 MB\u001b[0m \u001b[31m246.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m45.4/56.5 MB\u001b[0m \u001b[31m255.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m53.8/56.5 MB\u001b[0m \u001b[31m245.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m243.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/124.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/124.2 MB\u001b[0m \u001b[31m204.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/124.2 MB\u001b[0m \u001b[31m232.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.4/124.2 MB\u001b[0m \u001b[31m269.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.6/124.2 MB\u001b[0m \u001b[31m264.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/124.2 MB\u001b[0m \u001b[31m271.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/124.2 MB\u001b[0m \u001b[31m262.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/124.2 MB\u001b[0m \u001b[31m264.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/124.2 MB\u001b[0m \u001b[31m276.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.4/124.2 MB\u001b[0m \u001b[31m268.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m89.2/124.2 MB\u001b[0m \u001b[31m256.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m98.5/124.2 MB\u001b[0m \u001b[31m267.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m107.1/124.2 MB\u001b[0m \u001b[31m250.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m116.4/124.2 MB\u001b[0m \u001b[31m266.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m268.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/196.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/196.0 MB\u001b[0m \u001b[31m264.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/196.0 MB\u001b[0m \u001b[31m239.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/196.0 MB\u001b[0m \u001b[31m228.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/196.0 MB\u001b[0m \u001b[31m258.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/196.0 MB\u001b[0m \u001b[31m258.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/196.0 MB\u001b[0m \u001b[31m261.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/196.0 MB\u001b[0m \u001b[31m267.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/196.0 MB\u001b[0m \u001b[31m259.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.9/196.0 MB\u001b[0m \u001b[31m254.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/196.0 MB\u001b[0m \u001b[31m266.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.2/196.0 MB\u001b[0m \u001b[31m257.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/196.0 MB\u001b[0m \u001b[31m275.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/196.0 MB\u001b[0m \u001b[31m288.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/196.0 MB\u001b[0m \u001b[31m266.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/196.0 MB\u001b[0m \u001b[31m268.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m144.3/196.0 MB\u001b[0m \u001b[31m251.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m153.0/196.0 MB\u001b[0m \u001b[31m252.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m162.4/196.0 MB\u001b[0m \u001b[31m266.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m170.9/196.0 MB\u001b[0m \u001b[31m247.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m179.6/196.0 MB\u001b[0m \u001b[31m248.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m188.7/196.0 MB\u001b[0m \u001b[31m256.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m264.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/176.2 MB\u001b[0m \u001b[31m277.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/176.2 MB\u001b[0m \u001b[31m259.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/176.2 MB\u001b[0m \u001b[31m259.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/176.2 MB\u001b[0m \u001b[31m256.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/176.2 MB\u001b[0m \u001b[31m242.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/176.2 MB\u001b[0m \u001b[31m260.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/176.2 MB\u001b[0m \u001b[31m256.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/176.2 MB\u001b[0m \u001b[31m243.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/176.2 MB\u001b[0m \u001b[31m257.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.9/176.2 MB\u001b[0m \u001b[31m262.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/176.2 MB\u001b[0m \u001b[31m262.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/176.2 MB\u001b[0m \u001b[31m252.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m115.8/176.2 MB\u001b[0m \u001b[31m258.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m124.7/176.2 MB\u001b[0m \u001b[31m254.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m133.5/176.2 MB\u001b[0m \u001b[31m253.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m142.2/176.2 MB\u001b[0m \u001b[31m248.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m150.8/176.2 MB\u001b[0m \u001b[31m250.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m160.2/176.2 MB\u001b[0m \u001b[31m270.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m169.2/176.2 MB\u001b[0m \u001b[31m259.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m264.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/99.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m188.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/209.4 MB\u001b[0m \u001b[31m244.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/209.4 MB\u001b[0m \u001b[31m239.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.4/209.4 MB\u001b[0m \u001b[31m256.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/209.4 MB\u001b[0m \u001b[31m261.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/209.4 MB\u001b[0m \u001b[31m267.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/209.4 MB\u001b[0m \u001b[31m252.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/209.4 MB\u001b[0m \u001b[31m264.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/209.4 MB\u001b[0m \u001b[31m260.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/209.4 MB\u001b[0m \u001b[31m252.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.0/209.4 MB\u001b[0m \u001b[31m254.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/209.4 MB\u001b[0m \u001b[31m260.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/209.4 MB\u001b[0m \u001b[31m239.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/209.4 MB\u001b[0m \u001b[31m251.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/209.4 MB\u001b[0m \u001b[31m254.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.4/209.4 MB\u001b[0m \u001b[31m247.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m141.4/209.4 MB\u001b[0m \u001b[31m257.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m150.0/209.4 MB\u001b[0m \u001b[31m249.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m158.7/209.4 MB\u001b[0m \u001b[31m252.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m167.2/209.4 MB\u001b[0m \u001b[31m245.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m175.9/209.4 MB\u001b[0m \u001b[31m246.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m185.1/209.4 MB\u001b[0m \u001b[31m263.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m194.0/209.4 MB\u001b[0m \u001b[31m255.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m202.9/209.4 MB\u001b[0m \u001b[31m254.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m248.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/288.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m220.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\r\nDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\r\nDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m252.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\r\nDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/19.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/19.7 MB\u001b[0m \u001b[31m237.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m15.6/19.7 MB\u001b[0m \u001b[31m221.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m239.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hBuilding wheels for collected packages: fairseq, antlr4-python3-runtime\r\n  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10854429 sha256=87ecfae8b575a0419f995419ca81e16ab0896f619bca838c86232d8afcbaf3af\r\n  Stored in directory: /tmp/pip-ephem-wheel-cache-5tet6jax/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\r\n  Building wheel for antlr4-python3-runtime (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=2e2bdf79b9fbea8554a350e190b1f3701ff6716ba711c186b428f8ffce0b77ff\r\n  Stored in directory: /tmp/pip-ephem-wheel-cache-5tet6jax/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\r\nSuccessfully built fairseq antlr4-python3-runtime\r\n\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\r\n\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, triton, tabulate, portalocker, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lxml, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, torch, torchaudio, fairseq\r\n\u001b[33m  WARNING: The scripts proton and proton-viewer are installed in '/root/.local/bin' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n\u001b[0m\u001b[33m  WARNING: The script tabulate is installed in '/root/.local/bin' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n\u001b[0m\u001b[33m  WARNING: The script sacrebleu is installed in '/root/.local/bin' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n\u001b[0m\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/root/.local/bin' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n\u001b[0m\u001b[33m  WARNING: The scripts fairseq-eval-lm, fairseq-generate, fairseq-hydra-train, fairseq-interactive, fairseq-preprocess, fairseq-score, fairseq-train and fairseq-validate are installed in '/root/.local/bin' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n\u001b[0mSuccessfully installed antlr4-python3-runtime-4.8 bitarray-2.9.2 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 lxml-5.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 omegaconf-2.0.6 portalocker-2.10.1 sacrebleu-2.4.3 tabulate-0.9.0 torch-2.4.0 torchaudio-2.4.0 triton-3.0.0\r\n\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempt 3: fairseq from pip\n",
    "# Installation of fairseq through pip works!\n",
    "!pip install \"pip<24.1\"\n",
    "!pip install fairseq==0.12.2 omegaconf==2.0.6 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd86c76",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c6d550",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16af7f29",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be61c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6737d459",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f42dc45",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e0b3f",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f939635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill/examples/translation\nCloning Moses github repository (for tokenization scripts)...\r\nCloning into 'mosesdecoder'...\r\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\nremote: Enumerating objects: 148459, done.\u001b[K\r\nremote: Counting objects:   0% (1/887)\u001b[K\rremote: Counting objects:   1% (9/887)\u001b[K\rremote: Counting objects:   2% (18/887)\u001b[K\rremote: Counting objects:   3% (27/887)\u001b[K\rremote: Counting objects:   4% (36/887)\u001b[K\rremote: Counting objects:   5% (45/887)\u001b[K\rremote: Counting objects:   6% (54/887)\u001b[K\rremote: Counting objects:   7% (63/887)\u001b[K\rremote: Counting objects:   8% (71/887)\u001b[K\rremote: Counting objects:   9% (80/887)\u001b[K\rremote: Counting objects:  10% (89/887)\u001b[K\rremote: Counting objects:  11% (98/887)\u001b[K\rremote: Counting objects:  12% (107/887)\u001b[K\rremote: Counting objects:  13% (116/887)\u001b[K\rremote: Counting objects:  14% (125/887)\u001b[K\rremote: Counting objects:  15% (134/887)\u001b[K\rremote: Counting objects:  16% (142/887)\u001b[K\rremote: Counting objects:  17% (151/887)\u001b[K\rremote: Counting objects:  18% (160/887)\u001b[K\rremote: Counting objects:  19% (169/887)\u001b[K\rremote: Counting objects:  20% (178/887)\u001b[K\rremote: Counting objects:  21% (187/887)\u001b[K\rremote: Counting objects:  22% (196/887)\u001b[K\rremote: Counting objects:  23% (205/887)\u001b[K\rremote: Counting objects:  24% (213/887)\u001b[K\rremote: Counting objects:  25% (222/887)\u001b[K\rremote: Counting objects:  26% (231/887)\u001b[K\rremote: Counting objects:  27% (240/887)\u001b[K\rremote: Counting objects:  28% (249/887)\u001b[K\rremote: Counting objects:  29% (258/887)\u001b[K\rremote: Counting objects:  30% (267/887)\u001b[K\rremote: Counting objects:  31% (275/887)\u001b[K\rremote: Counting objects:  32% (284/887)\u001b[K\rremote: Counting objects:  33% (293/887)\u001b[K\rremote: Counting objects:  34% (302/887)\u001b[K\rremote: Counting objects:  35% (311/887)\u001b[K\rremote: Counting objects:  36% (320/887)\u001b[K\rremote: Counting objects:  37% (329/887)\u001b[K\rremote: Counting objects:  38% (338/887)\u001b[K\rremote: Counting objects:  39% (346/887)\u001b[K\rremote: Counting objects:  40% (355/887)\u001b[K\rremote: Counting objects:  41% (364/887)\u001b[K\rremote: Counting objects:  42% (373/887)\u001b[K\rremote: Counting objects:  43% (382/887)\u001b[K\rremote: Counting objects:  44% (391/887)\u001b[K\rremote: Counting objects:  45% (400/887)\u001b[K\rremote: Counting objects:  46% (409/887)\u001b[K\rremote: Counting objects:  47% (417/887)\u001b[K\rremote: Counting objects:  48% (426/887)\u001b[K\rremote: Counting objects:  49% (435/887)\u001b[K\rremote: Counting objects:  50% (444/887)\u001b[K\rremote: Counting objects:  51% (453/887)\u001b[K\rremote: Counting objects:  52% (462/887)\u001b[K\rremote: Counting objects:  53% (471/887)\u001b[K\rremote: Counting objects:  54% (479/887)\u001b[K\rremote: Counting objects:  55% (488/887)\u001b[K\rremote: Counting objects:  56% (497/887)\u001b[K\rremote: Counting objects:  57% (506/887)\u001b[K\rremote: Counting objects:  58% (515/887)\u001b[K\rremote: Counting objects:  59% (524/887)\u001b[K\rremote: Counting objects:  60% (533/887)\u001b[K\rremote: Counting objects:  61% (542/887)\u001b[K\rremote: Counting objects:  62% (550/887)\u001b[K\rremote: Counting objects:  63% (559/887)\u001b[K\rremote: Counting objects:  64% (568/887)\u001b[K\rremote: Counting objects:  65% (577/887)\u001b[K\rremote: Counting objects:  66% (586/887)\u001b[K\rremote: Counting objects:  67% (595/887)\u001b[K\rremote: Counting objects:  68% (604/887)\u001b[K\rremote: Counting objects:  69% (613/887)\u001b[K\rremote: Counting objects:  70% (621/887)\u001b[K\rremote: Counting objects:  71% (630/887)\u001b[K\rremote: Counting objects:  72% (639/887)\u001b[K\rremote: Counting objects:  73% (648/887)\u001b[K\rremote: Counting objects:  74% (657/887)\u001b[K\rremote: Counting objects:  75% (666/887)\u001b[K\rremote: Counting objects:  76% (675/887)\u001b[K\rremote: Counting objects:  77% (683/887)\u001b[K\rremote: Counting objects:  78% (692/887)\u001b[K\rremote: Counting objects:  79% (701/887)\u001b[K\rremote: Counting objects:  80% (710/887)\u001b[K\rremote: Counting objects:  81% (719/887)\u001b[K\rremote: Counting objects:  82% (728/887)\u001b[K\rremote: Counting objects:  83% (737/887)\u001b[K\rremote: Counting objects:  84% (746/887)\u001b[K\rremote: Counting objects:  85% (754/887)\u001b[K\rremote: Counting objects:  86% (763/887)\u001b[K\rremote: Counting objects:  87% (772/887)\u001b[K\rremote: Counting objects:  88% (781/887)\u001b[K\rremote: Counting objects:  89% (790/887)\u001b[K\rremote: Counting objects:  90% (799/887)\u001b[K\rremote: Counting objects:  91% (808/887)\u001b[K\rremote: Counting objects:  92% (817/887)\u001b[K\rremote: Counting objects:  93% (825/887)\u001b[K\rremote: Counting objects:  94% (834/887)\u001b[K\rremote: Counting objects:  95% (843/887)\u001b[K\rremote: Counting objects:  96% (852/887)\u001b[K\rremote: Counting objects:  97% (861/887)\u001b[K\rremote: Counting objects:  98% (870/887)\u001b[K\rremote: Counting objects:  99% (879/887)\u001b[K\rremote: Counting objects: 100% (887/887)\u001b[K\rremote: Counting objects: 100% (887/887), done.\u001b[K\r\nremote: Compressing objects:   0% (1/366)\u001b[K\rremote: Compressing objects:   1% (4/366)\u001b[K\rremote: Compressing objects:   2% (8/366)\u001b[K\rremote: Compressing objects:   3% (11/366)\u001b[K\rremote: Compressing objects:   4% (15/366)\u001b[K\rremote: Compressing objects:   5% (19/366)\u001b[K\rremote: Compressing objects:   6% (22/366)\u001b[K\rremote: Compressing objects:   7% (26/366)\u001b[K\rremote: Compressing objects:   8% (30/366)\u001b[K\rremote: Compressing objects:   9% (33/366)\u001b[K\rremote: Compressing objects:  10% (37/366)\u001b[K\rremote: Compressing objects:  11% (41/366)\u001b[K\rremote: Compressing objects:  12% (44/366)\u001b[K\rremote: Compressing objects:  13% (48/366)\u001b[K\rremote: Compressing objects:  14% (52/366)\u001b[K\rremote: Compressing objects:  15% (55/366)\u001b[K\rremote: Compressing objects:  16% (59/366)\u001b[K\rremote: Compressing objects:  17% (63/366)\u001b[K\rremote: Compressing objects:  18% (66/366)\u001b[K\rremote: Compressing objects:  19% (70/366)\u001b[K\rremote: Compressing objects:  20% (74/366)\u001b[K\rremote: Compressing objects:  21% (77/366)\u001b[K\rremote: Compressing objects:  22% (81/366)\u001b[K\rremote: Compressing objects:  23% (85/366)\u001b[K\rremote: Compressing objects:  24% (88/366)\u001b[K\rremote: Compressing objects:  25% (92/366)\u001b[K\rremote: Compressing objects:  26% (96/366)\u001b[K\rremote: Compressing objects:  27% (99/366)\u001b[K\rremote: Compressing objects:  28% (103/366)\u001b[K\rremote: Compressing objects:  29% (107/366)\u001b[K\rremote: Compressing objects:  30% (110/366)\u001b[K\rremote: Compressing objects:  31% (114/366)\u001b[K\rremote: Compressing objects:  32% (118/366)\u001b[K\rremote: Compressing objects:  33% (121/366)\u001b[K\rremote: Compressing objects:  34% (125/366)\u001b[K\rremote: Compressing objects:  35% (129/366)\u001b[K\rremote: Compressing objects:  36% (132/366)\u001b[K\rremote: Compressing objects:  37% (136/366)\u001b[K\rremote: Compressing objects:  38% (140/366)\u001b[K\rremote: Compressing objects:  39% (143/366)\u001b[K\rremote: Compressing objects:  40% (147/366)\u001b[K\rremote: Compressing objects:  41% (151/366)\u001b[K\rremote: Compressing objects:  42% (154/366)\u001b[K\rremote: Compressing objects:  43% (158/366)\u001b[K\rremote: Compressing objects:  44% (162/366)\u001b[K\rremote: Compressing objects:  45% (165/366)\u001b[K\rremote: Compressing objects:  46% (169/366)\u001b[K\rremote: Compressing objects:  47% (173/366)\u001b[K\rremote: Compressing objects:  48% (176/366)\u001b[K\rremote: Compressing objects:  49% (180/366)\u001b[K\rremote: Compressing objects:  50% (183/366)\u001b[K\rremote: Compressing objects:  51% (187/366)\u001b[K\rremote: Compressing objects:  52% (191/366)\u001b[K\rremote: Compressing objects:  53% (194/366)\u001b[K\rremote: Compressing objects:  54% (198/366)\u001b[K\rremote: Compressing objects:  55% (202/366)\u001b[K\rremote: Compressing objects:  56% (205/366)\u001b[K\rremote: Compressing objects:  57% (209/366)\u001b[K\rremote: Compressing objects:  58% (213/366)\u001b[K\rremote: Compressing objects:  59% (216/366)\u001b[K\rremote: Compressing objects:  60% (220/366)\u001b[K\rremote: Compressing objects:  61% (224/366)\u001b[K\rremote: Compressing objects:  62% (227/366)\u001b[K\rremote: Compressing objects:  63% (231/366)\u001b[K\rremote: Compressing objects:  64% (235/366)\u001b[K\rremote: Compressing objects:  65% (238/366)\u001b[K\rremote: Compressing objects:  66% (242/366)\u001b[K\rremote: Compressing objects:  67% (246/366)\u001b[K\rremote: Compressing objects:  68% (249/366)\u001b[K\rremote: Compressing objects:  69% (253/366)\u001b[K\rremote: Compressing objects:  70% (257/366)\u001b[K\rremote: Compressing objects:  71% (260/366)\u001b[K\rremote: Compressing objects:  72% (264/366)\u001b[K\rremote: Compressing objects:  73% (268/366)\u001b[K\rremote: Compressing objects:  74% (271/366)\u001b[K\rremote: Compressing objects:  75% (275/366)\u001b[K\rremote: Compressing objects:  76% (279/366)\u001b[K\rremote: Compressing objects:  77% (282/366)\u001b[K\rremote: Compressing objects:  78% (286/366)\u001b[K\rremote: Compressing objects:  79% (290/366)\u001b[K\rremote: Compressing objects:  80% (293/366)\u001b[K\rremote: Compressing objects:  81% (297/366)\u001b[K\rremote: Compressing objects:  82% (301/366)\u001b[K\rremote: Compressing objects:  83% (304/366)\u001b[K\rremote: Compressing objects:  84% (308/366)\u001b[K\rremote: Compressing objects:  85% (312/366)\u001b[K\rremote: Compressing objects:  86% (315/366)\u001b[K\rremote: Compressing objects:  87% (319/366)\u001b[K\rremote: Compressing objects:  88% (323/366)\u001b[K\rremote: Compressing objects:  89% (326/366)\u001b[K\rremote: Compressing objects:  90% (330/366)\u001b[K\rremote: Compressing objects:  91% (334/366)\u001b[K\rremote: Compressing objects:  92% (337/366)\u001b[K\rremote: Compressing objects:  93% (341/366)\u001b[K\rremote: Compressing objects:  94% (345/366)\u001b[K\rremote: Compressing objects:  95% (348/366)\u001b[K\rremote: Compressing objects:  96% (352/366)\u001b[K\rremote: Compressing objects:  97% (356/366)\u001b[K\rremote: Compressing objects:  98% (359/366)\u001b[K\rremote: Compressing objects:  99% (363/366)\u001b[K\rremote: Compressing objects: 100% (366/366)\u001b[K\rremote: Compressing objects: 100% (366/366), done.\u001b[K\r\nReceiving objects:   0% (1/148459)\rReceiving objects:   1% (1485/148459)\rReceiving objects:   2% (2970/148459)\rReceiving objects:   3% (4454/148459)\rReceiving objects:   4% (5939/148459)\rReceiving objects:   5% (7423/148459)\rReceiving objects:   6% (8908/148459)\rReceiving objects:   7% (10393/148459)\rReceiving objects:   8% (11877/148459)\rReceiving objects:   9% (13362/148459)\rReceiving objects:  10% (14846/148459)\rReceiving objects:  11% (16331/148459)\rReceiving objects:  12% (17816/148459)\rReceiving objects:  13% (19300/148459)\rReceiving objects:  14% (20785/148459)\rReceiving objects:  15% (22269/148459)\rReceiving objects:  16% (23754/148459)\rReceiving objects:  17% (25239/148459)\rReceiving objects:  18% (26723/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  19% (28208/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  20% (29692/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  21% (31177/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  22% (32661/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  23% (34146/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  24% (35631/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  25% (37115/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  26% (38600/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  27% (40084/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  28% (41569/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  28% (42836/148459), 14.38 MiB | 28.75 MiB/s\rReceiving objects:  29% (43054/148459), 32.10 MiB | 32.09 MiB/s\rReceiving objects:  30% (44538/148459), 32.10 MiB | 32.09 MiB/s\rReceiving objects:  31% (46023/148459), 32.10 MiB | 32.09 MiB/s\rReceiving objects:  32% (47507/148459), 32.10 MiB | 32.09 MiB/s\rReceiving objects:  33% (48992/148459), 32.10 MiB | 32.09 MiB/s\rReceiving objects:  34% (50477/148459), 32.10 MiB | 32.09 MiB/s\rReceiving objects:  35% (51961/148459), 32.10 MiB | 32.09 MiB/s\rReceiving objects:  36% (53446/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  37% (54930/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  38% (56415/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  39% (57900/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  40% (59384/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  41% (60869/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  42% (62353/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  43% (63838/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  44% (65322/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  45% (66807/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  46% (68292/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  47% (69776/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  48% (71261/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  49% (72745/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  50% (74230/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  51% (75715/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  52% (77199/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  53% (78684/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  54% (80168/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  55% (81653/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  56% (83138/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  57% (84622/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  58% (86107/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  59% (87591/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  60% (89076/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  61% (90560/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  62% (92045/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  63% (93530/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  64% (95014/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  65% (96499/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  66% (97983/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  67% (99468/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  68% (100953/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  69% (102437/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  70% (103922/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  71% (105406/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  72% (106891/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  73% (108376/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  74% (109860/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  75% (111345/148459), 47.90 MiB | 31.93 MiB/s\rReceiving objects:  75% (112747/148459), 66.85 MiB | 33.42 MiB/s\rReceiving objects:  76% (112829/148459), 76.37 MiB | 30.54 MiB/s\rReceiving objects:  77% (114314/148459), 76.37 MiB | 30.54 MiB/s\rReceiving objects:  78% (115799/148459), 76.37 MiB | 30.54 MiB/s\rReceiving objects:  78% (116759/148459), 86.62 MiB | 28.88 MiB/s\rReceiving objects:  79% (117283/148459), 86.62 MiB | 28.88 MiB/s\rReceiving objects:  80% (118768/148459), 86.62 MiB | 28.88 MiB/s\rReceiving objects:  81% (120252/148459), 86.62 MiB | 28.88 MiB/s\rReceiving objects:  82% (121737/148459), 86.62 MiB | 28.88 MiB/s\rReceiving objects:  83% (123221/148459), 86.62 MiB | 28.88 MiB/s\rReceiving objects:  84% (124706/148459), 86.62 MiB | 28.88 MiB/s\rReceiving objects:  85% (126191/148459), 86.62 MiB | 28.88 MiB/s\rReceiving objects:  86% (127675/148459), 110.88 MiB | 31.69 MiB/s\rReceiving objects:  86% (128687/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  87% (129160/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  88% (130644/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  89% (132129/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  90% (133614/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  91% (135098/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  92% (136583/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  93% (138067/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  94% (139552/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  95% (141037/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  96% (142521/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  97% (144006/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  98% (145490/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects:  99% (146975/148459), 123.91 MiB | 30.98 MiB/s\rremote: Total 148459 (delta 565), reused 797 (delta 517), pack-reused 147572 (from 1)\u001b[K\r\nReceiving objects: 100% (148459/148459), 123.91 MiB | 30.98 MiB/s\rReceiving objects: 100% (148459/148459), 129.99 MiB | 31.02 MiB/s, done.\r\nResolving deltas:   0% (0/114591)\rResolving deltas:   1% (1146/114591)\rResolving deltas:   2% (2292/114591)\rResolving deltas:   3% (3438/114591)\rResolving deltas:   4% (4584/114591)\rResolving deltas:   5% (5730/114591)\rResolving deltas:   6% (6876/114591)\rResolving deltas:   7% (8022/114591)\rResolving deltas:   8% (9168/114591)\rResolving deltas:   9% (10314/114591)\rResolving deltas:  10% (11460/114591)\rResolving deltas:  11% (12606/114591)\rResolving deltas:  12% (13751/114591)\rResolving deltas:  13% (14897/114591)\rResolving deltas:  14% (16043/114591)\rResolving deltas:  15% (17189/114591)\rResolving deltas:  16% (18335/114591)\rResolving deltas:  17% (19481/114591)\rResolving deltas:  18% (20627/114591)\rResolving deltas:  19% (21773/114591)\rResolving deltas:  20% (22919/114591)\rResolving deltas:  21% (24065/114591)\rResolving deltas:  22% (25211/114591)\rResolving deltas:  23% (26356/114591)\rResolving deltas:  24% (27502/114591)\rResolving deltas:  25% (28648/114591)\rResolving deltas:  26% (29794/114591)\rResolving deltas:  27% (30940/114591)\rResolving deltas:  28% (32086/114591)\rResolving deltas:  29% (33232/114591)\rResolving deltas:  30% (34378/114591)\rResolving deltas:  31% (35524/114591)\rResolving deltas:  32% (36670/114591)\rResolving deltas:  33% (37816/114591)\rResolving deltas:  34% (38961/114591)\rResolving deltas:  35% (40107/114591)\rResolving deltas:  36% (41253/114591)\rResolving deltas:  37% (42399/114591)\rResolving deltas:  38% (43545/114591)\rResolving deltas:  39% (44691/114591)\rResolving deltas:  40% (45837/114591)\rResolving deltas:  41% (46983/114591)\rResolving deltas:  42% (48129/114591)\rResolving deltas:  43% (49275/114591)\rResolving deltas:  44% (50421/114591)\rResolving deltas:  45% (51566/114591)\rResolving deltas:  46% (52712/114591)\rResolving deltas:  47% (53858/114591)\rResolving deltas:  48% (55004/114591)\rResolving deltas:  49% (56150/114591)\rResolving deltas:  50% (57296/114591)\rResolving deltas:  51% (58442/114591)\rResolving deltas:  52% (59588/114591)\rResolving deltas:  53% (60734/114591)\rResolving deltas:  54% (61880/114591)\rResolving deltas:  55% (63026/114591)\rResolving deltas:  55% (64000/114591)\rResolving deltas:  56% (64171/114591)\rResolving deltas:  57% (65317/114591)\rResolving deltas:  58% (66463/114591)\rResolving deltas:  59% (67609/114591)\rResolving deltas:  60% (68755/114591)\rResolving deltas:  61% (69901/114591)\rResolving deltas:  62% (71047/114591)\rResolving deltas:  63% (72193/114591)\rResolving deltas:  64% (73339/114591)\rResolving deltas:  65% (74485/114591)\rResolving deltas:  66% (75631/114591)\rResolving deltas:  67% (76776/114591)\rResolving deltas:  68% (77922/114591)\rResolving deltas:  69% (79068/114591)\rResolving deltas:  70% (80214/114591)\rResolving deltas:  71% (81360/114591)\rResolving deltas:  72% (82506/114591)\rResolving deltas:  73% (83652/114591)\rResolving deltas:  74% (84798/114591)\rResolving deltas:  75% (85944/114591)\rResolving deltas:  76% (87090/114591)\rResolving deltas:  77% (88236/114591)\rResolving deltas:  78% (89381/114591)\rResolving deltas:  79% (90527/114591)\rResolving deltas:  80% (91673/114591)\rResolving deltas:  81% (92819/114591)\rResolving deltas:  82% (93965/114591)\rResolving deltas:  83% (95111/114591)\rResolving deltas:  84% (96257/114591)\rResolving deltas:  85% (97403/114591)\rResolving deltas:  86% (98549/114591)\rResolving deltas:  87% (99695/114591)\rResolving deltas:  88% (100841/114591)\rResolving deltas:  89% (101986/114591)\rResolving deltas:  90% (103132/114591)\rResolving deltas:  91% (104278/114591)\rResolving deltas:  92% (105424/114591)\rResolving deltas:  93% (106570/114591)\rResolving deltas:  94% (107716/114591)\rResolving deltas:  95% (108862/114591)\rResolving deltas:  96% (110008/114591)\rResolving deltas:  97% (111154/114591)\rResolving deltas:  98% (112300/114591)\rResolving deltas:  99% (113446/114591)\rResolving deltas: 100% (114591/114591)\rResolving deltas: 100% (114591/114591), done.\r\nCloning Subword NMT repository (for BPE pre-processing)...\r\nCloning into 'subword-nmt'...\r\nremote: Enumerating objects: 622, done.\u001b[K\r\nremote: Counting objects:   2% (1/46)\u001b[K\rremote: Counting objects:   4% (2/46)\u001b[K\rremote: Counting objects:   6% (3/46)\u001b[K\rremote: Counting objects:   8% (4/46)\u001b[K\rremote: Counting objects:  10% (5/46)\u001b[K\rremote: Counting objects:  13% (6/46)\u001b[K\rremote: Counting objects:  15% (7/46)\u001b[K\rremote: Counting objects:  17% (8/46)\u001b[K\rremote: Counting objects:  19% (9/46)\u001b[K\rremote: Counting objects:  21% (10/46)\u001b[K\rremote: Counting objects:  23% (11/46)\u001b[K\rremote: Counting objects:  26% (12/46)\u001b[K\rremote: Counting objects:  28% (13/46)\u001b[K\rremote: Counting objects:  30% (14/46)\u001b[K\rremote: Counting objects:  32% (15/46)\u001b[K\rremote: Counting objects:  34% (16/46)\u001b[K\rremote: Counting objects:  36% (17/46)\u001b[K\rremote: Counting objects:  39% (18/46)\u001b[K\rremote: Counting objects:  41% (19/46)\u001b[K\rremote: Counting objects:  43% (20/46)\u001b[K\rremote: Counting objects:  45% (21/46)\u001b[K\rremote: Counting objects:  47% (22/46)\u001b[K\rremote: Counting objects:  50% (23/46)\u001b[K\rremote: Counting objects:  52% (24/46)\u001b[K\rremote: Counting objects:  54% (25/46)\u001b[K\rremote: Counting objects:  56% (26/46)\u001b[K\rremote: Counting objects:  58% (27/46)\u001b[K\rremote: Counting objects:  60% (28/46)\u001b[K\rremote: Counting objects:  63% (29/46)\u001b[K\rremote: Counting objects:  65% (30/46)\u001b[K\rremote: Counting objects:  67% (31/46)\u001b[K\rremote: Counting objects:  69% (32/46)\u001b[K\rremote: Counting objects:  71% (33/46)\u001b[K\rremote: Counting objects:  73% (34/46)\u001b[K\rremote: Counting objects:  76% (35/46)\u001b[K\rremote: Counting objects:  78% (36/46)\u001b[K\rremote: Counting objects:  80% (37/46)\u001b[K\rremote: Counting objects:  82% (38/46)\u001b[K\rremote: Counting objects:  84% (39/46)\u001b[K\rremote: Counting objects:  86% (40/46)\u001b[K\rremote: Counting objects:  89% (41/46)\u001b[K\rremote: Counting objects:  91% (42/46)\u001b[K\rremote: Counting objects:  93% (43/46)\u001b[K\rremote: Counting objects:  95% (44/46)\u001b[K\rremote: Counting objects:  97% (45/46)\u001b[K\rremote: Counting objects: 100% (46/46)\u001b[K\rremote: Counting objects: 100% (46/46), done.\u001b[K\r\nremote: Compressing objects:   3% (1/30)\u001b[K\rremote: Compressing objects:   6% (2/30)\u001b[K\rremote: Compressing objects:  10% (3/30)\u001b[K\rremote: Compressing objects:  13% (4/30)\u001b[K\rremote: Compressing objects:  16% (5/30)\u001b[K\rremote: Compressing objects:  20% (6/30)\u001b[K\rremote: Compressing objects:  23% (7/30)\u001b[K\rremote: Compressing objects:  26% (8/30)\u001b[K\rremote: Compressing objects:  30% (9/30)\u001b[K\rremote: Compressing objects:  33% (10/30)\u001b[K\rremote: Compressing objects:  36% (11/30)\u001b[K\rremote: Compressing objects:  40% (12/30)\u001b[K\rremote: Compressing objects:  43% (13/30)\u001b[K\rremote: Compressing objects:  46% (14/30)\u001b[K\rremote: Compressing objects:  50% (15/30)\u001b[K\rremote: Compressing objects:  53% (16/30)\u001b[K\rremote: Compressing objects:  56% (17/30)\u001b[K\rremote: Compressing objects:  60% (18/30)\u001b[K\rremote: Compressing objects:  63% (19/30)\u001b[K\rremote: Compressing objects:  66% (20/30)\u001b[K\rremote: Compressing objects:  70% (21/30)\u001b[K\rremote: Compressing objects:  73% (22/30)\u001b[K\rremote: Compressing objects:  76% (23/30)\u001b[K\rremote: Compressing objects:  80% (24/30)\u001b[K\rremote: Compressing objects:  83% (25/30)\u001b[K\rremote: Compressing objects:  86% (26/30)\u001b[K\rremote: Compressing objects:  90% (27/30)\u001b[K\rremote: Compressing objects:  93% (28/30)\u001b[K\rremote: Compressing objects:  96% (29/30)\u001b[K\rremote: Compressing objects: 100% (30/30)\u001b[K\rremote: Compressing objects: 100% (30/30), done.\u001b[K\r\nReceiving objects:   0% (1/622)\rReceiving objects:   1% (7/622)\rReceiving objects:   2% (13/622)\rReceiving objects:   3% (19/622)\rReceiving objects:   4% (25/622)\rReceiving objects:   5% (32/622)\rReceiving objects:   6% (38/622)\rReceiving objects:   7% (44/622)\rReceiving objects:   8% (50/622)\rReceiving objects:   9% (56/622)\rReceiving objects:  10% (63/622)\rReceiving objects:  11% (69/622)\rReceiving objects:  12% (75/622)\rReceiving objects:  13% (81/622)\rReceiving objects:  14% (88/622)\rReceiving objects:  15% (94/622)\rReceiving objects:  16% (100/622)\rReceiving objects:  17% (106/622)\rReceiving objects:  18% (112/622)\rReceiving objects:  19% (119/622)\rReceiving objects:  20% (125/622)\rReceiving objects:  21% (131/622)\rReceiving objects:  22% (137/622)\rReceiving objects:  23% (144/622)\rReceiving objects:  24% (150/622)\rReceiving objects:  25% (156/622)\rReceiving objects:  26% (162/622)\rReceiving objects:  27% (168/622)\rReceiving objects:  28% (175/622)\rReceiving objects:  29% (181/622)\rReceiving objects:  30% (187/622)\rReceiving objects:  31% (193/622)\rReceiving objects:  32% (200/622)\rReceiving objects:  33% (206/622)\rReceiving objects:  34% (212/622)\rReceiving objects:  35% (218/622)\rReceiving objects:  36% (224/622)\rReceiving objects:  37% (231/622)\rReceiving objects:  38% (237/622)\rReceiving objects:  39% (243/622)\rReceiving objects:  40% (249/622)\rReceiving objects:  41% (256/622)\rReceiving objects:  42% (262/622)\rReceiving objects:  43% (268/622)\rReceiving objects:  44% (274/622)\rReceiving objects:  45% (280/622)\rReceiving objects:  46% (287/622)\rReceiving objects:  47% (293/622)\rReceiving objects:  48% (299/622)\rReceiving objects:  49% (305/622)\rReceiving objects:  50% (311/622)\rReceiving objects:  51% (318/622)\rReceiving objects:  52% (324/622)\rReceiving objects:  53% (330/622)\rReceiving objects:  54% (336/622)\rReceiving objects:  55% (343/622)\rReceiving objects:  56% (349/622)\rReceiving objects:  57% (355/622)\rReceiving objects:  58% (361/622)\rReceiving objects:  59% (367/622)\rReceiving objects:  60% (374/622)\rremote: Total 622 (delta 25), reused 31 (delta 16), pack-reused 576 (from 1)\u001b[K\r\nReceiving objects:  61% (380/622)\rReceiving objects:  62% (386/622)\rReceiving objects:  63% (392/622)\rReceiving objects:  64% (399/622)\rReceiving objects:  65% (405/622)\rReceiving objects:  66% (411/622)\rReceiving objects:  67% (417/622)\rReceiving objects:  68% (423/622)\rReceiving objects:  69% (430/622)\rReceiving objects:  70% (436/622)\rReceiving objects:  71% (442/622)\rReceiving objects:  72% (448/622)\rReceiving objects:  73% (455/622)\rReceiving objects:  74% (461/622)\rReceiving objects:  75% (467/622)\rReceiving objects:  76% (473/622)\rReceiving objects:  77% (479/622)\rReceiving objects:  78% (486/622)\rReceiving objects:  79% (492/622)\rReceiving objects:  80% (498/622)\rReceiving objects:  81% (504/622)\rReceiving objects:  82% (511/622)\rReceiving objects:  83% (517/622)\rReceiving objects:  84% (523/622)\rReceiving objects:  85% (529/622)\rReceiving objects:  86% (535/622)\rReceiving objects:  87% (542/622)\rReceiving objects:  88% (548/622)\rReceiving objects:  89% (554/622)\rReceiving objects:  90% (560/622)\rReceiving objects:  91% (567/622)\rReceiving objects:  92% (573/622)\rReceiving objects:  93% (579/622)\rReceiving objects:  94% (585/622)\rReceiving objects:  95% (591/622)\rReceiving objects:  96% (598/622)\rReceiving objects:  97% (604/622)\rReceiving objects:  98% (610/622)\rReceiving objects:  99% (616/622)\rReceiving objects: 100% (622/622)\rReceiving objects: 100% (622/622), 261.27 KiB | 18.66 MiB/s, done.\r\nResolving deltas:   0% (0/374)\rResolving deltas:   1% (4/374)\rResolving deltas:   2% (8/374)\rResolving deltas:   3% (12/374)\rResolving deltas:   4% (15/374)\rResolving deltas:   5% (19/374)\rResolving deltas:   6% (23/374)\rResolving deltas:   7% (27/374)\rResolving deltas:   8% (30/374)\rResolving deltas:   9% (34/374)\rResolving deltas:  10% (38/374)\rResolving deltas:  11% (42/374)\rResolving deltas:  12% (45/374)\rResolving deltas:  13% (49/374)\rResolving deltas:  14% (53/374)\rResolving deltas:  15% (57/374)\rResolving deltas:  16% (60/374)\rResolving deltas:  17% (64/374)\rResolving deltas:  18% (68/374)\rResolving deltas:  19% (72/374)\rResolving deltas:  20% (75/374)\rResolving deltas:  21% (79/374)\rResolving deltas:  22% (83/374)\rResolving deltas:  23% (87/374)\rResolving deltas:  24% (90/374)\rResolving deltas:  25% (94/374)\rResolving deltas:  26% (98/374)\rResolving deltas:  27% (101/374)\rResolving deltas:  28% (105/374)\rResolving deltas:  29% (109/374)\rResolving deltas:  30% (113/374)\rResolving deltas:  31% (116/374)\rResolving deltas:  32% (120/374)\rResolving deltas:  33% (124/374)\rResolving deltas:  34% (128/374)\rResolving deltas:  35% (131/374)\rResolving deltas:  36% (135/374)\rResolving deltas:  37% (139/374)\rResolving deltas:  38% (143/374)\rResolving deltas:  39% (146/374)\rResolving deltas:  40% (150/374)\rResolving deltas:  41% (154/374)\rResolving deltas:  42% (158/374)\rResolving deltas:  43% (161/374)\rResolving deltas:  44% (165/374)\rResolving deltas:  45% (169/374)\rResolving deltas:  46% (173/374)\rResolving deltas:  47% (176/374)\rResolving deltas:  48% (180/374)\rResolving deltas:  49% (184/374)\rResolving deltas:  50% (187/374)\rResolving deltas:  51% (191/374)\rResolving deltas:  52% (195/374)\rResolving deltas:  53% (199/374)\rResolving deltas:  54% (202/374)\rResolving deltas:  55% (206/374)\rResolving deltas:  56% (210/374)\rResolving deltas:  57% (214/374)\rResolving deltas:  58% (217/374)\rResolving deltas:  59% (221/374)\rResolving deltas:  60% (225/374)\rResolving deltas:  61% (229/374)\rResolving deltas:  62% (232/374)\rResolving deltas:  63% (236/374)\rResolving deltas:  64% (240/374)\rResolving deltas:  65% (244/374)\rResolving deltas:  66% (247/374)\rResolving deltas:  67% (251/374)\rResolving deltas:  68% (255/374)\rResolving deltas:  69% (259/374)\rResolving deltas:  70% (262/374)\rResolving deltas:  71% (266/374)\rResolving deltas:  72% (270/374)\rResolving deltas:  73% (274/374)\rResolving deltas:  74% (277/374)\rResolving deltas:  75% (281/374)\rResolving deltas:  76% (285/374)\rResolving deltas:  77% (288/374)\rResolving deltas:  78% (292/374)\rResolving deltas:  79% (296/374)\rResolving deltas:  80% (300/374)\rResolving deltas:  81% (303/374)\rResolving deltas:  82% (307/374)\rResolving deltas:  83% (311/374)\rResolving deltas:  84% (315/374)\rResolving deltas:  85% (318/374)\rResolving deltas:  86% (322/374)\rResolving deltas:  87% (326/374)\rResolving deltas:  88% (330/374)\rResolving deltas:  89% (333/374)\rResolving deltas:  90% (337/374)\rResolving deltas:  91% (341/374)\rResolving deltas:  92% (345/374)\rResolving deltas:  93% (348/374)\rResolving deltas:  94% (352/374)\rResolving deltas:  95% (356/374)\rResolving deltas:  96% (360/374)\rResolving deltas:  97% (363/374)\rResolving deltas:  98% (367/374)\rResolving deltas:  99% (371/374)\rResolving deltas: 100% (374/374)\rResolving deltas: 100% (374/374), done.\r\nDownloading data from http://dl.fbaipublicfiles.com/fairseq/data/iwslt14/de-en.tgz...\r\n--2024-08-22 06:04:34--  http://dl.fbaipublicfiles.com/fairseq/data/iwslt14/de-en.tgz\r\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.165.83.35, 18.165.83.44, 18.165.83.91, ...\r\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.165.83.35|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 19982877 (19M) [application/x-tar]\r\nSaving to: ‘de-en.tgz’\r\n\r\n\rde-en.tgz             0%[                    ]       0  --.-KB/s               \rde-en.tgz           100%[===================>]  19.06M  --.-KB/s    in 0.1s    \r\n\r\n2024-08-22 06:04:34 (187 MB/s) - ‘de-en.tgz’ saved [19982877/19982877]\r\n\r\nData successfully downloaded.\r\nde-en/\r\nde-en/IWSLT14.TED.dev2010.de-en.de.xml\r\nde-en/IWSLT14.TED.dev2010.de-en.en.xml\r\nde-en/IWSLT14.TED.tst2010.de-en.de.xml\r\nde-en/IWSLT14.TED.tst2010.de-en.en.xml\r\nde-en/IWSLT14.TED.tst2011.de-en.de.xml\r\nde-en/IWSLT14.TED.tst2011.de-en.en.xml\r\nde-en/IWSLT14.TED.tst2012.de-en.de.xml\r\nde-en/IWSLT14.TED.tst2012.de-en.en.xml\r\nde-en/IWSLT14.TEDX.dev2012.de-en.de.xml\r\nde-en/IWSLT14.TEDX.dev2012.de-en.en.xml\r\nde-en/README\r\nde-en/train.en\r\nde-en/train.tags.de-en.de\r\nde-en/train.tags.de-en.en\r\npre-processing train data...\r\nTokenizer Version 1.1\r\nLanguage: de\r\nNumber of threads: 8\r\n\r\nTokenizer Version 1.1\r\nLanguage: en\r\nNumber of threads: 8\r\n\r\nclean-corpus.perl: processing iwslt14.tokenized.de-en/tmp/train.tags.de-en.tok.de & .en to iwslt14.tokenized.de-en/tmp/train.tags.de-en.clean, cutoff 1-175, ratio 1.5\r\n..........(100000).......\r\nInput sentences: 174443  Output sentences:  167522\r\npre-processing valid/test data...\r\norig/de-en/IWSLT14.TED.dev2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.de\r\nTokenizer Version 1.1\r\nLanguage: de\r\nNumber of threads: 8\r\n\r\norig/de-en/IWSLT14.TED.tst2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.de\r\nTokenizer Version 1.1\r\nLanguage: de\r\nNumber of threads: 8\r\n\r\norig/de-en/IWSLT14.TED.tst2011.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.de\r\nTokenizer Version 1.1\r\nLanguage: de\r\nNumber of threads: 8\r\n\r\norig/de-en/IWSLT14.TED.tst2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.de\r\nTokenizer Version 1.1\r\nLanguage: de\r\nNumber of threads: 8\r\n\r\norig/de-en/IWSLT14.TEDX.dev2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.de\r\nTokenizer Version 1.1\r\nLanguage: de\r\nNumber of threads: 8\r\n\r\norig/de-en/IWSLT14.TED.dev2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.en\r\nTokenizer Version 1.1\r\nLanguage: en\r\nNumber of threads: 8\r\n\r\norig/de-en/IWSLT14.TED.tst2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.en\r\nTokenizer Version 1.1\r\nLanguage: en\r\nNumber of threads: 8\r\n\r\norig/de-en/IWSLT14.TED.tst2011.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.en\r\nTokenizer Version 1.1\r\nLanguage: en\r\nNumber of threads: 8\r\n\r\norig/de-en/IWSLT14.TED.tst2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.en\r\nTokenizer Version 1.1\r\nLanguage: en\r\nNumber of threads: 8\r\n\r\norig/de-en/IWSLT14.TEDX.dev2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.en\r\nTokenizer Version 1.1\r\nLanguage: en\r\nNumber of threads: 8\r\n\r\ncreating train, valid, test...\r\nlearn_bpe.py on iwslt14.tokenized.de-en/tmp/train.en-de...\r\n\r  0%|                                                 | 0/10000 [00:00<?, ?it/s]\r  0%|                                         | 1/10000 [00:00<21:58,  7.58it/s]\r  0%|                                         | 3/10000 [00:00<16:11, 10.29it/s]\r  0%|                                         | 5/10000 [00:00<21:30,  7.75it/s]\r  0%|                                         | 6/10000 [00:00<24:26,  6.82it/s]\r  0%|                                         | 8/10000 [00:01<20:59,  7.93it/s]\r  0%|                                         | 9/10000 [00:01<20:00,  8.32it/s]\r  0%|                                        | 11/10000 [00:01<16:14, 10.25it/s]\r  0%|                                        | 13/10000 [00:01<14:30, 11.48it/s]\r  0%|                                        | 15/10000 [00:01<12:42, 13.09it/s]\r  0%|                                        | 18/10000 [00:01<10:35, 15.70it/s]\r  0%|                                        | 20/10000 [00:01<12:25, 13.39it/s]\r  0%|1                                       | 25/10000 [00:01<08:08, 20.40it/s]\r  0%|1                                       | 28/10000 [00:02<07:34, 21.92it/s]\r  0%|1                                       | 31/10000 [00:02<07:38, 21.76it/s]\r  0%|1                                       | 37/10000 [00:02<05:25, 30.58it/s]\r  0%|1                                       | 48/10000 [00:02<03:26, 48.31it/s]\r  1%|2                                       | 54/10000 [00:02<04:39, 35.54it/s]\r  1%|2                                       | 59/10000 [00:02<04:48, 34.51it/s]\r  1%|2                                       | 65/10000 [00:02<04:19, 38.22it/s]\r  1%|2                                       | 73/10000 [00:03<03:36, 45.83it/s]\r  1%|3                                       | 81/10000 [00:03<03:15, 50.77it/s]\r  1%|3                                       | 91/10000 [00:03<02:48, 58.87it/s]\r  1%|4                                      | 104/10000 [00:03<02:13, 73.99it/s]\r  1%|4                                      | 112/10000 [00:03<02:17, 71.94it/s]\r  1%|4                                      | 120/10000 [00:03<02:31, 65.30it/s]\r  1%|4                                      | 127/10000 [00:03<02:30, 65.54it/s]\r  1%|5                                      | 136/10000 [00:03<02:17, 71.63it/s]\r  2%|6                                      | 154/10000 [00:04<01:38, 99.82it/s]\r  2%|6                                     | 171/10000 [00:04<01:24, 116.65it/s]\r  2%|6                                     | 184/10000 [00:04<01:22, 119.46it/s]\r  2%|7                                     | 198/10000 [00:04<01:20, 121.47it/s]\r  2%|8                                     | 214/10000 [00:04<01:15, 130.19it/s]\r  2%|8                                     | 229/10000 [00:04<01:12, 134.59it/s]\r  2%|9                                     | 244/10000 [00:04<01:11, 136.93it/s]\r  3%|9                                     | 262/10000 [00:04<01:06, 147.39it/s]\r  3%|#                                     | 277/10000 [00:04<01:05, 147.97it/s]\r  3%|#1                                    | 294/10000 [00:04<01:03, 153.69it/s]\r  3%|#1                                    | 311/10000 [00:05<01:01, 157.70it/s]\r  3%|#2                                    | 331/10000 [00:05<00:58, 163.94it/s]\r  3%|#3                                    | 348/10000 [00:05<01:06, 145.96it/s]\r  4%|#3                                    | 363/10000 [00:05<01:06, 145.54it/s]\r  4%|#4                                    | 378/10000 [00:05<01:06, 144.32it/s]\r  4%|#5                                    | 397/10000 [00:05<01:01, 156.17it/s]\r  4%|#6                                    | 430/10000 [00:05<00:46, 204.39it/s]\r  5%|#7                                    | 459/10000 [00:05<00:42, 226.08it/s]\r  5%|#8                                    | 486/10000 [00:05<00:40, 237.46it/s]\r  5%|#9                                    | 515/10000 [00:06<00:37, 251.87it/s]\r  5%|##                                    | 541/10000 [00:06<00:38, 248.57it/s]\r  6%|##1                                   | 570/10000 [00:06<00:37, 254.62it/s]\r  6%|##2                                   | 597/10000 [00:06<00:36, 257.85it/s]\r  6%|##4                                   | 635/10000 [00:06<00:32, 292.55it/s]\r  7%|##5                                   | 668/10000 [00:06<00:30, 303.32it/s]\r  7%|##6                                   | 699/10000 [00:06<00:36, 256.11it/s]\r  7%|##7                                   | 732/10000 [00:06<00:33, 274.18it/s]\r  8%|##9                                   | 770/10000 [00:06<00:30, 302.39it/s]\r  8%|###                                   | 802/10000 [00:07<00:31, 288.35it/s]\r  8%|###2                                  | 844/10000 [00:07<00:28, 323.58it/s]\r  9%|###3                                  | 885/10000 [00:07<00:26, 347.61it/s]\r  9%|###5                                  | 926/10000 [00:07<00:25, 360.70it/s]\r 10%|###6                                  | 971/10000 [00:07<00:23, 385.44it/s]\r 10%|###7                                 | 1011/10000 [00:07<00:23, 386.05it/s]\r 11%|###9                                 | 1061/10000 [00:07<00:21, 418.54it/s]\r 11%|####                                 | 1104/10000 [00:07<00:25, 349.02it/s]\r 12%|####3                                | 1164/10000 [00:07<00:21, 412.52it/s]\r 12%|####4                                | 1208/10000 [00:08<00:21, 402.70it/s]\r 13%|####6                                | 1258/10000 [00:08<00:20, 428.76it/s]\r 13%|####8                                | 1303/10000 [00:08<00:20, 429.40it/s]\r 14%|#####                                | 1365/10000 [00:08<00:17, 479.83it/s]\r 14%|#####2                               | 1415/10000 [00:08<00:17, 483.47it/s]\r 15%|#####4                               | 1474/10000 [00:08<00:16, 512.92it/s]\r 15%|#####6                               | 1526/10000 [00:08<00:16, 507.22it/s]\r 16%|#####8                               | 1578/10000 [00:08<00:16, 509.80it/s]\r 16%|######                               | 1635/10000 [00:08<00:15, 526.07it/s]\r 17%|######2                              | 1690/10000 [00:08<00:15, 532.16it/s]\r 17%|######4                              | 1744/10000 [00:09<00:17, 476.19it/s]\r 18%|######6                              | 1805/10000 [00:09<00:16, 511.71it/s]\r 19%|######9                              | 1876/10000 [00:09<00:14, 562.80it/s]\r 19%|#######1                             | 1945/10000 [00:09<00:13, 598.13it/s]\r 20%|#######4                             | 2006/10000 [00:09<00:13, 589.58it/s]\r 21%|#######7                             | 2087/10000 [00:09<00:12, 649.30it/s]\r 22%|########                             | 2164/10000 [00:09<00:11, 681.76it/s]\r 22%|########2                            | 2233/10000 [00:09<00:11, 668.42it/s]\r 23%|########5                            | 2301/10000 [00:09<00:11, 662.39it/s]\r 24%|########8                            | 2393/10000 [00:10<00:10, 734.72it/s]\r 25%|#########1                           | 2483/10000 [00:10<00:09, 782.47it/s]\r 26%|#########4                           | 2562/10000 [00:10<00:09, 782.06it/s]\r 26%|#########7                           | 2644/10000 [00:10<00:09, 791.80it/s]\r 27%|##########                           | 2724/10000 [00:10<00:11, 660.30it/s]\r 28%|##########3                          | 2801/10000 [00:10<00:10, 679.13it/s]\r 29%|##########7                          | 2897/10000 [00:10<00:09, 754.00it/s]\r 30%|###########                          | 2999/10000 [00:10<00:08, 825.95it/s]\r 31%|###########5                         | 3111/10000 [00:10<00:07, 906.27it/s]\r 32%|###########6                        | 3235/10000 [00:11<00:06, 1001.02it/s]\r 34%|############                        | 3354/10000 [00:11<00:06, 1055.48it/s]\r 35%|############5                       | 3473/10000 [00:11<00:05, 1094.19it/s]\r 36%|############9                       | 3596/10000 [00:11<00:05, 1131.98it/s]\r 37%|#############4                      | 3749/10000 [00:11<00:05, 1244.74it/s]\r 39%|##############                      | 3894/10000 [00:11<00:04, 1305.30it/s]\r 40%|##############8                      | 4026/10000 [00:12<00:11, 510.02it/s]\r 41%|###############2                     | 4125/10000 [00:12<00:11, 499.11it/s]\r 42%|###############5                     | 4208/10000 [00:12<00:11, 483.87it/s]\r 43%|###############8                     | 4280/10000 [00:12<00:11, 486.26it/s]\r 43%|################                     | 4345/10000 [00:12<00:13, 407.02it/s]\r 44%|################2                    | 4398/10000 [00:13<00:13, 414.63it/s]\r 44%|################4                    | 4449/10000 [00:13<00:12, 430.30it/s]\r 45%|################6                    | 4500/10000 [00:13<00:12, 426.41it/s]\r 45%|################8                    | 4548/10000 [00:13<00:12, 434.88it/s]\r 46%|#################                    | 4596/10000 [00:13<00:12, 425.57it/s]\r 46%|#################1                   | 4646/10000 [00:13<00:12, 442.47it/s]\r 47%|#################3                   | 4694/10000 [00:13<00:11, 451.58it/s]\r 47%|#################5                   | 4747/10000 [00:13<00:11, 472.57it/s]\r 48%|#################7                   | 4798/10000 [00:13<00:10, 482.51it/s]\r 49%|#################9                   | 4853/10000 [00:14<00:10, 501.31it/s]\r 49%|##################1                  | 4904/10000 [00:14<00:10, 497.24it/s]\r 50%|##################3                  | 4963/10000 [00:14<00:09, 523.85it/s]\r 50%|##################5                  | 5016/10000 [00:14<00:09, 522.44it/s]\r 51%|##################7                  | 5075/10000 [00:14<00:09, 539.50it/s]\r 51%|##################9                  | 5130/10000 [00:14<00:08, 541.58it/s]\r 52%|###################1                 | 5188/10000 [00:14<00:08, 550.81it/s]\r 52%|###################4                 | 5249/10000 [00:14<00:08, 567.83it/s]\r 53%|###################6                 | 5306/10000 [00:14<00:08, 560.55it/s]\r 54%|###################8                 | 5372/10000 [00:14<00:07, 588.42it/s]\r 54%|####################1                | 5436/10000 [00:15<00:07, 603.32it/s]\r 55%|####################3                | 5503/10000 [00:15<00:07, 622.78it/s]\r 56%|####################6                | 5586/10000 [00:15<00:06, 682.20it/s]\r 57%|####################9                | 5665/10000 [00:15<00:06, 713.10it/s]\r 57%|#####################2               | 5744/10000 [00:15<00:05, 735.53it/s]\r 58%|#####################5               | 5822/10000 [00:15<00:05, 747.22it/s]\r 59%|#####################8               | 5902/10000 [00:15<00:05, 761.50it/s]\r 60%|######################1              | 5995/10000 [00:15<00:04, 806.92it/s]\r 61%|######################4              | 6079/10000 [00:15<00:04, 816.67it/s]\r 62%|######################8              | 6163/10000 [00:15<00:04, 822.64it/s]\r 63%|#######################1             | 6255/10000 [00:16<00:04, 849.55it/s]\r 63%|#######################4             | 6349/10000 [00:16<00:04, 875.10it/s]\r 64%|#######################8             | 6438/10000 [00:16<00:04, 877.77it/s]\r 65%|########################1            | 6535/10000 [00:16<00:03, 902.62it/s]\r 66%|########################5            | 6634/10000 [00:16<00:03, 927.33it/s]\r 67%|########################9            | 6730/10000 [00:16<00:03, 936.02it/s]\r 68%|#########################2           | 6826/10000 [00:16<00:03, 942.56it/s]\r 69%|#########################6           | 6930/10000 [00:16<00:03, 970.27it/s]\r 70%|##########################           | 7034/10000 [00:16<00:02, 989.15it/s]\r 71%|##########################3          | 7133/10000 [00:17<00:04, 703.88it/s]\r 72%|##########################8          | 7247/10000 [00:17<00:03, 805.30it/s]\r 74%|###########################2         | 7365/10000 [00:17<00:02, 898.05it/s]\r 75%|###########################6         | 7486/10000 [00:17<00:02, 979.07it/s]\r 76%|###########################4        | 7621/10000 [00:17<00:02, 1078.31it/s]\r 78%|###########################9        | 7756/10000 [00:17<00:01, 1152.49it/s]\r 79%|############################4       | 7891/10000 [00:17<00:01, 1208.32it/s]\r 80%|############################9       | 8034/10000 [00:17<00:01, 1271.23it/s]\r 82%|#############################4      | 8192/10000 [00:17<00:01, 1358.35it/s]\r 84%|##############################      | 8361/10000 [00:18<00:01, 1454.37it/s]\r 85%|##############################7     | 8538/10000 [00:18<00:00, 1546.08it/s]\r 87%|###############################4    | 8729/10000 [00:18<00:00, 1653.68it/s]\r 90%|################################2   | 8954/10000 [00:18<00:00, 1829.48it/s]\r 92%|#################################1  | 9222/10000 [00:18<00:00, 2082.27it/s]\r 95%|###################################  | 9474/10000 [00:19<00:00, 731.30it/s]\r 96%|###################################6 | 9630/10000 [00:19<00:00, 674.10it/s]\r 98%|#################################### | 9756/10000 [00:19<00:00, 644.46it/s]\r 99%|####################################4| 9861/10000 [00:19<00:00, 618.82it/s]\r100%|####################################8| 9950/10000 [00:20<00:00, 601.98it/s]\r100%|####################################| 10000/10000 [00:20<00:00, 496.13it/s]\r\napply_bpe.py to train.de...\r\napply_bpe.py to valid.de...\r\napply_bpe.py to test.de...\r\napply_bpe.py to train.en...\r\napply_bpe.py to valid.en...\r\napply_bpe.py to test.en...\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/Align-to-Distill/examples/translation/\n",
    "!bash prepare-iwslt14.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a91dad",
   "metadata": {},
   "source": [
    "### Step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c4bf7",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb52e1",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee950be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill/examples/translation/iwslt14.tokenized.de-en\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/Align-to-Distill/examples/translation/iwslt14.tokenized.de-en/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c91a39",
   "metadata": {},
   "source": [
    "### Step 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e5a13",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c1156",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1473a414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001 code\n6750 test.de\n6750 test.en\n160239 train.de\n160239 train.en\n7283 valid.de\n7283 valid.en\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "# print the number of lines\n",
    "for file in *\n",
    "do\n",
    "  # Check if it is a file\n",
    "  if [ -f \"$file\" ]; then\n",
    "    # Print the number of lines\n",
    "    wc -l \"$file\"\n",
    "  fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1106e65b",
   "metadata": {},
   "source": [
    "### Step 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2fe477",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf92fe",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02b08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and it can be a very complicated thing , what human health is .\r\nand bringing those two together might seem a very da@@ un@@ ting task , but what i &apos;m going to try to say is that even in that complexity , there &apos;s some simple the@@ mes that i think , if we understand , we can really move forward .\r\nund was menschliche gesundheit ist , kann auch ziemlich kompliziert sein .\r\nund diese zwei zusammen zu bringen , erscheint vielleicht wie eine gewal@@ tige aufgabe . aber was ich ihnen zu sagen versuche ist , dass es trotz dieser komplexität einige einfache themen gibt , von denen ich denke , wenn wir diese verstehen , können wir uns wirklich weiter entwickeln .\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example parallel sentence\n",
    "!head -2 train.en\n",
    "!head -2 train.de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e4c2d",
   "metadata": {},
   "source": [
    "### Step 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0246c4",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45236246",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a3c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Extract First 10 Sentences Each\n",
    "# From each dataset, use only the first 10 sentences each!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f4bc3c",
   "metadata": {},
   "source": [
    "### Step 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291d8fb",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245cf1df",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46cae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10 train10.en\r\n10 test10.en\r\n10 valid10.en\r\n10 train10.de\r\n10 test10.de\r\n10 valid10.de\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!head -10 train.en > train10.en\n",
    "!head -10 test.en > test10.en\n",
    "!head -10 valid.en > valid10.en\n",
    "!head -10 train.de > train10.de\n",
    "!head -10 test.de > test10.de\n",
    "!head -10 valid.de > valid10.de\n",
    "\n",
    "!wc -l train10.en\n",
    "!wc -l test10.en\n",
    "!wc -l valid10.en\n",
    "!wc -l train10.de\n",
    "!wc -l test10.de\n",
    "!wc -l valid10.de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7363c452",
   "metadata": {},
   "source": [
    "### Step 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b313fb",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a850f",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3969e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move these files to data/de-en\n",
    "!mkdir -p /content/Align-to-Distill/data/de-en\n",
    "!mv *.en /content/Align-to-Distill/data/de-en\n",
    "!mv *.de /content/Align-to-Distill/data/de-en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e36dbdb",
   "metadata": {},
   "source": [
    "### Step 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf58e98e",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f6507",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78814a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Preprocess/binarize the data\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b0dc02",
   "metadata": {},
   "source": [
    "### Step 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc63a26",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3540417",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09373290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Be in the root directory\n",
    "# %cd /content/Align-to-Distill/\n",
    "%cd /content/Align-to-Distill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebfaae",
   "metadata": {},
   "source": [
    "### Step 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe4873b",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda22ae",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5c31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 06:05:35 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\nTraceback (most recent call last):\n  File \"/content/Align-to-Distill/fairseq_cli/preprocess.py\", line 21, in <module>\n    from fairseq import options, tasks, utils\n  File \"/content/Align-to-Distill/fairseq/__init__.py\", line 36, in <module>\n    import fairseq.criterions  # noqa\n  File \"/content/Align-to-Distill/fairseq/criterions/__init__.py\", line 39, in <module>\n    importlib.import_module(\"fairseq.criterions.\" + file_name)\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/content/Align-to-Distill/fairseq/criterions/ctc.py\", line 22, in <module>\n    from fairseq.tasks import FairseqTask\n  File \"/content/Align-to-Distill/fairseq/tasks/__init__.py\", line 139, in <module>\n    import_tasks(tasks_dir, \"fairseq.tasks\")\n  File \"/content/Align-to-Distill/fairseq/tasks/__init__.py\", line 120, in import_tasks\n    importlib.import_module(namespace + \".\" + task_name)\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/content/Align-to-Distill/fairseq/tasks/multilingual_translation.py\", line 23, in <module>\n    from fairseq.models import FairseqMultiModel\n  File \"/content/Align-to-Distill/fairseq/models/__init__.py\", line 238, in <module>\n    import_models(models_dir, \"fairseq.models\")\n  File \"/content/Align-to-Distill/fairseq/models/__init__.py\", line 220, in import_models\n    importlib.import_module(namespace + \".\" + model_name)\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/content/Align-to-Distill/fairseq/models/bart/__init__.py\", line 10, in <module>\n    from .model import *  # noqa\n  File \"/content/Align-to-Distill/fairseq/models/bart/model.py\", line 20, in <module>\n    from fairseq.models.transformer import TransformerModel\n  File \"/content/Align-to-Distill/fairseq/models/transformer/__init__.py\", line 16, in <module>\n    from .transformer_decoder import TransformerDecoder, TransformerDecoderBase, Linear\n  File \"/content/Align-to-Distill/fairseq/models/transformer/transformer_decoder.py\", line 19, in <module>\n    from fairseq.modules import (\n  File \"/content/Align-to-Distill/fairseq/modules/__init__.py\", line 37, in <module>\n    from .multihead_attention import MultiheadAttention\n  File \"/content/Align-to-Distill/fairseq/modules/multihead_attention.py\", line 8, in <module>\n    from einops import rearrange\nModuleNotFoundError: No module named 'einops'\nError: CalledProcessError: Command 'b'DATA_DIR=data/de-en\\nrm -rf data-bin/\\n# Add current directory to path\\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\\n\\npython fairseq_cli/preprocess.py --source-lang de --target-lang en \\\\\\n    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\\\\n    --destdir data-bin/ \\\\\\n    --cpu\\n'' returned non-zero exit status 1.\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDATA_DIR=data/de-en\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mrm -rf data-bin/\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Add current directory to path\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mexport PYTHONPATH=$PYTHONPATH:$(pwd)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mpython fairseq_cli/preprocess.py --source-lang de --target-lang en \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --destdir data-bin/ \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --cpu\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\nFile \u001b[0;32m/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\nFile \u001b[0;32m/usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\nFile \u001b[0;32m/usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'DATA_DIR=data/de-en\\nrm -rf data-bin/\\n# Add current directory to path\\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\\n\\npython fairseq_cli/preprocess.py --source-lang de --target-lang en \\\\\\n    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\\\\n    --destdir data-bin/ \\\\\\n    --cpu\\n'' returned non-zero exit status 1."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=data/de-en\n",
    "rm -rf data-bin/\n",
    "# Add current directory to path\n",
    "export PYTHONPATH=$PYTHONPATH:$(pwd)\n",
    "\n",
    "python fairseq_cli/preprocess.py --source-lang de --target-lang en \\\n",
    "    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\n",
    "    --destdir data-bin/ \\\n",
    "    --cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbacbab",
   "metadata": {},
   "source": [
    "### Step 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae46a7c7",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60b95bb",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015305f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/Align-to-Distill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c7748",
   "metadata": {},
   "source": [
    "### Step 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f6f8d",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3fb36",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b445eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Training a Teacher Model\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553646c9",
   "metadata": {},
   "source": [
    "### Step 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17971b",
   "metadata": {},
   "source": [
    "Execution Start time: 06:05:39, End time: 06:05:46 (duration: 6 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df5143",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aef529",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416ff72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 06:05:42 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n2024-08-22 06:05:44 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': True, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'custom/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 0, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'data/de-en/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=True, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='custom/', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=1, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=1, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_teacher', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='data/de-en/ckpt', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='data-bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, alignment_module=True, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_layers=6, encoder_attention_heads=4, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_teacher'), 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\nTraceback (most recent call last):\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 599, in <module>\n    cli_main()\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 592, in cli_main\n    distributed_utils.call_main(cfg, main)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/distributed/utils.py\", line 369, in call_main\n    main(cfg, **kwargs)\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 92, in main\n    task = tasks.setup_task(cfg.task)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/tasks/__init__.py\", line 46, in setup_task\n    return task.setup_task(cfg, **kwargs)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/tasks/translation.py\", line 301, in setup_task\n    cfg.source_lang, cfg.target_lang = data_utils.infer_language_pair(paths[0])\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/data/data_utils.py\", line 30, in infer_language_pair\n    for filename in PathManager.ls(path):\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/file_io.py\", line 100, in ls\n    return os.listdir(path)\nFileNotFoundError: [Errno 2] No such file or directory: 'data-bin'\nError: CalledProcessError: Command 'b'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n'' returned non-zero exit status 1.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[52], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n')\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n'' returned non-zero exit status 1."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --arch transformer_teacher --share-decoder-input-output-embed \\\n",
    "    --user-dir custom/ --cpu \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67458ac",
   "metadata": {},
   "source": [
    "### Step 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2784cd",
   "metadata": {},
   "source": [
    "Execution Start time: 06:05:48, End time: 06:05:48 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1804fe7",
   "metadata": {},
   "source": [
    "**Thought**: It seems there was an error because the `data-bin` directory was not found. This likely happened because the preprocessing step failed earlier. Let's go back and ensure the preprocessing step is completed successfully before proceeding with training the teacher model.\n",
    "\n",
    "I'll navigate to the directory where the data is located and attempt to preprocess it again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e022d7a8",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db501db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill/examples/translation/iwslt14.tokenized.de-en\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/Align-to-Distill/examples/translation/iwslt14.tokenized.de-en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50613df1",
   "metadata": {},
   "source": [
    "### Step 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685dfd6e",
   "metadata": {},
   "source": [
    "Execution Start time: 06:05:49, End time: 06:05:49 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a4ffe7",
   "metadata": {},
   "source": [
    "**Thought**: Let's check the contents of the directory to ensure that the necessary files are present for preprocessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f9d780",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166de68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code  tmp/\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54598895",
   "metadata": {},
   "source": [
    "### Step 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354422b",
   "metadata": {},
   "source": [
    "Execution Start time: 06:05:50, End time: 06:05:51 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f38d992",
   "metadata": {},
   "source": [
    "**Thought**: It seems that the files were moved to the `data/de-en` directory. Let's navigate to that directory and verify the files are there before attempting preprocessing again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d88d4f",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05de54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill/data/de-en\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/Align-to-Distill/data/de-en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284cda4",
   "metadata": {},
   "source": [
    "### Step 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682bf52",
   "metadata": {},
   "source": [
    "Execution Start time: 06:05:52, End time: 06:05:52 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de5b7c",
   "metadata": {},
   "source": [
    "**Thought**: Let's list the contents of the `data/de-en` directory to ensure that the necessary files for preprocessing are present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af8fea",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b37e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ckpt/    test.en    test10.en  train.en    train10.en  valid.en    valid10.en\ntest.de  test10.de  train.de   train10.de  valid.de    valid10.de\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd79ae13",
   "metadata": {},
   "source": [
    "### Step 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66463367",
   "metadata": {},
   "source": [
    "Execution Start time: 06:05:54, End time: 06:05:54 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc04f1b",
   "metadata": {},
   "source": [
    "**Thought**: The necessary files are present in the `data/de-en` directory. Let's attempt to preprocess the data again using the correct paths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44970bc",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e999fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/Align-to-Distill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72397004",
   "metadata": {},
   "source": [
    "### Step 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a3e66",
   "metadata": {},
   "source": [
    "Execution Start time: 06:05:56, End time: 06:06:00 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040948d4",
   "metadata": {},
   "source": [
    "**Thought**: Now that we are in the root directory, let's preprocess the data using the correct paths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6c248",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5850a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 06:05:58 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=True, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='de', target_lang='en', trainpref='data/de-en/train10', validpref='data/de-en/valid10', testpref='data/de-en/test10', align_suffix=None, destdir='data-bin/', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=1, dict_only=False)\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [de] Dictionary: 128 types\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [de] data/de-en/train10.de: 10 sents, 207 tokens, 0.0% replaced (by <unk>)\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [de] Dictionary: 128 types\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [de] data/de-en/valid10.de: 10 sents, 174 tokens, 60.9% replaced (by <unk>)\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [de] Dictionary: 128 types\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [de] data/de-en/test10.de: 10 sents, 494 tokens, 63.6% replaced (by <unk>)\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [en] Dictionary: 120 types\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [en] data/de-en/train10.en: 10 sents, 234 tokens, 0.0% replaced (by <unk>)\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [en] Dictionary: 120 types\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [en] data/de-en/valid10.en: 10 sents, 175 tokens, 54.9% replaced (by <unk>)\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [en] Dictionary: 120 types\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | [en] data/de-en/test10.en: 10 sents, 474 tokens, 53.6% replaced (by <unk>)\n2024-08-22 06:05:59 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python fairseq_cli/preprocess.py --source-lang de --target-lang en \\\n",
    "    --trainpref data/de-en/train10 --validpref data/de-en/valid10 --testpref data/de-en/test10 \\\n",
    "    --destdir data-bin/ \\\n",
    "    --cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbacb6b",
   "metadata": {},
   "source": [
    "### Step 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac1e479",
   "metadata": {},
   "source": [
    "Execution Start time: 06:06:05, End time: 06:06:11 (duration: 6 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca2425c",
   "metadata": {},
   "source": [
    "**Thought**: The preprocessing step has completed successfully, and the preprocessed data has been written to the `data-bin/` directory. Now, let's proceed with training the teacher model using the preprocessed data.\n",
    "\n",
    "I'll run the training command for the teacher model again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cdade7",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ebd18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 06:06:07 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n2024-08-22 06:06:09 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': True, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'custom/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 0, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'data/de-en/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=True, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='custom/', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=1, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=1, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_teacher', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='data/de-en/ckpt', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='data-bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, alignment_module=True, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_layers=6, encoder_attention_heads=4, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_teacher'), 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n2024-08-22 06:06:09 | INFO | fairseq.tasks.translation | [de] dictionary: 128 types\n2024-08-22 06:06:09 | INFO | fairseq.tasks.translation | [en] dictionary: 120 types\nTraceback (most recent call last):\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/data/encoders/moses_tokenizer.py\", line 31, in __init__\n    from sacremoses import MosesTokenizer, MosesDetokenizer\nModuleNotFoundError: No module named 'sacremoses'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 599, in <module>\n    cli_main()\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 592, in cli_main\n    distributed_utils.call_main(cfg, main)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/distributed/utils.py\", line 369, in call_main\n    main(cfg, **kwargs)\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 98, in main\n    model = task.build_model(cfg.model)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/tasks/translation.py\", line 372, in build_model\n    self.tokenizer = encoders.build_tokenizer(\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/registry.py\", line 61, in build_x\n    return builder(cfg, *extra_args, **extra_kwargs)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/data/encoders/moses_tokenizer.py\", line 36, in __init__\n    raise ImportError(\nImportError: Please install Moses tokenizer with: pip install sacremoses\nError: CalledProcessError: Command 'b'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n'' returned non-zero exit status 1.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[66], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n')\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n'' returned non-zero exit status 1."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --arch transformer_teacher --share-decoder-input-output-embed \\\n",
    "    --user-dir custom/ --cpu \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980eab84",
   "metadata": {},
   "source": [
    "### Step 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea407f8",
   "metadata": {},
   "source": [
    "Execution Start time: 06:06:13, End time: 06:06:16 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaac1657",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `sacremoses` package is missing, which is required for the Moses tokenizer. Let's install the `sacremoses` package and then retry training the teacher model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa57f7e",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173fd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/site-packages (from sacremoses) (2023.12.25)\nRequirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from sacremoses) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from sacremoses) (1.4.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from sacremoses) (4.66.4)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/897.5 kB ? eta -:--:--\n\n\u001b[?25hDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\nInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e733767",
   "metadata": {},
   "source": [
    "### Step 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fee22f",
   "metadata": {},
   "source": [
    "Execution Start time: 06:06:22, End time: 06:06:43 (duration: 21 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba516f6",
   "metadata": {},
   "source": [
    "**Thought**: The `sacremoses` package has been successfully installed. Let's retry training the teacher model now that the required package is available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef0449",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e850939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 06:06:24 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n2024-08-22 06:06:27 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': True, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'custom/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 0, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'data/de-en/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=True, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='custom/', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=1, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=1, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_teacher', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='data/de-en/ckpt', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='data-bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, alignment_module=True, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_layers=6, encoder_attention_heads=4, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_teacher'), 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n2024-08-22 06:06:27 | INFO | fairseq.tasks.translation | [de] dictionary: 128 types\n2024-08-22 06:06:27 | INFO | fairseq.tasks.translation | [en] dictionary: 120 types\n2024-08-22 06:06:27 | INFO | fairseq_cli.train | TransformerModel(\n  (encoder): TransformerEncoderBase(\n    (dropout_module): FairseqDropout()\n    (embed_tokens): Embedding(128, 512, padding_idx=1)\n    (embed_positions): SinusoidalPositionalEmbedding()\n    (layers): ModuleList(\n      (0-5): 6 x TransformerEncoderLayerBase(\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n        (dropout_module): FairseqDropout()\n        (activation_dropout_module): FairseqDropout()\n      )\n    )\n  )\n  (decoder): TransformerDecoderBase(\n    (dropout_module): FairseqDropout()\n    (embed_tokens): Embedding(120, 512, padding_idx=1)\n    (embed_positions): SinusoidalPositionalEmbedding()\n    (layers): ModuleList(\n      (0-5): 6 x TransformerDecoderLayerBase(\n        (dropout_module): FairseqDropout()\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n        (activation_dropout_module): FairseqDropout()\n        (encoder_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n      )\n    )\n  )\n)\n2024-08-22 06:06:27 | INFO | fairseq_cli.train | task: TranslationTask\n2024-08-22 06:06:27 | INFO | fairseq_cli.train | model: TransformerModel\n2024-08-22 06:06:27 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n2024-08-22 06:06:27 | INFO | fairseq_cli.train | num. shared model params: 44,274,688 (num. trained: 44,274,688)\n2024-08-22 06:06:27 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n2024-08-22 06:06:27 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/valid.de-en.de\n2024-08-22 06:06:27 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/valid.de-en.en\n2024-08-22 06:06:27 | INFO | fairseq.tasks.translation | data-bin valid de-en 10 examples\n2024-08-22 06:06:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n2024-08-22 06:06:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n2024-08-22 06:06:27 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = 1\n2024-08-22 06:06:27 | INFO | fairseq.trainer | Preparing to load checkpoint data/de-en/ckpt/checkpoint_last.pt\n2024-08-22 06:06:27 | INFO | fairseq.trainer | No existing checkpoint found data/de-en/ckpt/checkpoint_last.pt\n2024-08-22 06:06:27 | INFO | fairseq.trainer | loading train data for epoch 1\n2024-08-22 06:06:27 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/train.de-en.de\n2024-08-22 06:06:27 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/train.de-en.en\n2024-08-22 06:06:27 | INFO | fairseq.tasks.translation | data-bin train de-en 10 examples\n2024-08-22 06:06:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 10\n2024-08-22 06:06:28 | INFO | fairseq.trainer | begin training epoch 1\n2024-08-22 06:06:28 | INFO | fairseq_cli.train | Start iterating over samples\n/root/.local/lib/python3.10/site-packages/fairseq/tasks/fairseq_task.py:514: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):\n2024-08-22 06:06:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n2024-08-22 06:06:37 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together\n2024-08-22 06:06:37 | INFO | fairseq.tasks.translation | example reference: in UNKNOWNTOKENINREF's UNKNOWNTOKENINREF.\n2024-08-22 06:06:37 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together\n2024-08-22 06:06:37 | INFO | fairseq.tasks.translation | example reference: it's that UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n2024-08-22 06:06:37 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together things things things things things things things things things things things things things things\n2024-08-22 06:06:37 | INFO | fairseq.tasks.translation | example reference: i really UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n2024-08-22 06:06:38 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together things things things things things things things things things things things things things things things things\n2024-08-22 06:06:38 | INFO | fairseq.tasks.translation | example reference: and UNKNOWNTOKENINREF we UNKNOWNTOKENINREF UNKNOWNTOKENINREF to UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF to UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n2024-08-22 06:06:38 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-22 06:06:38 | INFO | fairseq.tasks.translation | example reference: UNKNOWNTOKENINREF what UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF is UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n2024-08-22 06:06:38 | INFO | fairseq.tasks.translation | example hypothesis: complex complex together together together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-22 06:06:38 | INFO | fairseq.tasks.translation | example reference: UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF: UNKNOWNTOKENINREF the UNKNOWNTOKENINREF UNKNOWNTOKENINREF y UNKNOWNTOKENINREF UNKNOWNTOKENINREF\n2024-08-22 06:06:39 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-22 06:06:39 | INFO | fairseq.tasks.translation | example reference: what UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF this UNKNOWNTOKENINREF of UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF?\n2024-08-22 06:06:39 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-22 06:06:39 | INFO | fairseq.tasks.translation | example reference: UNKNOWNTOKENINREF UNKNOWNTOKENINREF: and UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF, in UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF, the UNKNOWNTOKENINREF to move the UNKNOWNTOKENINREF from UNKNOWNTOKENINREF to right, and UNKNOWNTOKENINREF and UNKNOWNTOKENINREF with the UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n2024-08-22 06:06:40 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-22 06:06:40 | INFO | fairseq.tasks.translation | example reference: it had UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF the UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF the UNKNOWNTOKENINREF a.\n2024-08-22 06:06:41 | INFO | fairseq.tasks.translation | example hypothesis: complex together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-22 06:06:41 | INFO | fairseq.tasks.translation | example reference: but we UNKNOWNTOKENINREF't UNKNOWNTOKENINREF at the time that we UNKNOWNTOKENINREF UNKNOWNTOKENINREF a UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF, UNKNOWNTOKENINREF we UNKNOWNTOKENINREF't UNKNOWNTOKENINREF UNKNOWNTOKENINREF the UNKNOWNTOKENINREF UNKNOWNTOKENINREF from UNKNOWNTOKENINREF and UNKNOWNTOKENINREF the UNKNOWNTOKENINREF at the UNKNOWNTOKENINREF time.\n2024-08-22 06:06:41 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.245 | nll_loss 6.084 | ppl 67.83 | bleu 0 | wps 42.9 | wpb 17.5 | bsz 1 | num_updates 10\n2024-08-22 06:06:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 10 updates\n2024-08-22 06:06:41 | INFO | fairseq.trainer | Saving checkpoint to /content/Align-to-Distill/data/de-en/ckpt/checkpoint1.pt\n2024-08-22 06:06:41 | INFO | fairseq.trainer | Finished saving checkpoint to /content/Align-to-Distill/data/de-en/ckpt/checkpoint1.pt\n2024-08-22 06:06:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint data/de-en/ckpt/checkpoint1.pt (epoch 1 @ 10 updates, score 0.0) (writing took 0.9869861669999977 seconds)\n2024-08-22 06:06:42 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n2024-08-22 06:06:42 | INFO | train | epoch 001 | loss 7.822 | nll_loss 7.837 | ppl 228.63 | wps 17.5 | ups 0.72 | wpb 23.4 | bsz 1 | num_updates 10 | lr 1.25e-06 | gnorm 20.127 | train_wall 8 | wall 14\n2024-08-22 06:06:42 | INFO | fairseq_cli.train | done training in 13.9 seconds\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --arch transformer_teacher --share-decoder-input-output-embed \\\n",
    "    --user-dir custom/ --cpu \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6fdf35",
   "metadata": {},
   "source": [
    "### Step 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f40f9",
   "metadata": {},
   "source": [
    "Execution Start time: 06:06:47, End time: 06:07:25 (duration: 38 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948319fe",
   "metadata": {},
   "source": [
    "**Thought**: The teacher model has been successfully trained for one epoch. The validation loss and nll_loss are reported as 6.245 and 6.084, respectively. Let's proceed to the next step, which involves generating predictions on the test set using `generate.py` and then evaluating them with `score.py`.\n",
    "\n",
    "I'll run the command to generate predictions first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf6253",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91da26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 06:06:49 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n2024-08-22 06:06:52 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'custom/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data/de-en/ckpt/checkpoint1.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': True, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n2024-08-22 06:06:52 | INFO | fairseq.tasks.translation | [de] dictionary: 128 types\n2024-08-22 06:06:52 | INFO | fairseq.tasks.translation | [en] dictionary: 120 types\n2024-08-22 06:06:52 | INFO | fairseq_cli.generate | loading model(s) from data/de-en/ckpt/checkpoint1.pt\n/root/.local/lib/python3.10/site-packages/fairseq/checkpoint_utils.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(f, map_location=torch.device(\"cpu\"))\n2024-08-22 06:06:52 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/test.de-en.de\n2024-08-22 06:06:52 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/test.de-en.en\n2024-08-22 06:06:52 | INFO | fairseq.tasks.translation | data-bin test de-en 10 examples\n/root/.local/lib/python3.10/site-packages/fairseq/models/transformer/transformer_encoder.py:281: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n  x = torch._nested_tensor_from_mask(\n2024-08-22 06:07:24 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n2024-08-22 06:07:24 | INFO | fairseq_cli.generate | Translated 10 sentences (2,010 tokens) in 32.0s (0.31 sentences/s, 62.85 tokens/s)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "CKPT=data/de-en/ckpt/checkpoint1.pt\n",
    "mkdir -p data/de-en/tmp/\n",
    "\n",
    "python fairseq_cli/generate.py data-bin \\\n",
    "      --path $CKPT \\\n",
    "      --beam 5 --batch-size 1 \\\n",
    "      --sacrebleu --remove-bpe \\\n",
    "      --user-dir custom/ > data/de-en/tmp/gen.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e17a14",
   "metadata": {},
   "source": [
    "### Step 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a6e082",
   "metadata": {},
   "source": [
    "Execution Start time: 06:07:29, End time: 06:07:33 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd31d4b",
   "metadata": {},
   "source": [
    "**Thought**: The generation of predictions on the test set has been completed successfully. Now, let's proceed to evaluate these predictions using the `score.py` script.\n",
    "\n",
    "I'll run the command to evaluate the generated predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745076e",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2ed5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 06:07:31 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\nNamespace(sys='data/de-en/tmp/gen.out.sys', ref='data/de-en/tmp/gen.out.ref', order=4, ignore_case=True, sacrebleu=True, sentence_bleu=False)\nTraceback (most recent call last):\n  File \"/content/Align-to-Distill/fairseq_cli/score.py\", line 109, in <module>\n    cli_main()\n  File \"/content/Align-to-Distill/fairseq_cli/score.py\", line 45, in cli_main\n    assert args.sys == \"-\" or os.path.exists(\nAssertionError: System output file data/de-en/tmp/gen.out.sys does not exist\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python fairseq_cli/score.py -s data/de-en/tmp/gen.out.sys -r data/de-en/tmp/gen.out.ref --ignore-case --sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f8aa4",
   "metadata": {},
   "source": [
    "### Step 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae7b1c",
   "metadata": {},
   "source": [
    "Execution Start time: 06:07:34, End time: 06:07:34 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef9180",
   "metadata": {},
   "source": [
    "**Thought**: It seems there was an issue with the file paths for the generated system outputs and references. Let's verify the contents of the `data/de-en/tmp/` directory to ensure the files are present and correctly named.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389b60b",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ad013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gen.out\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls data/de-en/tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af603d",
   "metadata": {},
   "source": [
    "### Step 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089ea51",
   "metadata": {},
   "source": [
    "Execution Start time: 06:07:37, End time: 06:07:37 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a9460",
   "metadata": {},
   "source": [
    "**Thought**: The `gen.out` file is present, but it seems the post-processing steps to separate hypotheses and references were not executed. Let's perform these steps to extract the system and reference outputs from `gen.out`.\n",
    "\n",
    "I'll run the commands to extract the hypotheses and references.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feef52b",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d8105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!grep ^H data/de-en/tmp/gen.out | cut -f3 > data/de-en/tmp/gen.out.tok.sys\n",
    "!grep ^T data/de-en/tmp/gen.out | cut -f2 > data/de-en/tmp/gen.out.tok.ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d074edc0",
   "metadata": {},
   "source": [
    "### Step 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a5767",
   "metadata": {},
   "source": [
    "Execution Start time: 06:07:40, End time: 06:07:40 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02412b5",
   "metadata": {},
   "source": [
    "**Thought**: The hypotheses and references have been successfully extracted. Now, let's proceed to de-tokenize them using `sed` to prepare them for evaluation.\n",
    "\n",
    "I'll run the commands to de-tokenize the outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1032f7a",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220ba82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.ref | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.ref\n",
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.sys | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3c9131",
   "metadata": {},
   "source": [
    "### Step 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f983a",
   "metadata": {},
   "source": [
    "Execution Start time: 06:07:42, End time: 06:07:45 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b82c78",
   "metadata": {},
   "source": [
    "**Thought**: The de-tokenization process has been completed successfully. Now, let's evaluate the generated predictions using the `score.py` script with the de-tokenized system and reference files.\n",
    "\n",
    "I'll run the command to evaluate the predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb2570",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67612e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 06:07:44 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\nNamespace(sys='data/de-en/tmp/gen.out.sys', ref='data/de-en/tmp/gen.out.ref', order=4, ignore_case=True, sacrebleu=True, sentence_bleu=False)\nBLEU = 0.00 0.0/0.0/0.0/0.0 (BP = 0.000 ratio = 0.007 hyp_len = 10 ref_len = 1422)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python fairseq_cli/score.py -s data/de-en/tmp/gen.out.sys -r data/de-en/tmp/gen.out.ref --ignore-case --sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c402561",
   "metadata": {},
   "source": [
    "### Step 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841e391e",
   "metadata": {},
   "source": [
    "Execution Start time: 06:07:47, End time: 06:07:47 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec1944d",
   "metadata": {},
   "source": [
    "**Thought**: The evaluation has been completed, and the BLEU score is reported as 0.00. This is expected given the limited data and training configuration. Now, let's prepare the final JSON output with the loss and nll_loss values obtained during the teacher model training.\n",
    "\n",
    "The values are:\n",
    "- `teacher_loss`: 7.822\n",
    "- `teacher_nll_loss`: 7.837\n",
    "\n",
    "I'll submit these values in the required JSON format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a4f540",
   "metadata": {},
   "source": [
    "**Action (submit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a17c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{teacher_loss: 7.822, teacher_nll_loss: 7.837}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit {\"teacher_loss\": 7.822, \"teacher_nll_loss\": 7.837}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
