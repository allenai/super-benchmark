{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537a9cca",
   "metadata": {},
   "source": [
    "### Query\n",
    "Train and evaluate the RAH-KBQA model on the webqsl data, available at https://drive.google.com/drive/folders/15WEkZ4JVBO-VjHXqpJMjWQDU3QbnoXjy?usp=drive_link, with bert as the base model. Report the F1 and H1 metrics as a json structured as follows: {\"F1\": 0.0, \"H1\": 0.0} (replace 0.0 with the actual values).\n",
    "\n",
    "Additional instructions:\n",
    "1. Load only the first 10 rows of each set in the dataset\n",
    "2. Train only one epoch\n",
    "3. Use the following hyperparameters: entity_dim=64, num_epoch=1, batch_size=1, lm=bert, num_iter=2, num_ins=2, num_gnn=2, relation_word_emb=True\n",
    "\n",
    "Git repository: https://github.com/yanmenxue/rah-kbqa\n",
    "\n",
    "I have already executed some of the required steps. Now, your goal is to complete the remaining steps and submit the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26eff3",
   "metadata": {},
   "source": [
    "### Prompt\n",
    "<details>\n",
    "[{'role': 'system', 'content': 'Interact in a jupyter notebook to solve the request.\\nOutput a thought and an action.\\nThought can reason about the current situation, and action allows you to interact with the Jupyter notebook. There are three types of actions:\\n(1) execute, which executes a notebook cell with the command under the \"content\" field. This could be a bash command (beginning with !), a python command, or magic command (beginning with %).\\n(2) edit, which allows you to replace existing lines in a file with new lines. To replace lines, you will need to provide the lines as they appear before the replacement, and the lines to replace them with.\\nIn the \"content\" field, format should be ```{filename}\\n<<<BEFORE_EDIT>>>\\nlines before edit\\nlines before edit\\n<<<AFTER_EDIT>>>\\nlines after edit\\nlines after edit```\\n  - Include the entire lines WITH indentation. After editing, make sure indentation is correct.\\n(3) submit, which submits the final answer (or null if there\\'s no answer to submit), formatted as JSON (make sure to use double quotes for keys and values).\\nAlways output exactly one \"thought\" and one \"action\", and encapsulate the content with <content>...</content> tags.\\nI will provide the cell output (observation) for you.\\n\\nTips:\\n- When a github repository is given, you should start by cloning it. You can read the readme file and browse the repo for installation and usage instructions.\\n- Avoid using conda, instead use pip for package management.\\n- Each execution has a 5-minute timeout. After this period, you can decide whether to interrupt the kernel or continue waiting.\\n  You should interrupt if: (1) you are prompted with an interactive message (e.g., \"Do you want to continue? [Y/n]\"). In that case, you can bypass it by executing echo \"y\" | command, or (2) the execution is taking longer than expected because the wrong task is being executed, such as a different model or incorrect number of epochs.\\n  You should continue to wait if the current execution is correct and proceeding as expected.\\n\\nHere are some examples.\\nGit repository: EleutherAI/lm-evaluation-harness\\nQuery: Evaluate EleutherAI/gpt-j-6B on hellaswag. What\\'s the score?\\nThought: First, I need to clone the GitHub repository \\'EleutherAI/lm-evaluation-harness\\'.\\nAction: execute\\n<content>\\n!git clone https://github.com/EleutherAI/lm-evaluation-harness.git\\n</content>\\nObservation: ```\\nCloning into \\'lm-evaluation-harness\\'...\\n```\\nThought: The repository has been cloned. Next, I should check the README file for installation and usage instructions to proceed with evaluating EleutherAI/gpt-j-6B on hellaswag.\\nAction: execute\\n<content>\\n!cat lm-evaluation-harness/README.md\\n</content>\\nObservation: ```# Language Model Evaluation Harness ... truncated ...\\n```\\nThought: The README provides detailed instructions for installing the `lm-eval` package and evaluating models like GPT-J-6B on tasks like hellaswag. I need to install the package and its dependencies first.\\nAction: execute\\n<content>\\n!pip install -e lm-evaluation-harness/.\\n</content>\\nObservation: ```\\nObtaining file:///home/nora/lm-evaluation-harness\\n  Installing build dependencies ... truncated ...\\n```\\nThought: The `lm-eval` package and its dependencies have been installed successfully. Now, I can proceed with evaluating the EleutherAI/gpt-j-6B model on the hellaswag task as per the instructions in the README.\\nAction: execute\\n<content>\\n!lm_eval --model hf --model_args pretrained=EleutherAI/gpt-j-6B --tasks hellaswag --device cuda:0 --batch_size 8\\n</content>\\nObservation: ```\\n{\\n  \"hellaswag\": {\\n    \"acc\": 0.24603658536585363,\\n    \"acc_norm\": 0.34436059706446426,\\n  },  ... truncated ...\\n```\\nThought: The `lm-eval` was executed successfully, providing the metrics I needed. The `acc` metric is 0.2460. The `acc_norm` metric is 0.3444\\nAction: submit\\n<content>\\n{\"acc\": 0.2460, \"acc_norm\": 0.3444}\\n</content>\\n\\nQuery: use pandas to read the file \\'data.csv\\' and display the first 2 rows.\\nThought: First, I need to read the file \\'data.csv\\' using the pandas library.\\nAction: execute\\n<content>\\nimport pandas as pd\\npd.read_csv(\\'data.csv\\').head()\\n</content>\\nObservation: ```\\n    name\\n  0  Alice\\n   1    Bob\\n  2  Charlie\\n```\\nThought: The file \\'data.csv\\' has been read successfully and the first 2 rows have been displayed.\\nAction: submit\\n<content>\\n[\"Alice\", \"Bob\"]\\n</content>\\n\\nQuery: Change the model name in the \\'config.json\\' file from \\'roberta-base\\' to \\'roberta-large\\'.\\nThought: First, I need to read the \\'config.json\\' file to find the location where I can replace the model name.\\nAction: execute\\n<content>\\n!cat config.json\\n</content>\\nObservation: ```\\n{\\n    \"model\": \"roberta-base\",\\n    \"batch_size\": 8,\\n    \"epochs\": 10\\n}\\n```\\nThought: The file has been read successfully. Now, I can replace the model name in the \\'config.json\\' file.\\nAction: edit\\n<content>\\nconfig.json\\n<<<BEFORE_EDIT>>>\\n{\\n    \"model\": \"roberta-base\",\\n    \"batch_size\": 8,\\n<<<AFTER_EDIT>>>\\n{\\n    \"model\": \"roberta-large\",\\n    \"batch_size\": 8,\\n</content>\\nObservation: \"editing file config.json\"\\nThought: The model name has been replaced in the \\'config.json\\' file.\\nAction: submit\\n<content>\\nnull\\n</content>\\n'}, {'role': 'user', 'content': 'Query: Train and evaluate the RAH-KBQA model on the webqsl data, available at https://drive.google.com/drive/folders/15WEkZ4JVBO-VjHXqpJMjWQDU3QbnoXjy?usp=drive_link, with bert as the base model. Report the F1 and H1 metrics as a json structured as follows: {\"F1\": 0.0, \"H1\": 0.0} (replace 0.0 with the actual values).\\n\\nAdditional instructions:\\n1. Load only the first 10 rows of each set in the dataset\\n2. Train only one epoch\\n3. Use the following hyperparameters: entity_dim=64, num_epoch=1, batch_size=1, lm=bert, num_iter=2, num_ins=2, num_gnn=2, relation_word_emb=True\\n\\nGit repository: https://github.com/yanmenxue/rah-kbqa\\n\\nI have already executed some of the required steps. Now, your goal is to complete the remaining steps and submit the answer.'}]\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e4a5",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18394c7",
   "metadata": {},
   "source": [
    "Execution Start time: 23:18:30, End time: 23:18:30 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704a3f9",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976aed75",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747a4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloning into 'RAH-KBQA'...\nremote: Enumerating objects: 49, done.\u001b[K\nremote: Counting objects: 100% (49/49)\u001b[K\nremote: Counting objects: 100% (49/49), done.\u001b[K\nremote: Compressing objects: 100% (42/42)\u001b[K\nremote: Compressing objects: 100% (42/42), done.\u001b[K\nremote: Total 49 (delta 8), reused 47 (delta 6), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (49/49)\nReceiving objects: 100% (49/49), 252.69 KiB | 31.59 MiB/s, done.\nResolving deltas: 100% (8/8)\nResolving deltas: 100% (8/8), done.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/yanmenxue/RAH-KBQA.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f10d8",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f4e03",
   "metadata": {},
   "source": [
    "Execution Start time: 23:18:30, End time: 23:18:30 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff66a5d1",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1140f39a",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b90150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/RAH-KBQA\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd RAH-KBQA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea1055",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87a9de",
   "metadata": {},
   "source": [
    "Execution Start time: 23:18:30, End time: 23:18:30 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008b746",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a4bbc",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d390e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452c2f2",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef46fdc",
   "metadata": {},
   "source": [
    "Execution Start time: 23:18:30, End time: 23:18:30 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed65c5",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54c5d69",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc0384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Task:Data\n",
    "# use gdown to download files\n",
    "# !pip install gdown --upgrade\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef968d2",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741cb0b",
   "metadata": {},
   "source": [
    "Execution Start time: 23:18:31, End time: 23:18:31 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655612c1",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c785a",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985c8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/RAH-KBQA/data\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Task:Data\n",
    "# create a new directory to place the dataset\n",
    "%mkdir data\n",
    "%cd data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87315771",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad150d0",
   "metadata": {},
   "source": [
    "Execution Start time: 23:18:31, End time: 23:18:41 (duration: 10 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3377b8",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9447c26a",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e428ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading...\nFrom (original): https://drive.google.com/uc?id=1-bifacnJ0RF658N-kk95HbB_qL4lvNnw\nFrom (redirected): https://drive.google.com/uc?id=1-bifacnJ0RF658N-kk95HbB_qL4lvNnw&confirm=t&uuid=21ed0bce-b742-40fb-959e-583b370f6db9\nTo: /content/RAH-KBQA/data/webqsp.tgz\n\n  0%|          | 0.00/143M [00:00<?, ?B/s]\n\n\n\n\n\n\n\n\n\n\n\n'webqsp.tgz'\n\nYour command has already run for 300 seconds. It is still running. You can continue to wait or interrupt it with Thought: ... \nAction: interrupt\n```\n``` \nor:\nThought: ... \nAction: continue_wait\n```\n```"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Task:Data\n",
    "# download the dataset from google drive\n",
    "gdown.download(\"https://drive.google.com/uc?id=1-bifacnJ0RF658N-kk95HbB_qL4lvNnw\", \"webqsp.tgz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3edcf7",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ab6f4",
   "metadata": {},
   "source": [
    "Execution Start time: 23:18:41, End time: 23:23:41 (duration: 300 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff158b",
   "metadata": {},
   "source": [
    "**Thought**: [continued after timeout]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2fbd92",
   "metadata": {},
   "source": [
    "**Action (continue_wait)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d307cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n\nYour command has already run for 300 seconds. It is still running. You can continue to wait or interrupt it with Thought: ... \nAction: interrupt\n```\n``` \nor:\nThought: ... \nAction: continue_wait\n```\n```"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea3a72e1",
   "metadata": {},
   "source": [
    "### Step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98943ee5",
   "metadata": {},
   "source": [
    "Execution Start time: 23:23:41, End time: 23:23:45 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f891cb",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68287ee1",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "webqsp/\nwebqsp/train_simple.json\nwebqsp/entities.txt\nwebqsp/test_simple.json\nwebqsp/vocab_new.txt\nwebqsp/dev_simple.json\nwebqsp/word_emb_300d.npy\nwebqsp/relations.txt\nwebqsp/train.dep\nwebqsp/test.dep\nwebqsp/dev.dep\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Task:Data\n",
    "!tar -xvzf webqsp.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77801d54",
   "metadata": {},
   "source": [
    "### Step 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd0784",
   "metadata": {},
   "source": [
    "Execution Start time: 23:23:45, End time: 23:23:46 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a7a2c",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f5bfb",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a48f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dev.dep          relations.txt     train.dep          word_emb_300d.npy\ndev_simple.json  test.dep          train_simple.json\nentities.txt     test_simple.json  vocab_new.txt\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Task:Data\n",
    "%ls webqsp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91c55a",
   "metadata": {},
   "source": [
    "### Step 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e1162",
   "metadata": {},
   "source": [
    "Execution Start time: 23:23:46, End time: 23:23:47 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30106210",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83785d1",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a9952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2848 webqsp/train_simple.json\n1639 webqsp/test_simple.json\n250 webqsp/dev_simple.json\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Task:Data\n",
    "!wc -l webqsp/train_simple.json\n",
    "!wc -l webqsp/test_simple.json\n",
    "!wc -l webqsp/dev_simple.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f5c51",
   "metadata": {},
   "source": [
    "### Step 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce8bff",
   "metadata": {},
   "source": [
    "Execution Start time: 23:23:47, End time: 23:23:47 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd45feb",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206a1a4e",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e508cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6718 webqsp/vocab_new.txt\nwhat\nis\nthe\nname\nof\njustin\nbieber\nbrother\ncharacter\ndid\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Task:Data\n",
    "!wc -l webqsp/vocab_new.txt\n",
    "!head webqsp/vocab_new.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea7b75",
   "metadata": {},
   "source": [
    "### Step 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7260880",
   "metadata": {},
   "source": [
    "Execution Start time: 23:23:47, End time: 23:23:48 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b41ca5",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260fa65",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb7ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10 webqsp/train.json\n10 webqsp/test.json\n10 webqsp/dev.json\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Task:Data\n",
    "# rename vocab_new.txt to vocab.txt in data/webqsp\n",
    "!mv webqsp/vocab_new.txt webqsp/vocab.txt\n",
    "\n",
    "# take only 10 rows of train_simple.json to train.json\n",
    "!head -10 webqsp/train_simple.json > webqsp/train.json\n",
    "\n",
    "# take only 10 rows of test_simple.json to test.json\n",
    "!head -10 webqsp/test_simple.json > webqsp/test.json\n",
    "\n",
    "# take only 10 rows of dev_simple.json to dev.json\n",
    "!head -10 webqsp/dev_simple.json > webqsp/dev.json\n",
    "\n",
    "# check the data files\n",
    "!wc -l webqsp/train.json\n",
    "!wc -l webqsp/test.json\n",
    "!wc -l webqsp/dev.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8417538",
   "metadata": {},
   "source": [
    "### Step 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879a40e",
   "metadata": {},
   "source": [
    "Execution Start time: 23:23:48, End time: 23:23:48 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd56de32",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee82c9",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b4135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Parameter Setup & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56103010",
   "metadata": {},
   "source": [
    "### Step 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e0123",
   "metadata": {},
   "source": [
    "Execution Start time: 23:23:48, End time: 23:23:49 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c4adf",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7de3d2",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbed8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/RAH-KBQA\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get back to the main folder\n",
    "%cd /content/RAH-KBQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfddc8f",
   "metadata": {},
   "source": [
    "### Step 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd27a57",
   "metadata": {},
   "source": [
    "Execution Start time: 23:23:50, End time: 23:23:50 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4cf0b",
   "metadata": {},
   "source": [
    "**Thought**: The data preparation steps have been completed, and the dataset has been reduced to the first 10 rows for each set. Now, I need to set up the parameters and train the RAH-KBQA model using the specified hyperparameters. I will check the repository for any scripts or instructions related to training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4995f92a",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da57ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LICENSE    dataset_load.py  models\tpipeline.pdf\t  train_model.py\nREADME.md  evaluate.py\t    modules\tpipeline.png\t  utils.py\ndata\t   main.py\t    parsing.py\trequirements.txt\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40ce3ea",
   "metadata": {},
   "source": [
    "### Step 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e8c47",
   "metadata": {},
   "source": [
    "Execution Start time: 23:23:52, End time: 23:23:52 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24803410",
   "metadata": {},
   "source": [
    "**Thought**: The repository contains several Python scripts, including `train_model.py`, which likely handles the training process. I should check the `README.md` or the `train_model.py` script for instructions on how to train the model with the specified hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de534eb9",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd002b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# RAH-KBQA [EMNLP 2023]\nThis is the code for the EMNLP 2023 Findings paper: [Relation-Aware Question Answering for Heterogeneous Knowledge Graphs](to be continue).\n\n\n## Overview \nOur methods utilizes information from head-tail entities and the semantic connection between relations to enhance the current relation representation.\n\n![](./pipeline.png)\n\n\n## Get Started\nWe have simple requirements in `requirements.txt'. You can always check if you can run the code immediately.\n\nWe use the pre-processed data from: https://drive.google.com/drive/folders/1qRXeuoL-ArQY7pJFnMpNnBu0G-cOz6xv\nDownload it and extract it to a folder named \"data\".\n\n__Acknowledgements__: \n\n[NSM](https://github.com/RichardHGL/WSDM2021_NSM): Datasets (webqsp, CWQ, MetaQA) / Code.\n\n[GraftNet](https://github.com/haitian-sun/GraftNet): Datasets (webqsp incomplete, MetaQA) / Code.\n\n## Training\n\nTo run Webqsp:\n```\npython main.py ReaRev --entity_dim 128 --num_epoch 150 --batch_size 8 --eval_every 2 \\ \n--data_folder data/webqsp/ --lm sbert --num_iter 3 --num_ins 2 --num_gnn 2 \\\n--relation_word_emb True --experiment_name Webqsp322 --name webqsp\n```\n\nTo run CWQ:\n```\npython main.py ReaRev --entity_dim 128 --num_epoch 70 --batch_size 8 --eval_every 2 \\\n--data_folder data/CWQ/ --lm sbert --num_iter 2 --num_ins 3 --num_gnn 3 \\\n--relation_word_emb True --experiment_name CWQ --name cwq\n```\n\n\nFor incomplete Webqsp, see  'data/incomplete/' (after obtaining them by [GraftNet](https://github.com/haitian-sun/GraftNet)). If you cannot afford a lot of memory for CWQ, use the '--data_eff' argument (see our arguments in `parsing.py').\n\n## Results\n\n\n\n|   Models    |  Webqsp  |   CWQ    | \n|:-----------:|:--------:|:--------:|\n|   KV-Mem    |   46.7   |   21.1   | \n|  GraftNet   |   66.4   |   32.8   |\n|   PullNet   |   68.1   |   45.9   | \n| NSM-distill |   74.3   |   48.8   | \n|   ReaRev    |   76.4   |   52.9   | \n|  RAH-KBQA   | **77.2** | **54.4** | \n\n## Cite\nIf you find our code or method useful, please cite our work as\n```\nto be continue\n```\nor\n```\n```\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!cat README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954ea6d",
   "metadata": {},
   "source": [
    "### Step 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412917c",
   "metadata": {},
   "source": [
    "Execution Start time: 23:23:54, End time: 23:23:59 (duration: 5 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70313e71",
   "metadata": {},
   "source": [
    "**Thought**: The README provides instructions for training the model using the `main.py` script. I will modify the command to use the specified hyperparameters and train the model for one epoch on the reduced dataset. The command will be adjusted to use `bert` as the language model and the specified hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa55ba5",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f1a2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/RAH-KBQA/main.py\", line 47, in <module>\n    main()\n  File \"/content/RAH-KBQA/main.py\", line 31, in main\n    os.mkdir(args.checkpoint_dir)\nFileNotFoundError: [Errno 2] No such file or directory: 'checkpoint/pretrain/'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python main.py ReaRev --entity_dim 64 --num_epoch 1 --batch_size 1 --eval_every 1 \\\n",
    "--data_folder data/webqsp/ --lm bert --num_iter 2 --num_ins 2 --num_gnn 2 \\\n",
    "--relation_word_emb True --experiment_name WebqspTest --name webqsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d4614",
   "metadata": {},
   "source": [
    "### Step 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c197a23",
   "metadata": {},
   "source": [
    "Execution Start time: 23:24:01, End time: 23:24:01 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e7d15",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the directory `checkpoint/pretrain/` does not exist, which is required for saving model checkpoints. I need to create this directory before running the training script again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d7e43",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7fbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir -p checkpoint/pretrain/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a5c883",
   "metadata": {},
   "source": [
    "### Step 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f20c0",
   "metadata": {},
   "source": [
    "Execution Start time: 23:24:04, End time: 23:27:16 (duration: 191 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f801f",
   "metadata": {},
   "source": [
    "**Thought**: The required directory `checkpoint/pretrain/` has been created. Now, I can proceed with running the training script again using the specified hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d4de1",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffdc857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-20 23:24:06,832 - root - INFO - PARAMETER----------\n2024-08-20 23:24:06,833 - root - INFO - ALG=bfs\n2024-08-20 23:24:06,833 - root - INFO - BATCH_SIZE=1\n2024-08-20 23:24:06,833 - root - INFO - CHAR2ID=chars.txt\n2024-08-20 23:24:06,833 - root - INFO - CHECKPOINT_DIR=checkpoint/pretrain/\n2024-08-20 23:24:06,833 - root - INFO - DATA_EFF=False\n2024-08-20 23:24:06,833 - root - INFO - DATA_FOLDER=data/webqsp/\n2024-08-20 23:24:06,833 - root - INFO - DECAY_RATE=0.0\n2024-08-20 23:24:06,833 - root - INFO - ENTITY2ID=entities.txt\n2024-08-20 23:24:06,833 - root - INFO - ENTITY_DIM=64\n2024-08-20 23:24:06,833 - root - INFO - ENTITY_EMB_FILE=None\n2024-08-20 23:24:06,833 - root - INFO - EPS=0.95\n2024-08-20 23:24:06,833 - root - INFO - EVAL_EVERY=1\n2024-08-20 23:24:06,833 - root - INFO - EXPERIMENT_NAME=WebqspTest\n2024-08-20 23:24:06,833 - root - INFO - FACT_DROP=0\n2024-08-20 23:24:06,833 - root - INFO - FACT_SCALE=3\n2024-08-20 23:24:06,833 - root - INFO - GRADIENT_CLIP=1.0\n2024-08-20 23:24:06,833 - root - INFO - IS_EVAL=False\n2024-08-20 23:24:06,833 - root - INFO - KG_DIM=100\n2024-08-20 23:24:06,833 - root - INFO - KGE_FROZEN=0\n2024-08-20 23:24:06,833 - root - INFO - LABEL_SMOOTH=0.1\n2024-08-20 23:24:06,834 - root - INFO - LINEAR_DROPOUT=0.2\n2024-08-20 23:24:06,834 - root - INFO - LM=bert\n2024-08-20 23:24:06,834 - root - INFO - LM_DROPOUT=0.3\n2024-08-20 23:24:06,834 - root - INFO - LM_FROZEN=1\n2024-08-20 23:24:06,834 - root - INFO - LOAD_CKPT_FILE=None\n2024-08-20 23:24:06,834 - root - INFO - LOAD_EXPERIMENT=None\n2024-08-20 23:24:06,834 - root - INFO - LOG_LEVEL=info\n2024-08-20 23:24:06,834 - root - INFO - LOSS_TYPE=kl\n2024-08-20 23:24:06,834 - root - INFO - LR=0.0005\n2024-08-20 23:24:06,834 - root - INFO - LR_SCHEDULE=False\n2024-08-20 23:24:06,834 - root - INFO - MAX_TRAIN=200000\n2024-08-20 23:24:06,834 - root - INFO - MODEL_NAME=ReaRev\n2024-08-20 23:24:06,834 - root - INFO - NAME=webqsp\n2024-08-20 23:24:06,834 - root - INFO - NORMALIZED_GNN=False\n2024-08-20 23:24:06,834 - root - INFO - NUM_EPOCH=1\n2024-08-20 23:24:06,834 - root - INFO - NUM_GNN=2\n2024-08-20 23:24:06,834 - root - INFO - NUM_INS=2\n2024-08-20 23:24:06,834 - root - INFO - NUM_ITER=2\n2024-08-20 23:24:06,834 - root - INFO - Q_TYPE=seq\n2024-08-20 23:24:06,834 - root - INFO - REL_WORD_IDS=rel_word_idx.npy\n2024-08-20 23:24:06,834 - root - INFO - RELATION2ID=relations.txt\n2024-08-20 23:24:06,834 - root - INFO - RELATION_EMB_FILE=None\n2024-08-20 23:24:06,835 - root - INFO - RELATION_WORD_EMB=True\n2024-08-20 23:24:06,835 - root - INFO - SEED=19960626\n2024-08-20 23:24:06,835 - root - INFO - TEST_BATCH_SIZE=20\n2024-08-20 23:24:06,835 - root - INFO - USE_CUDA=False\n2024-08-20 23:24:06,835 - root - INFO - USE_SELF_LOOP=True\n2024-08-20 23:24:06,835 - root - INFO - WORD2ID=vocab.txt\n2024-08-20 23:24:06,835 - root - INFO - WORD_DIM=300\n2024-08-20 23:24:06,835 - root - INFO - WORD_EMB_FILE=word_emb.npy\n2024-08-20 23:24:06,835 - root - INFO - -------------------\nbuilding word index ...\nEntity: 1441420, Relation in KB: 6102, Relation in use: 6103 \nloading data from data/webqsp/train.json\n\n0it [00:00, ?it/s]\n10it [00:00, 169.61it/s]\nskip set()\nmax_facts:  18176\nconverting global to local entity index ...\n\n  0%|                                                    | 0/10 [00:00<?, ?it/s]\n100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1955.39it/s]\navg local entity:  1402.1\nmax local entity:  2000\n\ntokenizer_config.json:   0%|                         | 0.00/48.0 [00:00<?, ?B/s]\ntokenizer_config.json: 100%|██████████████████| 48.0/48.0 [00:00<00:00, 367kB/s]\n\nconfig.json:   0%|                                    | 0.00/570 [00:00<?, ?B/s]\n\n\nvocab.txt:   0%|                                     | 0.00/232k [00:00<?, ?B/s]\n\n\ntokenizer.json:   0%|                                | 0.00/466k [00:00<?, ?B/s]\n\n\n  0%|                                                    | 0/10 [00:00<?, ?it/s]\n100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 226.97it/s]\n10 cases in total, 0 cases without query entity, 10 cases with single query entity, 0 cases with multiple query entities\nbuilding word index ...\nEntity: 1441420, Relation in KB: 6102, Relation in use: 6103 \nloading data from data/webqsp/dev.json\n\n0it [00:00, ?it/s]\n10it [00:00, 601.15it/s]\nskip set()\nmax_facts:  12586\nconverting global to local entity index ...\n\n  0%|                                                    | 0/10 [00:00<?, ?it/s]\n100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1657.76it/s]\navg local entity:  1606.6\nmax local entity:  2000\n\n  0%|                                                    | 0/10 [00:00<?, ?it/s]\n100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 229.59it/s]\n10 cases in total, 0 cases without query entity, 10 cases with single query entity, 0 cases with multiple query entities\nbuilding word index ...\nEntity: 1441420, Relation in KB: 6102, Relation in use: 6103 \nloading data from data/webqsp/test.json\n\n0it [00:00, ?it/s]\n10it [00:00, 641.26it/s]\nskip set()\nmax_facts:  13902\nconverting global to local entity index ...\n\n  0%|                                                    | 0/10 [00:00<?, ?it/s]\n100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1811.95it/s]\navg local entity:  1457.9\nmax local entity:  2000\n\n  0%|                                                    | 0/10 [00:00<?, ?it/s]\n100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 249.25it/s]\n10 cases in total, 0 cases without query entity, 10 cases with single query entity, 0 cases with multiple query entities\nNum Word 0\nEntity: 1441420, Relation: 6103, Word: 0\nword_dim 768\n\nmodel.safetensors:   0%|                             | 0.00/440M [00:00<?, ?B/s]\n\n\n\n\n\n\n\n\n\n\n\nTotal Params 109482240\nFreezing LM params\nWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\nEntity: 1441420, Relation: 6103, Word: 6718\nStart Training------------------\n\n  0%|                                                    | 0/10 [00:00<?, ?it/s]\n 10%|████▍                                       | 1/10 [00:00<00:05,  1.57it/s]\n 20%|████████▊                                   | 2/10 [00:01<00:05,  1.52it/s]\n 30%|█████████████▏                              | 3/10 [00:01<00:04,  1.55it/s]\n 40%|█████████████████▌                          | 4/10 [00:02<00:03,  1.65it/s]\n 50%|██████████████████████                      | 5/10 [00:03<00:02,  1.67it/s]\n 60%|██████████████████████████▍                 | 6/10 [00:03<00:02,  1.56it/s]\n 70%|██████████████████████████████▊             | 7/10 [00:04<00:01,  1.57it/s]\n 80%|███████████████████████████████████▏        | 8/10 [00:05<00:01,  1.58it/s]\n 90%|███████████████████████████████████████▌    | 9/10 [00:05<00:00,  1.47it/s]\n100%|███████████████████████████████████████████| 10/10 [00:06<00:00,  1.45it/s]\n100%|███████████████████████████████████████████| 10/10 [00:06<00:00,  1.53it/s]\n2024-08-20 23:27:08,893 - root - INFO - Epoch: 1, loss : 7.1302, time: 6.543208360671997\n2024-08-20 23:27:08,894 - root - INFO - Training h1 : 0.0000, f1 : 0.0000\n\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\n100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\nevaluation.......\n{3: 10}\n2024-08-20 23:27:10,187 - root - INFO - EVAL F1: 0.0048, H1: 0.1000\nBest h1, save model as checkpoint/pretrain/WebqspTest-h1.ckpt\n2024-08-20 23:27:10,504 - root - INFO - BEST EVAL H1: 0.1000\nBest f1, save model as checkpoint/pretrain/WebqspTest-f1.ckpt\n2024-08-20 23:27:10,829 - root - INFO - BEST EVAL F1: 0.0048\nBest final, save model as checkpoint/pretrain/WebqspTest-final.ckpt\n2024-08-20 23:27:11,145 - root - INFO - Train Done! Evaluate on testset with saved model\nEnd Training------------------\n\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\nevaluation.......\n{3: 10}\n2024-08-20 23:27:12,647 - root - INFO - Best h1 evaluation\n2024-08-20 23:27:12,648 - root - INFO - TEST F1: 0.0048, H1: 0.1000\n\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\nevaluation.......\n{3: 10}\n2024-08-20 23:27:14,150 - root - INFO - Best f1 evaluation\n2024-08-20 23:27:14,151 - root - INFO - TEST F1: 0.0048, H1: 0.1000\n\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\nevaluation.......\n{3: 10}\n2024-08-20 23:27:15,596 - root - INFO - Final evaluation\n2024-08-20 23:27:15,596 - root - INFO - TEST F1: 0.0048, H1: 0.1000\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python main.py ReaRev --entity_dim 64 --num_epoch 1 --batch_size 1 --eval_every 1 \\\n",
    "--data_folder data/webqsp/ --lm bert --num_iter 2 --num_ins 2 --num_gnn 2 \\\n",
    "--relation_word_emb True --experiment_name WebqspTest --name webqsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42cf97c",
   "metadata": {},
   "source": [
    "### Step 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd5bb3",
   "metadata": {},
   "source": [
    "Execution Start time: 23:27:18, End time: 23:27:18 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b363a4",
   "metadata": {},
   "source": [
    "**Thought**: The training and evaluation of the RAH-KBQA model on the webqsp dataset have been completed. The F1 and H1 metrics on the test set are 0.0048 and 0.1000, respectively. I will now submit these results in the required JSON format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb050b5c",
   "metadata": {},
   "source": [
    "**Action (submit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e8951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'F1': 0.0048, 'H1': 0.1}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
