{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a3cd826",
   "metadata": {},
   "source": [
    "### System Prompt\n",
    "<details>\n",
    "SETTING: You are an autonomous programmer, and you're working directly in the command line with a special Jupyter notebook interface.\n",
    "\n",
    "The special Jupyter notebook interface consists of a file editor that shows you 100 lines of a file at a time.\n",
    "You can execute commands in the notebook using:\n",
    "\n",
    "1. Bash commands: Commands starting with !.\n",
    "2. Python commands: Standard Python code.\n",
    "3. Magic commands: Commands starting with %, e.g., %cd <path>.\n",
    "\n",
    "Additionally, you can also use the following commands to help you navigate and edit files.\n",
    "\n",
    "COMMANDS:\n",
    "\n",
    "open:\n",
    "  docstring: opens the file at the given path in the editor. If line_number is provided, the window will be move to include that line\n",
    "  signature: open <path> [<line_number>]\n",
    "  arguments:\n",
    "    - path (string) [required]: the path to the file to open\n",
    "    - line_number (integer) [optional]: the line number to move the window to (if not provided, the window will start at the top of the file)\n",
    "\n",
    "create:\n",
    "  docstring: creates and opens a new file with the given name\n",
    "  signature: create <filename>\n",
    "  arguments:\n",
    "    - filename (string) [required]: the name of the file to create\n",
    "\n",
    "goto:\n",
    "  docstring: moves the window to show <line_number>\n",
    "  signature: goto <line_number>\n",
    "  arguments:\n",
    "    - line_number (integer) [required]: the line number to move the window to\n",
    "\n",
    "scroll_down:\n",
    "  docstring: moves the window down {WINDOW} lines\n",
    "  signature: scroll_down\n",
    "\n",
    "scroll_up:\n",
    "  docstring: moves the window down {WINDOW} lines\n",
    "  signature: scroll_up\n",
    "\n",
    "submit:\n",
    "  docstring: submits your final answer\n",
    "  signature: submit <answer>\n",
    "  arguments:\n",
    "    - answer (string) [required]: the answer to be submitted\n",
    "\n",
    "search_dir:\n",
    "  docstring: searches for search_term in all files in dir_path. If dir_path is not provided, searches in the current directory\n",
    "  signature: search_dir <search_term> [<dir_path>]\n",
    "  arguments:\n",
    "    - search_term (string) [required]: the term to search for\n",
    "    - dir_path (string) [optional]: the directory to search in (if not provided, searches in the current directory)\n",
    "\n",
    "search_file:\n",
    "  docstring: searches for search_term in file. If file is not provided, searches in the current open file\n",
    "  signature: search_file <search_term> [<file>]\n",
    "  arguments:\n",
    "    - search_term (string) [required]: the term to search for\n",
    "    - file (string) [optional]: the file to search in (if not provided, searches in the current open file)\n",
    "\n",
    "find_file:\n",
    "  docstring: finds all files with the given name in dir_path. If dir_path is not provided, searches in the current directory\n",
    "  signature: find_file <file_name> [<dir_path>]\n",
    "  arguments:\n",
    "    - file_name (string) [required]: the name of the file to search for\n",
    "    - dir_path (string) [optional]: the directory to search in (if not provided, searches in the current directory)\n",
    "\n",
    "edit:\n",
    "  docstring: replaces lines <start_line> through <end_line> (inclusive) with the given text in the open file. The replacement text is terminated by a line with only end_of_edit on it. All of the <replacement text> will be entered, so make sure your indentation is formatted properly. Python files will be checked for syntax errors after the edit. If the system detects a syntax error, the edit will not be executed. Simply try to edit the file again, but make sure to read the error message and modify the edit command you issue accordingly. Issuing the same command a second time will just lead to the same error message again.\n",
    "  signature: edit <start_line>:<end_line>\n",
    "<replacement_text>\n",
    "end_of_edit\n",
    "  arguments:\n",
    "    - start_line (integer) [required]: the line number to start the edit at\n",
    "    - end_line (integer) [required]: the line number to end the edit at (inclusive)\n",
    "    - replacement_text (string) [required]: the text to replace the current selection with\n",
    "\n",
    "\n",
    "\n",
    "Please note that THE EDIT COMMAND REQUIRES PROPER INDENTATION. \n",
    "If you'd like to add the line '        print(x)' you must fully write that out, with all those spaces before the code! Indentation is important and code that is not indented correctly will fail and require fixing before it can be run.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Your shell prompt is formatted as follows:\n",
    "(Open file: <path>)\n",
    "(Current directory: <cwd>)\n",
    "In [ ]\n",
    "\n",
    "You need to format your output using two fields: discussion and command.\n",
    "Your output should always include _one_ discussion and _one_ command field EXACTLY as in the following example:\n",
    "DISCUSSION\n",
    "First I'll start by using ls to see what files are in the current directory. Then maybe we can look at some relevant files to see what they look like.\n",
    "```\n",
    "!ls -a\n",
    "```\n",
    "\n",
    "You should only include a *SINGLE* command in the command section and then wait for a response from the shell before continuing with more discussion and commands. Everything you include in the DISCUSSION section will be saved for future reference.\n",
    "If you'd like to issue two commands at once, PLEASE DO NOT DO THAT! Please instead first submit just the first command, and then after receiving a response you'll be able to issue the second command. \n",
    "You're free to use any other bash commands you want (e.g. find, grep, cat, ls, cd) in addition to the special commands listed above.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41364919",
   "metadata": {},
   "source": [
    "### Query\n",
    "Perform prompt-based fine-tuning on the amazon_review dataset using the roberta-base model and the `run_prompt_ft.py` script. Report the test f1 score and test loss as a json structured as follows: {\"test_f1\": 0.0, \"test_loss\": 0.0} (replace 0.0 with the actual values).\n",
    "\n",
    "Additional instructions:\n",
    "1. Only load the first 10 examples of the dataset. Set the following indices as the labeled data: [0,1,2,3], and the following indices as the unlabeled data: [4,5,6,7,8,9].\n",
    "2. Run for only 1 epoch.\n",
    "3. Use the following hyperparameters: learning rate = 0.0001, per_device_train_batch_size = 2, per_device_eval_batch_size = 4, seed = 3, num_labeled_data = 4.\n",
    "\n",
    "\n",
    "Git repository: https://github.com/zhengxiangshi/powerfulpromptft\n",
    "\n",
    "I have already executed some of the required steps. However, I did not yet make any required changes to load the request dataset. Your goal is to successfully load the dataset and complete the remaining steps to achieve the user request. You can re-run any of the pre-executed steps, and finally should successfully run\n",
    "```\n",
    "!python run_prompt_ft.py \\\n",
    "            --task_type ssl \\\n",
    "            --model_type prompting \\\n",
    "            --downstream_task_name amazon_review \\\n",
    "            --seed 3 \\\n",
    "            --num_labelled_data 4 \\\n",
    "            --train_file data/amazon_review \\\n",
    "            --validation_file data/amazon_review \\\n",
    "            --test_file data/amazon_review \\\n",
    "            --model_name_or_path roberta-base \\\n",
    "            --do_train \\\n",
    "            --do_eval \\\n",
    "            --do_predict \\\n",
    "            --per_device_train_batch_size 2 \\\n",
    "            --per_device_eval_batch_size 4 \\\n",
    "            --max_seq_length 256 \\\n",
    "            --save_strategy steps \\\n",
    "            --evaluation_strategy steps \\\n",
    "            --max_steps 1 \\\n",
    "            --eval_steps 1 \\\n",
    "            --save_steps 1 \\\n",
    "            --learning_rate 0.0001 \\\n",
    "            --weight_decay 0.01 \\\n",
    "            --warmup_ratio 0.06 \\\n",
    "            --load_best_model_at_end \\\n",
    "            --save_total_limit 1 \\\n",
    "            --output_dir saved_ssl/prompting_amazon_review_3_0.0001_40 \\\n",
    "            --overwrite_output_dir\n",
    "\n",
    "```\n",
    "to submit the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d66faa",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a59ce8",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d0ea0",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aca2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Installing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c67d08f",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f63ec02",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38a59b1",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c4d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloning into 'PowerfulPromptFT'...\r\nremote: Enumerating objects: 737, done.\u001b[K\r\nremote: Counting objects:   0% (1/737)\u001b[K\rremote: Counting objects:   1% (8/737)\u001b[K\rremote: Counting objects:   2% (15/737)\u001b[K\rremote: Counting objects:   3% (23/737)\u001b[K\rremote: Counting objects:   4% (30/737)\u001b[K\rremote: Counting objects:   5% (37/737)\u001b[K\rremote: Counting objects:   6% (45/737)\u001b[K\rremote: Counting objects:   7% (52/737)\u001b[K\rremote: Counting objects:   8% (59/737)\u001b[K\rremote: Counting objects:   9% (67/737)\u001b[K\rremote: Counting objects:  10% (74/737)\u001b[K\rremote: Counting objects:  11% (82/737)\u001b[K\rremote: Counting objects:  12% (89/737)\u001b[K\rremote: Counting objects:  13% (96/737)\u001b[K\rremote: Counting objects:  14% (104/737)\u001b[K\rremote: Counting objects:  15% (111/737)\u001b[K\rremote: Counting objects:  16% (118/737)\u001b[K\rremote: Counting objects:  17% (126/737)\u001b[K\rremote: Counting objects:  18% (133/737)\u001b[K\rremote: Counting objects:  19% (141/737)\u001b[K\rremote: Counting objects:  20% (148/737)\u001b[K\rremote: Counting objects:  21% (155/737)\u001b[K\rremote: Counting objects:  22% (163/737)\u001b[K\rremote: Counting objects:  23% (170/737)\u001b[K\rremote: Counting objects:  24% (177/737)\u001b[K\rremote: Counting objects:  25% (185/737)\u001b[K\rremote: Counting objects:  26% (192/737)\u001b[K\rremote: Counting objects:  27% (199/737)\u001b[K\rremote: Counting objects:  28% (207/737)\u001b[K\rremote: Counting objects:  29% (214/737)\u001b[K\rremote: Counting objects:  30% (222/737)\u001b[K\rremote: Counting objects:  31% (229/737)\u001b[K\rremote: Counting objects:  32% (236/737)\u001b[K\rremote: Counting objects:  33% (244/737)\u001b[K\rremote: Counting objects:  34% (251/737)\u001b[K\rremote: Counting objects:  35% (258/737)\u001b[K\rremote: Counting objects:  36% (266/737)\u001b[K\rremote: Counting objects:  37% (273/737)\u001b[K\rremote: Counting objects:  38% (281/737)\u001b[K\rremote: Counting objects:  39% (288/737)\u001b[K\rremote: Counting objects:  40% (295/737)\u001b[K\rremote: Counting objects:  41% (303/737)\u001b[K\rremote: Counting objects:  42% (310/737)\u001b[K\rremote: Counting objects:  43% (317/737)\u001b[K\rremote: Counting objects:  44% (325/737)\u001b[K\rremote: Counting objects:  45% (332/737)\u001b[K\rremote: Counting objects:  46% (340/737)\u001b[K\rremote: Counting objects:  47% (347/737)\u001b[K\rremote: Counting objects:  48% (354/737)\u001b[K\rremote: Counting objects:  49% (362/737)\u001b[K\rremote: Counting objects:  50% (369/737)\u001b[K\rremote: Counting objects:  51% (376/737)\u001b[K\rremote: Counting objects:  52% (384/737)\u001b[K\rremote: Counting objects:  53% (391/737)\u001b[K\rremote: Counting objects:  54% (398/737)\u001b[K\rremote: Counting objects:  55% (406/737)\u001b[K\rremote: Counting objects:  56% (413/737)\u001b[K\rremote: Counting objects:  57% (421/737)\u001b[K\rremote: Counting objects:  58% (428/737)\u001b[K\rremote: Counting objects:  59% (435/737)\u001b[K\rremote: Counting objects:  60% (443/737)\u001b[K\rremote: Counting objects:  61% (450/737)\u001b[K\rremote: Counting objects:  62% (457/737)\u001b[K\rremote: Counting objects:  63% (465/737)\u001b[K\rremote: Counting objects:  64% (472/737)\u001b[K\rremote: Counting objects:  65% (480/737)\u001b[K\rremote: Counting objects:  66% (487/737)\u001b[K\rremote: Counting objects:  67% (494/737)\u001b[K\rremote: Counting objects:  68% (502/737)\u001b[K\rremote: Counting objects:  69% (509/737)\u001b[K\rremote: Counting objects:  70% (516/737)\u001b[K\rremote: Counting objects:  71% (524/737)\u001b[K\rremote: Counting objects:  72% (531/737)\u001b[K\rremote: Counting objects:  73% (539/737)\u001b[K\rremote: Counting objects:  74% (546/737)\u001b[K\rremote: Counting objects:  75% (553/737)\u001b[K\rremote: Counting objects:  76% (561/737)\u001b[K\rremote: Counting objects:  77% (568/737)\u001b[K\rremote: Counting objects:  78% (575/737)\u001b[K\rremote: Counting objects:  79% (583/737)\u001b[K\rremote: Counting objects:  80% (590/737)\u001b[K\rremote: Counting objects:  81% (597/737)\u001b[K\rremote: Counting objects:  82% (605/737)\u001b[K\rremote: Counting objects:  83% (612/737)\u001b[K\rremote: Counting objects:  84% (620/737)\u001b[K\rremote: Counting objects:  85% (627/737)\u001b[K\rremote: Counting objects:  86% (634/737)\u001b[K\rremote: Counting objects:  87% (642/737)\u001b[K\rremote: Counting objects:  88% (649/737)\u001b[K\rremote: Counting objects:  89% (656/737)\u001b[K\rremote: Counting objects:  90% (664/737)\u001b[K\rremote: Counting objects:  91% (671/737)\u001b[K\rremote: Counting objects:  92% (679/737)\u001b[K\rremote: Counting objects:  93% (686/737)\u001b[K\rremote: Counting objects:  94% (693/737)\u001b[K\rremote: Counting objects:  95% (701/737)\u001b[K\rremote: Counting objects:  96% (708/737)\u001b[K\rremote: Counting objects:  97% (715/737)\u001b[K\rremote: Counting objects:  98% (723/737)\u001b[K\rremote: Counting objects:  99% (730/737)\u001b[K\rremote: Counting objects: 100% (737/737)\u001b[K\rremote: Counting objects: 100% (737/737), done.\u001b[K\r\nremote: Compressing objects:   0% (1/631)\u001b[K\rremote: Compressing objects:   1% (7/631)\u001b[K\rremote: Compressing objects:   2% (13/631)\u001b[K\rremote: Compressing objects:   3% (19/631)\u001b[K\rremote: Compressing objects:   4% (26/631)\u001b[K\rremote: Compressing objects:   5% (32/631)\u001b[K\rremote: Compressing objects:   6% (38/631)\u001b[K\rremote: Compressing objects:   7% (45/631)\u001b[K\rremote: Compressing objects:   8% (51/631)\u001b[K\rremote: Compressing objects:   9% (57/631)\u001b[K\rremote: Compressing objects:  10% (64/631)\u001b[K\rremote: Compressing objects:  11% (70/631)\u001b[K\rremote: Compressing objects:  12% (76/631)\u001b[K\rremote: Compressing objects:  13% (83/631)\u001b[K\rremote: Compressing objects:  14% (89/631)\u001b[K\rremote: Compressing objects:  15% (95/631)\u001b[K\rremote: Compressing objects:  16% (101/631)\u001b[K\rremote: Compressing objects:  17% (108/631)\u001b[K\rremote: Compressing objects:  18% (114/631)\u001b[K\rremote: Compressing objects:  19% (120/631)\u001b[K\rremote: Compressing objects:  20% (127/631)\u001b[K\rremote: Compressing objects:  21% (133/631)\u001b[K\rremote: Compressing objects:  22% (139/631)\u001b[K\rremote: Compressing objects:  23% (146/631)\u001b[K\rremote: Compressing objects:  24% (152/631)\u001b[K\rremote: Compressing objects:  25% (158/631)\u001b[K\rremote: Compressing objects:  26% (165/631)\u001b[K\rremote: Compressing objects:  27% (171/631)\u001b[K\rremote: Compressing objects:  28% (177/631)\u001b[K\rremote: Compressing objects:  29% (183/631)\u001b[K\rremote: Compressing objects:  30% (190/631)\u001b[K\rremote: Compressing objects:  31% (196/631)\u001b[K\rremote: Compressing objects:  32% (202/631)\u001b[K\rremote: Compressing objects:  33% (209/631)\u001b[K\rremote: Compressing objects:  34% (215/631)\u001b[K\rremote: Compressing objects:  35% (221/631)\u001b[K\rremote: Compressing objects:  36% (228/631)\u001b[K\rremote: Compressing objects:  37% (234/631)\u001b[K\rremote: Compressing objects:  38% (240/631)\u001b[K\rremote: Compressing objects:  39% (247/631)\u001b[K\rremote: Compressing objects:  40% (253/631)\u001b[K\rremote: Compressing objects:  41% (259/631)\u001b[K\rremote: Compressing objects:  42% (266/631)\u001b[K\rremote: Compressing objects:  43% (272/631)\u001b[K\rremote: Compressing objects:  44% (278/631)\u001b[K\rremote: Compressing objects:  45% (284/631)\u001b[K\rremote: Compressing objects:  46% (291/631)\u001b[K\rremote: Compressing objects:  47% (297/631)\u001b[K\rremote: Compressing objects:  48% (303/631)\u001b[K\rremote: Compressing objects:  49% (310/631)\u001b[K\rremote: Compressing objects:  50% (316/631)\u001b[K\rremote: Compressing objects:  51% (322/631)\u001b[K\rremote: Compressing objects:  52% (329/631)\u001b[K\rremote: Compressing objects:  53% (335/631)\u001b[K\rremote: Compressing objects:  54% (341/631)\u001b[K\rremote: Compressing objects:  55% (348/631)\u001b[K\rremote: Compressing objects:  56% (354/631)\u001b[K\rremote: Compressing objects:  57% (360/631)\u001b[K\rremote: Compressing objects:  58% (366/631)\u001b[K\rremote: Compressing objects:  59% (373/631)\u001b[K\rremote: Compressing objects:  60% (379/631)\u001b[K\rremote: Compressing objects:  61% (385/631)\u001b[K\rremote: Compressing objects:  62% (392/631)\u001b[K\rremote: Compressing objects:  63% (398/631)\u001b[K\rremote: Compressing objects:  64% (404/631)\u001b[K\rremote: Compressing objects:  65% (411/631)\u001b[K\rremote: Compressing objects:  66% (417/631)\u001b[K\rremote: Compressing objects:  67% (423/631)\u001b[K\rremote: Compressing objects:  68% (430/631)\u001b[K\rremote: Compressing objects:  69% (436/631)\u001b[K\rremote: Compressing objects:  70% (442/631)\u001b[K\rremote: Compressing objects:  71% (449/631)\u001b[K\rremote: Compressing objects:  72% (455/631)\u001b[K\rremote: Compressing objects:  73% (461/631)\u001b[K\rremote: Compressing objects:  74% (467/631)\u001b[K\rremote: Compressing objects:  75% (474/631)\u001b[K\rremote: Compressing objects:  76% (480/631)\u001b[K\rremote: Compressing objects:  77% (486/631)\u001b[K\rremote: Compressing objects:  78% (493/631)\u001b[K\rremote: Compressing objects:  79% (499/631)\u001b[K\rremote: Compressing objects:  80% (505/631)\u001b[K\rremote: Compressing objects:  81% (512/631)\u001b[K\rremote: Compressing objects:  82% (518/631)\u001b[K\rremote: Compressing objects:  83% (524/631)\u001b[K\rremote: Compressing objects:  84% (531/631)\u001b[K\rremote: Compressing objects:  85% (537/631)\u001b[K\rremote: Compressing objects:  86% (543/631)\u001b[K\rremote: Compressing objects:  87% (549/631)\u001b[K\rremote: Compressing objects:  88% (556/631)\u001b[K\rremote: Compressing objects:  89% (562/631)\u001b[K\rremote: Compressing objects:  90% (568/631)\u001b[K\rremote: Compressing objects:  91% (575/631)\u001b[K\rremote: Compressing objects:  92% (581/631)\u001b[K\rremote: Compressing objects:  93% (587/631)\u001b[K\rremote: Compressing objects:  94% (594/631)\u001b[K\rremote: Compressing objects:  95% (600/631)\u001b[K\rremote: Compressing objects:  96% (606/631)\u001b[K\rremote: Compressing objects:  97% (613/631)\u001b[K\rremote: Compressing objects:  98% (619/631)\u001b[K\rremote: Compressing objects:  99% (625/631)\u001b[K\rremote: Compressing objects: 100% (631/631)\u001b[K\rremote: Compressing objects: 100% (631/631), done.\u001b[K\r\nReceiving objects:   0% (1/737)\rReceiving objects:   1% (8/737)\rReceiving objects:   2% (15/737)\rReceiving objects:   3% (23/737)\rReceiving objects:   4% (30/737)\rReceiving objects:   5% (37/737)\rReceiving objects:   6% (45/737)\rReceiving objects:   7% (52/737)\rReceiving objects:   8% (59/737)\rReceiving objects:   9% (67/737)\rReceiving objects:  10% (74/737)\rReceiving objects:  11% (82/737)\rReceiving objects:  12% (89/737)\rReceiving objects:  13% (96/737)\rReceiving objects:  14% (104/737)\rReceiving objects:  15% (111/737)\rReceiving objects:  16% (118/737)\rReceiving objects:  17% (126/737)\rReceiving objects:  18% (133/737)\rReceiving objects:  19% (141/737)\rReceiving objects:  20% (148/737)\rReceiving objects:  21% (155/737)\rReceiving objects:  22% (163/737), 9.53 MiB | 19.05 MiB/s\rReceiving objects:  23% (170/737), 9.53 MiB | 19.05 MiB/s\rReceiving objects:  24% (177/737), 9.53 MiB | 19.05 MiB/s\rReceiving objects:  25% (185/737), 9.53 MiB | 19.05 MiB/s\rReceiving objects:  26% (192/737), 9.53 MiB | 19.05 MiB/s\rReceiving objects:  27% (199/737), 9.53 MiB | 19.05 MiB/s\rReceiving objects:  28% (207/737), 9.53 MiB | 19.05 MiB/s\rReceiving objects:  29% (214/737), 9.53 MiB | 19.05 MiB/s\rReceiving objects:  29% (215/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  30% (222/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  31% (229/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  32% (236/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  33% (244/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  34% (251/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  35% (258/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  36% (266/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  37% (273/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  38% (281/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  39% (288/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  40% (295/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  41% (303/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  42% (310/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  43% (317/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  44% (325/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  45% (332/737), 18.13 MiB | 18.12 MiB/s\rReceiving objects:  46% (340/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  47% (347/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  48% (354/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  49% (362/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  50% (369/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  51% (376/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  52% (384/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  53% (391/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  54% (398/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  55% (406/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  56% (413/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  57% (421/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  58% (428/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  59% (435/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  60% (443/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  61% (450/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  62% (457/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  63% (465/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  64% (472/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  65% (480/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  66% (487/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  67% (494/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  68% (502/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  69% (509/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  70% (516/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  71% (524/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  72% (531/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  73% (539/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  74% (546/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  75% (553/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  76% (561/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  77% (568/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  78% (575/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  79% (583/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  80% (590/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  81% (597/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  82% (605/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  83% (612/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  84% (620/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  85% (627/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  86% (634/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  87% (642/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  88% (649/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  89% (656/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  90% (664/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  91% (671/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  92% (679/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  93% (686/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  94% (693/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  95% (701/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  96% (708/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  97% (715/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  98% (723/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects:  99% (730/737), 27.72 MiB | 18.48 MiB/s\rremote: Total 737 (delta 138), reused 681 (delta 102), pack-reused 0 (from 0)\u001b[K\r\nReceiving objects: 100% (737/737), 27.72 MiB | 18.48 MiB/s\rReceiving objects: 100% (737/737), 34.94 MiB | 18.70 MiB/s, done.\r\nResolving deltas:   0% (0/138)\rResolving deltas:   1% (2/138)\rResolving deltas:   2% (3/138)\rResolving deltas:   4% (6/138)\rResolving deltas:   5% (7/138)\rResolving deltas:   6% (9/138)\rResolving deltas:   7% (11/138)\rResolving deltas:   8% (12/138)\rResolving deltas:   9% (13/138)\rResolving deltas:  11% (16/138)\rResolving deltas:  12% (17/138)\rResolving deltas:  13% (18/138)\rResolving deltas:  14% (20/138)\rResolving deltas:  15% (21/138)\rResolving deltas:  16% (23/138)\rResolving deltas:  17% (24/138)\rResolving deltas:  18% (25/138)\rResolving deltas:  19% (27/138)\rResolving deltas:  21% (29/138)\rResolving deltas:  22% (31/138)\rResolving deltas:  23% (32/138)\rResolving deltas:  24% (34/138)\rResolving deltas:  25% (35/138)\rResolving deltas:  26% (36/138)\rResolving deltas:  27% (38/138)\rResolving deltas:  28% (39/138)\rResolving deltas:  29% (41/138)\rResolving deltas:  30% (42/138)\rResolving deltas:  31% (43/138)\rResolving deltas:  32% (45/138)\rResolving deltas:  33% (46/138)\rResolving deltas:  34% (47/138)\rResolving deltas:  35% (49/138)\rResolving deltas:  36% (50/138)\rResolving deltas:  37% (52/138)\rResolving deltas:  38% (53/138)\rResolving deltas:  39% (54/138)\rResolving deltas:  40% (56/138)\rResolving deltas:  42% (58/138)\rResolving deltas:  43% (60/138)\rResolving deltas:  44% (61/138)\rResolving deltas:  45% (63/138)\rResolving deltas:  47% (65/138)\rResolving deltas:  48% (67/138)\rResolving deltas:  49% (68/138)\rResolving deltas:  50% (70/138)\rResolving deltas:  51% (71/138)\rResolving deltas:  52% (72/138)\rResolving deltas:  53% (74/138)\rResolving deltas:  54% (75/138)\rResolving deltas:  55% (76/138)\rResolving deltas:  56% (78/138)\rResolving deltas:  57% (80/138)\rResolving deltas:  58% (81/138)\rResolving deltas:  59% (82/138)\rResolving deltas:  60% (83/138)\rResolving deltas:  61% (85/138)\rResolving deltas:  62% (86/138)\rResolving deltas:  63% (87/138)\rResolving deltas:  64% (89/138)\rResolving deltas:  65% (90/138)\rResolving deltas:  66% (92/138)\rResolving deltas:  67% (93/138)\rResolving deltas:  68% (94/138)\rResolving deltas:  69% (96/138)\rResolving deltas:  70% (97/138)\rResolving deltas:  71% (98/138)\rResolving deltas:  72% (100/138)\rResolving deltas:  73% (101/138)\rResolving deltas:  74% (103/138)\rResolving deltas:  75% (104/138)\rResolving deltas:  76% (105/138)\rResolving deltas:  77% (107/138)\rResolving deltas:  78% (108/138)\rResolving deltas:  79% (110/138)\rResolving deltas:  80% (111/138)\rResolving deltas:  81% (112/138)\rResolving deltas:  82% (114/138)\rResolving deltas:  83% (115/138)\rResolving deltas:  84% (116/138)\rResolving deltas:  85% (118/138)\rResolving deltas:  86% (119/138)\rResolving deltas:  87% (121/138)\rResolving deltas:  88% (122/138)\rResolving deltas:  89% (123/138)\rResolving deltas:  90% (125/138)\rResolving deltas:  91% (126/138)\rResolving deltas:  92% (127/138)\rResolving deltas:  93% (129/138)\rResolving deltas:  94% (130/138)\rResolving deltas:  95% (132/138)\rResolving deltas:  96% (133/138)\rResolving deltas:  97% (134/138)\rResolving deltas:  98% (136/138)\rResolving deltas:  99% (137/138)\rResolving deltas: 100% (138/138)\rResolving deltas: 100% (138/138), done.\r\nUpdating files:  41% (234/561)\rUpdating files:  42% (236/561)\rUpdating files:  43% (242/561)\rUpdating files:  44% (247/561)\rUpdating files:  45% (253/561)\rUpdating files:  46% (259/561)\rUpdating files:  47% (264/561)\rUpdating files:  48% (270/561)\rUpdating files:  49% (275/561)\rUpdating files:  50% (281/561)\rUpdating files:  51% (287/561)\rUpdating files:  52% (292/561)\rUpdating files:  53% (298/561)\rUpdating files:  54% (303/561)\rUpdating files:  55% (309/561)\rUpdating files:  56% (315/561)\rUpdating files:  57% (320/561)\rUpdating files:  58% (326/561)\rUpdating files:  59% (331/561)\rUpdating files:  60% (337/561)\rUpdating files:  61% (343/561)\rUpdating files:  62% (348/561)\rUpdating files:  63% (354/561)\rUpdating files:  64% (360/561)\rUpdating files:  65% (365/561)\rUpdating files:  66% (371/561)\rUpdating files:  67% (376/561)\rUpdating files:  68% (382/561)\rUpdating files:  69% (388/561)\rUpdating files:  70% (393/561)\rUpdating files:  71% (399/561)\rUpdating files:  72% (404/561)\rUpdating files:  73% (410/561)\rUpdating files:  74% (416/561)\rUpdating files:  75% (421/561)\rUpdating files:  76% (427/561)\rUpdating files:  77% (432/561)\rUpdating files:  78% (438/561)\rUpdating files:  79% (444/561)\rUpdating files:  80% (449/561)\rUpdating files:  81% (455/561)\rUpdating files:  82% (461/561)\rUpdating files:  83% (466/561)\rUpdating files:  84% (472/561)\rUpdating files:  85% (477/561)\rUpdating files:  86% (483/561)\rUpdating files:  87% (489/561)\rUpdating files:  88% (494/561)\rUpdating files:  89% (500/561)\rUpdating files:  90% (505/561)\rUpdating files:  91% (511/561)\rUpdating files:  92% (517/561)\rUpdating files:  93% (522/561)\rUpdating files:  94% (528/561)\rUpdating files:  95% (533/561)\rUpdating files:  96% (539/561)\rUpdating files:  97% (545/561)\rUpdating files:  98% (550/561)\rUpdating files:  99% (556/561)\rUpdating files: 100% (561/561)\rUpdating files: 100% (561/561), done.\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/ZhengxiangShi/PowerfulPromptFT.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7548f2aa",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b2730",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881c2290",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35be8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\r\n\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\nCollecting evaluate\r\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\r\nCollecting datasets>=2.0.0 (from evaluate)\r\n  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\r\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from evaluate) (1.25.2)\r\nCollecting dill (from evaluate)\r\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from evaluate) (2.0.3)\r\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/site-packages (from evaluate) (2.31.0)\r\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/site-packages (from evaluate) (4.66.4)\r\nCollecting xxhash (from evaluate)\r\n  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\nCollecting multiprocess (from evaluate)\r\n  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\r\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.6.0)\r\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/site-packages (from evaluate) (0.23.3)\r\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from evaluate) (24.1)\r\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\r\nCollecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\r\n  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\r\nCollecting requests>=2.19.0 (from evaluate)\r\n  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\r\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\r\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\r\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\r\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.7)\r\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.6.2)\r\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\r\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\r\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\r\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\r\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\r\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\r\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\r\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\r\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\r\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\r\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/527.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/134.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m208.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m137.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/39.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/39.9 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/39.9 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/39.9 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/39.9 MB\u001b[0m \u001b[31m141.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/39.9 MB\u001b[0m \u001b[31m166.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m29.5/39.9 MB\u001b[0m \u001b[31m159.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m36.5/39.9 MB\u001b[0m \u001b[31m193.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m180.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hInstalling collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets, evaluate\r\n  Attempting uninstall: requests\r\n    Found existing installation: requests 2.31.0\r\n    Uninstalling requests-2.31.0:\r\n      Successfully uninstalled requests-2.31.0\r\nSuccessfully installed datasets-2.21.0 dill-0.3.8 evaluate-0.4.2 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 xxhash-3.5.0\r\n\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\nCollecting accelerate\r\n  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\r\nRequirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/site-packages (from accelerate) (1.25.2)\r\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from accelerate) (24.1)\r\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate) (5.9.8)\r\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from accelerate) (6.0.1)\r\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/site-packages (from accelerate) (2.2.1+cpu)\r\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/site-packages (from accelerate) (0.23.3)\r\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from accelerate) (0.4.3)\r\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\r\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.6.0)\r\nRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\r\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\r\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\r\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\r\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\r\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.1.1)\r\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\r\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.6.2)\r\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\nDownloading accelerate-0.33.0-py3-none-any.whl (315 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/315.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m194.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hInstalling collected packages: accelerate\r\nSuccessfully installed accelerate-0.33.0\r\n\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\nCollecting transformers==4.20.1\r\n  Downloading transformers-4.20.1-py3-none-any.whl.metadata (77 kB)\r\n\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers==4.20.1) (3.15.1)\r\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.20.1) (0.23.3)\r\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.20.1) (1.25.2)\r\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.20.1) (24.1)\r\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.20.1) (6.0.1)\r\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.20.1) (2023.12.25)\r\nRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers==4.20.1) (2.32.3)\r\nCollecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.20.1)\r\n  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.5 kB)\r\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers==4.20.1) (4.66.4)\r\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (2023.6.0)\r\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (4.12.2)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.20.1) (2.1.1)\r\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.20.1) (3.7)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.20.1) (2.0.7)\r\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.20.1) (2024.6.2)\r\nDownloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/4.4 MB\u001b[0m \u001b[31m176.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/4.4 MB\u001b[0m \u001b[31m176.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/4.4 MB\u001b[0m \u001b[31m176.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/4.4 MB\u001b[0m \u001b[31m176.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/4.4 MB\u001b[0m \u001b[31m176.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/4.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/6.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m6.4/6.6 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hInstalling collected packages: tokenizers, transformers\r\n  Attempting uninstall: tokenizers\r\n    Found existing installation: tokenizers 0.19.1\r\n    Uninstalling tokenizers-0.19.1:\r\n      Successfully uninstalled tokenizers-0.19.1\r\n  Attempting uninstall: transformers\r\n    Found existing installation: transformers 4.40.2\r\n    Uninstalling transformers-4.40.2:\r\n      Successfully uninstalled transformers-4.40.2\r\nSuccessfully installed tokenizers-0.12.1 transformers-4.20.1\r\n\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install evaluate\n",
    "!pip install accelerate\n",
    "!pip install transformers==4.20.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d0f4f3",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb9119",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219bd8c",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c0913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/PowerfulPromptFT\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd PowerfulPromptFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5487116f",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db6665d",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e9457",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609fc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a4f92",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550bf4d3",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71208adf",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ca250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/PowerfulPromptFT\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/PowerfulPromptFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7f427",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd560d2",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9a25ec",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ffa11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2801e48f",
   "metadata": {},
   "source": [
    "### Step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f78b0d5",
   "metadata": {},
   "source": [
    "Execution Start time: 05:55:34, End time: 05:55:35 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19777d6",
   "metadata": {},
   "source": [
    "**Thought**: Now that we are in the correct directory, let's open the `run_prompt_ft.py` script to understand how the dataset is being loaded and where we might need to make modifications to load only the first 10 examples and set the labeled and unlabeled data indices as specified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df717e38",
   "metadata": {},
   "source": [
    "**Action (open)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09569970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/run_prompt_ft.py (468 lines total)]\n1:\"\"\" Finetuning the models for sequence classification on downstream tasks.\"\"\"\n2:\n3:import os\n4:import json\n5:import sys\n6:import copy\n7:import tqdm\n8:import random\n9:import logging\n10:import numpy as np\n11:from dataclasses import dataclass, field\n12:from typing import Optional, Callable, Dict\n13:\n14:import torch\n15:from src.processors import num_labels_mapping, output_modes_mapping, compute_metrics_mapping, evaluate_metrics_mapping\n16:from src.model import RobertaForPromptingClassification\n17:from src.dataset import SemiLMDatasetSequenceClassification, DartDatasetSequenceClassification\n18:from transformers import InputExample\n19:\n20:import evaluate\n21:import transformers\n22:from transformers import (\n23:    RobertaTokenizer,\n24:    EvalPrediction,\n25:    HfArgumentParser,\n26:    Trainer,\n27:    TrainingArguments,\n28:    default_data_collator,\n29:    set_seed,\n30:)\n31:from transformers.trainer_utils import get_last_checkpoint\n32:\n33:\n34:logger = logging.getLogger(__name__)\n35:\n36:\n37:@dataclass\n38:class DataTrainingArguments:\n39:    \"\"\"\n40:    Arguments pertaining to what data we are going to input our model for training and eval.\n41:\n42:    Using `HfArgumentParser` we can turn this class\n43:    into argparse arguments to be able to specify them on\n44:    the command line.\n45:    \"\"\"\n46:    train_embedding_first: bool = field(default=False, metadata={\"help\": \"Whether train the embeddings of the model first.\"})\n47:    downstream_task_name: Optional[str] = field(\n48:        default=None,\n49:        metadata={\"help\": \"The name of the task to train on\"},\n50:    )\n51:    task_name: Optional[str] = field(\n52:        default=None,\n53:        metadata={\"help\": \"The name of the task to train on.\"},\n54:    )\n55:    dataset_name: Optional[str] = field(\n56:        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n57:    )\n58:    dataset_config_name: Optional[str] = field(\n59:        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n60:    )\n61:    max_seq_length: int = field(\n62:        default=128,\n63:        metadata={\n64:            \"help\": (\n65:                \"The maximum total input sequence length after tokenization. Sequences longer \"\n66:                \"than this will be truncated, sequences shorter will be padded.\"\n67:            )\n68:        },\n69:    )\n70:    overwrite_cache: bool = field(\n71:        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n72:    )\n73:    truncate_head: bool = field(\n74:        default=False, metadata={\"help\": \"Truncate the head or tail of the sequence.\"}\n75:    )\n76:    pad_to_max_length: bool = field(\n77:        default=True,\n78:        metadata={\n79:            \"help\": (\n80:                \"Whether to pad all samples to `max_seq_length`. \"\n81:                \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n82:            )\n83:        },\n84:    )\n85:    max_train_samples: Optional[int] = field(\n86:        default=None,\n87:        metadata={\n88:            \"help\": (\n89:                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n90:                \"value if set.\"\n91:            )\n92:        },\n93:    )\n94:    max_eval_samples: Optional[int] = field(\n95:        default=None,\n96:        metadata={\n97:            \"help\": (\n98:                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n99:                \"value if set.\"\n100:            )\n(368 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open run_prompt_ft.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2de22",
   "metadata": {},
   "source": [
    "### Step 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c5a54",
   "metadata": {},
   "source": [
    "Execution Start time: 05:55:37, End time: 05:55:37 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b914d5",
   "metadata": {},
   "source": [
    "**Thought**: The `run_prompt_ft.py` script is quite extensive. We need to locate the section where the dataset is being loaded and processed. This will help us modify it to load only the first 10 examples and set the labeled and unlabeled data indices as specified.\n",
    "\n",
    "Let's search for keywords like \"load\", \"dataset\", or \"data\" to quickly find the relevant section in the script.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43eff1",
   "metadata": {},
   "source": [
    "**Action (search_file)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb04b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bash: line 1: syntax error near unexpected token `\"dataset\"'\nbash: line 1: `source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"dataset\")'\nError: CalledProcessError: Command 'b'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"dataset\")\\n'' returned non-zero exit status 2.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[32], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"dataset\")\\n')\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"dataset\")\\n'' returned non-zero exit status 2."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_file(\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6984d5",
   "metadata": {},
   "source": [
    "### Step 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989b5431",
   "metadata": {},
   "source": [
    "Execution Start time: 05:55:41, End time: 05:55:41 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05911b2e",
   "metadata": {},
   "source": [
    "**Thought**: It seems there was an error with the search command. Let's try searching for the term \"data\" instead, which might help us locate the relevant section for dataset loading and processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d5db6",
   "metadata": {},
   "source": [
    "**Action (search_file)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ecaafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bash: line 1: syntax error near unexpected token `\"data\"'\nbash: line 1: `source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"data\")'\nError: CalledProcessError: Command 'b'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"data\")\\n'' returned non-zero exit status 2.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[34], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"data\")\\n')\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"data\")\\n'' returned non-zero exit status 2."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_file(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650b5df",
   "metadata": {},
   "source": [
    "### Step 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bba1b0",
   "metadata": {},
   "source": [
    "Execution Start time: 05:55:43, End time: 05:55:44 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c54ea3d",
   "metadata": {},
   "source": [
    "**Thought**: It seems there is an issue with the search command. Let's try scrolling through the file manually to locate the section where the dataset is being loaded. This will help us identify where to make the necessary modifications.\n",
    "\n",
    "I'll scroll down to explore more of the file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f37f4e",
   "metadata": {},
   "source": [
    "**Action (scroll_down)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc040af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/run_prompt_ft.py (468 lines total)]\n(98 more lines above)\n99:                \"value if set.\"\n100:            )\n101:        },\n102:    )\n103:    max_predict_samples: Optional[int] = field(\n104:        default=None,\n105:        metadata={\n106:            \"help\": (\n107:                \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n108:                \"value if set.\"\n109:            )\n110:        },\n111:    )\n112:    num_labelled_data: Optional[int] = field(\n113:        default=None,\n114:        metadata={\n115:            \"help\": (\n116:                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n117:                \"value if set.\"\n118:            )\n119:        },\n120:    )\n121:    train_file: Optional[str] = field(\n122:        default=None, metadata={\"help\": \"A csv or a json file containing the training data.\"}\n123:    )\n124:    validation_file: Optional[str] = field(\n125:        default=None, metadata={\"help\": \"A csv or a json file containing the validation data.\"}\n126:    )\n127:    test_file: Optional[str] = field(\n128:        default=None, metadata={\"help\": \"A csv or a json file containing the test data.\"}\n129:    )\n130:    task_type: str = field(default=\"glue\", metadata={\"help\": \"The type of the task.\"})\n131:\n132:\n133:@dataclass\n134:class ModelArguments:\n135:    \"\"\"\n136:    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n137:    \"\"\"\n138:\n139:    model_name_or_path: str = field(\n140:        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n141:    )\n142:    model_type: str = field(\n143:        default=\"prompting\",\n144:        metadata={\"help\": \"Select prompting, dart, or mask for the model type\"},\n145:    )\n146:    config_name: Optional[str] = field(\n147:        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n148:    )\n149:    tokenizer_name: Optional[str] = field(\n150:        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n151:    )\n152:    cache_dir: Optional[str] = field(\n153:        default=None,\n154:        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n155:    )\n156:    use_fast_tokenizer: bool = field(\n157:        default=True,\n158:        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n159:    )\n160:    model_revision: str = field(\n161:        default=\"main\",\n162:        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n163:    )\n164:    use_auth_token: bool = field(\n165:        default=False,\n166:        metadata={\n167:            \"help\": (\n168:                \"Will use the token generated when running `huggingface-cli login` (necessary to use this script \"\n169:                \"with private models).\"\n170:            )\n171:        },\n172:    )\n173:    ignore_mismatched_sizes: bool = field(\n174:        default=False,\n175:        metadata={\"help\": \"Will enable to load a pretrained model whose head dimensions are different.\"},\n176:    )\n177:    eb_learning_rate: float = field(default=1e-5, metadata={\"help\": \"The initial learning rate for AdamW for embedding training.\"})\n178:    eb_num_train_epochs: float = field(default=5.0, metadata={\"help\": \"Total number of training epochs to perform for embedding training.\"})\n179:    run_pseduo_label: bool = field(default=False, metadata={\"help\": \"Whether to run pseudo label.\"})\n180:\n181:\n182:def main():\n183:    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n184:    if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n185:        model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n186:    else:\n187:        model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n188:    \n189:    logger.info(f\"Runing task_type: {data_args.task_type}\")\n190:    if data_args.task_type == \"glue\":\n191:        training_args.metric_for_best_model = evaluate_metrics_mapping[data_args.downstream_task_name]\n192:        training_args.greater_is_better = True\n193:        logger.info(\"metric_for_best_model is set to {}\".format(training_args.metric_for_best_model))\n194:    else:\n195:        training_args.metric_for_best_model = \"eval_f1\"\n196:        training_args.greater_is_better = True\n197:        logger.info(\"metric_for_best_model is set to {}\".format(training_args.metric_for_best_model))\n198:\n(270 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scroll_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002409e3",
   "metadata": {},
   "source": [
    "### Step 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a787d3b",
   "metadata": {},
   "source": [
    "Execution Start time: 05:55:45, End time: 05:55:46 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b8243",
   "metadata": {},
   "source": [
    "**Thought**: We are getting closer to the main function where the script execution begins. Let's scroll down further to find the section where the dataset is being loaded and processed. This will help us make the necessary modifications to load only the first 10 examples and set the labeled and unlabeled data indices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5db288",
   "metadata": {},
   "source": [
    "**Action (scroll_down)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a290ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/run_prompt_ft.py (468 lines total)]\n(196 more lines above)\n197:        logger.info(\"metric_for_best_model is set to {}\".format(training_args.metric_for_best_model))\n198:\n199:    # Detecting last checkpoint.\n200:    last_checkpoint = None\n201:    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n202:        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n203:        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n204:            raise ValueError(\n205:                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n206:                \"Use --overwrite_output_dir to overcome.\"\n207:            )\n208:        elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n209:            logger.info(\n210:                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n211:                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n212:            )\n213:\n214:    # Setup logging\n215:    if not os.path.exists(training_args.output_dir):\n216:        os.makedirs(training_args.output_dir)\n217:\n218:    logging.basicConfig(\n219:        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n220:        datefmt=\"%m/%d/%Y %H:%M:%S\",\n221:        handlers=[logging.FileHandler(os.path.join(training_args.output_dir, 'output.log'), mode='w'),\n222:                  logging.StreamHandler(sys.stdout)],\n223:    )\n224:\n225:    log_level = training_args.get_process_log_level()\n226:    logger.setLevel(log_level)\n227:    transformers.utils.logging.set_verbosity(log_level)\n228:    transformers.utils.logging.enable_default_handler()\n229:    transformers.utils.logging.enable_explicit_format()\n230:\n231:    # Log on each process the small summary:\n232:    logger.warning(\n233:        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n234:        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n235:    )\n236:    logger.info(f\"Training/evaluation parameters {training_args}\")\n237:\n238:    # Set seed before initializing model.\n239:    set_seed(training_args.seed)\n240:    data_args.seed = training_args.seed\n241:\n242:    try:\n243:        num_labels = num_labels_mapping[data_args.downstream_task_name.lower()]\n244:        output_mode = output_modes_mapping[data_args.downstream_task_name.lower()]\n245:        logger.info(\"Task name: {}, number of labels: {}, output mode: {}\".format(data_args.downstream_task_name, num_labels, output_mode))\n246:    except KeyError:\n247:        raise ValueError(\"Task not found: %s\" % (data_args.downstream_task_name))\n248:\n249:    # Loading a dataset from your local files.\n250:    data_files = {\"train\": data_args.train_file, \"validation\": data_args.validation_file, \"test\": data_args.test_file}\n251:    for key in data_files.keys():\n252:        logger.info(f\"load a local file for {key}: {data_files[key]}\")\n253:\n254:    # Load tokenizer\n255:    tokenizer = RobertaTokenizer.from_pretrained(\n256:        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n257:        cache_dir=model_args.cache_dir,\n258:        use_fast=model_args.use_fast_tokenizer,\n259:        revision=model_args.model_revision,\n260:        use_auth_token=True if model_args.use_auth_token else None,\n261:    )\n262:    logger.info(f'before {len(tokenizer)}')\n263:\n264:    # Preprocessing the raw_datasets\n265:    if model_args.model_type == \"prompting\":\n266:        ModelSpecificDataset = SemiLMDatasetSequenceClassification\n267:    elif model_args.model_type == \"dart\":\n268:        ModelSpecificDataset = DartDatasetSequenceClassification\n269:    else:\n270:        raise NotImplementedError(f\"model type {model_args.model_type} is not implemented\")\n271:\n272:    train_dataset, eval_dataset, predict_dataset = None, None, None\n273:    if training_args.do_train:\n274:        train_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"train\"], mode=\"train\")\n275:    if training_args.do_eval:\n276:        eval_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"validation\"], mode=\"dev\")\n277:    if training_args.do_predict:\n278:        if model_args.run_pseduo_label:\n279:            # We use train and dev set with pseduo label for mlm training\n280:            predict_dataset_train = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"pseudo_train\")\n281:            predict_dataset_dev = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"pseudo_dev\")\n282:        else:\n283:            # Otherwise, we use test set for reuglar evaluation\n284:            predict_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"test\")\n285:    processed_dataset = train_dataset if train_dataset is not None else eval_dataset if eval_dataset is not None else predict_dataset\n286:    logger.info(f'after {len(tokenizer)}')\n287:    if model_args.model_type == \"dart\":\n288:        logger.info(f'pattern: {processed_dataset.pattern}')\n289:\n290:    # Load pretrained model\n291:    if model_args.model_type == \"prompting\" or model_args.model_type == \"dart\":\n292:        model = RobertaForPromptingClassification.from_pretrained(model_args.model_name_or_path)\n293:    else:\n294:        raise NotImplementedError(f\"model type {model_args.model_type} is not implemented\")\n295:\n296:    model.mlm_logits_to_cls_logits_tensor = processed_dataset.mlm_logits_to_cls_logits_tensor\n(172 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scroll_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581729d0",
   "metadata": {},
   "source": [
    "### Step 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7424070",
   "metadata": {},
   "source": [
    "Execution Start time: 05:55:49, End time: 05:55:49 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9edd351",
   "metadata": {},
   "source": [
    "**Thought**: We have found the section where the dataset is being loaded and processed. The datasets are being loaded using the `ModelSpecificDataset` class, which is likely defined elsewhere in the codebase. We need to modify this process to load only the first 10 examples and set the labeled and unlabeled data indices.\n",
    "\n",
    "Let's search for the definition of `ModelSpecificDataset` to understand how it processes the data and where we can make the necessary changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c119a2",
   "metadata": {},
   "source": [
    "**Action (search_file)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe28022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bash: line 1: syntax error near unexpected token `\"class ModelSpecificDataset\"'\nbash: line 1: `source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"class ModelSpecificDataset\")'\nError: CalledProcessError: Command 'b'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"class ModelSpecificDataset\")\\n'' returned non-zero exit status 2.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[40], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"class ModelSpecificDataset\")\\n')\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"class ModelSpecificDataset\")\\n'' returned non-zero exit status 2."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_file(\"class ModelSpecificDataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b6731",
   "metadata": {},
   "source": [
    "### Step 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8928e79",
   "metadata": {},
   "source": [
    "Execution Start time: 05:55:50, End time: 05:55:51 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e9e8a",
   "metadata": {},
   "source": [
    "**Thought**: It seems there is an issue with the search command. Let's try searching for the term \"ModelSpecificDataset\" without the \"class\" keyword to locate its definition and understand how it processes the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0da42",
   "metadata": {},
   "source": [
    "**Action (search_file)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70fee91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bash: line 1: syntax error near unexpected token `\"ModelSpecificDataset\"'\nbash: line 1: `source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"ModelSpecificDataset\")'\nError: CalledProcessError: Command 'b'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"ModelSpecificDataset\")\\n'' returned non-zero exit status 2.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[42], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"ModelSpecificDataset\")\\n')\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"ModelSpecificDataset\")\\n'' returned non-zero exit status 2."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_file(\"ModelSpecificDataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33fba72",
   "metadata": {},
   "source": [
    "### Step 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2529f6c9",
   "metadata": {},
   "source": [
    "Execution Start time: 05:55:52, End time: 05:55:53 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd0dc24",
   "metadata": {},
   "source": [
    "**Thought**: It seems there is a persistent issue with the search command. Let's try a different approach by listing the files in the directory to identify where the `ModelSpecificDataset` class might be defined. This will help us locate the file and make the necessary modifications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6258171c",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b8e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LICENSE    config_roberta    run_cls_ft.py     run_st.py    src\nREADME.md  data\t\t     run_mlm.py        semilearn\nasset\t   requirements.txt  run_prompt_ft.py  sh_examples\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2e080",
   "metadata": {},
   "source": [
    "### Step 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783a65f4",
   "metadata": {},
   "source": [
    "Execution Start time: 05:55:54, End time: 05:55:55 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f16968",
   "metadata": {},
   "source": [
    "**Thought**: The `src` directory likely contains the source code where the `ModelSpecificDataset` class might be defined. Let's explore the `src` directory to locate the file containing this class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27335e0",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89cbfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convert_to_pretrain_pcp.py     data_collator.py\t\tmodel.py\nconvert_to_pretrain_tapt_1.py  dataset.py\t\tprocessors.py\nconvert_to_pretrain_tapt_2.py  generate_k_shot_data.py\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ls src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43d001",
   "metadata": {},
   "source": [
    "### Step 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60471f9",
   "metadata": {},
   "source": [
    "Execution Start time: 05:55:57, End time: 05:55:57 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e117f",
   "metadata": {},
   "source": [
    "**Thought**: The `dataset.py` file is likely where the `ModelSpecificDataset` class is defined. Let's open this file to examine its contents and identify where we can make the necessary modifications to load only the first 10 examples and set the labeled and unlabeled data indices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb205ce2",
   "metadata": {},
   "source": [
    "**Action (open)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4be40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/src/dataset.py (500 lines total)]\n1:\"\"\"Dataset utils for different data settings for 21 different datasets.\"\"\"\n2:\n3:import os\n4:import json\n5:import logging\n6:import torch\n7:import time\n8:import tqdm\n9:import dataclasses\n10:from dataclasses import dataclass\n11:from src.processors import processors_mapping, map_of_mapping, template_mapping\n12:from transformers.data.processors.utils import InputFeatures\n13:from transformers import GPT2Tokenizer, RobertaTokenizer, InputExample\n14:from typing import Tuple, List, Optional, Union\n15:\n16:logger = logging.getLogger(__name__)\n17:\n18:\n19:@dataclass(frozen=True)\n20:class OurInputFeatures(InputFeatures):\n21:    \"\"\"\n22:    A single set of features of data. Property names are the same names as the corresponding inputs to a model.\n23:    \"\"\"\n24:\n25:    input_ids: List[int]\n26:    attention_mask: Optional[List[int]] = None\n27:    token_type_ids: Optional[List[int]] = None\n28:    label: Optional[Union[int, float]] = None\n29:    mlms: Optional[List[int]] = None\n30:\n31:    def to_json_string(self):\n32:        \"\"\"Serializes this instance to a JSON string.\"\"\"\n33:        return json.dumps(dataclasses.asdict(self)) + \"\\n\"\n34:\n35:      \n36:class SemiLMDatasetSequenceClassification(torch.utils.data.Dataset):\n37:    \"\"\"Few-shot dataset.\"\"\"\n38:    def __init__(self, args, tokenizer, file_path, mode=\"train\"):\n39:        self.args = args\n40:        self.task_name = args.downstream_task_name\n41:        self.processor = processors_mapping[self.task_name.lower()]\n42:        self.tokenizer = tokenizer\n43:        self.kwargs = {'add_prefix_space': True} if isinstance(self.tokenizer, GPT2Tokenizer) or isinstance(self.tokenizer, RobertaTokenizer) else {}\n44:        self.mode = mode\n45:        self.file_path = file_path\n46:\n47:        # assert mode in [\"train\", \"dev\", \"test\"]\n48:\n49:        self.max_length = args.max_seq_length\n50:\n51:        # Get label list and its mapping to word\n52:        self.label_to_word = map_of_mapping[self.task_name]\n53:        self.word_to_label = {v: k for k, v in self.label_to_word.items()}\n54:        self.label_map = {label: i for i, label in enumerate(self.label_to_word.keys())}\n55:        self.build_mlm_logits_to_cls_logits_tensor(self.get_label_words())\n56:\n57:        # Load cache\n58:        cache_path, file_name = os.path.split(self.file_path)\n59:        file_name = file_name.split(\".\")[0]\n60:\n61:        logger.info(f\"Creating examples from dataset file at {self.file_path}\")\n62:        \n63:        start = time.time()\n64:\n65:        if self.mode == \"train\" and self.task_name in [\"aclImdb\", \"ag_news\", \"yelp_review\", \"yahoo_answers\", \"amazon_review\", \"reverse_SST-2\"]:\n66:            self.examples = self.processor.get_train_examples(self.file_path, seed=self.args.seed, num_labelled_data=self.args.num_labelled_data)\n67:        elif self.mode == \"train\":\n68:            self.examples = self.processor.get_train_examples(self.file_path)\n69:        elif self.mode == \"dev\":\n70:            self.examples = self.processor.get_dev_examples(self.file_path)\n71:        elif self.mode == \"test\":\n72:            self.examples = self.processor.get_test_examples(self.file_path)\n73:        elif \"pseudo\" in self.mode:\n74:            if \"train\" in self.mode:\n75:                self.examples = self.processor.get_psuedo_examples(os.path.join(self.file_path, \"train.json\"))\n76:            elif \"dev\" in self.mode:\n77:                self.examples = self.processor.get_psuedo_examples(os.path.join(self.file_path, \"dev.json\"))\n78:        else:\n79:            raise ValueError(\"Invalid mode: %s\" % self.mode)\n80:\n81:        logger.info(f\"Creating {self.mode} features from dataset file at {self.file_path}\")\n82:\n83:        self.features = []\n84:\n85:        for ex in tqdm.tqdm(self.examples, desc=\"Creating {} features\".format(self.mode)):\n86:                self.features.append(self.convert_fn(ex))\n87:\n88:        self.num_sample = len(self.features)\n89:        logger.info(\"Getting {} {} samples in total.\".format(self.num_sample, self.mode))\n90:\n91:    def __len__(self):\n92:        return len(self.features)\n93:\n94:    def __getitem__(self, i):\n95:        return {\"input_ids\": self.features[i].input_ids,\n96:                \"attention_mask\": self.features[i].attention_mask,\n97:                \"labels\": self.features[i].label,\n98:                \"mlms\": self.features[i].mlms}\n99:\n100:    def enc(self, label):\n(400 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open src/dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300bdbd1",
   "metadata": {},
   "source": [
    "### Step 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e63af",
   "metadata": {},
   "source": [
    "Execution Start time: 05:55:59, End time: 05:55:59 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9576d1",
   "metadata": {},
   "source": [
    "**Thought**: The `SemiLMDatasetSequenceClassification` class in `dataset.py` is responsible for loading and processing the dataset. We can modify this class to load only the first 10 examples and set the labeled and unlabeled data indices.\n",
    "\n",
    "Let's scroll down to see more of the class definition and find the best place to make these modifications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c44abc",
   "metadata": {},
   "source": [
    "**Action (scroll_down)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f544e34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/src/dataset.py (500 lines total)]\n(98 more lines above)\n99:\n100:    def enc(self, label):\n101:        return self.tokenizer.encode(label, add_special_tokens=False, **self.kwargs)\n102:    \n103:    def get_label_words(self):\n104:        return list(self.label_to_word.values())\n105:\n106:    def convert_fn(self, example):\n107:        \"\"\"\n108:        Returns a list of processed \"InputFeatures\".\n109:        \"\"\"\n110:        input_ids, token_type_ids = self.encode(example)\n111:        if self.task_name.lower() == \"sts-b\":\n112:            # STS-B is a regression task\n113:            label = float(example.label)\n114:        else:\n115:            label = self.label_map[example.label] if example.label is not None else None\n116:\n117:        mlm_label = [-100] * len(input_ids)\n118:        if self.task_name.lower() == \"sts-b\":\n119:            # STS-B is a regression task\n120:            hard_label = '0' if float(example.label) <= 2.5 else '1'\n121:            new_label = self.enc(self.label_to_word[hard_label])\n122:        else:\n123:            new_label = self.enc(self.label_to_word[example.label]) if example.label is not None else [1]\n124:        assert len(new_label) == 1\n125:        mlm_index = input_ids.index(self.tokenizer.mask_token_id)\n126:        mlm_label[mlm_index] = new_label[0]\n127:        attention_mask = [1] * len(input_ids)\n128:\n129:        # Pad\n130:        while len(input_ids) < self.max_length:\n131:            input_ids.append(self.tokenizer.pad_token_id)\n132:            attention_mask.append(0)\n133:            mlm_label.append(-100)\n134:\n135:        assert len(input_ids) == self.max_length\n136:        assert len(attention_mask) == self.max_length\n137:        assert len(mlm_label) == self.max_length\n138:        assert sum([1 if i > 0 else 0 for i in mlm_label])\n139:        \n140:        return OurInputFeatures(\n141:            input_ids=input_ids,\n142:            attention_mask=attention_mask,\n143:            label=label,\n144:            mlms=mlm_label,\n145:        )\n146:\n147:    def encode(self, example: InputExample, priming: bool = False, labeled: bool = False) \\\n148:            -> Tuple[List[int], List[int]]:\n149:        \"\"\"\n150:        Encode an input example using this pattern-verbalizer pair.\n151:\n152:        :param example: the input example to encode\n153:        :param priming: whether to use this example for priming\n154:        :param labeled: if ``priming=True``, whether the label should be appended to this example\n155:        :return: A tuple, consisting of a list of input ids and a list of token type ids\n156:        \"\"\"\n157:\n158:        parts_a, parts_b = self.get_parts(example)\n159:\n160:        parts_a = [x if isinstance(x, tuple) else (x, False) for x in parts_a]\n161:        parts_a = [(self.tokenizer.encode(x, add_special_tokens=False, **self.kwargs), s) for x, s in parts_a if x]\n162:\n163:        if parts_b:\n164:            parts_b = [x if isinstance(x, tuple) else (x, False) for x in parts_b]\n165:            parts_b = [(self.tokenizer.encode(x, add_special_tokens=False, **self.kwargs), s) for x, s in parts_b if x]\n166:\n167:        num_special = self.tokenizer.num_special_tokens_to_add(bool(parts_b))\n168:        self.truncate(parts_a, parts_b, max_length=self.max_length - num_special)\n169:\n170:        tokens_a = [token_id for part, _ in parts_a for token_id in part]\n171:        tokens_b = [token_id for part, _ in parts_b for token_id in part] if parts_b else []\n172:\n173:        if tokens_b:\n174:            input_ids = self.tokenizer.build_inputs_with_special_tokens(tokens_a, tokens_b)\n175:            token_type_ids = self.tokenizer.create_token_type_ids_from_sequences(tokens_a, tokens_b)\n176:        else:\n177:            input_ids = self.tokenizer.build_inputs_with_special_tokens(tokens_a)\n178:            token_type_ids = self.tokenizer.create_token_type_ids_from_sequences(tokens_a)\n179:\n180:        return input_ids, token_type_ids\n181:    \n182:    def get_parts(self, example: InputExample):\n183:        text_a = self.shortenable(example.text_a)\n184:        text_b = self.shortenable(example.text_b)\n185:        return template_mapping[self.task_name](text_a, text_b, self.tokenizer)\n186:        # return [text_a, text_b, \"In summary, the movie is\", self.tokenizer.mask_token], []\n187:        # return [self.tokenizer.mask_token, ':', text_a, text_b], []\n188:        \n189:    def shortenable(self, s):\n190:        \"\"\"Return an instance of this string that is marked as shortenable\"\"\"\n191:        return s, True\n192:    \n193:    def _seq_length(self, parts: List[Tuple[str, bool]], only_shortenable: bool = False):\n194:        return sum([len(x) for x, shortenable in parts if not only_shortenable or shortenable]) if parts else 0\n195:\n196:    def _remove_last(self, parts: List[Tuple[str, bool]]):\n197:        last_idx = max(idx for idx, (seq, shortenable) in enumerate(parts) if shortenable and seq)\n198:        parts[last_idx] = (parts[last_idx][0][:-1], parts[last_idx][1])\n(302 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scroll_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c926a",
   "metadata": {},
   "source": [
    "### Step 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513982a6",
   "metadata": {},
   "source": [
    "Execution Start time: 05:56:01, End time: 05:56:02 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2931cb2d",
   "metadata": {},
   "source": [
    "**Thought**: The `SemiLMDatasetSequenceClassification` class contains methods for encoding and processing input examples. However, we haven't yet found where the dataset is initially loaded. Let's scroll further to see if there are any methods or sections related to loading or initializing the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6ff08",
   "metadata": {},
   "source": [
    "**Action (scroll_down)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd32661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/src/dataset.py (500 lines total)]\n(196 more lines above)\n197:        last_idx = max(idx for idx, (seq, shortenable) in enumerate(parts) if shortenable and seq)\n198:        parts[last_idx] = (parts[last_idx][0][:-1], parts[last_idx][1])\n199:\n200:    def truncate(self, parts_a: List[Tuple[str, bool]], parts_b: List[Tuple[str, bool]], max_length: int):\n201:        \"\"\"Truncate two sequences of text to a predefined total maximum length\"\"\"\n202:        total_len = self._seq_length(parts_a) + self._seq_length(parts_b)\n203:        total_len += self.tokenizer.num_special_tokens_to_add(bool(parts_b))\n204:        num_tokens_to_remove = total_len - max_length\n205:\n206:        if num_tokens_to_remove <= 0:\n207:            return parts_a, parts_b\n208:\n209:        for _ in range(num_tokens_to_remove):\n210:            if self._seq_length(parts_a, only_shortenable=True) > self._seq_length(parts_b, only_shortenable=True):\n211:                self._remove_last(parts_a)\n212:            else:\n213:                self._remove_last(parts_b)\n214:\n215:    def build_mlm_logits_to_cls_logits_tensor(self, labels: List[str]):\n216:        self.mlm_logits_to_cls_logits_tensor = torch.zeros(len(labels), dtype=torch.long, requires_grad=False)\n217:        for i, label in enumerate(labels):\n218:            self.mlm_logits_to_cls_logits_tensor[i] = self.get_verbalization_ids(label, force_single_token=True)\n219:    \n220:    def get_verbalization_ids(self, word: str, force_single_token: bool) -> Union[int, List[int]]:\n221:        \"\"\"\n222:        Get the token ids corresponding to a verbalization\n223:\n224:        :param word: the verbalization\n225:        :param tokenizer: the tokenizer to use\n226:        :param force_single_token: whether it should be enforced that the verbalization corresponds to a single token.\n227:            If set to true, this method returns a single int instead of a list and throws an error if the word\n228:            corresponds to multiple tokens.\n229:        :return: either the list of token ids or the single token id corresponding to this word\n230:        \"\"\"\n231:        ids = self.tokenizer.encode(word, add_special_tokens=False, **self.kwargs)\n232:        if not force_single_token:\n233:            return ids\n234:        assert len(ids) == 1, \\\n235:            f'Verbalization \"{word}\" does not correspond to a single token, got {self.tokenizer.convert_ids_to_tokens(ids)}'\n236:        verbalization_id = ids[0]\n237:        assert verbalization_id not in self.tokenizer.all_special_ids, \\\n238:            f'Verbalization {word} is mapped to a special token {self.tokenizer.convert_ids_to_tokens(verbalization_id)}'\n239:        return verbalization_id\n240:\n241:\n242:class DartDatasetSequenceClassification(torch.utils.data.Dataset):\n243:    \"\"\"Dataset for sequence classification tasks with DART\"\"\"\n244:\n245:    def __init__(self, args, tokenizer, file_path, mode=\"train\"):\n246:        self.args = args\n247:        self.task_name = args.downstream_task_name\n248:        self.processor = processors_mapping[self.task_name.lower()]\n249:        self.tokenizer = tokenizer\n250:        self.kwargs = {'add_prefix_space': True} if isinstance(self.tokenizer, GPT2Tokenizer) or isinstance(self.tokenizer, RobertaTokenizer) else {}\n251:        assert isinstance(self.tokenizer, RobertaTokenizer), \"Only RobertaTokenizer is supported for now\"\n252:        self.mode = mode\n253:        self.file_path = file_path\n254:        self.max_length = args.max_seq_length\n255:\n256:        # assert mode in [\"train\", \"dev\", \"test\", \"\"]\n257:\n258:        # Get label list and its mapping to word\n259:        self.label_to_word = map_of_mapping[self.task_name]\n260:        self.word_to_label = {v: k for k, v in self.label_to_word.items()}\n261:        self.label_map = {label: i for i, label in enumerate(self.label_to_word.keys())}\n262:\n263:        self.pattern_index = []\n264:        self.mlm_label_index = []\n265:\n266:        # self.pattern = \"In summary, it is\"\n267:        if self.task_name in ['SST-2', 'sst-5', 'mr', 'cr', 'mpqa', 'subj', 'trec', 'CoLA', \"aclImdb\", \"ag_news\", \"yelp_review\", \"yahoo_answers\", \"amazon_review\", \"reverse_SST-2\"]:\n268:            # For single sentence tasks\n269:            self.pattern = \"It was\"\n270:        elif self.task_name in ['MRPC', 'QQP', 'STS-B', 'MNLI', 'SNLI', 'QNLI', 'RTE', 'MNLI-mm']:\n271:            # For pair sentence tasks\n272:            self.pattern = \",\"\n273:\n274:        # Resize model embedding to accommodate the new tokens\n275:        # new_id = self.tokenizer.vocab_size\n276:        if isinstance(self.tokenizer, RobertaTokenizer):\n277:            new_id = 50265\n278:        else:\n279:            raise NotImplementedError\n280:\n281:        # Set new id for pattern\n282:        pattern_token_ids = self.enc(self.pattern)\n283:        for origin_id in pattern_token_ids:\n284:            self.pattern_index.append([origin_id, new_id])\n285:            new_id += 1\n286:\n287:        # Set new id for label\n288:        self.word_to_new_label = {}\n289:        for origin_word in self.word_to_label.keys():\n290:            origin_label_id = self.enc(origin_word)\n291:            assert len(origin_label_id) == 1\n292:            origin_label_id = origin_label_id[0]\n293:            self.mlm_label_index.append([origin_label_id, new_id])\n294:            self.word_to_new_label[origin_word] = new_id\n295:            new_id += 1\n296:\n(204 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scroll_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189453f",
   "metadata": {},
   "source": [
    "### Step 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e351181c",
   "metadata": {},
   "source": [
    "Execution Start time: 05:56:04, End time: 05:56:04 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99362cbe",
   "metadata": {},
   "source": [
    "**Thought**: The `DartDatasetSequenceClassification` class is responsible for initializing and processing the dataset. We can modify the initialization process to load only the first 10 examples and set the labeled and unlabeled data indices.\n",
    "\n",
    "Let's scroll further to see if there are any specific methods or sections related to loading or initializing the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf7d50",
   "metadata": {},
   "source": [
    "**Action (scroll_down)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd1ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/src/dataset.py (500 lines total)]\n(294 more lines above)\n295:            new_id += 1\n296:\n297:        # Add custom tokens, where tokenizer.vocab_size will not be affected\n298:        if mode == \"train\":\n299:            num_new_tokens = len(self.pattern_index) + len(self.mlm_label_index)\n300:            custom_tokens = ['<my_token{}>'.format(str(i+1)) for i in range(num_new_tokens)]\n301:            num_added_tokens = tokenizer.add_tokens(custom_tokens)\n302:            logger.info('We have added {} tokens'.format(num_added_tokens))\n303:\n304:        self.pattern_index_ids = [x[1] for x in self.pattern_index]\n305:        self.mlm_logits_to_cls_logits_tensor = torch.tensor([x[1] for x in self.mlm_label_index], dtype=torch.long, requires_grad=False)\n306:\n307:        # Load cache\n308:        cache_path, file_name = os.path.split(self.file_path)\n309:        file_name = file_name.split(\".\")[0]\n310:\n311:        # cached_features_file = os.path.join(\n312:        #     cache_path,\n313:        #     \"fine_tuning_cached_{}_{}_{}_{}\".format(\n314:        #         mode,\n315:        #         tokenizer.__class__.__name__,\n316:        #         str(args.max_seq_length),\n317:        #         file_name,\n318:        #     ),\n319:        # )\n320:\n321:        logger.info(f\"Creating examples from dataset file at {self.file_path}\")\n322:        if self.mode == \"train\" and self.task_name in [\"aclImdb\", \"ag_news\", \"yelp_review\", \"yahoo_answers\", \"amazon_review\", \"reverse_SST-2\"]:\n323:            self.examples = self.processor.get_train_examples(self.file_path, seed=self.args.seed, num_labelled_data=self.args.num_labelled_data)\n324:        elif self.mode == \"train\":\n325:            self.examples = self.processor.get_train_examples(self.file_path)\n326:        elif self.mode == \"dev\":\n327:            self.examples = self.processor.get_dev_examples(self.file_path)\n328:        elif self.mode == \"test\":\n329:            self.examples = self.processor.get_test_examples(self.file_path)\n330:        elif \"pseudo\" in self.mode:\n331:            if \"train\" in self.mode:\n332:                self.examples = self.processor.get_psuedo_examples(os.path.join(self.file_path, \"train.json\"))\n333:            elif \"dev\" in self.mode:\n334:                self.examples = self.processor.get_psuedo_examples(os.path.join(self.file_path, \"dev.json\"))\n335:        else:\n336:            raise ValueError(\"Invalid mode: %s\" % self.mode)\n337:\n338:        logger.info(f\"Creating {self.mode} features from dataset file at {self.file_path}\")\n339:\n340:        self.features = []\n341:\n342:        for ex in tqdm.tqdm(self.examples, desc=\"Creating {} features\".format(self.mode)):\n343:                self.features.append(self.convert_fn(ex))\n344:\n345:        logger.info(\"Getting {} {} samples in total.\".format(len(self.features), self.mode))\n346:\n347:    def __len__(self):\n348:        return len(self.features)\n349:\n350:    def __getitem__(self, i):\n351:        return {\"input_ids\": self.features[i].input_ids,\n352:                \"attention_mask\": self.features[i].attention_mask,\n353:                \"labels\": self.features[i].label,\n354:                \"mlms\": self.features[i].mlms}\n355:\n356:    def enc(self, label):\n357:        return self.tokenizer.encode(label, add_special_tokens=False, **self.kwargs)\n358:\n359:    def convert_fn(self, example):\n360:        \"\"\"\n361:        Returns a list of processed \"InputFeatures\".\n362:        \"\"\"\n363:        \n364:        input_ids, token_type_ids = self.encode(example)\n365:        if self.task_name.lower() == \"sts-b\":\n366:            # STS-B is a regression task\n367:            label = float(example.label)\n368:        else:\n369:            label = self.label_map[example.label] if example.label is not None else None\n370:\n371:        mlm_label = [-100] * len(input_ids)\n372:        if self.task_name.lower() == \"sts-b\":\n373:            # STS-B is a regression task\n374:            hard_label = '0' if float(example.label) <= 2.5 else '1'\n375:            new_label = self.word_to_new_label[self.label_to_word[hard_label]]\n376:        else:        \n377:            new_label = self.word_to_new_label[self.label_to_word[example.label]] if example.label is not None else 1\n378:        mlm_index = input_ids.index(self.tokenizer.mask_token_id)\n379:        mlm_label[mlm_index] = new_label\n380:        attention_mask = [1] * len(input_ids)\n381:\n382:        # Pad\n383:        while len(input_ids) < self.max_length:\n384:            input_ids.append(self.tokenizer.pad_token_id)\n385:            attention_mask.append(0)\n386:            mlm_label.append(-100)\n387:\n388:        assert len(input_ids) == self.max_length\n389:        assert len(attention_mask) == self.max_length\n390:        assert len(mlm_label) == self.max_length\n391:        assert sum([1 if i > 0 else 0 for i in mlm_label])\n392:        \n393:        return OurInputFeatures(\n394:            input_ids=input_ids,\n(106 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scroll_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac855ff5",
   "metadata": {},
   "source": [
    "### Step 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79788ca",
   "metadata": {},
   "source": [
    "Execution Start time: 05:56:11, End time: 05:56:14 (duration: 2 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a86c67",
   "metadata": {},
   "source": [
    "**Thought**: We have found the section where the dataset examples are being loaded and processed. The examples are being fetched using methods like `get_train_examples`, `get_dev_examples`, and `get_test_examples`. We need to modify this process to load only the first 10 examples and set the labeled and unlabeled data indices.\n",
    "\n",
    "Let's edit the file to implement these changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fbedea",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e802e07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/src/dataset.py (505 lines total)]\n(271 more lines above)\n272:            self.pattern = \",\"\n273:\n274:        # Resize model embedding to accommodate the new tokens\n275:        # new_id = self.tokenizer.vocab_size\n276:        if isinstance(self.tokenizer, RobertaTokenizer):\n277:            new_id = 50265\n278:        else:\n279:            raise NotImplementedError\n280:\n281:        # Set new id for pattern\n282:        pattern_token_ids = self.enc(self.pattern)\n283:        for origin_id in pattern_token_ids:\n284:            self.pattern_index.append([origin_id, new_id])\n285:            new_id += 1\n286:\n287:        # Set new id for label\n288:        self.word_to_new_label = {}\n289:        for origin_word in self.word_to_label.keys():\n290:            origin_label_id = self.enc(origin_word)\n291:            assert len(origin_label_id) == 1\n292:            origin_label_id = origin_label_id[0]\n293:            self.mlm_label_index.append([origin_label_id, new_id])\n294:            self.word_to_new_label[origin_word] = new_id\n295:            new_id += 1\n296:\n297:        # Add custom tokens, where tokenizer.vocab_size will not be affected\n298:        if mode == \"train\":\n299:            num_new_tokens = len(self.pattern_index) + len(self.mlm_label_index)\n300:            custom_tokens = ['<my_token{}>'.format(str(i+1)) for i in range(num_new_tokens)]\n301:            num_added_tokens = tokenizer.add_tokens(custom_tokens)\n302:            logger.info('We have added {} tokens'.format(num_added_tokens))\n303:\n304:        self.pattern_index_ids = [x[1] for x in self.pattern_index]\n305:        self.mlm_logits_to_cls_logits_tensor = torch.tensor([x[1] for x in self.mlm_label_index], dtype=torch.long, requires_grad=False)\n306:\n307:        # Load cache\n308:        cache_path, file_name = os.path.split(self.file_path)\n309:        file_name = file_name.split(\".\")[0]\n310:\n311:        # cached_features_file = os.path.join(\n312:        #     cache_path,\n313:        #     \"fine_tuning_cached_{}_{}_{}_{}\".format(\n314:        #         mode,\n315:        #         tokenizer.__class__.__name__,\n316:        #         str(args.max_seq_length),\n317:        #         file_name,\n318:        #     ),\n319:        # )\n320:\n321:        logger.info(f\"Creating examples from dataset file at {self.file_path}\")\n322:        logger.info(f\"Creating examples from dataset file at {self.file_path}\")\n323:        if self.mode == \"train\" and self.task_name in [\"aclImdb\", \"ag_news\", \"yelp_review\", \"yahoo_answers\", \"amazon_review\", \"reverse_SST-2\"]:\n324:            self.examples = self.processor.get_train_examples(self.file_path, seed=self.args.seed, num_labelled_data=self.args.num_labelled_data)[:10]\n325:        elif self.mode == \"train\":\n326:            self.examples = self.processor.get_train_examples(self.file_path)[:10]\n327:        elif self.mode == \"dev\":\n328:            self.examples = self.processor.get_dev_examples(self.file_path)[:10]\n329:        elif self.mode == \"test\":\n330:            self.examples = self.processor.get_test_examples(self.file_path)[:10]\n331:        elif \"pseudo\" in self.mode:\n332:            if \"train\" in self.mode:\n333:                self.examples = self.processor.get_psuedo_examples(os.path.join(self.file_path, \"train.json\"))[:10]\n334:            elif \"dev\" in self.mode:\n335:                self.examples = self.processor.get_psuedo_examples(os.path.join(self.file_path, \"dev.json\"))[:10]\n336:        else:\n337:            raise ValueError(\"Invalid mode: %s\" % self.mode)\n338:\n339:        # Set labeled and unlabeled data indices\n340:        labeled_indices = [0, 1, 2, 3]\n341:        unlabeled_indices = [4, 5, 6, 7, 8, 9]\n342:\n343:        logger.info(f\"Creating {self.mode} features from dataset file at {self.file_path}\")\n344:\n345:        self.features = []\n346:\n347:        for ex in tqdm.tqdm(self.examples, desc=\"Creating {} features\".format(self.mode)):\n348:            self.features.append(self.convert_fn(ex))\n349:\n350:        logger.info(\"Getting {} {} samples in total.\".format(len(self.features), self.mode))\n351:\n352:    def __len__(self):\n353:        return len(self.features)\n354:\n355:    def __getitem__(self, i):\n356:        return {\"input_ids\": self.features[i].input_ids,\n357:                \"attention_mask\": self.features[i].attention_mask,\n358:                \"labels\": self.features[i].label,\n359:                \"mlms\": self.features[i].mlms}\n360:\n361:    def enc(self, label):\n362:        return self.tokenizer.encode(label, add_special_tokens=False, **self.kwargs)\n363:\n364:    def convert_fn(self, example):\n365:        \"\"\"\n366:        Returns a list of processed \"InputFeatures\".\n367:        \"\"\"\n368:        \n369:        input_ids, token_type_ids = self.encode(example)\n370:        if self.task_name.lower() == \"sts-b\":\n371:            # STS-B is a regression task\n(134 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 322:345\n",
    "        logger.info(f\"Creating examples from dataset file at {self.file_path}\")\n",
    "        if self.mode == \"train\" and self.task_name in [\"aclImdb\", \"ag_news\", \"yelp_review\", \"yahoo_answers\", \"amazon_review\", \"reverse_SST-2\"]:\n",
    "            self.examples = self.processor.get_train_examples(self.file_path, seed=self.args.seed, num_labelled_data=self.args.num_labelled_data)[:10]\n",
    "        elif self.mode == \"train\":\n",
    "            self.examples = self.processor.get_train_examples(self.file_path)[:10]\n",
    "        elif self.mode == \"dev\":\n",
    "            self.examples = self.processor.get_dev_examples(self.file_path)[:10]\n",
    "        elif self.mode == \"test\":\n",
    "            self.examples = self.processor.get_test_examples(self.file_path)[:10]\n",
    "        elif \"pseudo\" in self.mode:\n",
    "            if \"train\" in self.mode:\n",
    "                self.examples = self.processor.get_psuedo_examples(os.path.join(self.file_path, \"train.json\"))[:10]\n",
    "            elif \"dev\" in self.mode:\n",
    "                self.examples = self.processor.get_psuedo_examples(os.path.join(self.file_path, \"dev.json\"))[:10]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode: %s\" % self.mode)\n",
    "\n",
    "        # Set labeled and unlabeled data indices\n",
    "        labeled_indices = [0, 1, 2, 3]\n",
    "        unlabeled_indices = [4, 5, 6, 7, 8, 9]\n",
    "\n",
    "        logger.info(f\"Creating {self.mode} features from dataset file at {self.file_path}\")\n",
    "\n",
    "        self.features = []\n",
    "\n",
    "        for ex in tqdm.tqdm(self.examples, desc=\"Creating {} features\".format(self.mode)):\n",
    "            self.features.append(self.convert_fn(ex))\n",
    "\n",
    "        logger.info(\"Getting {} {} samples in total.\".format(len(self.features), self.mode))\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d675da8",
   "metadata": {},
   "source": [
    "### Step 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3d12e",
   "metadata": {},
   "source": [
    "Execution Start time: 05:56:18, End time: 05:56:47 (duration: 29 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87927f19",
   "metadata": {},
   "source": [
    "**Thought**: The modifications to load only the first 10 examples and set the labeled and unlabeled data indices have been made successfully. Now, let's proceed to run the `run_prompt_ft.py` script with the specified parameters to perform prompt-based fine-tuning on the amazon_review dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf38b43",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a7302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "08/22/2024 05:56:41 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n08/22/2024 05:56:41 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n_n_gpu=0,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=True,\ndo_train=True,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=1,\nevaluation_strategy=IntervalStrategy.STEPS,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_min_num_params=0,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngreater_is_better=True,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=HubStrategy.EVERY_SAVE,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=0.0001,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=-1,\nlog_level=-1,\nlog_level_replica=-1,\nlog_on_each_node=True,\nlogging_dir=saved_ssl/prompting_amazon_review_3_0.0001_40/runs/Aug22_05-56-41_modal,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=IntervalStrategy.STEPS,\nlr_scheduler_type=SchedulerType.LINEAR,\nmax_grad_norm=1.0,\nmax_steps=1,\nmetric_for_best_model=eval_f1,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=OptimizerNames.ADAMW_HF,\noutput_dir=saved_ssl/prompting_amazon_review_3_0.0001_40,\noverwrite_output_dir=True,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard'],\nresume_from_checkpoint=None,\nrun_name=saved_ssl/prompting_amazon_review_3_0.0001_40,\nsave_on_each_node=False,\nsave_steps=1,\nsave_strategy=IntervalStrategy.STEPS,\nsave_total_limit=1,\nseed=3,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nwarmup_ratio=0.06,\nwarmup_steps=0,\nweight_decay=0.01,\nxpu_backend=None,\n)\n08/22/2024 05:56:41 - INFO - __main__ - Task name: amazon_review, number of labels: 5, output mode: classification\n08/22/2024 05:56:41 - INFO - __main__ - load a local file for train: data/amazon_review\n08/22/2024 05:56:41 - INFO - __main__ - load a local file for validation: data/amazon_review\n08/22/2024 05:56:41 - INFO - __main__ - load a local file for test: data/amazon_review\n[INFO|hub.py:592] 2024-08-22 05:56:41,689 >> https://huggingface.co/roberta-base/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp32iz1qwf\n\nDownloading:   0%|                                   | 0.00/878k [00:00<?, ?B/s]\nDownloading:   3%|▊                          | 25.0k/878k [00:00<00:03, 235kB/s]\nDownloading:  10%|██▋                        | 89.0k/878k [00:00<00:01, 445kB/s]\nDownloading:  27%|███████▋                    | 241k/878k [00:00<00:00, 881kB/s]\n\n\n[INFO|hub.py:596] 2024-08-22 05:56:42,274 >> storing https://huggingface.co/roberta-base/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n[INFO|hub.py:604] 2024-08-22 05:56:42,274 >> creating metadata file for /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n[INFO|hub.py:592] 2024-08-22 05:56:42,412 >> https://huggingface.co/roberta-base/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpi5n2d6m3\n\nDownloading:   0%|                                   | 0.00/446k [00:00<?, ?B/s]\nDownloading:   7%|█▉                         | 33.0k/446k [00:00<00:01, 313kB/s]\nDownloading:  22%|█████▉                     | 97.0k/446k [00:00<00:00, 475kB/s]\nDownloading:  54%|███████████████▏            | 241k/446k [00:00<00:00, 862kB/s]\n\n[INFO|hub.py:596] 2024-08-22 05:56:42,884 >> storing https://huggingface.co/roberta-base/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n[INFO|hub.py:604] 2024-08-22 05:56:42,884 >> creating metadata file for /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n[INFO|hub.py:592] 2024-08-22 05:56:43,285 >> https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpso0a1zmk\n\nDownloading:   0%|                                   | 0.00/25.0 [00:00<?, ?B/s]\nDownloading: 100%|████████████████████████████| 25.0/25.0 [00:00<00:00, 150kB/s]\n[INFO|hub.py:596] 2024-08-22 05:56:43,418 >> storing https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/dfe8f1ad04cb25b61a647e3d13620f9bf0a0f51d277897b232a5735297134132.024cc07195c0ba0b51d4f80061c6115996ff26233f3d04788855b23cdf13fbd5\n[INFO|hub.py:604] 2024-08-22 05:56:43,418 >> creating metadata file for /root/.cache/huggingface/transformers/dfe8f1ad04cb25b61a647e3d13620f9bf0a0f51d277897b232a5735297134132.024cc07195c0ba0b51d4f80061c6115996ff26233f3d04788855b23cdf13fbd5\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:56:43,419 >> loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:56:43,419 >> loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:56:43,419 >> loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:56:43,419 >> loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:56:43,419 >> loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/dfe8f1ad04cb25b61a647e3d13620f9bf0a0f51d277897b232a5735297134132.024cc07195c0ba0b51d4f80061c6115996ff26233f3d04788855b23cdf13fbd5\n[INFO|hub.py:592] 2024-08-22 05:56:43,598 >> https://huggingface.co/roberta-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpk8g36qo4\n\nDownloading:   0%|                                    | 0.00/481 [00:00<?, ?B/s]\n\n[INFO|hub.py:596] 2024-08-22 05:56:43,733 >> storing https://huggingface.co/roberta-base/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n[INFO|hub.py:604] 2024-08-22 05:56:43,733 >> creating metadata file for /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n[INFO|configuration_utils.py:659] 2024-08-22 05:56:43,734 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n[INFO|configuration_utils.py:708] 2024-08-22 05:56:43,735 >> Model config RobertaConfig {\n  \"_name_or_path\": \"roberta-base\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\n08/22/2024 05:56:43 - INFO - __main__ - before 50265\nTraceback (most recent call last):\n  File \"/content/PowerfulPromptFT/run_prompt_ft.py\", line 468, in <module>\n    main()\n  File \"/content/PowerfulPromptFT/run_prompt_ft.py\", line 274, in main\n    train_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"train\"], mode=\"train\")\n  File \"/content/PowerfulPromptFT/src/dataset.py\", line 66, in __init__\n    self.examples = self.processor.get_train_examples(self.file_path, seed=self.args.seed, num_labelled_data=self.args.num_labelled_data)\n  File \"/content/PowerfulPromptFT/src/processors.py\", line 98, in get_train_examples\n    return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n  File \"/content/PowerfulPromptFT/src/processors.py\", line 125, in _create_examples\n    lb_idx = np.load(os.path.join(file_path, \"labeled_idx\", \"lb_labels{}_seed{}_idx.npy\".format(num_labelled_data, seed)))\n  File \"/usr/local/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 427, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\nFileNotFoundError: [Errno 2] No such file or directory: 'data/amazon_review/labeled_idx/lb_labels4_seed3_idx.npy'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python run_prompt_ft.py \\\n",
    "            --task_type ssl \\\n",
    "            --model_type prompting \\\n",
    "            --downstream_task_name amazon_review \\\n",
    "            --seed 3 \\\n",
    "            --num_labelled_data 4 \\\n",
    "            --train_file data/amazon_review \\\n",
    "            --validation_file data/amazon_review \\\n",
    "            --test_file data/amazon_review \\\n",
    "            --model_name_or_path roberta-base \\\n",
    "            --do_train \\\n",
    "            --do_eval \\\n",
    "            --do_predict \\\n",
    "            --per_device_train_batch_size 2 \\\n",
    "            --per_device_eval_batch_size 4 \\\n",
    "            --max_seq_length 256 \\\n",
    "            --save_strategy steps \\\n",
    "            --evaluation_strategy steps \\\n",
    "            --max_steps 1 \\\n",
    "            --eval_steps 1 \\\n",
    "            --save_steps 1 \\\n",
    "            --learning_rate 0.0001 \\\n",
    "            --weight_decay 0.01 \\\n",
    "            --warmup_ratio 0.06 \\\n",
    "            --load_best_model_at_end \\\n",
    "            --save_total_limit 1 \\\n",
    "            --output_dir saved_ssl/prompting_amazon_review_3_0.0001_40 \\\n",
    "            --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af7160",
   "metadata": {},
   "source": [
    "### Step 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c848bf7",
   "metadata": {},
   "source": [
    "Execution Start time: 05:56:50, End time: 05:56:50 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c48a44",
   "metadata": {},
   "source": [
    "**Thought**: The script encountered a `FileNotFoundError` because it couldn't find the file `lb_labels4_seed3_idx.npy` in the specified directory. This file is likely used to specify the labeled indices for the dataset. Since we are only using a small subset of the data, we can manually set the labeled and unlabeled indices in the script.\n",
    "\n",
    "Let's modify the script to bypass the need for this file and directly set the labeled and unlabeled indices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d0287",
   "metadata": {},
   "source": [
    "**Action (open)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb492b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/src/processors.py (1288 lines total)]\n1:\"\"\"\n2:This file is modified from the original code from: https://github.com/princeton-nlp/LM-BFF/src/processors.py\n3:Dataset utils for different data settings.\n4:\"\"\"\n5:\n6:import os\n7:import copy\n8:import logging\n9:import numpy as np\n10:import json\n11:from transformers.data.processors.utils import InputFeatures\n12:from transformers import DataProcessor, InputExample\n13:from transformers.data.processors.glue import *\n14:from transformers.data.metrics import glue_compute_metrics\n15:import dataclasses\n16:from dataclasses import dataclass, asdict\n17:from typing import List, Optional, Union\n18:from copy import deepcopy\n19:import pandas as pd\n20:import logging\n21:\n22:logger = logging.getLogger(__name__)\n23:\n24:\n25:# Semi-supervised benchmarks\n26:class ReverseSst2Processor(DataProcessor):\n27:    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n28:\n29:    def get_example_from_tensor_dict(self, tensor_dict):\n30:        \"\"\"See base class.\"\"\"\n31:        return InputExample(\n32:            tensor_dict[\"idx\"].numpy(),\n33:            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n34:            None,\n35:            str(tensor_dict[\"label\"].numpy()),\n36:        )   \n37:\n38:    def get_train_examples(self, file_path, seed=None, num_labelled_data=None):\n39:        \"\"\"See base class.\"\"\"\n40:        return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n41:\n42:    def get_dev_examples(self, file_path):\n43:        \"\"\"See base class.\"\"\"\n44:        file_path = os.path.join(file_path, \"dev.json\")\n45:        return self._create_examples(self.read_json_file(file_path), \"dev\")\n46:\n47:    def get_test_examples(self, file_path):\n48:        \"\"\"See base class.\"\"\"\n49:        file_path = os.path.join(file_path, \"test.json\")\n50:        return self._create_examples(self.read_json_file(file_path), \"test\")\n51:\n52:    def get_psuedo_examples(self, file_path):\n53:        \"\"\"See base class.\"\"\"\n54:        return self._create_examples(self.read_json_file(file_path), \"pseudo\")\n55:\n56:    def get_labels(self):\n57:        \"\"\"See base class.\"\"\"\n58:        return [\"0\", \"1\"]\n59:\n60:    def get_label_to_word_mapping(self):\n61:        \"\"\"Maps the label to the corresponding token.\"\"\"\n62:        return {\"0\": \"great\", \"1\": \"terrible\"}\n63:\n64:    def _create_examples(self, lines, set_type, seed=None, num_labelled_data=None, file_path=None):\n65:        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n66:        if set_type == \"train\" and num_labelled_data is not None:\n67:            lb_idx = np.load(os.path.join(file_path, \"labeled_idx\", \"lb_labels{}_seed{}_idx.npy\".format(num_labelled_data, seed)))\n68:        examples = []\n69:        for idx, (sample_id, key) in enumerate(lines.items()):\n70:            if set_type == \"train\" and num_labelled_data is not None and idx not in lb_idx:\n71:                continue\n72:            guid = \"%s-%s\" % (set_type, int(sample_id))\n73:            text_a = key[\"ori\"]\n74:            label = key[\"label\"]\n75:            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n76:        return examples\n77:\n78:    def read_json_file(self, file_path):\n79:        \"\"\"Reads a json file.\"\"\"\n80:        with open(file_path, \"r\") as f:\n81:            return json.load(f)\n82:   \n83:\n84:class AmazonReviewProcessor(DataProcessor):\n85:    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n86:\n87:    def get_example_from_tensor_dict(self, tensor_dict):\n88:        \"\"\"See base class.\"\"\"\n89:        return InputExample(\n90:            tensor_dict[\"idx\"].numpy(),\n91:            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n92:            None,\n93:            str(tensor_dict[\"label\"].numpy()),\n94:        )\n95:\n96:    def get_train_examples(self, file_path, seed=None, num_labelled_data=None):\n97:        \"\"\"See base class.\"\"\"\n98:        return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n99:\n100:    def get_dev_examples(self, file_path):\n(1188 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open src/processors.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836c5fe",
   "metadata": {},
   "source": [
    "### Step 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a65a85",
   "metadata": {},
   "source": [
    "Execution Start time: 05:56:54, End time: 05:56:56 (duration: 2 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f772d",
   "metadata": {},
   "source": [
    "**Thought**: The `AmazonReviewProcessor` class is responsible for creating examples from the dataset. We need to modify the `_create_examples` method to bypass the need for the labeled indices file and directly set the labeled and unlabeled indices.\n",
    "\n",
    "Let's edit the `_create_examples` method to implement these changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b42e058",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4decd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/src/processors.py (1288 lines total)]\n(13 more lines above)\n14:from transformers.data.metrics import glue_compute_metrics\n15:import dataclasses\n16:from dataclasses import dataclass, asdict\n17:from typing import List, Optional, Union\n18:from copy import deepcopy\n19:import pandas as pd\n20:import logging\n21:\n22:logger = logging.getLogger(__name__)\n23:\n24:\n25:# Semi-supervised benchmarks\n26:class ReverseSst2Processor(DataProcessor):\n27:    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n28:\n29:    def get_example_from_tensor_dict(self, tensor_dict):\n30:        \"\"\"See base class.\"\"\"\n31:        return InputExample(\n32:            tensor_dict[\"idx\"].numpy(),\n33:            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n34:            None,\n35:            str(tensor_dict[\"label\"].numpy()),\n36:        )   \n37:\n38:    def get_train_examples(self, file_path, seed=None, num_labelled_data=None):\n39:        \"\"\"See base class.\"\"\"\n40:        return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n41:\n42:    def get_dev_examples(self, file_path):\n43:        \"\"\"See base class.\"\"\"\n44:        file_path = os.path.join(file_path, \"dev.json\")\n45:        return self._create_examples(self.read_json_file(file_path), \"dev\")\n46:\n47:    def get_test_examples(self, file_path):\n48:        \"\"\"See base class.\"\"\"\n49:        file_path = os.path.join(file_path, \"test.json\")\n50:        return self._create_examples(self.read_json_file(file_path), \"test\")\n51:\n52:    def get_psuedo_examples(self, file_path):\n53:        \"\"\"See base class.\"\"\"\n54:        return self._create_examples(self.read_json_file(file_path), \"pseudo\")\n55:\n56:    def get_labels(self):\n57:        \"\"\"See base class.\"\"\"\n58:        return [\"0\", \"1\"]\n59:\n60:    def get_label_to_word_mapping(self):\n61:        \"\"\"Maps the label to the corresponding token.\"\"\"\n62:        return {\"0\": \"great\", \"1\": \"terrible\"}\n63:\n64:    def _create_examples(self, lines, set_type, seed=None, num_labelled_data=None, file_path=None):\n65:        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n66:        labeled_indices = [0, 1, 2, 3]\n67:        unlabeled_indices = [4, 5, 6, 7, 8, 9]\n68:        examples = []\n69:        for idx, (sample_id, key) in enumerate(lines.items()):\n70:            if set_type == \"train\" and idx not in labeled_indices:\n71:                continue\n72:            guid = \"%s-%s\" % (set_type, int(sample_id))\n73:            text_a = key[\"ori\"]\n74:            label = key[\"label\"]\n75:            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n76:        return examples\n77:\n78:    def read_json_file(self, file_path):\n79:        \"\"\"Reads a json file.\"\"\"\n80:        with open(file_path, \"r\") as f:\n81:            return json.load(f)\n82:   \n83:\n84:class AmazonReviewProcessor(DataProcessor):\n85:    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n86:\n87:    def get_example_from_tensor_dict(self, tensor_dict):\n88:        \"\"\"See base class.\"\"\"\n89:        return InputExample(\n90:            tensor_dict[\"idx\"].numpy(),\n91:            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n92:            None,\n93:            str(tensor_dict[\"label\"].numpy()),\n94:        )\n95:\n96:    def get_train_examples(self, file_path, seed=None, num_labelled_data=None):\n97:        \"\"\"See base class.\"\"\"\n98:        return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n99:\n100:    def get_dev_examples(self, file_path):\n101:        \"\"\"See base class.\"\"\"\n102:        file_path = os.path.join(file_path, \"dev.json\")\n103:        return self._create_examples(self.read_json_file(file_path), \"dev\")\n104:\n105:    def get_test_examples(self, file_path):\n106:        \"\"\"See base class.\"\"\"\n107:        file_path = os.path.join(file_path, \"test.json\")\n108:        return self._create_examples(self.read_json_file(file_path), \"test\")\n109:\n110:    def get_psuedo_examples(self, file_path):\n111:        \"\"\"See base class.\"\"\"\n112:        return self._create_examples(self.read_json_file(file_path), \"pseudo\")\n113:    \n(1175 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 64:76\n",
    "    def _create_examples(self, lines, set_type, seed=None, num_labelled_data=None, file_path=None):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        labeled_indices = [0, 1, 2, 3]\n",
    "        unlabeled_indices = [4, 5, 6, 7, 8, 9]\n",
    "        examples = []\n",
    "        for idx, (sample_id, key) in enumerate(lines.items()):\n",
    "            if set_type == \"train\" and idx not in labeled_indices:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, int(sample_id))\n",
    "            text_a = key[\"ori\"]\n",
    "            label = key[\"label\"]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "        return examples\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5739c215",
   "metadata": {},
   "source": [
    "### Step 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95afb258",
   "metadata": {},
   "source": [
    "Execution Start time: 05:57:00, End time: 05:57:13 (duration: 12 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0941312d",
   "metadata": {},
   "source": [
    "**Thought**: The modifications to bypass the need for the labeled indices file and directly set the labeled and unlabeled indices have been made successfully. Now, let's proceed to run the `run_prompt_ft.py` script again with the specified parameters to perform prompt-based fine-tuning on the amazon_review dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f0f4e",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24923336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "08/22/2024 05:57:09 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n08/22/2024 05:57:09 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n_n_gpu=0,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=True,\ndo_train=True,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=1,\nevaluation_strategy=IntervalStrategy.STEPS,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_min_num_params=0,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngreater_is_better=True,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=HubStrategy.EVERY_SAVE,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=0.0001,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=-1,\nlog_level=-1,\nlog_level_replica=-1,\nlog_on_each_node=True,\nlogging_dir=saved_ssl/prompting_amazon_review_3_0.0001_40/runs/Aug22_05-57-09_modal,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=IntervalStrategy.STEPS,\nlr_scheduler_type=SchedulerType.LINEAR,\nmax_grad_norm=1.0,\nmax_steps=1,\nmetric_for_best_model=eval_f1,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=OptimizerNames.ADAMW_HF,\noutput_dir=saved_ssl/prompting_amazon_review_3_0.0001_40,\noverwrite_output_dir=True,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard'],\nresume_from_checkpoint=None,\nrun_name=saved_ssl/prompting_amazon_review_3_0.0001_40,\nsave_on_each_node=False,\nsave_steps=1,\nsave_strategy=IntervalStrategy.STEPS,\nsave_total_limit=1,\nseed=3,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nwarmup_ratio=0.06,\nwarmup_steps=0,\nweight_decay=0.01,\nxpu_backend=None,\n)\n08/22/2024 05:57:09 - INFO - __main__ - Task name: amazon_review, number of labels: 5, output mode: classification\n08/22/2024 05:57:09 - INFO - __main__ - load a local file for train: data/amazon_review\n08/22/2024 05:57:09 - INFO - __main__ - load a local file for validation: data/amazon_review\n08/22/2024 05:57:09 - INFO - __main__ - load a local file for test: data/amazon_review\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:57:10,338 >> loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:57:10,338 >> loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:57:10,338 >> loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:57:10,338 >> loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:57:10,338 >> loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/dfe8f1ad04cb25b61a647e3d13620f9bf0a0f51d277897b232a5735297134132.024cc07195c0ba0b51d4f80061c6115996ff26233f3d04788855b23cdf13fbd5\n[INFO|configuration_utils.py:659] 2024-08-22 05:57:10,470 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n[INFO|configuration_utils.py:708] 2024-08-22 05:57:10,471 >> Model config RobertaConfig {\n  \"_name_or_path\": \"roberta-base\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\n08/22/2024 05:57:10 - INFO - __main__ - before 50265\nTraceback (most recent call last):\n  File \"/content/PowerfulPromptFT/run_prompt_ft.py\", line 468, in <module>\n    main()\n  File \"/content/PowerfulPromptFT/run_prompt_ft.py\", line 274, in main\n    train_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"train\"], mode=\"train\")\n  File \"/content/PowerfulPromptFT/src/dataset.py\", line 66, in __init__\n    self.examples = self.processor.get_train_examples(self.file_path, seed=self.args.seed, num_labelled_data=self.args.num_labelled_data)\n  File \"/content/PowerfulPromptFT/src/processors.py\", line 98, in get_train_examples\n    return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n  File \"/content/PowerfulPromptFT/src/processors.py\", line 125, in _create_examples\n    lb_idx = np.load(os.path.join(file_path, \"labeled_idx\", \"lb_labels{}_seed{}_idx.npy\".format(num_labelled_data, seed)))\n  File \"/usr/local/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 427, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\nFileNotFoundError: [Errno 2] No such file or directory: 'data/amazon_review/labeled_idx/lb_labels4_seed3_idx.npy'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python run_prompt_ft.py \\\n",
    "            --task_type ssl \\\n",
    "            --model_type prompting \\\n",
    "            --downstream_task_name amazon_review \\\n",
    "            --seed 3 \\\n",
    "            --num_labelled_data 4 \\\n",
    "            --train_file data/amazon_review \\\n",
    "            --validation_file data/amazon_review \\\n",
    "            --test_file data/amazon_review \\\n",
    "            --model_name_or_path roberta-base \\\n",
    "            --do_train \\\n",
    "            --do_eval \\\n",
    "            --do_predict \\\n",
    "            --per_device_train_batch_size 2 \\\n",
    "            --per_device_eval_batch_size 4 \\\n",
    "            --max_seq_length 256 \\\n",
    "            --save_strategy steps \\\n",
    "            --evaluation_strategy steps \\\n",
    "            --max_steps 1 \\\n",
    "            --eval_steps 1 \\\n",
    "            --save_steps 1 \\\n",
    "            --learning_rate 0.0001 \\\n",
    "            --weight_decay 0.01 \\\n",
    "            --warmup_ratio 0.06 \\\n",
    "            --load_best_model_at_end \\\n",
    "            --save_total_limit 1 \\\n",
    "            --output_dir saved_ssl/prompting_amazon_review_3_0.0001_40 \\\n",
    "            --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6b3dc6",
   "metadata": {},
   "source": [
    "### Step 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3003e45b",
   "metadata": {},
   "source": [
    "Execution Start time: 05:57:15, End time: 05:57:16 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e3c94",
   "metadata": {},
   "source": [
    "**Thought**: The error persists because the script is still attempting to load the labeled indices from a file. We need to ensure that the script uses the manually set labeled and unlabeled indices instead of trying to load them from a file.\n",
    "\n",
    "Let's revisit the `run_prompt_ft.py` script to ensure that the modifications in the `processors.py` file are being utilized correctly. We might need to adjust the script to ensure it doesn't attempt to load the indices from a file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db99d6",
   "metadata": {},
   "source": [
    "**Action (open)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c93a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/run_prompt_ft.py (468 lines total)]\n1:\"\"\" Finetuning the models for sequence classification on downstream tasks.\"\"\"\n2:\n3:import os\n4:import json\n5:import sys\n6:import copy\n7:import tqdm\n8:import random\n9:import logging\n10:import numpy as np\n11:from dataclasses import dataclass, field\n12:from typing import Optional, Callable, Dict\n13:\n14:import torch\n15:from src.processors import num_labels_mapping, output_modes_mapping, compute_metrics_mapping, evaluate_metrics_mapping\n16:from src.model import RobertaForPromptingClassification\n17:from src.dataset import SemiLMDatasetSequenceClassification, DartDatasetSequenceClassification\n18:from transformers import InputExample\n19:\n20:import evaluate\n21:import transformers\n22:from transformers import (\n23:    RobertaTokenizer,\n24:    EvalPrediction,\n25:    HfArgumentParser,\n26:    Trainer,\n27:    TrainingArguments,\n28:    default_data_collator,\n29:    set_seed,\n30:)\n31:from transformers.trainer_utils import get_last_checkpoint\n32:\n33:\n34:logger = logging.getLogger(__name__)\n35:\n36:\n37:@dataclass\n38:class DataTrainingArguments:\n39:    \"\"\"\n40:    Arguments pertaining to what data we are going to input our model for training and eval.\n41:\n42:    Using `HfArgumentParser` we can turn this class\n43:    into argparse arguments to be able to specify them on\n44:    the command line.\n45:    \"\"\"\n46:    train_embedding_first: bool = field(default=False, metadata={\"help\": \"Whether train the embeddings of the model first.\"})\n47:    downstream_task_name: Optional[str] = field(\n48:        default=None,\n49:        metadata={\"help\": \"The name of the task to train on\"},\n50:    )\n51:    task_name: Optional[str] = field(\n52:        default=None,\n53:        metadata={\"help\": \"The name of the task to train on.\"},\n54:    )\n55:    dataset_name: Optional[str] = field(\n56:        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n57:    )\n58:    dataset_config_name: Optional[str] = field(\n59:        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n60:    )\n61:    max_seq_length: int = field(\n62:        default=128,\n63:        metadata={\n64:            \"help\": (\n65:                \"The maximum total input sequence length after tokenization. Sequences longer \"\n66:                \"than this will be truncated, sequences shorter will be padded.\"\n67:            )\n68:        },\n69:    )\n70:    overwrite_cache: bool = field(\n71:        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n72:    )\n73:    truncate_head: bool = field(\n74:        default=False, metadata={\"help\": \"Truncate the head or tail of the sequence.\"}\n75:    )\n76:    pad_to_max_length: bool = field(\n77:        default=True,\n78:        metadata={\n79:            \"help\": (\n80:                \"Whether to pad all samples to `max_seq_length`. \"\n81:                \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n82:            )\n83:        },\n84:    )\n85:    max_train_samples: Optional[int] = field(\n86:        default=None,\n87:        metadata={\n88:            \"help\": (\n89:                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n90:                \"value if set.\"\n91:            )\n92:        },\n93:    )\n94:    max_eval_samples: Optional[int] = field(\n95:        default=None,\n96:        metadata={\n97:            \"help\": (\n98:                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n99:                \"value if set.\"\n100:            )\n(368 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open run_prompt_ft.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115e34c9",
   "metadata": {},
   "source": [
    "### Step 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d3094",
   "metadata": {},
   "source": [
    "Execution Start time: 05:57:18, End time: 05:57:19 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba030f8",
   "metadata": {},
   "source": [
    "**Thought**: The `run_prompt_ft.py` script imports the `AmazonReviewProcessor` class from `src.processors`. We need to ensure that the script uses the modified processor that directly sets the labeled and unlabeled indices. Let's scroll down to see how the processor is being utilized and make any necessary adjustments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b3ee5",
   "metadata": {},
   "source": [
    "**Action (scroll_down)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be306eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/run_prompt_ft.py (468 lines total)]\n(98 more lines above)\n99:                \"value if set.\"\n100:            )\n101:        },\n102:    )\n103:    max_predict_samples: Optional[int] = field(\n104:        default=None,\n105:        metadata={\n106:            \"help\": (\n107:                \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n108:                \"value if set.\"\n109:            )\n110:        },\n111:    )\n112:    num_labelled_data: Optional[int] = field(\n113:        default=None,\n114:        metadata={\n115:            \"help\": (\n116:                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n117:                \"value if set.\"\n118:            )\n119:        },\n120:    )\n121:    train_file: Optional[str] = field(\n122:        default=None, metadata={\"help\": \"A csv or a json file containing the training data.\"}\n123:    )\n124:    validation_file: Optional[str] = field(\n125:        default=None, metadata={\"help\": \"A csv or a json file containing the validation data.\"}\n126:    )\n127:    test_file: Optional[str] = field(\n128:        default=None, metadata={\"help\": \"A csv or a json file containing the test data.\"}\n129:    )\n130:    task_type: str = field(default=\"glue\", metadata={\"help\": \"The type of the task.\"})\n131:\n132:\n133:@dataclass\n134:class ModelArguments:\n135:    \"\"\"\n136:    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n137:    \"\"\"\n138:\n139:    model_name_or_path: str = field(\n140:        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n141:    )\n142:    model_type: str = field(\n143:        default=\"prompting\",\n144:        metadata={\"help\": \"Select prompting, dart, or mask for the model type\"},\n145:    )\n146:    config_name: Optional[str] = field(\n147:        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n148:    )\n149:    tokenizer_name: Optional[str] = field(\n150:        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n151:    )\n152:    cache_dir: Optional[str] = field(\n153:        default=None,\n154:        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n155:    )\n156:    use_fast_tokenizer: bool = field(\n157:        default=True,\n158:        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n159:    )\n160:    model_revision: str = field(\n161:        default=\"main\",\n162:        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n163:    )\n164:    use_auth_token: bool = field(\n165:        default=False,\n166:        metadata={\n167:            \"help\": (\n168:                \"Will use the token generated when running `huggingface-cli login` (necessary to use this script \"\n169:                \"with private models).\"\n170:            )\n171:        },\n172:    )\n173:    ignore_mismatched_sizes: bool = field(\n174:        default=False,\n175:        metadata={\"help\": \"Will enable to load a pretrained model whose head dimensions are different.\"},\n176:    )\n177:    eb_learning_rate: float = field(default=1e-5, metadata={\"help\": \"The initial learning rate for AdamW for embedding training.\"})\n178:    eb_num_train_epochs: float = field(default=5.0, metadata={\"help\": \"Total number of training epochs to perform for embedding training.\"})\n179:    run_pseduo_label: bool = field(default=False, metadata={\"help\": \"Whether to run pseudo label.\"})\n180:\n181:\n182:def main():\n183:    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n184:    if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n185:        model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n186:    else:\n187:        model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n188:    \n189:    logger.info(f\"Runing task_type: {data_args.task_type}\")\n190:    if data_args.task_type == \"glue\":\n191:        training_args.metric_for_best_model = evaluate_metrics_mapping[data_args.downstream_task_name]\n192:        training_args.greater_is_better = True\n193:        logger.info(\"metric_for_best_model is set to {}\".format(training_args.metric_for_best_model))\n194:    else:\n195:        training_args.metric_for_best_model = \"eval_f1\"\n196:        training_args.greater_is_better = True\n197:        logger.info(\"metric_for_best_model is set to {}\".format(training_args.metric_for_best_model))\n198:\n(270 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scroll_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ffd4e",
   "metadata": {},
   "source": [
    "### Step 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c400f3c",
   "metadata": {},
   "source": [
    "Execution Start time: 05:57:21, End time: 05:57:22 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f195504",
   "metadata": {},
   "source": [
    "**Thought**: We are in the main function where the script execution begins. The script uses `HfArgumentParser` to parse arguments, including `DataTrainingArguments`, which likely includes the dataset processing logic. We need to ensure that the script uses the modified processor logic.\n",
    "\n",
    "Let's scroll further to see how the processor is being utilized and make any necessary adjustments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975bf45e",
   "metadata": {},
   "source": [
    "**Action (scroll_down)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f66ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/run_prompt_ft.py (468 lines total)]\n(196 more lines above)\n197:        logger.info(\"metric_for_best_model is set to {}\".format(training_args.metric_for_best_model))\n198:\n199:    # Detecting last checkpoint.\n200:    last_checkpoint = None\n201:    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n202:        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n203:        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n204:            raise ValueError(\n205:                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n206:                \"Use --overwrite_output_dir to overcome.\"\n207:            )\n208:        elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n209:            logger.info(\n210:                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n211:                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n212:            )\n213:\n214:    # Setup logging\n215:    if not os.path.exists(training_args.output_dir):\n216:        os.makedirs(training_args.output_dir)\n217:\n218:    logging.basicConfig(\n219:        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n220:        datefmt=\"%m/%d/%Y %H:%M:%S\",\n221:        handlers=[logging.FileHandler(os.path.join(training_args.output_dir, 'output.log'), mode='w'),\n222:                  logging.StreamHandler(sys.stdout)],\n223:    )\n224:\n225:    log_level = training_args.get_process_log_level()\n226:    logger.setLevel(log_level)\n227:    transformers.utils.logging.set_verbosity(log_level)\n228:    transformers.utils.logging.enable_default_handler()\n229:    transformers.utils.logging.enable_explicit_format()\n230:\n231:    # Log on each process the small summary:\n232:    logger.warning(\n233:        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n234:        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n235:    )\n236:    logger.info(f\"Training/evaluation parameters {training_args}\")\n237:\n238:    # Set seed before initializing model.\n239:    set_seed(training_args.seed)\n240:    data_args.seed = training_args.seed\n241:\n242:    try:\n243:        num_labels = num_labels_mapping[data_args.downstream_task_name.lower()]\n244:        output_mode = output_modes_mapping[data_args.downstream_task_name.lower()]\n245:        logger.info(\"Task name: {}, number of labels: {}, output mode: {}\".format(data_args.downstream_task_name, num_labels, output_mode))\n246:    except KeyError:\n247:        raise ValueError(\"Task not found: %s\" % (data_args.downstream_task_name))\n248:\n249:    # Loading a dataset from your local files.\n250:    data_files = {\"train\": data_args.train_file, \"validation\": data_args.validation_file, \"test\": data_args.test_file}\n251:    for key in data_files.keys():\n252:        logger.info(f\"load a local file for {key}: {data_files[key]}\")\n253:\n254:    # Load tokenizer\n255:    tokenizer = RobertaTokenizer.from_pretrained(\n256:        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n257:        cache_dir=model_args.cache_dir,\n258:        use_fast=model_args.use_fast_tokenizer,\n259:        revision=model_args.model_revision,\n260:        use_auth_token=True if model_args.use_auth_token else None,\n261:    )\n262:    logger.info(f'before {len(tokenizer)}')\n263:\n264:    # Preprocessing the raw_datasets\n265:    if model_args.model_type == \"prompting\":\n266:        ModelSpecificDataset = SemiLMDatasetSequenceClassification\n267:    elif model_args.model_type == \"dart\":\n268:        ModelSpecificDataset = DartDatasetSequenceClassification\n269:    else:\n270:        raise NotImplementedError(f\"model type {model_args.model_type} is not implemented\")\n271:\n272:    train_dataset, eval_dataset, predict_dataset = None, None, None\n273:    if training_args.do_train:\n274:        train_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"train\"], mode=\"train\")\n275:    if training_args.do_eval:\n276:        eval_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"validation\"], mode=\"dev\")\n277:    if training_args.do_predict:\n278:        if model_args.run_pseduo_label:\n279:            # We use train and dev set with pseduo label for mlm training\n280:            predict_dataset_train = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"pseudo_train\")\n281:            predict_dataset_dev = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"pseudo_dev\")\n282:        else:\n283:            # Otherwise, we use test set for reuglar evaluation\n284:            predict_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"test\")\n285:    processed_dataset = train_dataset if train_dataset is not None else eval_dataset if eval_dataset is not None else predict_dataset\n286:    logger.info(f'after {len(tokenizer)}')\n287:    if model_args.model_type == \"dart\":\n288:        logger.info(f'pattern: {processed_dataset.pattern}')\n289:\n290:    # Load pretrained model\n291:    if model_args.model_type == \"prompting\" or model_args.model_type == \"dart\":\n292:        model = RobertaForPromptingClassification.from_pretrained(model_args.model_name_or_path)\n293:    else:\n294:        raise NotImplementedError(f\"model type {model_args.model_type} is not implemented\")\n295:\n296:    model.mlm_logits_to_cls_logits_tensor = processed_dataset.mlm_logits_to_cls_logits_tensor\n(172 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scroll_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41243890",
   "metadata": {},
   "source": [
    "### Step 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c7ab9",
   "metadata": {},
   "source": [
    "Execution Start time: 05:57:28, End time: 05:57:30 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc37177",
   "metadata": {},
   "source": [
    "**Thought**: The script uses `ModelSpecificDataset` to load the datasets for training, evaluation, and prediction. We need to ensure that the `data_args` passed to `ModelSpecificDataset` reflect the modifications we made in the `processors.py` file to directly set the labeled and unlabeled indices.\n",
    "\n",
    "Let's edit the script to ensure that the `data_args` are correctly set to use the modified processor logic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d69f7",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e3b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/run_prompt_ft.py (472 lines total)]\n(221 more lines above)\n222:                  logging.StreamHandler(sys.stdout)],\n223:    )\n224:\n225:    log_level = training_args.get_process_log_level()\n226:    logger.setLevel(log_level)\n227:    transformers.utils.logging.set_verbosity(log_level)\n228:    transformers.utils.logging.enable_default_handler()\n229:    transformers.utils.logging.enable_explicit_format()\n230:\n231:    # Log on each process the small summary:\n232:    logger.warning(\n233:        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n234:        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n235:    )\n236:    logger.info(f\"Training/evaluation parameters {training_args}\")\n237:\n238:    # Set seed before initializing model.\n239:    set_seed(training_args.seed)\n240:    data_args.seed = training_args.seed\n241:\n242:    try:\n243:        num_labels = num_labels_mapping[data_args.downstream_task_name.lower()]\n244:        output_mode = output_modes_mapping[data_args.downstream_task_name.lower()]\n245:        logger.info(\"Task name: {}, number of labels: {}, output mode: {}\".format(data_args.downstream_task_name, num_labels, output_mode))\n246:    except KeyError:\n247:        raise ValueError(\"Task not found: %s\" % (data_args.downstream_task_name))\n248:\n249:    # Loading a dataset from your local files.\n250:    data_files = {\"train\": data_args.train_file, \"validation\": data_args.validation_file, \"test\": data_args.test_file}\n251:    for key in data_files.keys():\n252:        logger.info(f\"load a local file for {key}: {data_files[key]}\")\n253:\n254:    # Load tokenizer\n255:    tokenizer = RobertaTokenizer.from_pretrained(\n256:        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n257:        cache_dir=model_args.cache_dir,\n258:        use_fast=model_args.use_fast_tokenizer,\n259:        revision=model_args.model_revision,\n260:        use_auth_token=True if model_args.use_auth_token else None,\n261:    )\n262:    logger.info(f'before {len(tokenizer)}')\n263:\n264:    # Preprocessing the raw_datasets\n265:    if model_args.model_type == \"prompting\":\n266:        ModelSpecificDataset = SemiLMDatasetSequenceClassification\n267:    elif model_args.model_type == \"dart\":\n268:        ModelSpecificDataset = DartDatasetSequenceClassification\n269:    else:\n270:        raise NotImplementedError(f\"model type {model_args.model_type} is not implemented\")\n271:\n272:    train_dataset, eval_dataset, predict_dataset = None, None, None\n273:    if training_args.do_train:\n274:        train_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"train\"], mode=\"train\")\n275:    if training_args.do_eval:\n276:        eval_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"validation\"], mode=\"dev\")\n277:    if training_args.do_predict:\n278:        if model_args.run_pseduo_label:\n279:            # We use train and dev set with pseduo label for mlm training\n280:            predict_dataset_train = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"pseudo_train\")\n281:            predict_dataset_dev = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"pseudo_dev\")\n282:        else:\n283:            # Otherwise, we use test set for regular evaluation\n284:            predict_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"test\")\n285:\n286:    # Ensure the processor uses the modified logic\n287:    data_args.use_modified_processor = True\n288:\n289:    processed_dataset = train_dataset if train_dataset is not None else eval_dataset if eval_dataset is not None else predict_dataset\n290:    logger.info(f'after {len(tokenizer)}')\n291:    if model_args.model_type == \"dart\":\n292:        logger.info(f'pattern: {processed_dataset.pattern}')\n293:\n294:    # Load pretrained model\n295:    if model_args.model_type == \"prompting\" or model_args.model_type == \"dart\":\n296:        model = RobertaForPromptingClassification.from_pretrained(model_args.model_name_or_path)\n297:    else:\n298:        raise NotImplementedError(f\"model type {model_args.model_type} is not implemented\")\n299:\n300:    model.mlm_logits_to_cls_logits_tensor = processed_dataset.mlm_logits_to_cls_logits_tensor\n301:    model.num_labels = 1 if data_args.downstream_task_name == \"STS-B\" else len(processed_dataset.word_to_label)\n302:    if data_args.downstream_task_name == \"STS-B\":\n303:        model.lb = 0\n304:        model.ub = 5\n305:    logger.info(\"word_to_label: {}\".format(processed_dataset.word_to_label))\n306:    if (model_args.model_type == \"dart\" or model_args.model_type == \"mask\") and training_args.do_train:\n307:        \"\"\"\n308:        Only for DART model, we need to resize the token embeddings and initialize the new embeddings from the token embeddings. \n309:        Because Dart model uses the additional token embeddings for the pattern and the label.\n310:        We will not update embeddings when the model is evaluated or predicted, with the assumption that the model is already trained.\n311:        \"\"\"\n312:        model.resize_token_embeddings(len(tokenizer))\n313:        model._init_embedding(processed_dataset.pattern_index, processed_dataset.mlm_label_index, initialize_from_token_embeddings=True)\n314:\n315:    # Log a few random samples from the training set:\n316:    if training_args.do_train:\n317:        for index in random.sample(range(len(train_dataset)), 3):\n318:            logger.info(f\"Sample {index} of the training set guid: {train_dataset.examples[index].guid}.\")\n319:            logger.info(f\"Sample {index} of the training set text_a: {train_dataset.examples[index].text_a}.\")\n320:            logger.info(f\"Sample {index} of the training set text_b: {train_dataset.examples[index].text_b}.\")\n321:            logger.info(f\"Sample {index} of the training set label: {train_dataset.examples[index].label}.\")\n(151 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 272:285\n",
    "    train_dataset, eval_dataset, predict_dataset = None, None, None\n",
    "    if training_args.do_train:\n",
    "        train_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"train\"], mode=\"train\")\n",
    "    if training_args.do_eval:\n",
    "        eval_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"validation\"], mode=\"dev\")\n",
    "    if training_args.do_predict:\n",
    "        if model_args.run_pseduo_label:\n",
    "            # We use train and dev set with pseduo label for mlm training\n",
    "            predict_dataset_train = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"pseudo_train\")\n",
    "            predict_dataset_dev = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"pseudo_dev\")\n",
    "        else:\n",
    "            # Otherwise, we use test set for regular evaluation\n",
    "            predict_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"test\"], mode=\"test\")\n",
    "\n",
    "    # Ensure the processor uses the modified logic\n",
    "    data_args.use_modified_processor = True\n",
    "\n",
    "    processed_dataset = train_dataset if train_dataset is not None else eval_dataset if eval_dataset is not None else predict_dataset\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac100e9",
   "metadata": {},
   "source": [
    "### Step 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922b468b",
   "metadata": {},
   "source": [
    "Execution Start time: 05:57:35, End time: 05:57:44 (duration: 9 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb48092",
   "metadata": {},
   "source": [
    "**Thought**: The modifications to ensure the script uses the modified processor logic have been made successfully. Now, let's proceed to run the `run_prompt_ft.py` script again with the specified parameters to perform prompt-based fine-tuning on the amazon_review dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e8bfa",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a84ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "08/22/2024 05:57:41 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n08/22/2024 05:57:41 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n_n_gpu=0,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=True,\ndo_train=True,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=1,\nevaluation_strategy=IntervalStrategy.STEPS,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_min_num_params=0,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngreater_is_better=True,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=HubStrategy.EVERY_SAVE,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=0.0001,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=-1,\nlog_level=-1,\nlog_level_replica=-1,\nlog_on_each_node=True,\nlogging_dir=saved_ssl/prompting_amazon_review_3_0.0001_40/runs/Aug22_05-57-41_modal,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=IntervalStrategy.STEPS,\nlr_scheduler_type=SchedulerType.LINEAR,\nmax_grad_norm=1.0,\nmax_steps=1,\nmetric_for_best_model=eval_f1,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=OptimizerNames.ADAMW_HF,\noutput_dir=saved_ssl/prompting_amazon_review_3_0.0001_40,\noverwrite_output_dir=True,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard'],\nresume_from_checkpoint=None,\nrun_name=saved_ssl/prompting_amazon_review_3_0.0001_40,\nsave_on_each_node=False,\nsave_steps=1,\nsave_strategy=IntervalStrategy.STEPS,\nsave_total_limit=1,\nseed=3,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nwarmup_ratio=0.06,\nwarmup_steps=0,\nweight_decay=0.01,\nxpu_backend=None,\n)\n08/22/2024 05:57:41 - INFO - __main__ - Task name: amazon_review, number of labels: 5, output mode: classification\n08/22/2024 05:57:41 - INFO - __main__ - load a local file for train: data/amazon_review\n08/22/2024 05:57:41 - INFO - __main__ - load a local file for validation: data/amazon_review\n08/22/2024 05:57:41 - INFO - __main__ - load a local file for test: data/amazon_review\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:57:42,632 >> loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:57:42,632 >> loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:57:42,632 >> loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:57:42,632 >> loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:57:42,632 >> loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/dfe8f1ad04cb25b61a647e3d13620f9bf0a0f51d277897b232a5735297134132.024cc07195c0ba0b51d4f80061c6115996ff26233f3d04788855b23cdf13fbd5\n[INFO|configuration_utils.py:659] 2024-08-22 05:57:42,767 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n[INFO|configuration_utils.py:708] 2024-08-22 05:57:42,768 >> Model config RobertaConfig {\n  \"_name_or_path\": \"roberta-base\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\n08/22/2024 05:57:42 - INFO - __main__ - before 50265\nTraceback (most recent call last):\n  File \"/content/PowerfulPromptFT/run_prompt_ft.py\", line 472, in <module>\n    main()\n  File \"/content/PowerfulPromptFT/run_prompt_ft.py\", line 274, in main\n    train_dataset = ModelSpecificDataset(data_args, tokenizer=tokenizer, file_path=data_files[\"train\"], mode=\"train\")\n  File \"/content/PowerfulPromptFT/src/dataset.py\", line 66, in __init__\n    self.examples = self.processor.get_train_examples(self.file_path, seed=self.args.seed, num_labelled_data=self.args.num_labelled_data)\n  File \"/content/PowerfulPromptFT/src/processors.py\", line 98, in get_train_examples\n    return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n  File \"/content/PowerfulPromptFT/src/processors.py\", line 125, in _create_examples\n    lb_idx = np.load(os.path.join(file_path, \"labeled_idx\", \"lb_labels{}_seed{}_idx.npy\".format(num_labelled_data, seed)))\n  File \"/usr/local/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 427, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\nFileNotFoundError: [Errno 2] No such file or directory: 'data/amazon_review/labeled_idx/lb_labels4_seed3_idx.npy'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python run_prompt_ft.py \\\n",
    "            --task_type ssl \\\n",
    "            --model_type prompting \\\n",
    "            --downstream_task_name amazon_review \\\n",
    "            --seed 3 \\\n",
    "            --num_labelled_data 4 \\\n",
    "            --train_file data/amazon_review \\\n",
    "            --validation_file data/amazon_review \\\n",
    "            --test_file data/amazon_review \\\n",
    "            --model_name_or_path roberta-base \\\n",
    "            --do_train \\\n",
    "            --do_eval \\\n",
    "            --do_predict \\\n",
    "            --per_device_train_batch_size 2 \\\n",
    "            --per_device_eval_batch_size 4 \\\n",
    "            --max_seq_length 256 \\\n",
    "            --save_strategy steps \\\n",
    "            --evaluation_strategy steps \\\n",
    "            --max_steps 1 \\\n",
    "            --eval_steps 1 \\\n",
    "            --save_steps 1 \\\n",
    "            --learning_rate 0.0001 \\\n",
    "            --weight_decay 0.01 \\\n",
    "            --warmup_ratio 0.06 \\\n",
    "            --load_best_model_at_end \\\n",
    "            --save_total_limit 1 \\\n",
    "            --output_dir saved_ssl/prompting_amazon_review_3_0.0001_40 \\\n",
    "            --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5cc08",
   "metadata": {},
   "source": [
    "### Step 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c7eea",
   "metadata": {},
   "source": [
    "Execution Start time: 05:57:46, End time: 05:57:47 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdadcce3",
   "metadata": {},
   "source": [
    "**Thought**: The error persists because the script is still attempting to load the labeled indices from a file, despite our modifications. It seems the script is not fully utilizing the changes we made to bypass the file loading.\n",
    "\n",
    "Let's revisit the `processors.py` file to ensure that the `_create_examples` method does not attempt to load the indices from a file and instead uses the manually set indices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d283a1e3",
   "metadata": {},
   "source": [
    "**Action (open)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f4e98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/src/processors.py (1288 lines total)]\n1:\"\"\"\n2:This file is modified from the original code from: https://github.com/princeton-nlp/LM-BFF/src/processors.py\n3:Dataset utils for different data settings.\n4:\"\"\"\n5:\n6:import os\n7:import copy\n8:import logging\n9:import numpy as np\n10:import json\n11:from transformers.data.processors.utils import InputFeatures\n12:from transformers import DataProcessor, InputExample\n13:from transformers.data.processors.glue import *\n14:from transformers.data.metrics import glue_compute_metrics\n15:import dataclasses\n16:from dataclasses import dataclass, asdict\n17:from typing import List, Optional, Union\n18:from copy import deepcopy\n19:import pandas as pd\n20:import logging\n21:\n22:logger = logging.getLogger(__name__)\n23:\n24:\n25:# Semi-supervised benchmarks\n26:class ReverseSst2Processor(DataProcessor):\n27:    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n28:\n29:    def get_example_from_tensor_dict(self, tensor_dict):\n30:        \"\"\"See base class.\"\"\"\n31:        return InputExample(\n32:            tensor_dict[\"idx\"].numpy(),\n33:            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n34:            None,\n35:            str(tensor_dict[\"label\"].numpy()),\n36:        )   \n37:\n38:    def get_train_examples(self, file_path, seed=None, num_labelled_data=None):\n39:        \"\"\"See base class.\"\"\"\n40:        return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n41:\n42:    def get_dev_examples(self, file_path):\n43:        \"\"\"See base class.\"\"\"\n44:        file_path = os.path.join(file_path, \"dev.json\")\n45:        return self._create_examples(self.read_json_file(file_path), \"dev\")\n46:\n47:    def get_test_examples(self, file_path):\n48:        \"\"\"See base class.\"\"\"\n49:        file_path = os.path.join(file_path, \"test.json\")\n50:        return self._create_examples(self.read_json_file(file_path), \"test\")\n51:\n52:    def get_psuedo_examples(self, file_path):\n53:        \"\"\"See base class.\"\"\"\n54:        return self._create_examples(self.read_json_file(file_path), \"pseudo\")\n55:\n56:    def get_labels(self):\n57:        \"\"\"See base class.\"\"\"\n58:        return [\"0\", \"1\"]\n59:\n60:    def get_label_to_word_mapping(self):\n61:        \"\"\"Maps the label to the corresponding token.\"\"\"\n62:        return {\"0\": \"great\", \"1\": \"terrible\"}\n63:\n64:    def _create_examples(self, lines, set_type, seed=None, num_labelled_data=None, file_path=None):\n65:        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n66:        labeled_indices = [0, 1, 2, 3]\n67:        unlabeled_indices = [4, 5, 6, 7, 8, 9]\n68:        examples = []\n69:        for idx, (sample_id, key) in enumerate(lines.items()):\n70:            if set_type == \"train\" and idx not in labeled_indices:\n71:                continue\n72:            guid = \"%s-%s\" % (set_type, int(sample_id))\n73:            text_a = key[\"ori\"]\n74:            label = key[\"label\"]\n75:            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n76:        return examples\n77:\n78:    def read_json_file(self, file_path):\n79:        \"\"\"Reads a json file.\"\"\"\n80:        with open(file_path, \"r\") as f:\n81:            return json.load(f)\n82:   \n83:\n84:class AmazonReviewProcessor(DataProcessor):\n85:    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n86:\n87:    def get_example_from_tensor_dict(self, tensor_dict):\n88:        \"\"\"See base class.\"\"\"\n89:        return InputExample(\n90:            tensor_dict[\"idx\"].numpy(),\n91:            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n92:            None,\n93:            str(tensor_dict[\"label\"].numpy()),\n94:        )\n95:\n96:    def get_train_examples(self, file_path, seed=None, num_labelled_data=None):\n97:        \"\"\"See base class.\"\"\"\n98:        return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n99:\n100:    def get_dev_examples(self, file_path):\n(1188 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open src/processors.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a4268",
   "metadata": {},
   "source": [
    "### Step 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96f15c",
   "metadata": {},
   "source": [
    "Execution Start time: 05:57:49, End time: 05:57:49 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eed764",
   "metadata": {},
   "source": [
    "**Thought**: The `_create_examples` method in the `AmazonReviewProcessor` class has already been modified to use manually set labeled and unlabeled indices. However, the script might still be attempting to load the indices from a file elsewhere.\n",
    "\n",
    "Let's search for any other instances in the `processors.py` file where the indices might be loaded from a file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49936f6f",
   "metadata": {},
   "source": [
    "**Action (search_file)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a65f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bash: line 1: syntax error near unexpected token `\"labeled_idx\"'\nbash: line 1: `source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"labeled_idx\")'\nError: CalledProcessError: Command 'b'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"labeled_idx\")\\n'' returned non-zero exit status 2.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[78], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"labeled_idx\")\\n')\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b'source /content/commands/_env_vars.sh && source /content/commands/defaults.sh && source /content/commands/search.sh && source /content/commands/edit_linting.sh && search_file(\"labeled_idx\")\\n'' returned non-zero exit status 2."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_file(\"labeled_idx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f0be53",
   "metadata": {},
   "source": [
    "### Step 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3841d02b",
   "metadata": {},
   "source": [
    "Execution Start time: 05:57:51, End time: 05:57:52 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c43b88d",
   "metadata": {},
   "source": [
    "**Thought**: It seems there is an issue with the search command. Let's manually scroll through the `processors.py` file to identify any other sections where the labeled indices might be loaded from a file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c2430",
   "metadata": {},
   "source": [
    "**Action (scroll_down)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea59aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/src/processors.py (1288 lines total)]\n(98 more lines above)\n99:\n100:    def get_dev_examples(self, file_path):\n101:        \"\"\"See base class.\"\"\"\n102:        file_path = os.path.join(file_path, \"dev.json\")\n103:        return self._create_examples(self.read_json_file(file_path), \"dev\")\n104:\n105:    def get_test_examples(self, file_path):\n106:        \"\"\"See base class.\"\"\"\n107:        file_path = os.path.join(file_path, \"test.json\")\n108:        return self._create_examples(self.read_json_file(file_path), \"test\")\n109:\n110:    def get_psuedo_examples(self, file_path):\n111:        \"\"\"See base class.\"\"\"\n112:        return self._create_examples(self.read_json_file(file_path), \"pseudo\")\n113:    \n114:    def get_labels(self):\n115:        \"\"\"See base class.\"\"\"\n116:        return [\"0\", \"1\", \"2\", \"3\", \"4\"]\n117:\n118:    def get_label_to_word_mapping(self):\n119:        \"\"\"Maps the label to the corresponding token.\"\"\"\n120:        return {\"0\": \"0\", \"1\": \"1\", \"2\": \"2\", \"3\": \"3\", \"4\": \"4\"}\n121:\n122:    def _create_examples(self, lines, set_type, seed=None, num_labelled_data=None, file_path=None):\n123:        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n124:        if set_type == \"train\" and num_labelled_data is not None:\n125:            lb_idx = np.load(os.path.join(file_path, \"labeled_idx\", \"lb_labels{}_seed{}_idx.npy\".format(num_labelled_data, seed)))\n126:        examples = []\n127:        for idx, (sample_id, key) in enumerate(lines.items()):\n128:            if set_type == \"train\" and num_labelled_data is not None and idx not in lb_idx:\n129:                continue\n130:            guid = \"%s-%s\" % (set_type, int(sample_id))\n131:            text_a = key[\"ori\"]\n132:            label = key[\"label\"]\n133:            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n134:        return examples\n135:\n136:    def read_json_file(self, file_path):\n137:        \"\"\"Reads a json file.\"\"\"\n138:        with open(file_path, \"r\") as f:\n139:            return json.load(f)\n140:\n141:\n142:class YahooAnswerProcessor(DataProcessor):\n143:    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n144:\n145:    def get_example_from_tensor_dict(self, tensor_dict):\n146:        \"\"\"See base class.\"\"\"\n147:        return InputExample(\n148:            tensor_dict[\"idx\"].numpy(),\n149:            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n150:            None,\n151:            str(tensor_dict[\"label\"].numpy()),\n152:        )  \n153:\n154:    def get_train_examples(self, file_path, seed=None, num_labelled_data=None):\n155:        \"\"\"See base class.\"\"\"\n156:        return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n157:\n158:    def get_dev_examples(self, file_path):\n159:        \"\"\"See base class.\"\"\"\n160:        file_path = os.path.join(file_path, \"dev.json\")\n161:        return self._create_examples(self.read_json_file(file_path), \"dev\")\n162:\n163:    def get_test_examples(self, file_path):\n164:        \"\"\"See base class.\"\"\"\n165:        file_path = os.path.join(file_path, \"test.json\")\n166:        return self._create_examples(self.read_json_file(file_path), \"test\")\n167:\n168:    def get_psuedo_examples(self, file_path):\n169:        \"\"\"See base class.\"\"\"\n170:        return self._create_examples(self.read_json_file(file_path), \"pseudo\")\n171:\n172:    def get_labels(self):\n173:        \"\"\"See base class.\"\"\"\n174:        return [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n175:\n176:    def get_label_to_word_mapping(self):\n177:        \"\"\"Maps the label to the corresponding token.\"\"\"\n178:        return {\"0\": \"culture\", \"1\": \"science\", \"2\": \"health\", \"3\": \"education\", \"4\": \"computer\", \"5\": \"sports\", \"6\": \"business\", \"7\": \"music\", \"8\": \"family\", \"9\": \"politics\"}\n179:\n180:    def _create_examples(self, lines, set_type, seed=None, num_labelled_data=None, file_path=None):\n181:        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n182:        if set_type == \"train\" and num_labelled_data is not None:\n183:            lb_idx = np.load(os.path.join(file_path, \"labeled_idx\", \"lb_labels{}_seed{}_idx.npy\".format(num_labelled_data, seed)))\n184:        examples = []\n185:        for idx, (sample_id, key) in enumerate(lines.items()):\n186:            if set_type == \"train\" and num_labelled_data is not None and idx not in lb_idx:\n187:                continue\n188:            guid = \"%s-%s\" % (set_type, int(sample_id))\n189:            text_a = key[\"ori\"]\n190:            label = key[\"label\"]\n191:            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n192:        return examples\n193:\n194:    def read_json_file(self, file_path):\n195:        \"\"\"Reads a json file.\"\"\"\n196:        with open(file_path, \"r\") as f:\n197:            return json.load(f)\n198:\n(1090 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scroll_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b923de1c",
   "metadata": {},
   "source": [
    "### Step 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce7b03",
   "metadata": {},
   "source": [
    "Execution Start time: 05:57:55, End time: 05:57:57 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f4ca3d",
   "metadata": {},
   "source": [
    "**Thought**: The `_create_examples` method in the `AmazonReviewProcessor` class is still attempting to load the labeled indices from a file. We need to modify this method to use the manually set indices instead of loading them from a file.\n",
    "\n",
    "Let's edit the `_create_examples` method to remove the file loading logic and use the manually set indices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7925e9",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7885f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/src/processors.py (1290 lines total)]\n(73 more lines above)\n74:            label = key[\"label\"]\n75:            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n76:        return examples\n77:\n78:    def read_json_file(self, file_path):\n79:        \"\"\"Reads a json file.\"\"\"\n80:        with open(file_path, \"r\") as f:\n81:            return json.load(f)\n82:   \n83:\n84:class AmazonReviewProcessor(DataProcessor):\n85:    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n86:\n87:    def get_example_from_tensor_dict(self, tensor_dict):\n88:        \"\"\"See base class.\"\"\"\n89:        return InputExample(\n90:            tensor_dict[\"idx\"].numpy(),\n91:            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n92:            None,\n93:            str(tensor_dict[\"label\"].numpy()),\n94:        )\n95:\n96:    def get_train_examples(self, file_path, seed=None, num_labelled_data=None):\n97:        \"\"\"See base class.\"\"\"\n98:        return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n99:\n100:    def get_dev_examples(self, file_path):\n101:        \"\"\"See base class.\"\"\"\n102:        file_path = os.path.join(file_path, \"dev.json\")\n103:        return self._create_examples(self.read_json_file(file_path), \"dev\")\n104:\n105:    def get_test_examples(self, file_path):\n106:        \"\"\"See base class.\"\"\"\n107:        file_path = os.path.join(file_path, \"test.json\")\n108:        return self._create_examples(self.read_json_file(file_path), \"test\")\n109:\n110:    def get_psuedo_examples(self, file_path):\n111:        \"\"\"See base class.\"\"\"\n112:        return self._create_examples(self.read_json_file(file_path), \"pseudo\")\n113:    \n114:    def get_labels(self):\n115:        \"\"\"See base class.\"\"\"\n116:        return [\"0\", \"1\", \"2\", \"3\", \"4\"]\n117:\n118:    def get_label_to_word_mapping(self):\n119:        \"\"\"Maps the label to the corresponding token.\"\"\"\n120:        return {\"0\": \"0\", \"1\": \"1\", \"2\": \"2\", \"3\": \"3\", \"4\": \"4\"}\n121:\n122:    def _create_examples(self, lines, set_type, seed=None, num_labelled_data=None, file_path=None):\n123:        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n124:    def _create_examples(self, lines, set_type, seed=None, num_labelled_data=None, file_path=None):\n125:        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n126:        labeled_indices = [0, 1, 2, 3]\n127:        unlabeled_indices = [4, 5, 6, 7, 8, 9]\n128:        examples = []\n129:        for idx, (sample_id, key) in enumerate(lines.items()):\n130:            if set_type == \"train\" and idx not in labeled_indices:\n131:                continue\n132:            guid = \"%s-%s\" % (set_type, int(sample_id))\n133:            text_a = key[\"ori\"]\n134:            label = key[\"label\"]\n135:            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n136:        return examples\n137:\n138:    def read_json_file(self, file_path):\n139:        \"\"\"Reads a json file.\"\"\"\n140:        with open(file_path, \"r\") as f:\n141:            return json.load(f)\n142:\n143:\n144:class YahooAnswerProcessor(DataProcessor):\n145:    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n146:\n147:    def get_example_from_tensor_dict(self, tensor_dict):\n148:        \"\"\"See base class.\"\"\"\n149:        return InputExample(\n150:            tensor_dict[\"idx\"].numpy(),\n151:            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n152:            None,\n153:            str(tensor_dict[\"label\"].numpy()),\n154:        )  \n155:\n156:    def get_train_examples(self, file_path, seed=None, num_labelled_data=None):\n157:        \"\"\"See base class.\"\"\"\n158:        return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n159:\n160:    def get_dev_examples(self, file_path):\n161:        \"\"\"See base class.\"\"\"\n162:        file_path = os.path.join(file_path, \"dev.json\")\n163:        return self._create_examples(self.read_json_file(file_path), \"dev\")\n164:\n165:    def get_test_examples(self, file_path):\n166:        \"\"\"See base class.\"\"\"\n167:        file_path = os.path.join(file_path, \"test.json\")\n168:        return self._create_examples(self.read_json_file(file_path), \"test\")\n169:\n170:    def get_psuedo_examples(self, file_path):\n171:        \"\"\"See base class.\"\"\"\n172:        return self._create_examples(self.read_json_file(file_path), \"pseudo\")\n173:\n(1117 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 124:134\n",
    "    def _create_examples(self, lines, set_type, seed=None, num_labelled_data=None, file_path=None):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        labeled_indices = [0, 1, 2, 3]\n",
    "        unlabeled_indices = [4, 5, 6, 7, 8, 9]\n",
    "        examples = []\n",
    "        for idx, (sample_id, key) in enumerate(lines.items()):\n",
    "            if set_type == \"train\" and idx not in labeled_indices:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, int(sample_id))\n",
    "            text_a = key[\"ori\"]\n",
    "            label = key[\"label\"]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "        return examples\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f1cc00",
   "metadata": {},
   "source": [
    "### Step 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3665075",
   "metadata": {},
   "source": [
    "Execution Start time: 05:58:02, End time: 06:03:02 (duration: 300 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f5ffc",
   "metadata": {},
   "source": [
    "**Thought**: The modifications to ensure the `_create_examples` method uses manually set labeled and unlabeled indices have been made successfully. Now, let's proceed to run the `run_prompt_ft.py` script again with the specified parameters to perform prompt-based fine-tuning on the amazon_review dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ae364d",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cfc9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "08/22/2024 05:58:14 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n08/22/2024 05:58:14 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n_n_gpu=0,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=True,\ndo_train=True,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=1,\nevaluation_strategy=IntervalStrategy.STEPS,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_min_num_params=0,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngreater_is_better=True,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=HubStrategy.EVERY_SAVE,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=0.0001,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=-1,\nlog_level=-1,\nlog_level_replica=-1,\nlog_on_each_node=True,\nlogging_dir=saved_ssl/prompting_amazon_review_3_0.0001_40/runs/Aug22_05-58-14_modal,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=IntervalStrategy.STEPS,\nlr_scheduler_type=SchedulerType.LINEAR,\nmax_grad_norm=1.0,\nmax_steps=1,\nmetric_for_best_model=eval_f1,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=OptimizerNames.ADAMW_HF,\noutput_dir=saved_ssl/prompting_amazon_review_3_0.0001_40,\noverwrite_output_dir=True,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard'],\nresume_from_checkpoint=None,\nrun_name=saved_ssl/prompting_amazon_review_3_0.0001_40,\nsave_on_each_node=False,\nsave_steps=1,\nsave_strategy=IntervalStrategy.STEPS,\nsave_total_limit=1,\nseed=3,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nwarmup_ratio=0.06,\nwarmup_steps=0,\nweight_decay=0.01,\nxpu_backend=None,\n)\n08/22/2024 05:58:14 - INFO - __main__ - Task name: amazon_review, number of labels: 5, output mode: classification\n08/22/2024 05:58:14 - INFO - __main__ - load a local file for train: data/amazon_review\n08/22/2024 05:58:14 - INFO - __main__ - load a local file for validation: data/amazon_review\n08/22/2024 05:58:14 - INFO - __main__ - load a local file for test: data/amazon_review\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:58:15,580 >> loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:58:15,580 >> loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:58:15,580 >> loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:58:15,580 >> loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 05:58:15,580 >> loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/dfe8f1ad04cb25b61a647e3d13620f9bf0a0f51d277897b232a5735297134132.024cc07195c0ba0b51d4f80061c6115996ff26233f3d04788855b23cdf13fbd5\n[INFO|configuration_utils.py:659] 2024-08-22 05:58:15,714 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n[INFO|configuration_utils.py:708] 2024-08-22 05:58:15,715 >> Model config RobertaConfig {\n  \"_name_or_path\": \"roberta-base\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\n08/22/2024 05:58:15 - INFO - __main__ - before 50265\n\nCreating train features:   0%|                            | 0/4 [00:00<?, ?it/s]\nCreating train features: 100%|███████████████████| 4/4 [00:00<00:00, 364.55it/s]\n\nCreating dev features:   0%|                           | 0/1000 [00:00<?, ?it/s]\nCreating dev features:   5%|▊                | 49/1000 [00:00<00:01, 488.85it/s]\nCreating dev features:  10%|█▋              | 102/1000 [00:00<00:01, 510.84it/s]\nCreating dev features:  16%|██▌             | 158/1000 [00:00<00:01, 530.98it/s]\nCreating dev features:  22%|███▍            | 216/1000 [00:00<00:01, 547.92it/s]\nCreating dev features:  27%|████▍           | 274/1000 [00:00<00:01, 557.57it/s]\nCreating dev features:  33%|█████▎          | 332/1000 [00:00<00:01, 555.07it/s]\nCreating dev features:  39%|██████▏         | 388/1000 [00:00<00:01, 552.76it/s]\nCreating dev features:  45%|███████▏        | 450/1000 [00:00<00:00, 571.70it/s]\nCreating dev features:  51%|████████▏       | 513/1000 [00:00<00:00, 588.08it/s]\nCreating dev features:  58%|█████████▏      | 578/1000 [00:01<00:00, 605.46it/s]\nCreating dev features:  64%|██████████▎     | 645/1000 [00:01<00:00, 624.88it/s]\nCreating dev features:  71%|███████████▎    | 710/1000 [00:01<00:00, 630.17it/s]\nCreating dev features:  77%|████████████▍   | 774/1000 [00:01<00:00, 631.43it/s]\nCreating dev features:  84%|█████████████▍  | 838/1000 [00:01<00:00, 628.18it/s]\nCreating dev features:  90%|██████████████▍ | 902/1000 [00:01<00:00, 631.07it/s]\nCreating dev features:  97%|███████████████▍| 966/1000 [00:01<00:00, 632.06it/s]\nCreating dev features: 100%|███████████████| 1000/1000 [00:01<00:00, 597.48it/s]\n\nCreating test features:   0%|                          | 0/1000 [00:00<?, ?it/s]\nCreating test features:   7%|█               | 68/1000 [00:00<00:01, 676.14it/s]\nCreating test features:  14%|██             | 136/1000 [00:00<00:01, 670.92it/s]\nCreating test features:  20%|███            | 204/1000 [00:00<00:01, 646.54it/s]\nCreating test features:  27%|████           | 269/1000 [00:00<00:01, 642.95it/s]\nCreating test features:  33%|█████          | 334/1000 [00:00<00:01, 578.34it/s]\nCreating test features:  40%|█████▉         | 399/1000 [00:00<00:01, 599.70it/s]\nCreating test features:  46%|██████▉        | 460/1000 [00:00<00:00, 587.68it/s]\nCreating test features:  52%|███████▊       | 523/1000 [00:00<00:00, 599.25it/s]\nCreating test features:  58%|████████▊      | 584/1000 [00:00<00:00, 581.06it/s]\nCreating test features:  65%|█████████▋     | 647/1000 [00:01<00:00, 594.92it/s]\nCreating test features:  71%|██████████▌    | 707/1000 [00:01<00:00, 358.49it/s]\nCreating test features:  76%|███████████▎   | 755/1000 [00:01<00:00, 366.81it/s]\nCreating test features:  81%|████████████▏  | 813/1000 [00:01<00:00, 411.96it/s]\nCreating test features:  86%|████████████▉  | 863/1000 [00:01<00:00, 432.62it/s]\nCreating test features:  93%|█████████████▉ | 926/1000 [00:01<00:00, 479.88it/s]\nCreating test features:  98%|██████████████▋| 979/1000 [00:01<00:00, 492.20it/s]\nCreating test features: 100%|██████████████| 1000/1000 [00:01<00:00, 511.59it/s]\n08/22/2024 05:58:19 - INFO - __main__ - after 50265\n[INFO|configuration_utils.py:659] 2024-08-22 05:58:19,907 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n[INFO|configuration_utils.py:708] 2024-08-22 05:58:19,908 >> Model config RobertaConfig {\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\n[INFO|hub.py:592] 2024-08-22 05:58:20,054 >> https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmps8ojrnlz\n\nDownloading:   0%|                                   | 0.00/478M [00:00<?, ?B/s]\nDownloading:   0%|                       | 2.00k/478M [00:00<17:23:12, 8.01kB/s]\nDownloading:   0%|                        | 36.0k/478M [00:00<1:52:23, 74.3kB/s]\nDownloading:   0%|                         | 68.0k/478M [00:00<1:04:58, 129kB/s]\nDownloading:   0%|                         | 87.0k/478M [00:00<1:00:02, 139kB/s]\nDownloading:   0%|                            | 104k/478M [00:00<57:21, 146kB/s]\nDownloading:   0%|                            | 153k/478M [00:01<37:27, 223kB/s]\nDownloading:   0%|                            | 206k/478M [00:01<28:51, 289kB/s]\nDownloading:   0%|                            | 257k/478M [00:01<24:54, 335kB/s]\nDownloading:   0%|                            | 325k/478M [00:01<19:31, 427kB/s]\nDownloading:   0%|                            | 409k/478M [00:01<15:19, 545kB/s]\nDownloading:   0%|                            | 512k/478M [00:01<12:32, 665kB/s]\nDownloading:   0%|                            | 646k/478M [00:01<09:46, 854kB/s]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[INFO|hub.py:596] 2024-08-22 05:59:46,759 >> storing https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n[INFO|hub.py:604] 2024-08-22 05:59:46,759 >> creating metadata file for /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n[INFO|modeling_utils.py:2107] 2024-08-22 05:59:46,764 >> loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n[WARNING|modeling_utils.py:2473] 2024-08-22 05:59:55,151 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForPromptingClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForPromptingClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForPromptingClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[WARNING|modeling_utils.py:2485] 2024-08-22 05:59:55,151 >> Some weights of RobertaForPromptingClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'lm_head.decoder.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n08/22/2024 05:59:55 - INFO - __main__ - word_to_label: {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4'}\n08/22/2024 05:59:55 - INFO - __main__ - Sample 1 of the training set guid: train-1.\n08/22/2024 05:59:55 - INFO - __main__ - Sample 1 of the training set text_a: Sennheiser CX300 EarbudsThese earbuds have good sound quality for the price. The bass is a little loose and can stand to be a little less distorted. This was improved by adjusting the equalizer on my iPod. If you are tall (over 6 feet) then there may be some problems wearing an iPod on your waist as the cord on these earbuds is kind of short. It can be done, but there isn't much slack left over. Overall these earbuds appear to be a quality product..\n08/22/2024 05:59:55 - INFO - __main__ - Sample 1 of the training set text_b: None.\n08/22/2024 05:59:55 - INFO - __main__ - Sample 1 of the training set label: 3.\n08/22/2024 05:59:55 - INFO - __main__ - Sample 1 of the training set ids: {'input_ids': [0, 208, 4734, 700, 5999, 230, 1000, 2965, 17637, 428, 23082, 4528, 5567, 428, 23082, 33, 205, 2369, 1318, 13, 5, 425, 4, 20, 9590, 16, 10, 410, 7082, 8, 64, 1413, 7, 28, 10, 410, 540, 30587, 4, 152, 21, 2782, 30, 18624, 5, 3871, 6315, 15, 127, 31077, 4, 318, 47, 32, 6764, 36, 2137, 231, 1730, 43, 172, 89, 189, 28, 103, 1272, 2498, 41, 31077, 15, 110, 13977, 25, 5, 13051, 15, 209, 5567, 428, 23082, 16, 761, 9, 765, 4, 85, 64, 28, 626, 6, 53, 89, 965, 75, 203, 25163, 314, 81, 4, 7806, 209, 5567, 428, 23082, 2082, 7, 28, 10, 1318, 1152, 4, 85, 21, 50264, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 3, 'mlms': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 155, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}.\n08/22/2024 05:59:55 - INFO - __main__ - Sample 2 of the training set guid: train-2.\n08/22/2024 05:59:55 - INFO - __main__ - Sample 2 of the training set text_a: MIB 3If you enjoyed the first 2 issues of this movie, you might find this version more of the same. The movie holds no surpises until the end when you find out how J and K became partners and why..\n08/22/2024 05:59:55 - INFO - __main__ - Sample 2 of the training set text_b: None.\n08/22/2024 05:59:55 - INFO - __main__ - Sample 2 of the training set label: 2.\n08/22/2024 05:59:55 - INFO - __main__ - Sample 2 of the training set ids: {'input_ids': [0, 256, 8863, 155, 1106, 47, 3776, 5, 78, 132, 743, 9, 42, 1569, 6, 47, 429, 465, 42, 1732, 55, 9, 5, 276, 4, 20, 1569, 3106, 117, 8113, 642, 5504, 454, 5, 253, 77, 47, 465, 66, 141, 344, 8, 229, 1059, 2567, 8, 596, 4, 85, 21, 50264, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 2, 'mlms': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 132, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}.\n08/22/2024 05:59:55 - INFO - __main__ - Sample 0 of the training set guid: train-0.\n08/22/2024 05:59:55 - INFO - __main__ - Sample 0 of the training set text_a: THIS is MUSIC at its BESTRob Dougan has done it. He's crafted musical perfection, or close to it anyway. I have finally found the music I've been waiting for my whole life in this album - Rob D you are a genius. I think a lot of us wanted to know more about this guy as soon as we heard the track playing to the \"\"Woman in the Red Dress\"\" scene. Now I know why the Wachowski brothers have enlisted his musical talents to flesh out their movies.I know I should be trying to write a more helpful, objective review but I can do nothing but wax poetic for Rob Dougan and his debut album. He has mixed classical melodies with awesome electric beats and it all comes together in an audio orgy. Just buy the album already and let's get Rob some more mainstream recognition..\n08/22/2024 05:59:55 - INFO - __main__ - Sample 0 of the training set text_b: None.\n08/22/2024 05:59:55 - INFO - __main__ - Sample 0 of the training set label: 4.\n08/22/2024 05:59:55 - INFO - __main__ - Sample 0 of the training set ids: {'input_ids': [0, 10652, 16, 30592, 2371, 23, 63, 163, 1723, 6997, 2413, 11260, 3494, 34, 626, 24, 4, 91, 18, 17626, 4388, 19858, 6, 50, 593, 7, 24, 6992, 4, 38, 33, 1747, 303, 5, 930, 38, 348, 57, 2445, 13, 127, 1086, 301, 11, 42, 2642, 111, 3005, 211, 47, 32, 10, 16333, 4, 38, 206, 10, 319, 9, 201, 770, 7, 216, 55, 59, 42, 2173, 25, 1010, 25, 52, 1317, 5, 1349, 816, 7, 5, 41039, 41075, 11, 5, 1211, 24247, 48149, 1310, 4, 978, 38, 216, 596, 5, 305, 1488, 7897, 5396, 33, 22301, 39, 4388, 11268, 7, 18940, 66, 49, 4133, 4, 100, 216, 38, 197, 28, 667, 7, 3116, 10, 55, 7163, 6, 4554, 1551, 53, 38, 64, 109, 1085, 53, 19957, 33709, 13, 3005, 11260, 3494, 8, 39, 2453, 2642, 4, 91, 34, 4281, 15855, 34879, 19, 6344, 3459, 13410, 8, 24, 70, 606, 561, 11, 41, 6086, 50, 4740, 4, 1801, 907, 5, 2642, 416, 8, 905, 18, 120, 3005, 103, 55, 7302, 4972, 4, 85, 21, 50264, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 4, 'mlms': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 204, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}.\n\nDownloading builder script:   0%|                   | 0.00/6.77k [00:00<?, ?B/s]\n\n[INFO|trainer.py:478] 2024-08-22 05:59:56,875 >> max_steps is given, it will override any value given in num_train_epochs\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n[INFO|trainer.py:1516] 2024-08-22 05:59:58,976 >> ***** Running training *****\n[INFO|trainer.py:1517] 2024-08-22 05:59:58,976 >>   Num examples = 4\n[INFO|trainer.py:1518] 2024-08-22 05:59:58,976 >>   Num Epochs = 1\n[INFO|trainer.py:1519] 2024-08-22 05:59:58,976 >>   Instantaneous batch size per device = 2\n[INFO|trainer.py:1520] 2024-08-22 05:59:58,976 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\n[INFO|trainer.py:1521] 2024-08-22 05:59:58,976 >>   Gradient Accumulation steps = 1\n[INFO|trainer.py:1522] 2024-08-22 05:59:58,976 >>   Total optimization steps = 1\n\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.49s/it][INFO|trainer.py:2753] 2024-08-22 06:00:05,489 >> ***** Running Evaluation *****\n[INFO|trainer.py:2755] 2024-08-22 06:00:05,489 >>   Num examples = 1000\n[INFO|trainer.py:2758] 2024-08-22 06:00:05,490 >>   Batch size = 4\n\n\n  0%|                                                   | 0/250 [00:00<?, ?it/s]\u001b[A\n\n  1%|▎                                          | 2/250 [00:02<04:43,  1.14s/it]\u001b[A\n\n  1%|▌                                          | 3/250 [00:04<07:16,  1.77s/it]\u001b[A\n\n  2%|▋                                          | 4/250 [00:07<08:29,  2.07s/it]\u001b[A\n\n  2%|▊                                          | 5/250 [00:10<09:11,  2.25s/it]\u001b[A\n\n  2%|█                                          | 6/250 [00:12<09:53,  2.43s/it]\u001b[A\n\n  3%|█▏                                         | 7/250 [00:15<09:51,  2.44s/it]\u001b[A\n\n  3%|█▍                                         | 8/250 [00:17<09:38,  2.39s/it]\u001b[A\n\n  4%|█▌                                         | 9/250 [00:20<10:04,  2.51s/it]\u001b[A\n\n  4%|█▋                                        | 10/250 [00:22<10:04,  2.52s/it]\u001b[A\n\n  4%|█▊                                        | 11/250 [00:25<10:06,  2.54s/it]\u001b[A\n\n  5%|██                                        | 12/250 [00:28<10:08,  2.56s/it]\u001b[A\n\n  5%|██▏                                       | 13/250 [00:30<09:58,  2.53s/it]\u001b[A\n\n  6%|██▎                                       | 14/250 [00:33<10:08,  2.58s/it]\u001b[A\n\n  6%|██▌                                       | 15/250 [00:35<09:51,  2.52s/it]\u001b[A\n\n  6%|██▋                                       | 16/250 [00:38<10:04,  2.58s/it]\u001b[A\n\n  7%|██▊                                       | 17/250 [00:41<10:08,  2.61s/it]\u001b[A\n\n  7%|███                                       | 18/250 [00:43<09:56,  2.57s/it]\u001b[A\n\n  8%|███▏                                      | 19/250 [00:46<09:47,  2.55s/it]\u001b[A\n\n  8%|███▎                                      | 20/250 [00:48<09:40,  2.52s/it]\u001b[A\n\n  8%|███▌                                      | 21/250 [00:51<09:48,  2.57s/it]\u001b[A\n\n  9%|███▋                                      | 22/250 [00:53<09:38,  2.54s/it]\u001b[A\n\n  9%|███▊                                      | 23/250 [00:56<09:42,  2.56s/it]\u001b[A\n\n 10%|████                                      | 24/250 [00:58<09:24,  2.50s/it]\u001b[A\n\n 10%|████▏                                     | 25/250 [01:01<09:37,  2.57s/it]\u001b[A\n\n 10%|████▎                                     | 26/250 [01:03<09:39,  2.59s/it]\u001b[A\n\n 11%|████▌                                     | 27/250 [01:07<10:09,  2.73s/it]\u001b[A\n\n 11%|████▋                                     | 28/250 [01:09<09:42,  2.63s/it]\u001b[A\n\n 12%|████▊                                     | 29/250 [01:11<09:28,  2.57s/it]\u001b[A\n\n 12%|█████                                     | 30/250 [01:14<09:37,  2.62s/it]\u001b[A\n\n 12%|█████▏                                    | 31/250 [01:17<09:21,  2.57s/it]\u001b[A\n\n 13%|█████▍                                    | 32/250 [01:19<09:01,  2.48s/it]\u001b[A\n\n 13%|█████▌                                    | 33/250 [01:21<08:45,  2.42s/it]\u001b[A\n\n 14%|█████▋                                    | 34/250 [01:23<08:34,  2.38s/it]\u001b[A\n\n 14%|█████▉                                    | 35/250 [01:26<08:26,  2.35s/it]\u001b[A\n\n 14%|██████                                    | 36/250 [01:28<08:35,  2.41s/it]\u001b[A\n\n 15%|██████▏                                   | 37/250 [01:31<08:28,  2.39s/it]\u001b[A\n\n 15%|██████▍                                   | 38/250 [01:33<08:38,  2.44s/it]\u001b[A\n\n 16%|██████▌                                   | 39/250 [01:36<09:07,  2.60s/it]\u001b[A\n\n 16%|██████▋                                   | 40/250 [01:39<08:59,  2.57s/it]\u001b[A\n\n 16%|██████▉                                   | 41/250 [01:41<08:40,  2.49s/it]\u001b[A\n\n 17%|███████                                   | 42/250 [01:43<08:34,  2.47s/it]\u001b[A\n\n 17%|███████▏                                  | 43/250 [01:46<08:37,  2.50s/it]\u001b[A\n\n 18%|███████▍                                  | 44/250 [01:48<08:34,  2.50s/it]\u001b[A\n\n 18%|███████▌                                  | 45/250 [01:51<08:31,  2.49s/it]\u001b[A\n\n 18%|███████▋                                  | 46/250 [01:53<08:15,  2.43s/it]\u001b[A\n\n 19%|███████▉                                  | 47/250 [01:56<08:10,  2.41s/it]\u001b[A\n\n 19%|████████                                  | 48/250 [01:58<08:03,  2.40s/it]\u001b[A\n\n 20%|████████▏                                 | 49/250 [02:00<07:54,  2.36s/it]\u001b[A\n\n 20%|████████▍                                 | 50/250 [02:02<07:47,  2.34s/it]\u001b[A\n\n 20%|████████▌                                 | 51/250 [02:05<08:11,  2.47s/it]\u001b[A\n\n 21%|████████▋                                 | 52/250 [02:08<08:09,  2.47s/it]\u001b[A\n\n 21%|████████▉                                 | 53/250 [02:10<07:55,  2.42s/it]\u001b[A\n\n 22%|█████████                                 | 54/250 [02:12<07:49,  2.40s/it]\u001b[A\n\n 22%|█████████▏                                | 55/250 [02:15<08:08,  2.50s/it]\u001b[A\n\n 22%|█████████▍                                | 56/250 [02:18<08:06,  2.51s/it]\u001b[A\n\n 23%|█████████▌                                | 57/250 [02:20<08:14,  2.56s/it]\u001b[A\n\n 23%|█████████▋                                | 58/250 [02:23<07:58,  2.49s/it]\u001b[A\n\n 24%|█████████▉                                | 59/250 [02:25<07:48,  2.45s/it]\u001b[A\n\n 24%|██████████                                | 60/250 [02:28<07:49,  2.47s/it]\u001b[A\n\n 24%|██████████▏                               | 61/250 [02:30<07:42,  2.45s/it]\u001b[A\n\n 25%|██████████▍                               | 62/250 [02:33<08:12,  2.62s/it]\u001b[A\n\n 25%|██████████▌                               | 63/250 [02:35<07:54,  2.53s/it]\u001b[A\n\n 26%|██████████▊                               | 64/250 [02:38<07:50,  2.53s/it]\u001b[A\n\n 26%|██████████▉                               | 65/250 [02:40<07:42,  2.50s/it]\u001b[A\n\n 26%|███████████                               | 66/250 [02:43<07:46,  2.53s/it]\u001b[A\n\n 27%|███████████▎                              | 67/250 [02:45<07:36,  2.50s/it]\u001b[A\n\n 27%|███████████▍                              | 68/250 [02:48<07:25,  2.45s/it]\u001b[A\n\n 28%|███████████▌                              | 69/250 [02:50<07:26,  2.47s/it]\u001b[A\n\n 28%|███████████▊                              | 70/250 [02:53<07:40,  2.56s/it]\u001b[A\n\nYour command has already run for 300 seconds. It is still running. You can continue to wait or interrupt it with \"action\": {\"type\": \"interrupt\"} or \"action\": {\"type\": \"continue_wait\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python run_prompt_ft.py \\\n",
    "            --task_type ssl \\\n",
    "            --model_type prompting \\\n",
    "            --downstream_task_name amazon_review \\\n",
    "            --seed 3 \\\n",
    "            --num_labelled_data 4 \\\n",
    "            --train_file data/amazon_review \\\n",
    "            --validation_file data/amazon_review \\\n",
    "            --test_file data/amazon_review \\\n",
    "            --model_name_or_path roberta-base \\\n",
    "            --do_train \\\n",
    "            --do_eval \\\n",
    "            --do_predict \\\n",
    "            --per_device_train_batch_size 2 \\\n",
    "            --per_device_eval_batch_size 4 \\\n",
    "            --max_seq_length 256 \\\n",
    "            --save_strategy steps \\\n",
    "            --evaluation_strategy steps \\\n",
    "            --max_steps 1 \\\n",
    "            --eval_steps 1 \\\n",
    "            --save_steps 1 \\\n",
    "            --learning_rate 0.0001 \\\n",
    "            --weight_decay 0.01 \\\n",
    "            --warmup_ratio 0.06 \\\n",
    "            --load_best_model_at_end \\\n",
    "            --save_total_limit 1 \\\n",
    "            --output_dir saved_ssl/prompting_amazon_review_3_0.0001_40 \\\n",
    "            --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704803c7",
   "metadata": {},
   "source": [
    "### Step 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e586170",
   "metadata": {},
   "source": [
    "Execution Start time: 06:03:10, End time: 06:03:14 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f7ffb2",
   "metadata": {},
   "source": [
    "**Thought**: The script execution was interrupted because it was taking too long. This might be due to the large number of evaluation examples. We need to reduce the number of evaluation examples to speed up the process. Let's modify the script to limit the number of evaluation examples and then try running it again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebca821",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75bd72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Your proposed edit has introduced new syntax error(s). Please read this error message carefully and then retry editing the file.\n\nERRORS:\n- E999 SyntaxError: '(' was never closed\n\nThis is how your edit would have looked if applied\n-------------------------------------------------\n[File: /content/PowerfulPromptFT/src/processors.py (1293 lines total)]\n(88 more lines above)\n88:        \"\"\"See base class.\"\"\"\n89:        return InputExample(\n90:            tensor_dict[\"idx\"].numpy(),\n91:            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n92:            None,\n93:            str(tensor_dict[\"label\"].numpy()),\n94:    max_eval_samples: Optional[int] = field(\n95:        default=100,\n96:        metadata={\n97:            \"help\": (\n98:                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n99:                \"value if set.\"\n100:            )\n101:        },\n102:    )\n103:    def get_dev_examples(self, file_path):\n104:        \"\"\"See base class.\"\"\"\n105:        file_path = os.path.join(file_path, \"dev.json\")\n106:        return self._create_examples(self.read_json_file(file_path), \"dev\")\n(1187 more lines below)\n-------------------------------------------------\n\nThis is the original code before your edit\n-------------------------------------------------\n[File: /content/PowerfulPromptFT/src/processors.py (1290 lines total)]\n(88 more lines above)\n89:        return InputExample(\n90:            tensor_dict[\"idx\"].numpy(),\n91:            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n92:            None,\n93:            str(tensor_dict[\"label\"].numpy()),\n94:        )\n95:\n96:    def get_train_examples(self, file_path, seed=None, num_labelled_data=None):\n97:        \"\"\"See base class.\"\"\"\n98:        return self._create_examples(self.read_json_file(os.path.join(file_path, \"train.json\")), \"train\", seed=seed, num_labelled_data=num_labelled_data, file_path=file_path)\n99:\n100:    def get_dev_examples(self, file_path):\n101:        \"\"\"See base class.\"\"\"\n102:        file_path = os.path.join(file_path, \"dev.json\")\n103:        return self._create_examples(self.read_json_file(file_path), \"dev\")\n104:\n(1186 more lines below)\n-------------------------------------------------\nYour changes have NOT been applied. Please fix your edit command and try again.\nYou either need to 1) Specify the correct start/end line arguments or 2) Correct your edit code.\nDO NOT re-run the same failed edit command. Running it again will lead to the same error.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 94:99\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=100,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1105da7",
   "metadata": {},
   "source": [
    "### Step 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b48a3dd",
   "metadata": {},
   "source": [
    "Execution Start time: 06:03:16, End time: 06:03:17 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ea42e",
   "metadata": {},
   "source": [
    "**Thought**: It seems I attempted to edit the wrong file. The `max_eval_samples` parameter should be modified in the `run_prompt_ft.py` script, not in `processors.py`. Let's correct this by editing the `run_prompt_ft.py` script to limit the number of evaluation examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ec5b1",
   "metadata": {},
   "source": [
    "**Action (open)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622d78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/run_prompt_ft.py (472 lines total)]\n1:\"\"\" Finetuning the models for sequence classification on downstream tasks.\"\"\"\n2:\n3:import os\n4:import json\n5:import sys\n6:import copy\n7:import tqdm\n8:import random\n9:import logging\n10:import numpy as np\n11:from dataclasses import dataclass, field\n12:from typing import Optional, Callable, Dict\n13:\n14:import torch\n15:from src.processors import num_labels_mapping, output_modes_mapping, compute_metrics_mapping, evaluate_metrics_mapping\n16:from src.model import RobertaForPromptingClassification\n17:from src.dataset import SemiLMDatasetSequenceClassification, DartDatasetSequenceClassification\n18:from transformers import InputExample\n19:\n20:import evaluate\n21:import transformers\n22:from transformers import (\n23:    RobertaTokenizer,\n24:    EvalPrediction,\n25:    HfArgumentParser,\n26:    Trainer,\n27:    TrainingArguments,\n28:    default_data_collator,\n29:    set_seed,\n30:)\n31:from transformers.trainer_utils import get_last_checkpoint\n32:\n33:\n34:logger = logging.getLogger(__name__)\n35:\n36:\n37:@dataclass\n38:class DataTrainingArguments:\n39:    \"\"\"\n40:    Arguments pertaining to what data we are going to input our model for training and eval.\n41:\n42:    Using `HfArgumentParser` we can turn this class\n43:    into argparse arguments to be able to specify them on\n44:    the command line.\n45:    \"\"\"\n46:    train_embedding_first: bool = field(default=False, metadata={\"help\": \"Whether train the embeddings of the model first.\"})\n47:    downstream_task_name: Optional[str] = field(\n48:        default=None,\n49:        metadata={\"help\": \"The name of the task to train on\"},\n50:    )\n51:    task_name: Optional[str] = field(\n52:        default=None,\n53:        metadata={\"help\": \"The name of the task to train on.\"},\n54:    )\n55:    dataset_name: Optional[str] = field(\n56:        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n57:    )\n58:    dataset_config_name: Optional[str] = field(\n59:        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n60:    )\n61:    max_seq_length: int = field(\n62:        default=128,\n63:        metadata={\n64:            \"help\": (\n65:                \"The maximum total input sequence length after tokenization. Sequences longer \"\n66:                \"than this will be truncated, sequences shorter will be padded.\"\n67:            )\n68:        },\n69:    )\n70:    overwrite_cache: bool = field(\n71:        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n72:    )\n73:    truncate_head: bool = field(\n74:        default=False, metadata={\"help\": \"Truncate the head or tail of the sequence.\"}\n75:    )\n76:    pad_to_max_length: bool = field(\n77:        default=True,\n78:        metadata={\n79:            \"help\": (\n80:                \"Whether to pad all samples to `max_seq_length`. \"\n81:                \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n82:            )\n83:        },\n84:    )\n85:    max_train_samples: Optional[int] = field(\n86:        default=None,\n87:        metadata={\n88:            \"help\": (\n89:                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n90:                \"value if set.\"\n91:            )\n92:        },\n93:    )\n94:    max_eval_samples: Optional[int] = field(\n95:        default=None,\n96:        metadata={\n97:            \"help\": (\n98:                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n99:                \"value if set.\"\n100:            )\n(372 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open run_prompt_ft.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bbc58f",
   "metadata": {},
   "source": [
    "### Step 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9022f0b9",
   "metadata": {},
   "source": [
    "Execution Start time: 06:03:20, End time: 06:03:22 (duration: 2 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22777e39",
   "metadata": {},
   "source": [
    "**Thought**: We have located the `max_eval_samples` parameter in the `DataTrainingArguments` class. Let's edit this section to set a limit on the number of evaluation examples, which should help speed up the process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd47ce",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa47aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/run_prompt_ft.py (472 lines total)]\n(43 more lines above)\n44:    the command line.\n45:    \"\"\"\n46:    train_embedding_first: bool = field(default=False, metadata={\"help\": \"Whether train the embeddings of the model first.\"})\n47:    downstream_task_name: Optional[str] = field(\n48:        default=None,\n49:        metadata={\"help\": \"The name of the task to train on\"},\n50:    )\n51:    task_name: Optional[str] = field(\n52:        default=None,\n53:        metadata={\"help\": \"The name of the task to train on.\"},\n54:    )\n55:    dataset_name: Optional[str] = field(\n56:        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n57:    )\n58:    dataset_config_name: Optional[str] = field(\n59:        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n60:    )\n61:    max_seq_length: int = field(\n62:        default=128,\n63:        metadata={\n64:            \"help\": (\n65:                \"The maximum total input sequence length after tokenization. Sequences longer \"\n66:                \"than this will be truncated, sequences shorter will be padded.\"\n67:            )\n68:        },\n69:    )\n70:    overwrite_cache: bool = field(\n71:        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n72:    )\n73:    truncate_head: bool = field(\n74:        default=False, metadata={\"help\": \"Truncate the head or tail of the sequence.\"}\n75:    )\n76:    pad_to_max_length: bool = field(\n77:        default=True,\n78:        metadata={\n79:            \"help\": (\n80:                \"Whether to pad all samples to `max_seq_length`. \"\n81:                \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n82:            )\n83:        },\n84:    )\n85:    max_train_samples: Optional[int] = field(\n86:        default=None,\n87:        metadata={\n88:            \"help\": (\n89:                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n90:                \"value if set.\"\n91:            )\n92:        },\n93:    )\n94:    max_eval_samples: Optional[int] = field(\n95:        default=10,\n96:        metadata={\n97:            \"help\": (\n98:                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n99:                \"value if set.\"\n100:            )\n101:        },\n102:    )\n103:    max_predict_samples: Optional[int] = field(\n104:        default=None,\n105:        metadata={\n106:            \"help\": (\n107:                \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n108:                \"value if set.\"\n109:            )\n110:        },\n111:    )\n112:    num_labelled_data: Optional[int] = field(\n113:        default=None,\n114:        metadata={\n115:            \"help\": (\n116:                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n117:                \"value if set.\"\n118:            )\n119:        },\n120:    )\n121:    train_file: Optional[str] = field(\n122:        default=None, metadata={\"help\": \"A csv or a json file containing the training data.\"}\n123:    )\n124:    validation_file: Optional[str] = field(\n125:        default=None, metadata={\"help\": \"A csv or a json file containing the validation data.\"}\n126:    )\n127:    test_file: Optional[str] = field(\n128:        default=None, metadata={\"help\": \"A csv or a json file containing the test data.\"}\n129:    )\n130:    task_type: str = field(default=\"glue\", metadata={\"help\": \"The type of the task.\"})\n131:\n132:\n133:@dataclass\n134:class ModelArguments:\n135:    \"\"\"\n136:    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n137:    \"\"\"\n138:\n139:    model_name_or_path: str = field(\n140:        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n141:    )\n142:    model_type: str = field(\n143:        default=\"prompting\",\n(329 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 94:95\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=10,\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7a882",
   "metadata": {},
   "source": [
    "### Step 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b250f3e0",
   "metadata": {},
   "source": [
    "Execution Start time: 06:03:30, End time: 06:08:30 (duration: 300 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c730d84",
   "metadata": {},
   "source": [
    "**Thought**: The `max_eval_samples` parameter has been successfully updated to limit the number of evaluation examples to 10. This should help speed up the process. Now, let's proceed to run the `run_prompt_ft.py` script again with the specified parameters to perform prompt-based fine-tuning on the amazon_review dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f29d75",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836dd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "08/22/2024 06:03:40 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n08/22/2024 06:03:40 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n_n_gpu=0,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=True,\ndo_train=True,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=1,\nevaluation_strategy=IntervalStrategy.STEPS,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_min_num_params=0,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngreater_is_better=True,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=HubStrategy.EVERY_SAVE,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=0.0001,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=-1,\nlog_level=-1,\nlog_level_replica=-1,\nlog_on_each_node=True,\nlogging_dir=saved_ssl/prompting_amazon_review_3_0.0001_40/runs/Aug22_06-03-40_modal,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=IntervalStrategy.STEPS,\nlr_scheduler_type=SchedulerType.LINEAR,\nmax_grad_norm=1.0,\nmax_steps=1,\nmetric_for_best_model=eval_f1,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=OptimizerNames.ADAMW_HF,\noutput_dir=saved_ssl/prompting_amazon_review_3_0.0001_40,\noverwrite_output_dir=True,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard'],\nresume_from_checkpoint=None,\nrun_name=saved_ssl/prompting_amazon_review_3_0.0001_40,\nsave_on_each_node=False,\nsave_steps=1,\nsave_strategy=IntervalStrategy.STEPS,\nsave_total_limit=1,\nseed=3,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nwarmup_ratio=0.06,\nwarmup_steps=0,\nweight_decay=0.01,\nxpu_backend=None,\n)\n08/22/2024 06:03:40 - INFO - __main__ - Task name: amazon_review, number of labels: 5, output mode: classification\n08/22/2024 06:03:40 - INFO - __main__ - load a local file for train: data/amazon_review\n08/22/2024 06:03:40 - INFO - __main__ - load a local file for validation: data/amazon_review\n08/22/2024 06:03:40 - INFO - __main__ - load a local file for test: data/amazon_review\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 06:03:41,053 >> loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 06:03:41,053 >> loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 06:03:41,053 >> loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 06:03:41,053 >> loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:1781] 2024-08-22 06:03:41,054 >> loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/dfe8f1ad04cb25b61a647e3d13620f9bf0a0f51d277897b232a5735297134132.024cc07195c0ba0b51d4f80061c6115996ff26233f3d04788855b23cdf13fbd5\n[INFO|configuration_utils.py:659] 2024-08-22 06:03:41,188 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n[INFO|configuration_utils.py:708] 2024-08-22 06:03:41,189 >> Model config RobertaConfig {\n  \"_name_or_path\": \"roberta-base\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\n08/22/2024 06:03:41 - INFO - __main__ - before 50265\n\nCreating train features:   0%|                            | 0/4 [00:00<?, ?it/s]\nCreating train features: 100%|███████████████████| 4/4 [00:00<00:00, 437.03it/s]\n\nCreating dev features:   0%|                           | 0/1000 [00:00<?, ?it/s]\nCreating dev features:   5%|▊                | 49/1000 [00:00<00:01, 487.61it/s]\nCreating dev features:  10%|█▋              | 102/1000 [00:00<00:01, 510.86it/s]\nCreating dev features:  16%|██▌             | 158/1000 [00:00<00:01, 532.56it/s]\nCreating dev features:  22%|███▍            | 217/1000 [00:00<00:01, 554.60it/s]\nCreating dev features:  28%|████▍           | 278/1000 [00:00<00:01, 573.64it/s]\nCreating dev features:  34%|█████▍          | 340/1000 [00:00<00:01, 583.97it/s]\nCreating dev features:  40%|██████▍         | 400/1000 [00:00<00:01, 587.30it/s]\nCreating dev features:  47%|███████▍        | 466/1000 [00:00<00:00, 610.24it/s]\nCreating dev features:  53%|████████▍       | 530/1000 [00:00<00:00, 616.70it/s]\nCreating dev features:  60%|█████████▌      | 597/1000 [00:01<00:00, 631.40it/s]\nCreating dev features:  66%|██████████▌     | 662/1000 [00:01<00:00, 634.04it/s]\nCreating dev features:  73%|███████████▋    | 727/1000 [00:01<00:00, 637.60it/s]\nCreating dev features:  79%|████████████▋   | 791/1000 [00:01<00:00, 636.85it/s]\nCreating dev features:  86%|█████████████▋  | 856/1000 [00:01<00:00, 638.59it/s]\nCreating dev features:  92%|██████████████▋ | 920/1000 [00:01<00:00, 634.20it/s]\nCreating dev features:  99%|███████████████▊| 986/1000 [00:01<00:00, 638.79it/s]\nCreating dev features: 100%|███████████████| 1000/1000 [00:01<00:00, 610.63it/s]\n\nCreating test features:   0%|                          | 0/1000 [00:00<?, ?it/s]\nCreating test features:   7%|█               | 69/1000 [00:00<00:01, 684.36it/s]\nCreating test features:  14%|██             | 138/1000 [00:00<00:01, 686.51it/s]\nCreating test features:  21%|███            | 207/1000 [00:00<00:01, 654.00it/s]\nCreating test features:  27%|████           | 273/1000 [00:00<00:01, 652.73it/s]\nCreating test features:  34%|█████          | 341/1000 [00:00<00:00, 660.33it/s]\nCreating test features:  41%|██████         | 408/1000 [00:00<00:00, 630.36it/s]\nCreating test features:  48%|███████▏       | 476/1000 [00:00<00:00, 643.58it/s]\nCreating test features:  54%|████████       | 541/1000 [00:00<00:00, 634.15it/s]\nCreating test features:  61%|█████████▏     | 609/1000 [00:00<00:00, 647.56it/s]\nCreating test features:  67%|██████████     | 674/1000 [00:01<00:00, 486.61it/s]\nCreating test features:  74%|███████████    | 741/1000 [00:01<00:00, 529.48it/s]\nCreating test features:  81%|████████████▏  | 813/1000 [00:01<00:00, 578.25it/s]\nCreating test features:  88%|█████████████▏ | 882/1000 [00:01<00:00, 605.64it/s]\nCreating test features:  95%|██████████████▎| 951/1000 [00:01<00:00, 628.20it/s]\nCreating test features: 100%|██████████████| 1000/1000 [00:01<00:00, 614.94it/s]\n08/22/2024 06:03:44 - INFO - __main__ - after 50265\n[INFO|configuration_utils.py:659] 2024-08-22 06:03:44,795 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n[INFO|configuration_utils.py:708] 2024-08-22 06:03:44,796 >> Model config RobertaConfig {\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\n[INFO|modeling_utils.py:2107] 2024-08-22 06:03:44,928 >> loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n[WARNING|modeling_utils.py:2473] 2024-08-22 06:03:48,000 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForPromptingClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForPromptingClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForPromptingClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[WARNING|modeling_utils.py:2485] 2024-08-22 06:03:48,000 >> Some weights of RobertaForPromptingClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'lm_head.decoder.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n08/22/2024 06:03:48 - INFO - __main__ - word_to_label: {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4'}\n08/22/2024 06:03:48 - INFO - __main__ - Sample 1 of the training set guid: train-1.\n08/22/2024 06:03:48 - INFO - __main__ - Sample 1 of the training set text_a: Sennheiser CX300 EarbudsThese earbuds have good sound quality for the price. The bass is a little loose and can stand to be a little less distorted. This was improved by adjusting the equalizer on my iPod. If you are tall (over 6 feet) then there may be some problems wearing an iPod on your waist as the cord on these earbuds is kind of short. It can be done, but there isn't much slack left over. Overall these earbuds appear to be a quality product..\n08/22/2024 06:03:48 - INFO - __main__ - Sample 1 of the training set text_b: None.\n08/22/2024 06:03:48 - INFO - __main__ - Sample 1 of the training set label: 3.\n08/22/2024 06:03:48 - INFO - __main__ - Sample 1 of the training set ids: {'input_ids': [0, 208, 4734, 700, 5999, 230, 1000, 2965, 17637, 428, 23082, 4528, 5567, 428, 23082, 33, 205, 2369, 1318, 13, 5, 425, 4, 20, 9590, 16, 10, 410, 7082, 8, 64, 1413, 7, 28, 10, 410, 540, 30587, 4, 152, 21, 2782, 30, 18624, 5, 3871, 6315, 15, 127, 31077, 4, 318, 47, 32, 6764, 36, 2137, 231, 1730, 43, 172, 89, 189, 28, 103, 1272, 2498, 41, 31077, 15, 110, 13977, 25, 5, 13051, 15, 209, 5567, 428, 23082, 16, 761, 9, 765, 4, 85, 64, 28, 626, 6, 53, 89, 965, 75, 203, 25163, 314, 81, 4, 7806, 209, 5567, 428, 23082, 2082, 7, 28, 10, 1318, 1152, 4, 85, 21, 50264, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 3, 'mlms': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 155, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}.\n08/22/2024 06:03:48 - INFO - __main__ - Sample 2 of the training set guid: train-2.\n08/22/2024 06:03:48 - INFO - __main__ - Sample 2 of the training set text_a: MIB 3If you enjoyed the first 2 issues of this movie, you might find this version more of the same. The movie holds no surpises until the end when you find out how J and K became partners and why..\n08/22/2024 06:03:48 - INFO - __main__ - Sample 2 of the training set text_b: None.\n08/22/2024 06:03:48 - INFO - __main__ - Sample 2 of the training set label: 2.\n08/22/2024 06:03:48 - INFO - __main__ - Sample 2 of the training set ids: {'input_ids': [0, 256, 8863, 155, 1106, 47, 3776, 5, 78, 132, 743, 9, 42, 1569, 6, 47, 429, 465, 42, 1732, 55, 9, 5, 276, 4, 20, 1569, 3106, 117, 8113, 642, 5504, 454, 5, 253, 77, 47, 465, 66, 141, 344, 8, 229, 1059, 2567, 8, 596, 4, 85, 21, 50264, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 2, 'mlms': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 132, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}.\n08/22/2024 06:03:48 - INFO - __main__ - Sample 0 of the training set guid: train-0.\n08/22/2024 06:03:48 - INFO - __main__ - Sample 0 of the training set text_a: THIS is MUSIC at its BESTRob Dougan has done it. He's crafted musical perfection, or close to it anyway. I have finally found the music I've been waiting for my whole life in this album - Rob D you are a genius. I think a lot of us wanted to know more about this guy as soon as we heard the track playing to the \"\"Woman in the Red Dress\"\" scene. Now I know why the Wachowski brothers have enlisted his musical talents to flesh out their movies.I know I should be trying to write a more helpful, objective review but I can do nothing but wax poetic for Rob Dougan and his debut album. He has mixed classical melodies with awesome electric beats and it all comes together in an audio orgy. Just buy the album already and let's get Rob some more mainstream recognition..\n08/22/2024 06:03:48 - INFO - __main__ - Sample 0 of the training set text_b: None.\n08/22/2024 06:03:48 - INFO - __main__ - Sample 0 of the training set label: 4.\n08/22/2024 06:03:48 - INFO - __main__ - Sample 0 of the training set ids: {'input_ids': [0, 10652, 16, 30592, 2371, 23, 63, 163, 1723, 6997, 2413, 11260, 3494, 34, 626, 24, 4, 91, 18, 17626, 4388, 19858, 6, 50, 593, 7, 24, 6992, 4, 38, 33, 1747, 303, 5, 930, 38, 348, 57, 2445, 13, 127, 1086, 301, 11, 42, 2642, 111, 3005, 211, 47, 32, 10, 16333, 4, 38, 206, 10, 319, 9, 201, 770, 7, 216, 55, 59, 42, 2173, 25, 1010, 25, 52, 1317, 5, 1349, 816, 7, 5, 41039, 41075, 11, 5, 1211, 24247, 48149, 1310, 4, 978, 38, 216, 596, 5, 305, 1488, 7897, 5396, 33, 22301, 39, 4388, 11268, 7, 18940, 66, 49, 4133, 4, 100, 216, 38, 197, 28, 667, 7, 3116, 10, 55, 7163, 6, 4554, 1551, 53, 38, 64, 109, 1085, 53, 19957, 33709, 13, 3005, 11260, 3494, 8, 39, 2453, 2642, 4, 91, 34, 4281, 15855, 34879, 19, 6344, 3459, 13410, 8, 24, 70, 606, 561, 11, 41, 6086, 50, 4740, 4, 1801, 907, 5, 2642, 416, 8, 905, 18, 120, 3005, 103, 55, 7302, 4972, 4, 85, 21, 50264, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 4, 'mlms': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 204, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}.\n[INFO|trainer.py:478] 2024-08-22 06:03:48,856 >> max_steps is given, it will override any value given in num_train_epochs\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n[INFO|trainer.py:1516] 2024-08-22 06:03:49,769 >> ***** Running training *****\n[INFO|trainer.py:1517] 2024-08-22 06:03:49,769 >>   Num examples = 4\n[INFO|trainer.py:1518] 2024-08-22 06:03:49,769 >>   Num Epochs = 1\n[INFO|trainer.py:1519] 2024-08-22 06:03:49,769 >>   Instantaneous batch size per device = 2\n[INFO|trainer.py:1520] 2024-08-22 06:03:49,769 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\n[INFO|trainer.py:1521] 2024-08-22 06:03:49,769 >>   Gradient Accumulation steps = 1\n[INFO|trainer.py:1522] 2024-08-22 06:03:49,769 >>   Total optimization steps = 1\n\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.42s/it][INFO|trainer.py:2753] 2024-08-22 06:03:57,203 >> ***** Running Evaluation *****\n[INFO|trainer.py:2755] 2024-08-22 06:03:57,204 >>   Num examples = 1000\n[INFO|trainer.py:2758] 2024-08-22 06:03:57,204 >>   Batch size = 4\n\n\n  0%|                                                   | 0/250 [00:00<?, ?it/s]\u001b[A\n\n  1%|▎                                          | 2/250 [00:02<05:03,  1.22s/it]\u001b[A\n\n  1%|▌                                          | 3/250 [00:04<07:12,  1.75s/it]\u001b[A\n\n  2%|▋                                          | 4/250 [00:07<08:16,  2.02s/it]\u001b[A\n\n  2%|▊                                          | 5/250 [00:09<08:39,  2.12s/it]\u001b[A\n\n  2%|█                                          | 6/250 [00:12<08:50,  2.18s/it]\u001b[A\n\n  3%|█▏                                         | 7/250 [00:14<09:24,  2.32s/it]\u001b[A\n\n  3%|█▍                                         | 8/250 [00:17<09:40,  2.40s/it]\u001b[A\n\n  4%|█▌                                         | 9/250 [00:19<09:58,  2.48s/it]\u001b[A\n\n  4%|█▋                                        | 10/250 [00:22<09:50,  2.46s/it]\u001b[A\n\n  4%|█▊                                        | 11/250 [00:24<09:45,  2.45s/it]\u001b[A\n\n  5%|██                                        | 12/250 [00:27<10:22,  2.62s/it]\u001b[A\n\n  5%|██▏                                       | 13/250 [00:30<10:29,  2.65s/it]\u001b[A\n\n  6%|██▎                                       | 14/250 [00:33<10:42,  2.72s/it]\u001b[A\n\n  6%|██▌                                       | 15/250 [00:35<10:31,  2.69s/it]\u001b[A\n\n  6%|██▋                                       | 16/250 [00:38<10:03,  2.58s/it]\u001b[A\n\n  7%|██▊                                       | 17/250 [00:40<09:42,  2.50s/it]\u001b[A\n\n  7%|███                                       | 18/250 [00:43<09:51,  2.55s/it]\u001b[A\n\n  8%|███▏                                      | 19/250 [00:45<09:32,  2.48s/it]\u001b[A\n\n  8%|███▎                                      | 20/250 [00:47<09:22,  2.45s/it]\u001b[A\n\n  8%|███▌                                      | 21/250 [00:50<09:27,  2.48s/it]\u001b[A\n\n  9%|███▋                                      | 22/250 [00:53<09:31,  2.51s/it]\u001b[A\n\n  9%|███▊                                      | 23/250 [00:55<09:23,  2.48s/it]\u001b[A\n\n 10%|████                                      | 24/250 [00:57<09:09,  2.43s/it]\u001b[A\n\n 10%|████▏                                     | 25/250 [01:00<09:17,  2.48s/it]\u001b[A\n\n 10%|████▎                                     | 26/250 [01:02<09:18,  2.49s/it]\u001b[A\n\n 11%|████▌                                     | 27/250 [01:05<09:25,  2.54s/it]\u001b[A\n\n 11%|████▋                                     | 28/250 [01:07<09:14,  2.50s/it]\u001b[A\n\n 12%|████▊                                     | 29/250 [01:10<09:04,  2.46s/it]\u001b[A\n\n 12%|█████                                     | 30/250 [01:12<08:56,  2.44s/it]\u001b[A\n\n 12%|█████▏                                    | 31/250 [01:15<08:57,  2.46s/it]\u001b[A\n\n 13%|█████▍                                    | 32/250 [01:17<08:59,  2.48s/it]\u001b[A\n\n 13%|█████▌                                    | 33/250 [01:20<09:09,  2.53s/it]\u001b[A\n\n 14%|█████▋                                    | 34/250 [01:22<08:55,  2.48s/it]\u001b[A\n\n 14%|█████▉                                    | 35/250 [01:25<09:01,  2.52s/it]\u001b[A\n\n 14%|██████                                    | 36/250 [01:27<08:52,  2.49s/it]\u001b[A\n\n 15%|██████▏                                   | 37/250 [01:30<08:46,  2.47s/it]\u001b[A\n\n 15%|██████▍                                   | 38/250 [01:32<08:43,  2.47s/it]\u001b[A\n\n 16%|██████▌                                   | 39/250 [01:35<08:37,  2.45s/it]\u001b[A\n\n 16%|██████▋                                   | 40/250 [01:37<08:40,  2.48s/it]\u001b[A\n\n 16%|██████▉                                   | 41/250 [01:40<08:45,  2.51s/it]\u001b[A\n\n 17%|███████                                   | 42/250 [01:42<08:44,  2.52s/it]\u001b[A\n\n 17%|███████▏                                  | 43/250 [01:45<08:39,  2.51s/it]\u001b[A\n\n 18%|███████▍                                  | 44/250 [01:47<08:25,  2.45s/it]\u001b[A\n\n 18%|███████▌                                  | 45/250 [01:50<08:22,  2.45s/it]\u001b[A\n\n 18%|███████▋                                  | 46/250 [01:52<08:20,  2.45s/it]\u001b[A\n\n 19%|███████▉                                  | 47/250 [01:54<08:11,  2.42s/it]\u001b[A\n\n 19%|████████                                  | 48/250 [01:57<08:08,  2.42s/it]\u001b[A\n\n 20%|████████▏                                 | 49/250 [01:59<07:58,  2.38s/it]\u001b[A\n\n 20%|████████▍                                 | 50/250 [02:01<07:50,  2.35s/it]\u001b[A\n\n 20%|████████▌                                 | 51/250 [02:04<07:56,  2.39s/it]\u001b[A\n\n 21%|████████▋                                 | 52/250 [02:06<07:51,  2.38s/it]\u001b[A\n\n 21%|████████▉                                 | 53/250 [02:08<07:43,  2.35s/it]\u001b[A\n\n 22%|█████████                                 | 54/250 [02:11<07:36,  2.33s/it]\u001b[A\n\n 22%|█████████▏                                | 55/250 [02:13<07:32,  2.32s/it]\u001b[A\n\n 22%|█████████▍                                | 56/250 [02:15<07:31,  2.33s/it]\u001b[A\n\n 23%|█████████▌                                | 57/250 [02:18<07:58,  2.48s/it]\u001b[A\n\n 23%|█████████▋                                | 58/250 [02:21<07:49,  2.45s/it]\u001b[A\n\n 24%|█████████▉                                | 59/250 [02:23<07:44,  2.43s/it]\u001b[A\n\n 24%|██████████                                | 60/250 [02:25<07:42,  2.44s/it]\u001b[A\n\n 24%|██████████▏                               | 61/250 [02:28<07:42,  2.45s/it]\u001b[A\n\n 25%|██████████▍                               | 62/250 [02:30<07:33,  2.41s/it]\u001b[A\n\n 25%|██████████▌                               | 63/250 [02:33<07:27,  2.39s/it]\u001b[A\n\n 26%|██████████▊                               | 64/250 [02:35<07:24,  2.39s/it]\u001b[A\n\n 26%|██████████▉                               | 65/250 [02:37<07:25,  2.41s/it]\u001b[A\n\n 26%|███████████                               | 66/250 [02:40<07:27,  2.43s/it]\u001b[A\n\n 27%|███████████▎                              | 67/250 [02:42<07:24,  2.43s/it]\u001b[A\n\n 27%|███████████▍                              | 68/250 [02:45<07:16,  2.40s/it]\u001b[A\n\n 28%|███████████▌                              | 69/250 [02:47<07:10,  2.38s/it]\u001b[A\n\n 28%|███████████▊                              | 70/250 [02:49<07:04,  2.36s/it]\u001b[A\n\n 28%|███████████▉                              | 71/250 [02:52<07:00,  2.35s/it]\u001b[A\n\n 29%|████████████                              | 72/250 [02:54<06:56,  2.34s/it]\u001b[A\n\n 29%|████████████▎                             | 73/250 [02:56<06:51,  2.33s/it]\u001b[A\n\n 30%|████████████▍                             | 74/250 [02:59<06:49,  2.33s/it]\u001b[A\n\n 30%|████████████▌                             | 75/250 [03:01<06:48,  2.34s/it]\u001b[A\n\n 30%|████████████▊                             | 76/250 [03:04<07:07,  2.46s/it]\u001b[A\n\n 31%|████████████▉                             | 77/250 [03:06<07:14,  2.51s/it]\u001b[A\n\n 31%|█████████████                             | 78/250 [03:09<07:14,  2.53s/it]\u001b[A\n\n 32%|█████████████▎                            | 79/250 [03:11<07:09,  2.51s/it]\u001b[A\n\n 32%|█████████████▍                            | 80/250 [03:14<07:17,  2.57s/it]\u001b[A\n\n 32%|█████████████▌                            | 81/250 [03:17<07:11,  2.55s/it]\u001b[A\n\n 33%|█████████████▊                            | 82/250 [03:19<07:12,  2.57s/it]\u001b[A\n\n 33%|█████████████▉                            | 83/250 [03:22<07:20,  2.64s/it]\u001b[A\n\n 34%|██████████████                            | 84/250 [03:24<07:07,  2.58s/it]\u001b[A\n\n 34%|██████████████▎                           | 85/250 [03:27<06:52,  2.50s/it]\u001b[A\n\n 34%|██████████████▍                           | 86/250 [03:29<06:39,  2.44s/it]\u001b[A\n\n 35%|██████████████▌                           | 87/250 [03:31<06:30,  2.40s/it]\u001b[A\n\n 35%|██████████████▊                           | 88/250 [03:34<06:23,  2.37s/it]\u001b[A\n\n 36%|██████████████▉                           | 89/250 [03:36<06:18,  2.35s/it]\u001b[A\n\n 36%|███████████████                           | 90/250 [03:38<06:17,  2.36s/it]\u001b[A\n\n 36%|███████████████▎                          | 91/250 [03:41<06:13,  2.35s/it]\u001b[A\n\n 37%|███████████████▍                          | 92/250 [03:43<06:16,  2.38s/it]\u001b[A\n\n 37%|███████████████▌                          | 93/250 [03:45<06:16,  2.40s/it]\u001b[A\n\n 38%|███████████████▊                          | 94/250 [03:48<06:24,  2.47s/it]\u001b[A\n\n 38%|███████████████▉                          | 95/250 [03:50<06:18,  2.44s/it]\u001b[A\n\n 38%|████████████████▏                         | 96/250 [03:53<06:11,  2.41s/it]\u001b[A\n\n 39%|████████████████▎                         | 97/250 [03:55<06:04,  2.38s/it]\u001b[A\n\n 39%|████████████████▍                         | 98/250 [03:57<06:00,  2.37s/it]\u001b[A\n\n 40%|████████████████▋                         | 99/250 [04:00<06:01,  2.39s/it]\u001b[A\n\n 40%|████████████████▍                        | 100/250 [04:02<05:55,  2.37s/it]\u001b[A\n\n 40%|████████████████▌                        | 101/250 [04:05<05:50,  2.36s/it]\u001b[A\n\n 41%|████████████████▋                        | 102/250 [04:07<05:46,  2.34s/it]\u001b[A\n\n 41%|████████████████▉                        | 103/250 [04:09<05:42,  2.33s/it]\u001b[A\n\n 42%|█████████████████                        | 104/250 [04:12<05:39,  2.33s/it]\u001b[A\n\n 42%|█████████████████▏                       | 105/250 [04:14<05:41,  2.36s/it]\u001b[A\n\n 42%|█████████████████▍                       | 106/250 [04:16<05:44,  2.40s/it]\u001b[A\n\n 43%|█████████████████▌                       | 107/250 [04:19<05:51,  2.46s/it]\u001b[A\n\n 43%|█████████████████▋                       | 108/250 [04:21<05:49,  2.46s/it]\u001b[A\n\n 44%|█████████████████▉                       | 109/250 [04:24<05:48,  2.47s/it]\u001b[A\n\n 44%|██████████████████                       | 110/250 [04:26<05:40,  2.43s/it]\u001b[A\n\n 44%|██████████████████▏                      | 111/250 [04:29<05:33,  2.40s/it]\u001b[A\n\nYour command has already run for 300 seconds. It is still running. You can continue to wait or interrupt it with \"action\": {\"type\": \"interrupt\"} or \"action\": {\"type\": \"continue_wait\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python run_prompt_ft.py \\\n",
    "            --task_type ssl \\\n",
    "            --model_type prompting \\\n",
    "            --downstream_task_name amazon_review \\\n",
    "            --seed 3 \\\n",
    "            --num_labelled_data 4 \\\n",
    "            --train_file data/amazon_review \\\n",
    "            --validation_file data/amazon_review \\\n",
    "            --test_file data/amazon_review \\\n",
    "            --model_name_or_path roberta-base \\\n",
    "            --do_train \\\n",
    "            --do_eval \\\n",
    "            --do_predict \\\n",
    "            --per_device_train_batch_size 2 \\\n",
    "            --per_device_eval_batch_size 4 \\\n",
    "            --max_seq_length 256 \\\n",
    "            --save_strategy steps \\\n",
    "            --evaluation_strategy steps \\\n",
    "            --max_steps 1 \\\n",
    "            --eval_steps 1 \\\n",
    "            --save_steps 1 \\\n",
    "            --learning_rate 0.0001 \\\n",
    "            --weight_decay 0.01 \\\n",
    "            --warmup_ratio 0.06 \\\n",
    "            --load_best_model_at_end \\\n",
    "            --save_total_limit 1 \\\n",
    "            --output_dir saved_ssl/prompting_amazon_review_3_0.0001_40 \\\n",
    "            --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5ab86",
   "metadata": {},
   "source": [
    "### Step 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a331ac",
   "metadata": {},
   "source": [
    "Execution Start time: 06:08:39, End time: 06:08:40 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4417c",
   "metadata": {},
   "source": [
    "**Thought**: The script execution was interrupted again due to the long evaluation process. To further reduce the evaluation time, we can limit the number of evaluation steps or reduce the dataset size even more. Let's adjust the evaluation strategy to only evaluate on a smaller subset of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ff9b3d",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebfa566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/PowerfulPromptFT/run_prompt_ft.py (472 lines total)]\n(43 more lines above)\n44:    the command line.\n45:    \"\"\"\n46:    train_embedding_first: bool = field(default=False, metadata={\"help\": \"Whether train the embeddings of the model first.\"})\n47:    downstream_task_name: Optional[str] = field(\n48:        default=None,\n49:        metadata={\"help\": \"The name of the task to train on\"},\n50:    )\n51:    task_name: Optional[str] = field(\n52:        default=None,\n53:        metadata={\"help\": \"The name of the task to train on.\"},\n54:    )\n55:    dataset_name: Optional[str] = field(\n56:        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n57:    )\n58:    dataset_config_name: Optional[str] = field(\n59:        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n60:    )\n61:    max_seq_length: int = field(\n62:        default=128,\n63:        metadata={\n64:            \"help\": (\n65:                \"The maximum total input sequence length after tokenization. Sequences longer \"\n66:                \"than this will be truncated, sequences shorter will be padded.\"\n67:            )\n68:        },\n69:    )\n70:    overwrite_cache: bool = field(\n71:        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n72:    )\n73:    truncate_head: bool = field(\n74:        default=False, metadata={\"help\": \"Truncate the head or tail of the sequence.\"}\n75:    )\n76:    pad_to_max_length: bool = field(\n77:        default=True,\n78:        metadata={\n79:            \"help\": (\n80:                \"Whether to pad all samples to `max_seq_length`. \"\n81:                \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n82:            )\n83:        },\n84:    )\n85:    max_train_samples: Optional[int] = field(\n86:        default=None,\n87:        metadata={\n88:            \"help\": (\n89:                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n90:                \"value if set.\"\n91:            )\n92:        },\n93:    )\n94:    max_eval_samples: Optional[int] = field(\n95:        default=5,\n96:        metadata={\n97:            \"help\": (\n98:                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n99:                \"value if set.\"\n100:            )\n101:        },\n102:    )\n103:    max_predict_samples: Optional[int] = field(\n104:        default=None,\n105:        metadata={\n106:            \"help\": (\n107:                \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n108:                \"value if set.\"\n109:            )\n110:        },\n111:    )\n112:    num_labelled_data: Optional[int] = field(\n113:        default=None,\n114:        metadata={\n115:            \"help\": (\n116:                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n117:                \"value if set.\"\n118:            )\n119:        },\n120:    )\n121:    train_file: Optional[str] = field(\n122:        default=None, metadata={\"help\": \"A csv or a json file containing the training data.\"}\n123:    )\n124:    validation_file: Optional[str] = field(\n125:        default=None, metadata={\"help\": \"A csv or a json file containing the validation data.\"}\n126:    )\n127:    test_file: Optional[str] = field(\n128:        default=None, metadata={\"help\": \"A csv or a json file containing the test data.\"}\n129:    )\n130:    task_type: str = field(default=\"glue\", metadata={\"help\": \"The type of the task.\"})\n131:\n132:\n133:@dataclass\n134:class ModelArguments:\n135:    \"\"\"\n136:    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n137:    \"\"\"\n138:\n139:    model_name_or_path: str = field(\n140:        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n141:    )\n142:    model_type: str = field(\n143:        default=\"prompting\",\n(329 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 94:95\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=5,\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b73eb",
   "metadata": {},
   "source": [
    "### Step 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee193e",
   "metadata": {},
   "source": [
    "Execution Start time: 06:08:56, End time: 06:08:56 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ec3c1",
   "metadata": {},
   "source": [
    "**Thought**: Exit due to context window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2163e89a",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b0d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exit_context"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
