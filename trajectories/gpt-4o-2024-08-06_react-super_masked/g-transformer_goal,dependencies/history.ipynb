{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b6567d",
   "metadata": {},
   "source": [
    "### Query\n",
    "Use the https://github.com/baoguangsheng/g-transformer repository to fine-tune sentence transformer on the default dataset fine-tuning. Report the Sentence-level and Document-level BLEU metrics, as a json structured as follows: {\"Sentence-level BLEU\": 0.0, \"Document-level BLEU\": 0.0} (replace 0.0 with the actual values).\n",
    "\n",
    "Additional instructions:\n",
    "1. Load only the first 10 rows of each set in the dataset.\n",
    "2. Train only one epoch.\n",
    "\n",
    "Git repository: https://github.com/baoguangsheng/g-transformer\n",
    "\n",
    "I have already executed some of the required steps. Now, your goal is to complete the remaining steps and submit the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d54d4",
   "metadata": {},
   "source": [
    "### Prompt\n",
    "<details>\n",
    "[{'role': 'system', 'content': 'Interact in a jupyter notebook to solve the request.\\nOutput a thought and an action.\\nThought can reason about the current situation, and action allows you to interact with the Jupyter notebook. There are three types of actions:\\n(1) execute, which executes a notebook cell with the command under the \"content\" field. This could be a bash command (beginning with !), a python command, or magic command (beginning with %).\\n(2) edit, which allows you to replace existing lines in a file with new lines. To replace lines, you will need to provide the lines as they appear before the replacement, and the lines to replace them with.\\nIn the \"content\" field, format should be ```{filename}\\n<<<BEFORE_EDIT>>>\\nlines before edit\\nlines before edit\\n<<<AFTER_EDIT>>>\\nlines after edit\\nlines after edit```\\n  - Include the entire lines WITH indentation. After editing, make sure indentation is correct.\\n(3) submit, which submits the final answer (or null if there\\'s no answer to submit), formatted as JSON (make sure to use double quotes for keys and values).\\nAlways output exactly one \"thought\" and one \"action\", and encapsulate the content with <content>...</content> tags.\\nI will provide the cell output (observation) for you.\\n\\nTips:\\n- When a github repository is given, you should start by cloning it. You can read the readme file and browse the repo for installation and usage instructions.\\n- Avoid using conda, instead use pip for package management.\\n- Each execution has a 5-minute timeout. After this period, you can decide whether to interrupt the kernel or continue waiting.\\n  You should interrupt if: (1) you are prompted with an interactive message (e.g., \"Do you want to continue? [Y/n]\"). In that case, you can bypass it by executing echo \"y\" | command, or (2) the execution is taking longer than expected because the wrong task is being executed, such as a different model or incorrect number of epochs.\\n  You should continue to wait if the current execution is correct and proceeding as expected.\\n\\nHere are some examples.\\nGit repository: EleutherAI/lm-evaluation-harness\\nQuery: Evaluate EleutherAI/gpt-j-6B on hellaswag. What\\'s the score?\\nThought: First, I need to clone the GitHub repository \\'EleutherAI/lm-evaluation-harness\\'.\\nAction: execute\\n<content>\\n!git clone https://github.com/EleutherAI/lm-evaluation-harness.git\\n</content>\\nObservation: ```\\nCloning into \\'lm-evaluation-harness\\'...\\n```\\nThought: The repository has been cloned. Next, I should check the README file for installation and usage instructions to proceed with evaluating EleutherAI/gpt-j-6B on hellaswag.\\nAction: execute\\n<content>\\n!cat lm-evaluation-harness/README.md\\n</content>\\nObservation: ```# Language Model Evaluation Harness ... truncated ...\\n```\\nThought: The README provides detailed instructions for installing the `lm-eval` package and evaluating models like GPT-J-6B on tasks like hellaswag. I need to install the package and its dependencies first.\\nAction: execute\\n<content>\\n!pip install -e lm-evaluation-harness/.\\n</content>\\nObservation: ```\\nObtaining file:///home/nora/lm-evaluation-harness\\n  Installing build dependencies ... truncated ...\\n```\\nThought: The `lm-eval` package and its dependencies have been installed successfully. Now, I can proceed with evaluating the EleutherAI/gpt-j-6B model on the hellaswag task as per the instructions in the README.\\nAction: execute\\n<content>\\n!lm_eval --model hf --model_args pretrained=EleutherAI/gpt-j-6B --tasks hellaswag --device cuda:0 --batch_size 8\\n</content>\\nObservation: ```\\n{\\n  \"hellaswag\": {\\n    \"acc\": 0.24603658536585363,\\n    \"acc_norm\": 0.34436059706446426,\\n  },  ... truncated ...\\n```\\nThought: The `lm-eval` was executed successfully, providing the metrics I needed. The `acc` metric is 0.2460. The `acc_norm` metric is 0.3444\\nAction: submit\\n<content>\\n{\"acc\": 0.2460, \"acc_norm\": 0.3444}\\n</content>\\n\\nQuery: use pandas to read the file \\'data.csv\\' and display the first 2 rows.\\nThought: First, I need to read the file \\'data.csv\\' using the pandas library.\\nAction: execute\\n<content>\\nimport pandas as pd\\npd.read_csv(\\'data.csv\\').head()\\n</content>\\nObservation: ```\\n    name\\n  0  Alice\\n   1    Bob\\n  2  Charlie\\n```\\nThought: The file \\'data.csv\\' has been read successfully and the first 2 rows have been displayed.\\nAction: submit\\n<content>\\n[\"Alice\", \"Bob\"]\\n</content>\\n\\nQuery: Change the model name in the \\'config.json\\' file from \\'roberta-base\\' to \\'roberta-large\\'.\\nThought: First, I need to read the \\'config.json\\' file to find the location where I can replace the model name.\\nAction: execute\\n<content>\\n!cat config.json\\n</content>\\nObservation: ```\\n{\\n    \"model\": \"roberta-base\",\\n    \"batch_size\": 8,\\n    \"epochs\": 10\\n}\\n```\\nThought: The file has been read successfully. Now, I can replace the model name in the \\'config.json\\' file.\\nAction: edit\\n<content>\\nconfig.json\\n<<<BEFORE_EDIT>>>\\n{\\n    \"model\": \"roberta-base\",\\n    \"batch_size\": 8,\\n<<<AFTER_EDIT>>>\\n{\\n    \"model\": \"roberta-large\",\\n    \"batch_size\": 8,\\n</content>\\nObservation: \"editing file config.json\"\\nThought: The model name has been replaced in the \\'config.json\\' file.\\nAction: submit\\n<content>\\nnull\\n</content>\\n'}, {'role': 'user', 'content': 'Query: Use the https://github.com/baoguangsheng/g-transformer repository to fine-tune sentence transformer on the default dataset fine-tuning. Report the Sentence-level and Document-level BLEU metrics, as a json structured as follows: {\"Sentence-level BLEU\": 0.0, \"Document-level BLEU\": 0.0} (replace 0.0 with the actual values).\\n\\nAdditional instructions:\\n1. Load only the first 10 rows of each set in the dataset.\\n2. Train only one epoch.\\n\\nGit repository: https://github.com/baoguangsheng/g-transformer\\n\\nI have already executed some of the required steps. Now, your goal is to complete the remaining steps and submit the answer.'}]\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f952a8d7",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2e1576",
   "metadata": {},
   "source": [
    "Execution Start time: 22:44:42, End time: 22:44:42 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe0e01f",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb13dad",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98835e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd1aaa",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd5fe77",
   "metadata": {},
   "source": [
    "Execution Start time: 22:44:42, End time: 22:44:42 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e0442",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e30deb",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0a483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Clone repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05475b66",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29537f0",
   "metadata": {},
   "source": [
    "Execution Start time: 22:44:42, End time: 22:44:43 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9fb19b",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc483503",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb98f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloning into 'g-transformer'...\nremote: Enumerating objects: 761, done.\u001b[K\nremote: Counting objects: 100% (151/151)\u001b[K\nremote: Counting objects: 100% (151/151), done.\u001b[K\nremote: Compressing objects: 100% (71/71)\u001b[K\nremote: Compressing objects: 100% (71/71), done.\u001b[K\nremote: Total 761 (delta 80), reused 147 (delta 77), pack-reused 610 (from 1)\u001b[K\nReceiving objects: 100% (761/761)\nReceiving objects: 100% (761/761), 3.03 MiB | 40.23 MiB/s, done.\nResolving deltas: 100% (186/186)\nResolving deltas: 100% (186/186), done.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/baoguangsheng/g-transformer.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018c395",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b461561",
   "metadata": {},
   "source": [
    "Execution Start time: 22:44:43, End time: 22:44:43 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31bc425",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecbc0e1",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233edb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/g-transformer\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/g-transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1fba6f",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908cee1",
   "metadata": {},
   "source": [
    "Execution Start time: 22:44:43, End time: 22:44:43 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dbd846",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf8eda",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf90ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4cf6f1",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c1181",
   "metadata": {},
   "source": [
    "Execution Start time: 22:44:43, End time: 22:45:10 (duration: 26 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d8659",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2947ba0",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a85589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Obtaining file:///content/g-transformer\n  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.10/site-packages (from fairseq-gtrans==0.9.0) (1.16.0)\nRequirement already satisfied: cython in /usr/local/lib/python3.10/site-packages (from fairseq-gtrans==0.9.0) (3.0.10)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from fairseq-gtrans==0.9.0) (1.25.2)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/site-packages (from fairseq-gtrans==0.9.0) (2023.12.25)\nCollecting sacrebleu (from fairseq-gtrans==0.9.0)\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/51.8 kB ? eta -:--:--\n\n\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from fairseq-gtrans==0.9.0) (2.2.1+cpu)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from fairseq-gtrans==0.9.0) (4.66.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi->fairseq-gtrans==0.9.0) (2.22)\nCollecting portalocker (from sacrebleu->fairseq-gtrans==0.9.0)\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\nCollecting tabulate>=0.8.9 (from sacrebleu->fairseq-gtrans==0.9.0)\n  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\nCollecting colorama (from sacrebleu->fairseq-gtrans==0.9.0)\n  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\nCollecting lxml (from sacrebleu->fairseq-gtrans==0.9.0)\n  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch->fairseq-gtrans==0.9.0) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch->fairseq-gtrans==0.9.0) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch->fairseq-gtrans==0.9.0) (1.12)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch->fairseq-gtrans==0.9.0) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch->fairseq-gtrans==0.9.0) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch->fairseq-gtrans==0.9.0) (2023.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch->fairseq-gtrans==0.9.0) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch->fairseq-gtrans==0.9.0) (1.3.0)\nDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/104.0 kB ? eta -:--:--\n\n\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\nDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/5.0 MB ? eta -:--:--\n\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\nBuilding wheels for collected packages: fairseq-gtrans\n  Building editable for fairseq-gtrans (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n\u001b[?25h  Created wheel for fairseq-gtrans: filename=fairseq_gtrans-0.9.0-0.editable-cp310-cp310-linux_x86_64.whl size=4671 sha256=be1e10c7f81121dc9d29179ef256d1e721b5a0962b9e98bb7420f89532898559\n  Stored in directory: /tmp/pip-ephem-wheel-cache-qetlhdch/wheels/3e/31/6f/20b9ec18bcb8b1f717cb8dc12fd7fddc85b94f9bc53df07604\nSuccessfully built fairseq-gtrans\nInstalling collected packages: tabulate, portalocker, lxml, colorama, sacrebleu, fairseq-gtrans\nSuccessfully installed colorama-0.4.6 fairseq-gtrans-0.9.0 lxml-5.3.0 portalocker-2.10.1 sacrebleu-2.4.3 tabulate-0.9.0\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50feecd0",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53437a",
   "metadata": {},
   "source": [
    "Execution Start time: 22:45:10, End time: 22:45:10 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054e670",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d3207",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894b5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempt to run code for perparating data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6d067",
   "metadata": {},
   "source": [
    "### Step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96cdf82",
   "metadata": {},
   "source": [
    "Execution Start time: 22:45:10, End time: 22:45:24 (duration: 14 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e625496",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55194c9",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41158e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/g-transformer\nTue Aug 20 22:45:10 UTC 2024, exp_path: data, data: g-transformer, input: doc, code: bpe, slang: en, tlang: de\nTue Aug 20 22:45:10 UTC 2024, Prepraring data...\nCloning Moses github repository (for tokenization scripts)...\nCloning into 'mosesdecoder'...\nremote: Enumerating objects: 148459, done.\u001b[K\nremote: Counting objects: 100% (887/887)\u001b[K\nremote: Counting objects: 100% (887/887), done.\u001b[K\nremote: Compressing objects: 100% (366/366)\u001b[K\nremote: Compressing objects: 100% (366/366), done.\u001b[K\nremote: Total 148459 (delta 565), reused 797 (delta 517), pack-reused 147572 (from 1)\u001b[K\nReceiving objects: 100% (148459/148459), 125.35 MiB | 31.33 MiB/s\nReceiving objects: 100% (148459/148459), 129.99 MiB | 31.50 MiB/s, done.\nResolving deltas: 100% (114591/114591)\nResolving deltas: 100% (114591/114591), done.\nCloning Subword NMT repository (for BPE pre-processing)...\nCloning into 'subword-nmt'...\nremote: Enumerating objects: 622, done.\u001b[K\nremote: Counting objects: 100% (46/46)\u001b[K\nremote: Counting objects: 100% (46/46), done.\u001b[K\nremote: Compressing objects: 100% (30/30)\u001b[K\nremote: Compressing objects: 100% (30/30), done.\u001b[K\nremote: Total 622 (delta 25), reused 31 (delta 16), pack-reused 576 (from 1)\u001b[K\nReceiving objects: 100% (622/622)\nReceiving objects: 100% (622/622), 261.27 KiB | 18.66 MiB/s, done.\nResolving deltas: 100% (374/374)\nResolving deltas: 100% (374/374), done.\nfilter out empty lines from original data and split doc with empty line...\ndata/g-transformer.tokenized.en-de/tmp/train.en-de.tag\npaste: raw_data/g-transformer/concatenated_en2de_train_en.txt: No such file or directory\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\ndata/g-transformer.tokenized.en-de/tmp/valid.en-de.tag\npaste: raw_data/g-transformer/concatenated_en2de_dev_en.txt: No such file or directory\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\ndata/g-transformer.tokenized.en-de/tmp/test.en-de.tag\npaste: raw_data/g-transformer/concatenated_en2de_test_en.txt: No such file or directory\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\ntruecase the train/valid/test data...\ndata/g-transformer.tokenized.en-de/tmp/truecase.en.mdl\ndata/g-transformer.tokenized.en-de/tmp/truecase.de.mdl\ndata/g-transformer.tokenized.en-de/tmp/train.en.tc\ndata/g-transformer.tokenized.en-de/tmp/train.de.tc\ndata/g-transformer.tokenized.en-de/tmp/valid.en.tc\ndata/g-transformer.tokenized.en-de/tmp/valid.de.tc\ndata/g-transformer.tokenized.en-de/tmp/test.en.tc\ndata/g-transformer.tokenized.en-de/tmp/test.de.tc\nlearn_bpe.py on ...\nTraceback (most recent call last):\n  File \"/content/g-transformer/subword-nmt/subword_nmt/learn_bpe.py\", line 400, in <module>\n    learn_bpe(args.input, args.output, args.symbols, args.min_frequency, args.verbose, is_dict=args.dict_input, is_bytes=args.byte, total_symbols=args.total_symbols, num_workers=args.num_workers)\n  File \"/content/g-transformer/subword-nmt/subword_nmt/learn_bpe.py\", line 332, in learn_bpe\n    threshold = max(stats.values()) / 10\nValueError: max() arg is an empty sequence\napply_bpe.py to train.en...\nError: invalid line 2 in BPE codes file: \nThe line should exist of exactly two subword units, separated by whitespace\napply_bpe.py to valid.en...\nError: invalid line 2 in BPE codes file: \nThe line should exist of exactly two subword units, separated by whitespace\napply_bpe.py to test.en...\nError: invalid line 2 in BPE codes file: \nThe line should exist of exactly two subword units, separated by whitespace\napply_bpe.py to train.de...\nError: invalid line 2 in BPE codes file: \nThe line should exist of exactly two subword units, separated by whitespace\napply_bpe.py to valid.de...\nError: invalid line 2 in BPE codes file: \nThe line should exist of exactly two subword units, separated by whitespace\napply_bpe.py to test.de...\nError: invalid line 2 in BPE codes file: \nThe line should exist of exactly two subword units, separated by whitespace\napply doc-level special tags...\n[2024-08-20 22:45:20,055 INFO] Building segmented data: Namespace(corpuses='test,valid,train', source_lang='en', target_lang='de', datadir='data/g-transformer.tokenized.en-de', destdir='data/g-transformer-sent.segmented.en-de/', max_sents=1, max_tokens=512, min_train_doclen=-1, no_special_tok=False, tempdir='data/g-transformer-sent.segmented.en-de/tmp')\n[2024-08-20 22:45:20,059 INFO] Processed 1 documents of test with a max_len of 512.\n[2024-08-20 22:45:20,059 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/test.en\n[2024-08-20 22:45:20,059 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/test.de\n[2024-08-20 22:45:20,059 INFO] Processed 1 documents of valid with a max_len of 512.\n[2024-08-20 22:45:20,060 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/valid.en\n[2024-08-20 22:45:20,060 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/valid.de\n[2024-08-20 22:45:20,060 INFO] Processed 1 documents of train with a max_len of 512.\n[2024-08-20 22:45:20,060 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/train.en\n[2024-08-20 22:45:20,060 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/train.de\n[2024-08-20 22:45:20,326 INFO] Building segmented data: Namespace(corpuses='test,valid,train', source_lang='en', target_lang='de', datadir='data/g-transformer.tokenized.en-de', destdir='data/g-transformer-doc.segmented.en-de/', max_sents=1000, max_tokens=512, min_train_doclen=-1, no_special_tok=False, tempdir='data/g-transformer-doc.segmented.en-de/tmp')\n[2024-08-20 22:45:20,327 INFO] Processed 1 documents of test with a max_len of 512.\n[2024-08-20 22:45:20,327 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/test.en\n[2024-08-20 22:45:20,327 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/test.de\n[2024-08-20 22:45:20,327 INFO] Processed 1 documents of valid with a max_len of 512.\n[2024-08-20 22:45:20,328 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/valid.en\n[2024-08-20 22:45:20,328 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/valid.de\n[2024-08-20 22:45:20,328 INFO] Processed 1 documents of train with a max_len of 512.\n[2024-08-20 22:45:20,328 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/train.en\n[2024-08-20 22:45:20,328 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/train.de\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/local/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 20, in <module>\n    from fairseq import options, tasks, utils\n  File \"/content/g-transformer/fairseq/__init__.py\", line 17, in <module>\n    import fairseq.criterions  # noqa\n  File \"/content/g-transformer/fairseq/criterions/__init__.py\", line 10, in <module>\n    from fairseq.criterions.fairseq_criterion import FairseqCriterion, LegacyFairseqCriterion\n  File \"/content/g-transformer/fairseq/criterions/fairseq_criterion.py\", line 11, in <module>\n    from fairseq import metrics, utils\n  File \"/content/g-transformer/fairseq/utils.py\", line 22, in <module>\n    from fairseq.modules import gelu, gelu_accurate\n  File \"/content/g-transformer/fairseq/modules/__init__.py\", line 9, in <module>\n    from .character_token_embedder import CharacterTokenEmbedder\n  File \"/content/g-transformer/fairseq/modules/character_token_embedder.py\", line 13, in <module>\n    from fairseq.data import Dictionary\n  File \"/content/g-transformer/fairseq/data/__init__.py\", line 21, in <module>\n    from .indexed_dataset import IndexedCachedDataset, IndexedDataset, IndexedRawTextDataset, MMapIndexedDataset\n  File \"/content/g-transformer/fairseq/data/indexed_dataset.py\", line 89, in <module>\n    6: np.float,\n  File \"/usr/local/lib/python3.10/site-packages/numpy/__init__.py\", line 319, in __getattr__\n    raise AttributeError(__former_attrs__[attr])\nAttributeError: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'cfloat'?\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/local/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 20, in <module>\n    from fairseq import options, tasks, utils\n  File \"/content/g-transformer/fairseq/__init__.py\", line 17, in <module>\n    import fairseq.criterions  # noqa\n  File \"/content/g-transformer/fairseq/criterions/__init__.py\", line 10, in <module>\n    from fairseq.criterions.fairseq_criterion import FairseqCriterion, LegacyFairseqCriterion\n  File \"/content/g-transformer/fairseq/criterions/fairseq_criterion.py\", line 11, in <module>\n    from fairseq import metrics, utils\n  File \"/content/g-transformer/fairseq/utils.py\", line 22, in <module>\n    from fairseq.modules import gelu, gelu_accurate\n  File \"/content/g-transformer/fairseq/modules/__init__.py\", line 9, in <module>\n    from .character_token_embedder import CharacterTokenEmbedder\n  File \"/content/g-transformer/fairseq/modules/character_token_embedder.py\", line 13, in <module>\n    from fairseq.data import Dictionary\n  File \"/content/g-transformer/fairseq/data/__init__.py\", line 21, in <module>\n    from .indexed_dataset import IndexedCachedDataset, IndexedDataset, IndexedRawTextDataset, MMapIndexedDataset\n  File \"/content/g-transformer/fairseq/data/indexed_dataset.py\", line 89, in <module>\n    6: np.float,\n  File \"/usr/local/lib/python3.10/site-packages/numpy/__init__.py\", line 319, in __getattr__\n    raise AttributeError(__former_attrs__[attr])\nAttributeError: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'cfloat'?\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/g-transformer\n",
    "!bash exp_gtrans/prepare-finetune.sh g-transformer data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a61041",
   "metadata": {},
   "source": [
    "### Step 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60fd865",
   "metadata": {},
   "source": [
    "Execution Start time: 22:45:24, End time: 22:45:24 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb0b5da",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24944f0b",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd985189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The previous error because the attribute `float` was removed from `numpy` in version 1.24. It can be solved downgrading this package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea2b6c",
   "metadata": {},
   "source": [
    "### Step 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d6a223",
   "metadata": {},
   "source": [
    "Execution Start time: 22:45:24, End time: 22:45:31 (duration: 7 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69533f85",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed13b53",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f10d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting numpy==1.23\n  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\nDownloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/17.0 MB ? eta -:--:--\n\n\n\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.25.2\n    Uninstalling numpy-1.25.2:\n      Successfully uninstalled numpy-1.25.2\nSuccessfully installed numpy-1.23.0\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install --upgrade numpy==1.23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12171151",
   "metadata": {},
   "source": [
    "### Step 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8947220f",
   "metadata": {},
   "source": [
    "Execution Start time: 22:45:31, End time: 22:45:40 (duration: 8 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c1a50",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0499599",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de48b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/g-transformer\nTue Aug 20 22:45:32 UTC 2024, exp_path: data, data: g-transformer, input: doc, code: bpe, slang: en, tlang: de\nTue Aug 20 22:45:32 UTC 2024, Prepraring data...\nmosesdecoder already exists, skipping download\nsubword-nmt already exists, skipping download\nBPE code data/g-transformer.tokenized.en-de/code is already exist, skipping data preparation.\n[2024-08-20 22:45:32,329 INFO] Building segmented data: Namespace(corpuses='test,valid,train', source_lang='en', target_lang='de', datadir='data/g-transformer.tokenized.en-de', destdir='data/g-transformer-sent.segmented.en-de/', max_sents=1, max_tokens=512, min_train_doclen=-1, no_special_tok=False, tempdir='data/g-transformer-sent.segmented.en-de/tmp')\n[2024-08-20 22:45:32,329 INFO] Processed 1 documents of test with a max_len of 512.\n[2024-08-20 22:45:32,329 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/test.en\n[2024-08-20 22:45:32,329 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/test.de\n[2024-08-20 22:45:32,330 INFO] Processed 1 documents of valid with a max_len of 512.\n[2024-08-20 22:45:32,330 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/valid.en\n[2024-08-20 22:45:32,330 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/valid.de\n[2024-08-20 22:45:32,330 INFO] Processed 1 documents of train with a max_len of 512.\n[2024-08-20 22:45:32,330 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/train.en\n[2024-08-20 22:45:32,330 INFO] Saved 0 lines into data/g-transformer-sent.segmented.en-de/train.de\n[2024-08-20 22:45:32,585 INFO] Building segmented data: Namespace(corpuses='test,valid,train', source_lang='en', target_lang='de', datadir='data/g-transformer.tokenized.en-de', destdir='data/g-transformer-doc.segmented.en-de/', max_sents=1000, max_tokens=512, min_train_doclen=-1, no_special_tok=False, tempdir='data/g-transformer-doc.segmented.en-de/tmp')\n[2024-08-20 22:45:32,585 INFO] Processed 1 documents of test with a max_len of 512.\n[2024-08-20 22:45:32,585 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/test.en\n[2024-08-20 22:45:32,586 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/test.de\n[2024-08-20 22:45:32,586 INFO] Processed 1 documents of valid with a max_len of 512.\n[2024-08-20 22:45:32,586 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/valid.en\n[2024-08-20 22:45:32,586 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/valid.de\n[2024-08-20 22:45:32,586 INFO] Processed 1 documents of train with a max_len of 512.\n[2024-08-20 22:45:32,586 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/train.en\n[2024-08-20 22:45:32,586 INFO] Saved 0 lines into data/g-transformer-doc.segmented.en-de/train.de\n2024-08-20 22:45:35 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir='', seed=1, cpu=False, tpu=False, bf16=False, fp16=False, memory_efficient_bf16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='nag', lr_scheduler='fixed', task='translation_doc', source_lang='en', target_lang='de', trainpref='data/g-transformer-sent.segmented.en-de/train', validpref='data/g-transformer-sent.segmented.en-de/valid', testpref='data/g-transformer-sent.segmented.en-de/test', align_suffix=None, destdir='data/g-transformer-sent.binarized.en-de', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=8)\n2024-08-20 22:45:35 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8 types\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/local/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 367, in <module>\n    cli_main()\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 363, in cli_main\n    main(args)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 262, in main\n    make_all(args.source_lang, src_dict)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 244, in make_all\n    make_dataset(vocab, args.trainpref, \"train\", lang, num_workers=args.workers)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 240, in make_dataset\n    make_binary_dataset(vocab, input_prefix, output_prefix, lang, num_workers)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 172, in make_binary_dataset\n    100 * sum(replaced.values()) / n_seq_tok[1],\nZeroDivisionError: division by zero\n2024-08-20 22:45:39 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir='', seed=1, cpu=False, tpu=False, bf16=False, fp16=False, memory_efficient_bf16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='nag', lr_scheduler='fixed', task='translation_doc', source_lang='en', target_lang='de', trainpref='data/g-transformer-doc.segmented.en-de/train', validpref='data/g-transformer-doc.segmented.en-de/valid', testpref='data/g-transformer-doc.segmented.en-de/test', align_suffix=None, destdir='data/g-transformer-doc.binarized.en-de', thresholdtgt=0, thresholdsrc=0, tgtdict='data/g-transformer-sent.binarized.en-de/dict.en.txt', srcdict='data/g-transformer-sent.binarized.en-de/dict.en.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=8)\n2024-08-20 22:45:39 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8 types\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/local/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 367, in <module>\n    cli_main()\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 363, in cli_main\n    main(args)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 262, in main\n    make_all(args.source_lang, src_dict)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 244, in make_all\n    make_dataset(vocab, args.trainpref, \"train\", lang, num_workers=args.workers)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 240, in make_dataset\n    make_binary_dataset(vocab, input_prefix, output_prefix, lang, num_workers)\n  File \"/content/g-transformer/fairseq_cli/preprocess.py\", line 172, in make_binary_dataset\n    100 * sum(replaced.values()) / n_seq_tok[1],\nZeroDivisionError: division by zero\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/g-transformer\n",
    "!bash exp_gtrans/prepare-finetune.sh g-transformer data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb9d01",
   "metadata": {},
   "source": [
    "### Step 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4053addf",
   "metadata": {},
   "source": [
    "Execution Start time: 22:45:40, End time: 22:45:40 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678df4fd",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a6787",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c80f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The script runs but we need the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e28e87",
   "metadata": {},
   "source": [
    "### Step 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1956c4",
   "metadata": {},
   "source": [
    "Execution Start time: 22:45:40, End time: 22:45:40 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120fb2cf",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e683ebab",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb6aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f223ed",
   "metadata": {},
   "source": [
    "### Step 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fadb2e8",
   "metadata": {},
   "source": [
    "Execution Start time: 22:45:40, End time: 22:45:40 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8ebae",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841dcb16",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea88ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b250e61",
   "metadata": {},
   "source": [
    "### Step 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ff914",
   "metadata": {},
   "source": [
    "Execution Start time: 22:45:40, End time: 22:45:43 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f938a1",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae1053",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8de2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Requirement already satisfied: gdown in /usr/local/lib/python3.10/site-packages (5.1.0)\nCollecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests[socks]->gdown) (2.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.6.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\n  Attempting uninstall: gdown\n    Found existing installation: gdown 5.1.0\n    Uninstalling gdown-5.1.0:\n      Successfully uninstalled gdown-5.1.0\nSuccessfully installed gdown-5.2.0\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!# use gdown to download files\n",
    "!pip install gdown --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c94cec",
   "metadata": {},
   "source": [
    "### Step 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc3e78",
   "metadata": {},
   "source": [
    "Execution Start time: 22:45:43, End time: 22:46:05 (duration: 21 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e72381",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf90003f",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a2a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\nRetrieving folder contents\n/content/g-transformer/raw_data\nProcessing file 138-yMWU1fh7fnpikRPYLjN7SH6khVCqz de_dev.txt\nProcessing file 14hwJWO5J_2pDNmCRYuPvnzdthfy9AQRZ de_test.txt\nProcessing file 1fXu1u4Im2B0t_HNQNxSssdIh-fu1ezFt de_train.txt\nProcessing file 1vkLr8aM2xaPVjEVIbm4Yj5Tc73qs1jwR en_dev.txt\nProcessing file 1SwSf98ctYohXe-PRTQCBqJItip69TD2S en_test.txt\nProcessing file 12wTfUJ98St3IX9YIrKi52KZHifN_0jfA en_train.txt\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=138-yMWU1fh7fnpikRPYLjN7SH6khVCqz\nTo: /content/g-transformer/raw_data/g-transformer/de_dev.txt\n\n  0%|          | 0.00/8.01k [00:00<?, ?B/s]\n\nDownloading...\nFrom: https://drive.google.com/uc?id=14hwJWO5J_2pDNmCRYuPvnzdthfy9AQRZ\nTo: /content/g-transformer/raw_data/g-transformer/de_test.txt\n\n  0%|          | 0.00/8.96k [00:00<?, ?B/s]\n\nDownloading...\nFrom: https://drive.google.com/uc?id=1fXu1u4Im2B0t_HNQNxSssdIh-fu1ezFt\nTo: /content/g-transformer/raw_data/g-transformer/de_train.txt\n\n  0%|          | 0.00/1.69k [00:00<?, ?B/s]\n\nDownloading...\nFrom: https://drive.google.com/uc?id=1vkLr8aM2xaPVjEVIbm4Yj5Tc73qs1jwR\nTo: /content/g-transformer/raw_data/g-transformer/en_dev.txt\n\n  0%|          | 0.00/6.46k [00:00<?, ?B/s]\n\nDownloading...\nFrom: https://drive.google.com/uc?id=1SwSf98ctYohXe-PRTQCBqJItip69TD2S\nTo: /content/g-transformer/raw_data/g-transformer/en_test.txt\n\n  0%|          | 0.00/7.65k [00:00<?, ?B/s]\n\nDownloading...\nFrom: https://drive.google.com/uc?id=12wTfUJ98St3IX9YIrKi52KZHifN_0jfA\nTo: /content/g-transformer/raw_data/g-transformer/en_train.txt\n\n  0%|          | 0.00/1.51k [00:00<?, ?B/s]\n\nDownload completed\n['/content/g-transformer/raw_data/g-transformer/de_dev.txt',\n '/content/g-transformer/raw_data/g-transformer/de_test.txt',\n '/content/g-transformer/raw_data/g-transformer/de_train.txt',\n '/content/g-transformer/raw_data/g-transformer/en_dev.txt',\n '/content/g-transformer/raw_data/g-transformer/en_test.txt',\n '/content/g-transformer/raw_data/g-transformer/en_train.txt']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"/content/g-transformer/raw_data\").mkdir(exist_ok=True)\n",
    "\n",
    "%cd /content/g-transformer/raw_data\n",
    "gdown.download_folder(\"https://drive.google.com/drive/folders/1pmFy4R9cjgmIxi94qZbJVVza51rQpzNX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5f0b5",
   "metadata": {},
   "source": [
    "### Step 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e9aa8c",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:05, End time: 22:46:05 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e579527",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a827057",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de5d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Rename datasets\n",
    "# \n",
    "# Script `prepare-finetune.sh` expects a different datafile naming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c19931",
   "metadata": {},
   "source": [
    "### Step 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cade89f8",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:05, End time: 22:46:06 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2812960",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458025f4",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92bfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/g-transformer/raw_data/g-transformer\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/g-transformer/raw_data/g-transformer\n",
    "!cp en_train.txt concatenated_en2de_train_en.txt\n",
    "!cp de_train.txt concatenated_en2de_train_de.txt\n",
    "!cp en_dev.txt concatenated_en2de_dev_en.txt\n",
    "!cp de_dev.txt concatenated_en2de_dev_de.txt\n",
    "!cp en_test.txt concatenated_en2de_test_en.txt\n",
    "!cp de_test.txt concatenated_en2de_test_de.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cec29a",
   "metadata": {},
   "source": [
    "### Step 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ffda11",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:06, End time: 22:46:18 (duration: 12 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c9e440",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f197466",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2ad08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/g-transformer\nTue Aug 20 22:46:06 UTC 2024, exp_path: data, data: g-transformer, input: doc, code: bpe, slang: en, tlang: de\nTue Aug 20 22:46:06 UTC 2024, Prepraring data...\nmosesdecoder already exists, skipping download\nsubword-nmt already exists, skipping download\nfilter out empty lines from original data and split doc with empty line...\ndata/g-transformer.tokenized.en-de/tmp/train.en-de.tag\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\ndata/g-transformer.tokenized.en-de/tmp/valid.en-de.tag\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\ndata/g-transformer.tokenized.en-de/tmp/test.en-de.tag\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\ntruecase the train/valid/test data...\ndata/g-transformer.tokenized.en-de/tmp/truecase.en.mdl\ndata/g-transformer.tokenized.en-de/tmp/truecase.de.mdl\ndata/g-transformer.tokenized.en-de/tmp/train.en.tc\ndata/g-transformer.tokenized.en-de/tmp/train.de.tc\ndata/g-transformer.tokenized.en-de/tmp/valid.en.tc\ndata/g-transformer.tokenized.en-de/tmp/valid.de.tc\ndata/g-transformer.tokenized.en-de/tmp/test.en.tc\ndata/g-transformer.tokenized.en-de/tmp/test.de.tc\nlearn_bpe.py on ...\n\n  0%|                                                 | 0/30000 [00:00<?, ?it/s]no pair has frequency >= 2. Stopping\n\n  1%|4                                    | 330/30000 [00:00<00:05, 5881.36it/s]\napply_bpe.py to train.en...\napply_bpe.py to valid.en...\napply_bpe.py to test.en...\napply_bpe.py to train.de...\napply_bpe.py to valid.de...\napply_bpe.py to test.de...\napply doc-level special tags...\n[2024-08-20 22:46:09,659 INFO] Building segmented data: Namespace(corpuses='test,valid,train', source_lang='en', target_lang='de', datadir='data/g-transformer.tokenized.en-de', destdir='data/g-transformer-sent.segmented.en-de/', max_sents=1, max_tokens=512, min_train_doclen=-1, no_special_tok=False, tempdir='data/g-transformer-sent.segmented.en-de/tmp')\n[2024-08-20 22:46:09,661 INFO] Processed 2 documents of test with a max_len of 512.\n[2024-08-20 22:46:09,662 INFO] Saved 72 lines into data/g-transformer-sent.segmented.en-de/test.en\n[2024-08-20 22:46:09,662 INFO] Saved 72 lines into data/g-transformer-sent.segmented.en-de/test.de\n[2024-08-20 22:46:09,663 INFO] Processed 4 documents of valid with a max_len of 512.\n[2024-08-20 22:46:09,663 INFO] Saved 47 lines into data/g-transformer-sent.segmented.en-de/valid.en\n[2024-08-20 22:46:09,664 INFO] Saved 47 lines into data/g-transformer-sent.segmented.en-de/valid.de\n[2024-08-20 22:46:09,664 INFO] Processed 2 documents of train with a max_len of 512.\n[2024-08-20 22:46:09,664 INFO] Saved 14 lines into data/g-transformer-sent.segmented.en-de/train.en\n[2024-08-20 22:46:09,665 INFO] Saved 14 lines into data/g-transformer-sent.segmented.en-de/train.de\n[2024-08-20 22:46:09,928 INFO] Building segmented data: Namespace(corpuses='test,valid,train', source_lang='en', target_lang='de', datadir='data/g-transformer.tokenized.en-de', destdir='data/g-transformer-doc.segmented.en-de/', max_sents=1000, max_tokens=512, min_train_doclen=-1, no_special_tok=False, tempdir='data/g-transformer-doc.segmented.en-de/tmp')\n[2024-08-20 22:46:09,930 INFO] Processed 2 documents of test with a max_len of 512.\n[2024-08-20 22:46:09,930 INFO] Saved 11 lines into data/g-transformer-doc.segmented.en-de/test.en\n[2024-08-20 22:46:09,930 INFO] Saved 11 lines into data/g-transformer-doc.segmented.en-de/test.de\n[2024-08-20 22:46:09,932 INFO] Processed 4 documents of valid with a max_len of 512.\n[2024-08-20 22:46:09,932 INFO] Saved 11 lines into data/g-transformer-doc.segmented.en-de/valid.en\n[2024-08-20 22:46:09,932 INFO] Saved 11 lines into data/g-transformer-doc.segmented.en-de/valid.de\n[2024-08-20 22:46:09,933 INFO] Processed 2 documents of train with a max_len of 512.\n[2024-08-20 22:46:09,933 INFO] Saved 2 lines into data/g-transformer-doc.segmented.en-de/train.en\n[2024-08-20 22:46:09,933 INFO] Saved 2 lines into data/g-transformer-doc.segmented.en-de/train.de\n2024-08-20 22:46:12 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir='', seed=1, cpu=False, tpu=False, bf16=False, fp16=False, memory_efficient_bf16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='nag', lr_scheduler='fixed', task='translation_doc', source_lang='en', target_lang='de', trainpref='data/g-transformer-sent.segmented.en-de/train', validpref='data/g-transformer-sent.segmented.en-de/valid', testpref='data/g-transformer-sent.segmented.en-de/test', align_suffix=None, destdir='data/g-transformer-sent.binarized.en-de', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=8)\n2024-08-20 22:46:12 | INFO | fairseq_cli.preprocess | [en] Dictionary: 320 types\n2024-08-20 22:46:13 | INFO | fairseq_cli.preprocess | [en] data/g-transformer-sent.segmented.en-de/train.en: 14 sents, 524 tokens, 0.0% replaced by <unk>\n2024-08-20 22:46:13 | INFO | fairseq_cli.preprocess | [en] Dictionary: 320 types\n2024-08-20 22:46:13 | INFO | fairseq_cli.preprocess | [en] data/g-transformer-sent.segmented.en-de/valid.en: 47 sents, 3421 tokens, 3.83% replaced by <unk>\n2024-08-20 22:46:13 | INFO | fairseq_cli.preprocess | [en] Dictionary: 320 types\n2024-08-20 22:46:13 | INFO | fairseq_cli.preprocess | [en] data/g-transformer-sent.segmented.en-de/test.en: 72 sents, 4296 tokens, 6.45% replaced by <unk>\n2024-08-20 22:46:13 | INFO | fairseq_cli.preprocess | [de] Dictionary: 320 types\n2024-08-20 22:46:13 | INFO | fairseq_cli.preprocess | [de] data/g-transformer-sent.segmented.en-de/train.de: 14 sents, 601 tokens, 0.0% replaced by <unk>\n2024-08-20 22:46:13 | INFO | fairseq_cli.preprocess | [de] Dictionary: 320 types\n2024-08-20 22:46:13 | INFO | fairseq_cli.preprocess | [de] data/g-transformer-sent.segmented.en-de/valid.de: 47 sents, 4082 tokens, 5.1% replaced by <unk>\n2024-08-20 22:46:13 | INFO | fairseq_cli.preprocess | [de] Dictionary: 320 types\n2024-08-20 22:46:14 | INFO | fairseq_cli.preprocess | [de] data/g-transformer-sent.segmented.en-de/test.de: 72 sents, 4857 tokens, 6.11% replaced by <unk>\n2024-08-20 22:46:14 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data/g-transformer-sent.binarized.en-de\n2024-08-20 22:46:17 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir='', seed=1, cpu=False, tpu=False, bf16=False, fp16=False, memory_efficient_bf16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='nag', lr_scheduler='fixed', task='translation_doc', source_lang='en', target_lang='de', trainpref='data/g-transformer-doc.segmented.en-de/train', validpref='data/g-transformer-doc.segmented.en-de/valid', testpref='data/g-transformer-doc.segmented.en-de/test', align_suffix=None, destdir='data/g-transformer-doc.binarized.en-de', thresholdtgt=0, thresholdsrc=0, tgtdict='data/g-transformer-sent.binarized.en-de/dict.en.txt', srcdict='data/g-transformer-sent.binarized.en-de/dict.en.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=8)\n2024-08-20 22:46:17 | INFO | fairseq_cli.preprocess | [en] Dictionary: 320 types\n2024-08-20 22:46:17 | INFO | fairseq_cli.preprocess | [en] data/g-transformer-doc.segmented.en-de/train.en: 2 sents, 524 tokens, 0.0% replaced by <unk>\n2024-08-20 22:46:17 | INFO | fairseq_cli.preprocess | [en] Dictionary: 320 types\n2024-08-20 22:46:17 | INFO | fairseq_cli.preprocess | [en] data/g-transformer-doc.segmented.en-de/valid.en: 11 sents, 3421 tokens, 3.83% replaced by <unk>\n2024-08-20 22:46:17 | INFO | fairseq_cli.preprocess | [en] Dictionary: 320 types\n2024-08-20 22:46:17 | INFO | fairseq_cli.preprocess | [en] data/g-transformer-doc.segmented.en-de/test.en: 11 sents, 4296 tokens, 6.45% replaced by <unk>\n2024-08-20 22:46:17 | INFO | fairseq_cli.preprocess | [de] Dictionary: 320 types\n2024-08-20 22:46:17 | INFO | fairseq_cli.preprocess | [de] data/g-transformer-doc.segmented.en-de/train.de: 2 sents, 601 tokens, 0.0% replaced by <unk>\n2024-08-20 22:46:17 | INFO | fairseq_cli.preprocess | [de] Dictionary: 320 types\n2024-08-20 22:46:18 | INFO | fairseq_cli.preprocess | [de] data/g-transformer-doc.segmented.en-de/valid.de: 11 sents, 4082 tokens, 5.1% replaced by <unk>\n2024-08-20 22:46:18 | INFO | fairseq_cli.preprocess | [de] Dictionary: 320 types\n2024-08-20 22:46:18 | INFO | fairseq_cli.preprocess | [de] data/g-transformer-doc.segmented.en-de/test.de: 11 sents, 4857 tokens, 6.11% replaced by <unk>\n2024-08-20 22:46:18 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data/g-transformer-doc.binarized.en-de\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/g-transformer\n",
    "!rm -r data/g-*  # remove previously generated files and directories\n",
    "!bash exp_gtrans/prepare-finetune.sh g-transformer data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6082511d",
   "metadata": {},
   "source": [
    "### Step 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdf4c3",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:18, End time: 22:46:19 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72934cd2",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c1cd8",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24977df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Run finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4795d01",
   "metadata": {},
   "source": [
    "### Step 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb8677",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:19, End time: 22:46:19 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f131de",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff0fc3",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b68168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First attempt to train data using the default model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3efe57",
   "metadata": {},
   "source": [
    "### Step 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7e5b3",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:19, End time: 22:46:39 (duration: 20 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d3791",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f578a",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a4f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/g-transformer\nTue Aug 20 22:46:19 UTC 2024, data: g-transformer, mode: train, exp_path: data, slang: en, tlang: de\nTue Aug 20 22:46:19 UTC 2024, run path: data/run-finetune\nTue Aug 20 22:46:19 UTC 2024, Training sentence-level model...\nTue Aug 20 22:46:25 UTC 2024, Training document-level model...\nLoad sentence model from data/run-finetune/g-transformer-sent.checkpoints.en-de/checkpoint_best.pt\nTue Aug 20 22:46:25 UTC 2024, Training model...\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/g-transformer\n",
    "!bash exp_gtrans/run-finetune.sh g-transformer train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3617bf6a",
   "metadata": {},
   "source": [
    "### Step 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d1564",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:39, End time: 22:46:39 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48911d3",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade4adb",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e85ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No errors are shown in the standard output, but a log file is created. There, the following error can be seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b784fb",
   "metadata": {},
   "source": [
    "### Step 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b14f5",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:39, End time: 22:46:39 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbfb845",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a92854",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a077bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  File \"/content/g-transformer/fairseq/criterions/label_smoothed_cross_entropy.py\", line 72, in compute_loss\n    target = model.get_targets(sample, net_output).view(-1, 1)\nRuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!tail -3 data/run-finetune/train.g-transformer-doc.en-de.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910e49e1",
   "metadata": {},
   "source": [
    "### Step 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d0a38",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:39, End time: 22:46:39 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6e655",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c113527",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098b2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the suggestion given by the traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef413f7b",
   "metadata": {},
   "source": [
    "### Step 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee143f",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:39, End time: 22:46:40 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d862b",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83eba4",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7719b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n            'ntokens': sample['ntokens'],\n            'nsentences': sample['target'].size(0),\n            'sample_size': sample_size,\n        }\n        logging_output.update(net_output[1]['attn'])\n        return loss, sample_size, logging_output\n\n    def compute_loss(self, model, net_output, sample, reduce=True):\n        lprobs = model.get_normalized_probs(net_output, log_probs=True)\n        lprobs = lprobs.view(-1, lprobs.size(-1))\n        target = model.get_targets(sample, net_output).reshape(-1, 1)\n        loss, nll_loss = label_smoothed_nll_loss(\n            lprobs, target, self.eps, ignore_index=self.padding_idx, reduce=reduce,\n        )\n        return loss, nll_loss\n\n    @staticmethod\n    def reduce_metrics(logging_outputs) -> None:\n        \"\"\"Aggregate logging outputs from data parallel training.\"\"\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/content/g-transformer/fairseq/criterions/label_smoothed_cross_entropy.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    def compute_loss(self, model, net_output, sample, reduce=True):\n",
    "        lprobs = model.get_normalized_probs(net_output, log_probs=True)\n",
    "        lprobs = lprobs.view(-1, lprobs.size(-1))\n",
    "        target = model.get_targets(sample, net_output).view(-1, 1)\n",
    "        loss, nll_loss = label_smoothed_nll_loss(\n",
    "            lprobs, target, self.eps, ignore_index=self.padding_idx, reduce=reduce,\n",
    "<<<AFTER_EDIT>>>\n",
    "    def compute_loss(self, model, net_output, sample, reduce=True):\n",
    "        lprobs = model.get_normalized_probs(net_output, log_probs=True)\n",
    "        lprobs = lprobs.view(-1, lprobs.size(-1))\n",
    "        target = model.get_targets(sample, net_output).reshape(-1, 1)\n",
    "        loss, nll_loss = label_smoothed_nll_loss(\n",
    "            lprobs, target, self.eps, ignore_index=self.padding_idx, reduce=reduce,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a90194",
   "metadata": {},
   "source": [
    "### Step 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05266570",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:40, End time: 22:46:40 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5628b432",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f57b13",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833fd373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also, patch finetune script to avoid ussing Half floats (remove `--fp16` argument) and train only one epoch (add `--max-epoch 1`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c418cf80",
   "metadata": {},
   "source": [
    "### Step 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90cff6",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:40, End time: 22:46:40 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2444e9",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae57e811",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e7e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\necho `date`, run path: $run_path\n\ncp_path_sent=$run_path/$data-sent.checkpoints.$slang-$tlang\ncp_path_doc=$run_path/$data-doc.checkpoints.$slang-$tlang\nres_path=$run_path/$data.results.$slang-$tlang\ndoc_langs=$slang,$tlang\n\nif [ $mode == \"train\" ]; then\n  echo `date`, Training sentence-level model...\n  doc_langs=$slang,$tlang\n  python train.py $bin_path_sent --save-dir $cp_path_sent --tensorboard-logdir $cp_path_sent --seed 444 --max-epoch 1 --num-workers 4 \\\n         --task translation_doc --source-lang $slang --target-lang $tlang --langs $doc_langs \\\n         --arch gtransformer_base --doc-mode full --share-all-embeddings \\\n         --optimizer adam --adam-betas \"(0.9, 0.98)\" --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n         --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --no-epoch-checkpoints \\\n         --max-tokens 4096 --update-freq 1 --validate-interval 1 --patience 10 \\\n         > $run_path/train.$data-sent.$slang-$tlang.log 2>&1\n\n  echo `date`, Training document-level model..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/content/g-transformer/exp_gtrans/run-finetune.sh\n",
    "<<<BEFORE_EDIT>>>\n",
    "if [ $mode == \"train\" ]; then\n",
    "  echo `date`, Training sentence-level model...\n",
    "  doc_langs=$slang,$tlang\n",
    "  python train.py $bin_path_sent --save-dir $cp_path_sent --tensorboard-logdir $cp_path_sent --seed 444 --fp16 --num-workers 4 \\\n",
    "         --task translation_doc --source-lang $slang --target-lang $tlang --langs $doc_langs \\\n",
    "         --arch gtransformer_base --doc-mode full --share-all-embeddings \\\n",
    "<<<AFTER_EDIT>>>\n",
    "if [ $mode == \"train\" ]; then\n",
    "  echo `date`, Training sentence-level model...\n",
    "  doc_langs=$slang,$tlang\n",
    "  python train.py $bin_path_sent --save-dir $cp_path_sent --tensorboard-logdir $cp_path_sent --seed 444 --max-epoch 1 --num-workers 4 \\\n",
    "         --task translation_doc --source-lang $slang --target-lang $tlang --langs $doc_langs \\\n",
    "         --arch gtransformer_base --doc-mode full --share-all-embeddings \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34c962",
   "metadata": {},
   "source": [
    "### Step 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f76741",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:40, End time: 22:46:41 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1690dd",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a923d46",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b887af9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n         --arch gtransformer_base --doc-mode full --share-all-embeddings \\\n         --optimizer adam --adam-betas \"(0.9, 0.98)\" --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n         --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --no-epoch-checkpoints \\\n         --max-tokens 4096 --update-freq 1 --validate-interval 1 --patience 10 \\\n         > $run_path/train.$data-sent.$slang-$tlang.log 2>&1\n\n  echo `date`, Training document-level model...\n  sent_model=$cp_path_sent/checkpoint_best.pt\n  echo Load sentence model from $sent_model\n  echo `date`, Training model...\n  python train.py $bin_path_doc --save-dir $cp_path_doc --tensorboard-logdir $cp_path_doc --seed 444  --max-epoch 1 --num-workers 4 \\\n         --task translation_doc --source-lang $slang --target-lang $tlang --langs $doc_langs \\\n         --arch gtransformer_base --doc-mode partial --share-all-embeddings \\\n         --optimizer adam --adam-betas \"(0.9, 0.98)\" \\\n         --lr-scheduler inverse_sqrt --lr 5e-04 --warmup-updates 4000 \\\n         --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --no-epoch-checkpoints \\\n         --max-tokens 4096 --update-freq 1 --validate-interval 1 --patience 10 \\\n         --restore-file $sent_model --reset-optimizer --reset-meters --reset-dataloader --reset-lr-scheduler \\\n         --load-partial --doc-double-lr --lr-scale-pretrained 0.2 \\"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/content/g-transformer/exp_gtrans/run-finetune.sh\n",
    "<<<BEFORE_EDIT>>>\n",
    "  sent_model=$cp_path_sent/checkpoint_best.pt\n",
    "  echo Load sentence model from $sent_model\n",
    "  echo `date`, Training model...\n",
    "  python train.py $bin_path_doc --save-dir $cp_path_doc --tensorboard-logdir $cp_path_doc --seed 444 --num-workers 4 \\\n",
    "         --task translation_doc --source-lang $slang --target-lang $tlang --langs $doc_langs \\\n",
    "         --arch gtransformer_base --doc-mode partial --share-all-embeddings \\\n",
    "<<<AFTER_EDIT>>>\n",
    "  sent_model=$cp_path_sent/checkpoint_best.pt\n",
    "  echo Load sentence model from $sent_model\n",
    "  echo `date`, Training model...\n",
    "  python train.py $bin_path_doc --save-dir $cp_path_doc --tensorboard-logdir $cp_path_doc --seed 444  --max-epoch 1 --num-workers 4 \\\n",
    "         --task translation_doc --source-lang $slang --target-lang $tlang --langs $doc_langs \\\n",
    "         --arch gtransformer_base --doc-mode partial --share-all-embeddings \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00534827",
   "metadata": {},
   "source": [
    "### Step 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03871c28",
   "metadata": {},
   "source": [
    "Execution Start time: 22:46:42, End time: 22:47:12 (duration: 29 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2005e8",
   "metadata": {},
   "source": [
    "**Thought**: The necessary changes have been made to the script to ensure it runs for only one epoch and avoids using half-precision floats. Now, I will attempt to run the fine-tuning process again with these modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b670ebf",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76cb03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/g-transformer\nTue Aug 20 22:46:42 UTC 2024, data: g-transformer, mode: train, exp_path: data, slang: en, tlang: de\nTue Aug 20 22:46:42 UTC 2024, run path: data/run-finetune\nTue Aug 20 22:46:42 UTC 2024, Training sentence-level model...\nTue Aug 20 22:46:56 UTC 2024, Training document-level model...\nLoad sentence model from data/run-finetune/g-transformer-sent.checkpoints.en-de/checkpoint_best.pt\nTue Aug 20 22:46:56 UTC 2024, Training model...\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/g-transformer\n",
    "!bash exp_gtrans/run-finetune.sh g-transformer train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601fa45",
   "metadata": {},
   "source": [
    "### Step 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7747c1",
   "metadata": {},
   "source": [
    "Execution Start time: 22:47:13, End time: 22:47:13 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b8f2c",
   "metadata": {},
   "source": [
    "**Thought**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0e147",
   "metadata": {},
   "source": [
    "**Action ()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac49ca6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thought or action not provided in the correct format. Please retry while making sure the response is correctly formatted and does not exceed 1500 tokens."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57b0c605",
   "metadata": {},
   "source": [
    "### Step 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48e24a",
   "metadata": {},
   "source": [
    "Execution Start time: 22:47:15, End time: 22:47:15 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4542d6b",
   "metadata": {},
   "source": [
    "**Thought**: The fine-tuning process has been initiated successfully with the modified script. Now, I need to wait for the training to complete and then evaluate the model to obtain the Sentence-level and Document-level BLEU metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3bb45d",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fde7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-20 22:46:59 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n2024-08-20 22:46:59 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n2024-08-20 22:46:59 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n2024-08-20 22:46:59 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None\n2024-08-20 22:46:59 | WARNING | fairseq.trainer | Load checkpoint: missing_keys=['encoder.layers.4.self_attn_global.k_proj.weight', 'encoder.layers.4.self_attn_global.k_proj.bias', 'encoder.layers.4.self_attn_global.v_proj.weight', 'encoder.layers.4.self_attn_global.v_proj.bias', 'encoder.layers.4.self_attn_global.q_proj.weight', 'encoder.layers.4.self_attn_global.q_proj.bias', 'encoder.layers.4.self_attn_global.out_proj.weight', 'encoder.layers.4.self_attn_global.out_proj.bias', 'encoder.layers.4.self_attn_gate.0.weight', 'encoder.layers.4.self_attn_gate.0.bias', 'encoder.layers.5.self_attn_global.k_proj.weight', 'encoder.layers.5.self_attn_global.k_proj.bias', 'encoder.layers.5.self_attn_global.v_proj.weight', 'encoder.layers.5.self_attn_global.v_proj.bias', 'encoder.layers.5.self_attn_global.q_proj.weight', 'encoder.layers.5.self_attn_global.q_proj.bias', 'encoder.layers.5.self_attn_global.out_proj.weight', 'encoder.layers.5.self_attn_global.out_proj.bias', 'encoder.layers.5.self_attn_gate.0.weight', 'encoder.layers.5.self_attn_gate.0.bias', 'decoder.layers.4.self_attn_global.k_proj.weight', 'decoder.layers.4.self_attn_global.k_proj.bias', 'decoder.layers.4.self_attn_global.v_proj.weight', 'decoder.layers.4.self_attn_global.v_proj.bias', 'decoder.layers.4.self_attn_global.q_proj.weight', 'decoder.layers.4.self_attn_global.q_proj.bias', 'decoder.layers.4.self_attn_global.out_proj.weight', 'decoder.layers.4.self_attn_global.out_proj.bias', 'decoder.layers.4.self_attn_gate.0.weight', 'decoder.layers.4.self_attn_gate.0.bias', 'decoder.layers.4.encoder_attn_global.k_proj.weight', 'decoder.layers.4.encoder_attn_global.k_proj.bias', 'decoder.layers.4.encoder_attn_global.v_proj.weight', 'decoder.layers.4.encoder_attn_global.v_proj.bias', 'decoder.layers.4.encoder_attn_global.q_proj.weight', 'decoder.layers.4.encoder_attn_global.q_proj.bias', 'decoder.layers.4.encoder_attn_global.out_proj.weight', 'decoder.layers.4.encoder_attn_global.out_proj.bias', 'decoder.layers.4.encoder_attn_gate.0.weight', 'decoder.layers.4.encoder_attn_gate.0.bias', 'decoder.layers.5.self_attn_global.k_proj.weight', 'decoder.layers.5.self_attn_global.k_proj.bias', 'decoder.layers.5.self_attn_global.v_proj.weight', 'decoder.layers.5.self_attn_global.v_proj.bias', 'decoder.layers.5.self_attn_global.q_proj.weight', 'decoder.layers.5.self_attn_global.q_proj.bias', 'decoder.layers.5.self_attn_global.out_proj.weight', 'decoder.layers.5.self_attn_global.out_proj.bias', 'decoder.layers.5.self_attn_gate.0.weight', 'decoder.layers.5.self_attn_gate.0.bias', 'decoder.layers.5.encoder_attn_global.k_proj.weight', 'decoder.layers.5.encoder_attn_global.k_proj.bias', 'decoder.layers.5.encoder_attn_global.v_proj.weight', 'decoder.layers.5.encoder_attn_global.v_proj.bias', 'decoder.layers.5.encoder_attn_global.q_proj.weight', 'decoder.layers.5.encoder_attn_global.q_proj.bias', 'decoder.layers.5.encoder_attn_global.out_proj.weight', 'decoder.layers.5.encoder_attn_global.out_proj.bias', 'decoder.layers.5.encoder_attn_gate.0.weight', 'decoder.layers.5.encoder_attn_gate.0.bias']\n2024-08-20 22:46:59 | WARNING | fairseq.trainer | Load checkpoint: unexpected_keys=[]\n2024-08-20 22:47:00 | WARNING | fairseq.trainer | Build partial optimizer: randinit=60, loaded=253(lr_scale=0.2)\n2024-08-20 22:47:00 | INFO | fairseq.trainer | loaded checkpoint data/run-finetune/g-transformer-sent.checkpoints.en-de/checkpoint_best.pt (epoch 1 @ 0 updates)\n2024-08-20 22:47:00 | INFO | fairseq.trainer | loading train data for epoch 1\n2024-08-20 22:47:00 | INFO | fairseq.data.data_utils | loaded 2 examples from: data/g-transformer-doc.binarized.en-de/train.en-de.en\n2024-08-20 22:47:00 | INFO | fairseq.data.data_utils | loaded 2 examples from: data/g-transformer-doc.binarized.en-de/train.en-de.de\n2024-08-20 22:47:00 | INFO | fairseq.tasks.translation | data/g-transformer-doc.binarized.en-de train en-de 2 examples\n2024-08-20 22:47:00 | INFO | fairseq.data.doc_noise_dataset | DocNoiseDataset epoch 1: doc_noise_epochs=40, doc_noise_ratio=0.1\n2024-08-20 22:47:00 | INFO | fairseq.data.doc_noise_dataset | DocNoiseDataset epoch 1: doc_noise_epochs=40, doc_noise_ratio=0.1\n2024-08-20 22:47:00 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboardX\n2024-08-20 22:47:03 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboardX\n2024-08-20 22:47:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.162 | nll_loss 9.158 | encoder_self_local 6.501 | encoder_self_global 8.119 | decoder_self_local 5.709 | decoder_self_global 7.254 | decoder_cross_local 6.551 | decoder_cross_global 8.122 | ppl 571.13 | wps 754 | wpb 2046.5 | bsz 5.5 | num_updates 1\n2024-08-20 22:47:11 | INFO | fairseq.checkpoint_utils | saved checkpoint data/run-finetune/g-transformer-doc.checkpoints.en-de/checkpoint_best.pt (epoch 1 @ 1 updates, score 9.162) (writing took 0.8104976829999941 seconds)\n2024-08-20 22:47:11 | INFO | train | epoch 001 | loss 9.182 | nll_loss 9.188 | encoder_self_local 5.817 | encoder_self_global 7.963 | decoder_self_local 4.796 | decoder_self_global 7.003 | decoder_cross_local 5.718 | decoder_cross_global 7.965 | ppl 583.26 | wps 0 | ups 0 | wpb 603 | bsz 2 | num_updates 1 | lr 1.25e-07 | gnorm 5.894 | train_wall 3 | wall 12\n2024-08-20 22:47:11 | INFO | fairseq_cli.train | done training in 11.3 seconds\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the logs to see if the training has completed and to find the BLEU scores.\n",
    "!tail -n 20 data/run-finetune/train.g-transformer-doc.en-de.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a5223",
   "metadata": {},
   "source": [
    "### Step 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019e94b",
   "metadata": {},
   "source": [
    "Execution Start time: 22:47:17, End time: 22:47:17 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66946366",
   "metadata": {},
   "source": [
    "**Thought**: The training process has completed successfully. Now, I need to evaluate the model to obtain the Sentence-level and Document-level BLEU metrics. I will check if there is a script or command available in the repository for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0676bab",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dcdc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__pycache__\t prepare-finetune.sh  prepare-spm.sh   run-mbart.sh\ndata_builder.py  prepare-mbart.sh     run-all.sh       run-randinit.sh\nprepare-bpe.sh\t prepare-randinit.sh  run-finetune.sh\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for evaluation scripts or instructions in the repository\n",
    "!ls exp_gtrans/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d0dfbb",
   "metadata": {},
   "source": [
    "### Step 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d8b98",
   "metadata": {},
   "source": [
    "Execution Start time: 22:47:19, End time: 22:47:19 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d59212",
   "metadata": {},
   "source": [
    "**Thought**: There is no explicit evaluation script in the `exp_gtrans` directory. However, the `run-finetune.sh` script might include evaluation steps. I will check the script to see if it includes evaluation commands or if I need to run a separate command for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b323e8",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8215084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#!/usr/bin/env bash\n# Copyright (c) Guangsheng Bao.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n# command help\nif [ $# == '0' ]; then\n    echo \"Please follow the usage:\"\n    echo \"    bash $0 iwslt17 train exp_test\"\n    exit\nfi\n\n# run command\ndata=$1\nmode=$2\nexp_path=$3\n\nslang=en\ntlang=de\n\necho `date`, data: $data, mode: $mode, exp_path: $exp_path, slang: $slang, tlang: $tlang\nbin_path_sent=$exp_path/$data-sent.binarized.$slang-$tlang\nbin_path_doc=$exp_path/$data-doc.binarized.$slang-$tlang\n\nrun_path=$exp_path/run-finetune\nmkdir -p $run_path\necho `date`, run path: $run_path\n\ncp_path_sent=$run_path/$data-sent.checkpoints.$slang-$tlang\ncp_path_doc=$run_path/$data-doc.checkpoints.$slang-$tlang\nres_path=$run_path/$data.results.$slang-$tlang\ndoc_langs=$slang,$tlang\n\nif [ $mode == \"train\" ]; then\n  echo `date`, Training sentence-level model...\n  doc_langs=$slang,$tlang\n  python train.py $bin_path_sent --save-dir $cp_path_sent --tensorboard-logdir $cp_path_sent --seed 444 --max-epoch 1 --num-workers 4 \\\n         --task translation_doc --source-lang $slang --target-lang $tlang --langs $doc_langs \\\n         --arch gtransformer_base --doc-mode full --share-all-embeddings \\\n         --optimizer adam --adam-betas \"(0.9, 0.98)\" --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n         --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --no-epoch-checkpoints \\\n         --max-tokens 4096 --update-freq 1 --validate-interval 1 --patience 10 \\\n         > $run_path/train.$data-sent.$slang-$tlang.log 2>&1\n\n  echo `date`, Training document-level model...\n  sent_model=$cp_path_sent/checkpoint_best.pt\n  echo Load sentence model from $sent_model\n  echo `date`, Training model...\n  python train.py $bin_path_doc --save-dir $cp_path_doc --tensorboard-logdir $cp_path_doc --seed 444  --max-epoch 1 --num-workers 4 \\\n         --task translation_doc --source-lang $slang --target-lang $tlang --langs $doc_langs \\\n         --arch gtransformer_base --doc-mode partial --share-all-embeddings \\\n         --optimizer adam --adam-betas \"(0.9, 0.98)\" \\\n         --lr-scheduler inverse_sqrt --lr 5e-04 --warmup-updates 4000 \\\n         --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --no-epoch-checkpoints \\\n         --max-tokens 4096 --update-freq 1 --validate-interval 1 --patience 10 \\\n         --restore-file $sent_model --reset-optimizer --reset-meters --reset-dataloader --reset-lr-scheduler \\\n         --load-partial --doc-double-lr --lr-scale-pretrained 0.2 \\\n         --encoder-ctxlayers 2 --decoder-ctxlayers 2 --cross-ctxlayers 2 \\\n         --doc-noise-mask 0.1 --doc-noise-epochs 40 > $run_path/train.$data-doc.$slang-$tlang.log 2>&1\nelif [ $mode == \"test\" ]; then\n  mkdir -p $res_path\n  echo `date`, Testing model on test dataset...\n  python -m fairseq_cli.generate $bin_path_doc --path $cp_path_doc/checkpoint_best.pt \\\n         --gen-subset test --batch-size 16 --beam 5 --max-len-a 1.2 --max-len-b 10 \\\n         --task translation_doc --source-lang $slang --target-lang $tlang --langs $doc_langs \\\n         --doc-mode partial --tokenizer moses --remove-bpe --sacrebleu \\\n         --gen-output $res_path/test > $run_path/test.$data.$slang-$tlang.log 2>&1\nelse\n  echo Unknown mode ${mode}.\nfi\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!cat exp_gtrans/run-finetune.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b53a1",
   "metadata": {},
   "source": [
    "### Step 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8280c",
   "metadata": {},
   "source": [
    "Execution Start time: 22:47:21, End time: 22:47:25 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40801459",
   "metadata": {},
   "source": [
    "**Thought**: The `run-finetune.sh` script includes a section for testing the model, which generates BLEU scores. I need to run the script in \"test\" mode to evaluate the model and obtain the Sentence-level and Document-level BLEU metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8b446",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500d5df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tue Aug 20 22:47:21 UTC 2024, data: g-transformer, mode: test, exp_path: data, slang: en, tlang: de\nTue Aug 20 22:47:21 UTC 2024, run path: data/run-finetune\nTue Aug 20 22:47:21 UTC 2024, Testing model on test dataset...\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the evaluation in test mode to obtain BLEU scores\n",
    "!bash exp_gtrans/run-finetune.sh g-transformer test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f5fe89",
   "metadata": {},
   "source": [
    "### Step 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1cd14",
   "metadata": {},
   "source": [
    "Execution Start time: 22:47:26, End time: 22:47:26 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a32c6",
   "metadata": {},
   "source": [
    "**Thought**: The evaluation process has been initiated successfully. I need to wait for it to complete and then check the logs to find the Sentence-level and Document-level BLEU metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f609e69b",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde6947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "During handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/local/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/content/g-transformer/fairseq_cli/generate.py\", line 356, in <module>\n    cli_main()\n  File \"/content/g-transformer/fairseq_cli/generate.py\", line 352, in cli_main\n    main(args)\n  File \"/content/g-transformer/fairseq_cli/generate.py\", line 40, in main\n    return _main(args, sys.stdout)\n  File \"/content/g-transformer/fairseq_cli/generate.py\", line 124, in _main\n    tokenizer = encoders.build_tokenizer(args)\n  File \"/content/g-transformer/fairseq/registry.py\", line 41, in build_x\n    return builder(args, *extra_args, **extra_kwargs)\n  File \"/content/g-transformer/fairseq/data/encoders/moses_tokenizer.py\", line 38, in __init__\n    raise ImportError('Please install Moses tokenizer with: pip install sacremoses')\nImportError: Please install Moses tokenizer with: pip install sacremoses\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the logs to find the BLEU scores after the evaluation is complete\n",
    "!tail -n 20 data/run-finetune/test.g-transformer.en-de.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340fb70",
   "metadata": {},
   "source": [
    "### Step 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10066c8",
   "metadata": {},
   "source": [
    "Execution Start time: 22:47:28, End time: 22:47:31 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f7d81",
   "metadata": {},
   "source": [
    "**Thought**: The evaluation process failed because the Moses tokenizer is not installed. I need to install the `sacremoses` package to proceed with the evaluation. After installing, I will rerun the evaluation script in test mode to obtain the BLEU scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3737710",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceada69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/site-packages (from sacremoses) (2023.12.25)\nRequirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from sacremoses) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from sacremoses) (1.4.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from sacremoses) (4.66.4)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/897.5 kB ? eta -:--:--\n\n\u001b[?25hInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbe5147",
   "metadata": {},
   "source": [
    "### Step 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f609188a",
   "metadata": {},
   "source": [
    "Execution Start time: 22:47:33, End time: 22:51:03 (duration: 210 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca20b2d",
   "metadata": {},
   "source": [
    "**Thought**: The `sacremoses` package has been installed successfully. Now, I will rerun the evaluation script in test mode to obtain the Sentence-level and Document-level BLEU metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150d164",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3f74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tue Aug 20 22:47:33 UTC 2024, data: g-transformer, mode: test, exp_path: data, slang: en, tlang: de\nTue Aug 20 22:47:33 UTC 2024, run path: data/run-finetune\nTue Aug 20 22:47:33 UTC 2024, Testing model on test dataset...\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rerun the evaluation in test mode to obtain BLEU scores\n",
    "!bash exp_gtrans/run-finetune.sh g-transformer test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ff3d8",
   "metadata": {},
   "source": [
    "### Step 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b835d9",
   "metadata": {},
   "source": [
    "Execution Start time: 22:51:05, End time: 22:51:06 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d4842",
   "metadata": {},
   "source": [
    "**Thought**: The evaluation process has been initiated again. I need to wait for it to complete and then check the logs to find the Sentence-level and Document-level BLEU metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1dcaf",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9132b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P-4\t-5.2434 -1.2261 -1.2793 -1.3507 -1.4130 -1.4558 -1.4969 -1.5420 -1.5814 -5.1186 -1.3796 -1.3336 -1.3125 -1.3037 -1.2961 -1.2875 -1.2748 -1.2612 -1.2423 -1.2230 -1.2112 -1.2117 -1.2239 -1.2448 -1.2611 -1.2571 -1.2352 -1.2209 -1.2369 -1.2789 -1.3231 -1.3378 -1.3143 -1.2654 -1.2267 -1.2215 -1.2452 -1.2801 -1.2977 -1.2907 -1.2794 -1.2886 -1.3205 -1.3590 -1.3817 -1.3776 -1.3615 -1.3555 -1.3744 -1.4053 -1.4278 -1.4211 -1.3916 -1.3655 -1.3696 -1.4003 -1.4300 -1.4314 -1.4050 -1.3740 -1.3589 -1.3751 -1.4136 -1.4409 -1.4353 -1.4037 -1.3789 -1.3786 -1.3985 -1.4154 -1.4100 -1.3885 -1.3715 -1.3813 -1.4233 -1.4814 -1.5191 -1.5116 -1.4701 -1.4222 -1.3831 -1.3577 -1.3377 -1.3150 -1.2991 -1.3059 -1.3335 -1.3583 -1.3599 -1.3367 -1.3061 -1.2964 -1.3243 -1.3775 -1.4262 -1.4405 -1.4171 -1.3835 -1.3671 -1.3793 -1.4003 -1.4103 -1.4041 -1.3969 -1.4060 -1.4309 -1.4582 0.0000 0.0000 -5.2035 -1.6490 -1.5488 -1.5565 -1.6021 -1.6428 -1.6600 -1.6648 -1.6764 -1.7021 -1.7303 -1.7262 -1.6835 -1.6256 -1.5853 -1.5885 -1.6344 -1.6956 -1.7435 -1.7612 -1.7572 -1.7528 -1.7591 -1.7700 -1.7722 -1.7609 -1.7471 -1.7479 -1.7769 -1.8312 -5.8329 -1.8769 -1.8322 -1.7926 -1.7641 -1.7474 -1.7404 -1.7432 -1.7531 -1.7600 -1.7559 -1.7456 -1.7294 -1.7088 -1.6908 -1.6821 -1.6806 -1.6757 -1.6554 -1.6186 -1.5820 -1.5550 -1.5458 -1.5481 -1.5553 -1.5480 -1.5127 -1.4639 -1.4282 -1.4204 -1.4488 -1.5024 -1.5563 -1.5893 -1.5983 -1.5789 -1.5433 -1.5058 -1.4842 -1.4709 -1.4733 -1.4825 -1.4852 -1.4822 -1.4683 -1.4500 -1.4280 -1.4110 -1.4046 -1.4117 -1.4337 -1.4636 -1.4893 -1.5047 -1.5088 -1.4993 -1.4866 -1.4788 0.0000 0.0000 -4.2695 -0.8284 -0.8879 -0.9468 -0.9781 -0.9813 -0.9713 -0.9646 -0.9745 -1.0036 -1.0359 -1.0573 -1.0608 -1.0448 -1.0206 -1.0048 -1.0022 -1.0085 -1.0186 -1.0265 -1.0317 -1.0357 -1.0421 -1.0567 -1.0740 -1.0826 -1.0783 -1.0683 -1.0628 -1.0797 -1.1210 -1.1735 -1.2156 -1.2265 -1.2070 -1.1784 -1.1592 -1.1588 -1.1707 -1.1789 -1.1649 -1.1307 -1.0963 -1.0810 -1.0971 -1.1408 -1.1908 -1.2258 -1.2303 -1.2081 -1.1804 -1.1626 -1.1646 -1.1850 -1.2070 -1.2223 -1.2263 -1.2285 -1.2323 -1.2380 -1.2413 -1.2388 -1.2261 -1.2116 -1.2049 -1.2150 -1.2341 -1.2492 -1.2562 -1.2598 -1.2646 -1.2843 -1.3210 -1.3640 -1.3973 -1.4084 -1.3911 -1.3564 -1.3176 -1.2916 -1.2861 -1.2980 -1.3158 -1.3281 -1.3334 -1.3273 -1.3141 -1.3000 -1.2909 0.0000 0.0000 -3.9228 -0.8455 -0.9004 -0.9607 -1.0059 -1.0425 -1.0726 -1.0955 -1.1069 -1.1058 -1.1033 -1.1090 -1.1242 -1.1452 -1.1576 -1.1692 -1.1888 -1.2209 -1.2590 -1.2938 -1.3184 -1.3297 -1.3285 -1.3164 -1.3065 -1.3061 -1.3020 -1.2839 -1.2558 -1.2356 -1.2433 -1.2765 -1.3213 -1.3531 -1.3569 -1.3349 -1.3104 -1.3086 -1.3374 -1.3844 -1.4208 0.0000 0.0000 -3.1271 -0.5584 -0.5944 -0.6385 -0.6722 -0.6898 -0.6952 -0.6932 -0.6942 -0.6996 -0.7081 -0.7153 -0.7196 -0.7287 -0.7460 -0.7694 -0.7939 -0.8120 -0.8202 -0.8201 -0.8157 -0.8102 -0.8056 -0.7998 -0.7930 -0.7868 -0.7864 -0.7947 -0.8085 -0.8239 -0.8356 -0.8416 -0.8450 -0.8493 -0.8583 -0.8709 -0.8798 -0.8754 -0.8589 -0.8410 -0.8248 -0.8184 -0.8212 -0.8293 -0.8342 -0.8349 -0.8382 -0.8468 -0.8619 -0.8813 -0.8949 -0.8979 -0.8917 -0.8776 -0.8632 -0.8589 -0.8647 -0.8690 -0.8661 -0.8570 -0.8437 -0.8290 -0.8205 -0.8206 -0.8268 -0.8356 -0.8444 -0.8517 -0.8540 -0.8538 -0.8588 -0.8677 -0.8809 -0.8935 -0.8997 -0.8989 -0.8907 -0.8839 -0.8834 -0.8909 -0.8964 -0.8935 -0.8829 -0.8717 -0.8708 -0.8906 -0.9255 -0.9581 -0.9712 -0.9550 -0.9173 -0.8782 -0.8611 -0.8662 -0.8857 -0.9005 -0.9000 -0.8853 -0.8711 -0.8777 -0.9024 -0.9296 -0.9407 -0.9312 -0.9056 -0.8821 -0.8768 -0.8902 -0.9101 -0.9204 -0.9145 -0.8993 -0.8909 -0.8996 -0.9211 -0.9410 -0.9451 -0.9293 -0.9071 -0.8932 -0.8918 -0.9044 -0.9206 -0.9252 -0.9179 -0.9063 -0.9008 0.0000 0.0000\nS-0\t<s> Obama receives Netanyahu </s> <s> the relationship between Obama and Netanyahu is not exactly friendly. </s> <s> the two wanted to talk about the implementation of the international agreement and about Teheran 's destabilising activities in the Middle East. </s> <s> the meeting was also planned to cover the conflict with the Palestinians and the disputed two state solution. </s> <s> Relations between Obama and Netanyahu have been strained for years. </s> <s> Washington criticises the continuous building of settlements in Israel and accuses Netanyahu of a lack of initiative in the peace process. </s> <s> the relationship between the two has further deteriorated because of the deal that Obama negotiated on Iran 's atomic programme,. </s> <s> in March, at the invitation of the Republicans, Netanyahu made a controversial speech to the US Congress, which was partly seen as an affront to Obama. </s> <s> the speech had not been agreed with Obama, who had rejected a meeting with reference to the election that was at that time impending in Israel. </s>\nT-0\tObama empfängt Netanyahu </s> <s> das Verhältnis zwischen Obama und Netanyahu ist nicht gerade freundschaftlich. </s> <s> die beiden wollten über die Umsetzung der internationalen Vereinbarung sowie über Teherans destabilisierende Maßnahmen im Nahen Osten sprechen. </s> <s> bei der Begegnung soll es aber auch um den Konflikt mit den Palästinensern und die diskutierte Zwei-Staaten-Lösung gehen. </s> <s> das Verhältnis zwischen Obama und Netanyahu ist seit Jahren gespannt. </s> <s> Washington kritisiert den andauernden Siedlungsbau Israels und wirft Netanyahu mangelnden Willen beim Friedensprozess vor. </s> <s> Durch den von Obama beworbenen Deal um das iranische Atomprogramm hat sich die Beziehung der beiden weiter verschlechtert. </s> <s> im März hatte Netanyahu auf Einladung der Republikaner vor dem US-Kongress eine umstrittene Rede gehalten, die teils als Affront gegen Obama gewertet wurde. </s> <s> die Rede war mit Obama nicht abgesprochen, ein Treffen hatte dieser mit Hinweis auf die seinerzeit bevorstehende Wahl in Israel abgelehnt. </s>\nH-0\t-1.4947208166122437\tschschschschschschschschschschschschschschschschsch</s> <s> schschschschschschschschschschschschschschschschschschschschschschschschschschschschsch</s> <s> ritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiriti</s> <s> ritiritiritiritiritiritiritih h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h </s> <s> terterterterterterterununununununununununununununununununununununununununun</s> <s> ritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiriti</s> <s> und und und und und und und und und und und und und und und ritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiriti</s> <s> ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen </s> <s> ischen ischen ischen ischen ischen ischen ischen ischen ischen mamamamamamamamamamamamamamamamamamamamamaunununununununununununununununununununununununununununun</s>\nD-0\t-1.4947208166122437\tschschschschschschschschschschschschschschschschsch</s> <s> schschschschschschschschschschschschschschschschschschschschschschschschschschschschsch</s> <s> ritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiriti</s> <s> ritiritiritiritiritiritiritih h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h </s> <s> terterterterterterterununununununununununununununununununununununununununun</s> <s> ritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiriti</s> <s> und und und und und und und und und und und und und und und ritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiriti</s> <s> ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen </s> <s> ischen ischen ischen ischen ischen ischen ischen ischen ischen mamamamamamamamamamamamamamamamamamamamamaunununununununununununununununununununununununununununun</s>\nP-0\t-5.0178 -1.7736 -1.7786 -1.8264 -1.8900 -1.9565 -2.0043 -2.0229 -2.0073 -1.9692 -1.9388 -1.9324 -1.9485 -1.9786 -2.0095 -2.0281 -2.0239 0.0000 0.0000 -3.9926 -0.9592 -1.0095 -1.0672 -1.0915 -1.0803 -1.0465 -1.0151 -1.0054 -1.0298 -1.0799 -1.1289 -1.1543 -1.1505 -1.1278 -1.1039 -1.0954 -1.1039 -1.1214 -1.1327 -1.1273 -1.1162 -1.1153 -1.1263 -1.1441 -1.1536 -1.1491 -1.1394 -1.1353 0.0000 0.0000 -5.3279 -1.5691 -1.5588 -1.5600 -1.5676 -1.5913 -1.6236 -1.6469 -1.6546 -1.6388 -1.6129 -1.6085 -1.6336 -1.6688 -1.6922 -1.6852 -1.6558 -1.6245 -1.6124 -1.6258 -1.6535 -1.6726 -1.6733 -1.6665 -1.6735 -1.7027 -1.7374 -1.7626 -1.7612 -1.7352 -1.6948 -1.6582 -1.6359 -1.6325 -1.6452 -1.6712 -1.7021 -1.7149 -1.7056 -1.6701 -1.6293 -1.6070 -1.6159 -1.6443 -1.6777 -1.6938 -1.6751 -1.6369 -1.6120 -1.6118 -1.6297 -1.6493 -1.6507 -1.6299 -1.6061 -1.6035 -1.6224 -1.6452 -1.6443 -1.6098 -1.5583 0.0000 0.0000 -5.4439 -1.6747 -1.6813 -1.6892 -1.6897 -1.6963 -1.7130 -5.2175 -1.5763 -1.5375 -1.5117 -1.5074 -1.5324 -1.5671 -1.5898 -1.5874 -1.5587 -1.5304 -1.5174 -1.5323 -1.5714 -1.6106 -1.6323 -1.6388 -1.6388 -1.6488 -1.6686 -1.6909 -1.6987 -1.6822 -1.6548 -1.6316 -1.6276 -1.6395 -1.6515 -1.6530 -1.6435 -1.6331 -1.6254 -1.6214 -1.6242 -1.6353 -1.6534 -1.6785 -1.7074 -1.7343 -1.7506 -1.7490 -1.7324 -1.7141 -1.7023 -1.7075 -1.7303 -1.7537 0.0000 0.0000 -6.0610 -2.2252 -2.2064 -2.2349 -2.2780 -2.3261 -2.3632 -6.0974 -2.2877 -2.2509 -2.2113 -2.1642 -2.1130 -2.0703 -2.0384 -2.0138 -1.9994 -1.9988 -2.0130 -2.0357 -2.0625 -2.0901 -2.1260 -2.1662 -2.1963 -2.1971 -2.1640 -2.1176 -2.0821 -2.0746 -2.0996 -2.1356 -2.1601 -2.1653 0.0000 0.0000 -5.3808 -1.2965 -1.2303 -1.2053 -1.1993 -1.2053 -1.2040 -1.1810 -1.1433 -1.1139 -1.0989 -1.0993 -1.1085 -1.1154 -1.1144 -1.1066 -1.1014 -1.1047 -1.1204 -1.1526 -1.1874 -1.2154 -1.2247 -1.2202 -1.2226 -1.2298 -1.2411 -1.2495 -1.2443 -1.2283 -1.2125 -1.2144 -1.2429 -1.2838 -1.3211 -1.3304 -1.2986 -1.2501 -1.2176 -1.2188 -1.2514 -1.2948 -1.3249 -1.3301 -1.3133 -1.2898 -1.2743 -1.2690 -1.2731 -1.2812 -1.2833 -1.2714 -1.2484 -1.2221 -1.1901 -1.1622 -1.1413 -1.1427 -1.1603 -1.1832 -1.2001 -1.2115 -1.2141 -1.2196 -1.2323 -1.2500 -1.2639 -1.2728 -1.2797 -1.2834 -1.2865 -1.2832 0.0000 0.0000 -5.8088 -1.7326 -1.6260 -1.5689 -1.5109 -1.4594 -1.4308 -1.4287 -1.4578 -1.5137 -1.5690 -1.5990 -1.5920 -1.5624 -1.5412 -5.7993 -1.5564 -1.5075 -1.4509 -1.3801 -1.3074 -1.2513 -1.2227 -1.2179 -1.2169 -1.2034 -1.1804 -1.1673 -1.1701 -1.1877 -1.2012 -1.1912 -1.1684 -1.1511 -1.1433 -1.1440 -1.1436 -1.1262 -1.0984 -1.0751 -1.0688 -1.0781 -1.0957 -1.1109 -1.1137 -1.1178 -1.1326 -1.1635 -1.2035 -1.2343 -1.2445 -1.2352 -1.2189 -1.2095 -1.2087 -1.2090 -1.2043 -1.1992 -1.1957 -1.1969 -1.2035 -1.2087 0.0000 0.0000 -3.8439 -0.7508 -0.8086 -0.8630 -0.9091 -0.9499 -0.9925 -1.0282 -1.0501 -1.0596 -1.0597 -1.0582 -1.0593 -1.0623 -1.0616 -1.0588 -1.0576 -1.0640 -1.0799 -1.0973 -1.1091 -1.1146 -1.1216 -1.1306 -1.1453 -1.1600 -1.1633 -1.1500 -1.1300 -1.1050 -1.0865 -1.0847 -1.0980 -1.1099 -1.1115 -1.1076 -1.1035 -1.1086 -1.1244 -1.1409 -1.1517 -1.1502 -1.1409 -1.1281 -1.1169 -1.1184 -1.1290 -1.1363 -1.1351 -1.1290 -1.1201 -1.1059 -1.0947 -1.0929 -1.0976 -1.1066 -1.1127 -1.1177 -1.1172 -1.1122 -1.1133 -1.1240 -1.1419 -1.1588 -1.1652 -1.1596 0.0000 0.0000 -5.2428 -1.4043 -1.4390 -1.5039 -1.5620 -1.6119 -1.6557 -1.6974 -1.7427 -5.5617 -1.9157 -1.8256 -1.7317 -1.6541 -1.6141 -1.6186 -1.6403 -1.6465 -1.6200 -1.5638 -1.5130 -1.4976 -1.5250 -1.5756 -1.6057 -1.6012 -1.5653 -1.5333 -1.5387 -1.5788 -5.3603 -1.4787 -1.4246 -1.3819 -1.3540 -1.3302 -1.3092 -1.2926 -1.2819 -1.2821 -1.2858 -1.2949 -1.2946 -1.2854 -1.2699 -1.2660 -1.2754 -1.2837 -1.2866 -1.2917 -1.2999 -1.3212 -1.3588 -1.3964 -1.4088 -1.3898 -1.3521 -1.3155 0.0000 0.0000\nS-10\t<s> <unk> <unk> uot<unk> We <unk> apo<unk> re trying to get our students to come back, <unk> <unk> uot<unk> LaForge said. </s> <s> the crisis is over. </s> <s> This is a day of healing. </s> <s> Amy and <unk> ogelio Solis reported from Cleveland, Mississippi. </s> <s> Associated Press writers Emily Wagster Pettus in <unk> reenville, Mississippi, and Rebecca Santana in new Orleans contributed to this report. </s> <s> This story has been corrected to ref<unk> t that police are now saying L<unk> <unk> made the <unk> <unk> <unk> call after shooting Schmidt, and that while L<unk> <unk> referred to Prentiss as his wife in the <unk> <unk> <unk> call, there is no indication the two ever married. </s>\nT-10\t<<unk>> <<unk>> uot<<unk>> Wir versuchen, unsere Studenten zur <<unk>> <<unk>> ckk<<unk>> r zu bewegen <<unk>> <<unk>> uot<<unk>>, sagte LaForge. </s> <s> die Krise ist vorüber. </s> <s> Dies ist ein Tag der Heilung. </s> <s> Amy und <<unk>> ogelio Solis berichteten aus Cleveland, Mississippi. </s> <s> Associated Press Autoren Emily Wagster Pettus in <<unk>> reenville, Mississippi, und Rebecca Santana in New Orleans trugen zu diesem Bericht bei. </s> <s> Diese <<unk>> eschichte wurde korrigiert, um widerzuspiegeln, dass die Polizei jetzt sagt, dass L<<unk>> <<unk>> den Notru<<unk>> machte, nachdem er Schmidt erschossen hatte, und dass L<<unk>> m in seinem Notru<<unk>> Prentiss <<unk>> ar als seine Frau bezeichnete, aber es keinen Hinweis darauf gibt, dass die beiden jemals geheiratet haben. </s>\nH-10\t-1.4625496864318848\thinhinhinhinhinterterterterterterterterterterterterterterterterterterhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhin</s> <s> ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen </s> <s> etetetetetetetetetetetetetetetetetetetetetetetet</s> <s> h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h </s> <s> ritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiriti</s> <s> ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen </s>\nD-10\t-1.4625496864318848\thinhinhinhinhinterterterterterterterterterterterterterterterterterterhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhinhin</s> <s> ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen </s> <s> etetetetetetetetetetetetetetetetetetetetetetetet</s> <s> h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h h </s> <s> ritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiritiriti</s> <s> ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen ischen </s>\nP-10\t-5.3891 -1.4469 -1.4349 -1.4527 -1.4685 -5.0936 -1.3984 -1.3715 -1.3554 -1.3329 -1.3047 -1.2889 -1.2944 -1.3291 -1.3654 -1.3797 -1.3745 -1.3619 -1.3501 -1.3510 -1.3705 -1.4078 -1.4430 -5.9067 -1.4488 -1.4289 -1.4230 -1.4242 -1.4193 -1.4096 -1.3942 -1.3874 -1.3969 -1.4209 -1.4482 -1.4526 -1.4376 -1.4044 -1.3757 -1.3656 -1.3793 -1.4053 -1.4253 -1.4273 -1.4225 -1.4273 -1.4473 -1.4773 -1.5053 -1.5134 -1.4861 -1.4317 -1.3741 -1.3260 -1.3122 -1.3291 -1.3667 -1.4050 -1.4273 -1.4228 -1.3922 -1.3541 -1.3269 -1.3163 -1.3242 -1.3425 -1.3539 -1.3511 -1.3492 -1.3600 -1.3828 -1.4106 -1.4287 0.0000 0.0000 -5.4855 -1.4769 -1.5410 -1.5975 -1.6248 -1.6365 -1.6563 -1.6950 -1.7467 -1.8005 -1.8379 -1.8678 -1.9034 -1.9472 -1.9925 -2.0281 -2.0348 -2.0067 -1.9623 -1.9341 0.0000 0.0000 -5.5089 -1.8921 -1.8343 -1.8369 -1.8456 -1.8490 -1.8681 -1.9077 -1.9660 -2.0182 -2.0305 -2.0038 -1.9507 -1.9134 -1.9302 -1.9903 -2.0477 -2.0777 -2.0830 -2.0821 -2.0962 -2.1247 -2.1431 -2.1207 0.0000 0.0000 -4.7212 -1.5140 -1.5947 -1.6687 -1.7130 -1.7230 -1.7061 -1.6930 -1.7044 -1.7390 -1.7783 -1.8104 -1.8156 -1.7998 -1.7829 -1.7859 -1.8061 -1.8335 -1.8500 -1.8467 -1.8234 -1.7909 -1.7654 -1.7527 -1.7448 -1.7315 -1.7176 -1.7025 -1.6842 -1.6625 -1.6462 -1.6459 -1.6680 -1.7075 -1.7570 -1.7888 -1.7956 -1.7814 -1.7606 -1.7411 -1.7302 -1.7339 -1.7469 -1.7611 -1.7655 -1.7574 -1.7423 -1.7341 -1.7360 -1.7469 0.0000 0.0000 -5.5202 -1.5626 -1.5353 -1.5178 -1.4973 -1.4871 -1.4998 -1.5292 -1.5587 -1.5700 -1.5646 -1.5436 -1.5164 -1.5017 -1.5048 -1.5217 -1.5443 -1.5659 -1.5745 -1.5713 -1.5525 -1.5242 -1.4989 -1.4900 -1.5059 -1.5428 -1.5830 -1.6145 -1.6223 -1.6000 -1.5671 -1.5425 -1.5373 -1.5498 -1.5730 -1.5903 -1.5814 -1.5477 -1.5031 -1.4664 -1.4467 -1.4385 -1.4421 -1.4513 -1.4566 -1.4541 -1.4545 -1.4676 -1.4989 -1.5435 -1.5870 -1.6118 -1.6129 -1.6046 -1.6018 -1.6125 -1.6334 -1.6438 -1.6369 -1.6140 -1.5931 -1.5938 -1.6215 -1.6724 -1.7203 -1.7336 -1.7070 -1.6616 -1.6337 -1.6432 -1.6822 -1.7305 -1.7649 -1.7718 -1.7533 -1.7273 -1.7126 -1.7118 -1.7198 -1.7239 -1.7217 -1.7086 -1.6884 -1.6668 -1.6438 -1.6216 -1.6047 -1.5986 -1.6019 -1.6067 -1.6108 -1.6184 -1.6313 -1.6458 -1.6653 -1.6860 -1.7005 -1.7127 -1.7237 -1.7359 -1.7409 -1.7299 0.0000 0.0000 -3.7968 -0.6208 -0.6522 -0.6912 -0.7208 -0.7442 -0.7662 -0.7906 -0.8152 -0.8356 -0.8540 -0.8769 -0.9027 -0.9326 -0.9638 -0.9916 -1.0108 -1.0245 -1.0302 -1.0220 -1.0077 -0.9948 -0.9922 -1.0021 -1.0169 -1.0281 -1.0368 -1.0473 -1.0658 -1.0914 -1.1136 -1.1307 -1.1399 -1.1364 -1.1225 -1.1038 -1.0849 -1.0612 -1.0326 -1.0078 -1.0012 -1.0158 -1.0455 -1.0792 -1.1055 -1.1121 -1.1023 -1.0925 -1.0992 -1.1233 -1.1543 -1.1786 -1.1861 -1.1780 -1.1624 -1.1528 -1.1532 -1.1604 -1.1651 -1.1590 -1.1441 -1.1296 -1.1190 -1.1144 -1.1105 -1.1073 -1.1094 -1.1204 -1.1449 -1.1754 -1.1991 -1.2069 -1.2008 -1.1906 -1.1821 -1.1794 -1.1734 -1.1559 -1.1264 -1.0971 -1.0822 -1.0851 -1.1040 -1.1236 -1.1353 -1.1345 -1.1303 -1.1330 -1.1463 -1.1617 -1.1691 -1.1557 -1.1304 -1.1032 -1.0870 -1.0877 -1.0994 -1.1094 -1.1131 -1.1105 -1.1136 -1.1316 -1.1558 -1.1752 -1.1799 -1.1748 -1.1647 -1.1535 -1.1458 -1.1490 -1.1555 -1.1548 -1.1470 -1.1340 -1.1148 -1.0945 -1.0823 -1.0788 -1.0860 -1.1005 -1.1130 -1.1179 -1.1143 -1.1085 -1.1129 -1.1299 -1.1512 -1.1697 -1.1744 -1.1658 -1.1537 -1.1513 -1.1663 -1.1941 -1.2131 -1.2111 -1.1916 -1.1706 -1.1674 -1.1920 -1.2361 -1.2727 -1.2806 -1.2566 -1.2138 0.0000 0.0000\n2024-08-20 22:51:03 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n2024-08-20 22:51:03 | INFO | fairseq_cli.generate | Translated 11 sentences (5733 tokens) in 205.6s (0.05 sentences/s, 27.89 tokens/s)\n2024-08-20 22:51:03 | INFO | fairseq_cli.generate | [sentence-level] Generate test with beam=5: BLEU = 0.00, 0.0/0.0/0.0/0.0 (BP=1.000, ratio=1.274, hyp_len=3881, ref_len=3047)\n2024-08-20 22:51:03 | INFO | fairseq_cli.generate | [document-level] Generate test with beam=5: BLEU = 0.01, 0.1/0.0/0.0/0.0 (BP=1.000, ratio=1.274, hyp_len=3881, ref_len=3047)\n2024-08-20 22:51:03 | INFO | fairseq_cli.generate | Bucket 0-th sent: BLEU = 0.00, 0.0/0.0/0.0/0.0 (BP=0.237, ratio=0.410, hyp_len=279, ref_len=681)\n2024-08-20 22:51:03 | INFO | fairseq_cli.generate | Bucket 1-th sent: BLEU = 0.00, 0.0/0.0/0.0/0.0 (BP=0.831, ratio=0.844, hyp_len=281, ref_len=333)\n2024-08-20 22:51:03 | INFO | fairseq_cli.generate | Bucket 2-th sent: BLEU = 0.00, 0.0/0.0/0.0/0.0 (BP=1.000, ratio=1.393, hyp_len=507, ref_len=364)\n2024-08-20 22:51:03 | INFO | fairseq_cli.generate | Bucket 3-th sent: BLEU = 0.00, 0.0/0.0/0.0/0.0 (BP=1.000, ratio=1.802, hyp_len=1195, ref_len=663)\n2024-08-20 22:51:03 | INFO | fairseq_cli.generate | Bucket 4-th sent: BLEU = 0.00, 0.0/0.0/0.0/0.0 (BP=1.000, ratio=1.521, hyp_len=712, ref_len=468)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the logs to find the BLEU scores after the evaluation is complete\n",
    "!tail -n 20 data/run-finetune/test.g-transformer.en-de.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af8c29",
   "metadata": {},
   "source": [
    "### Step 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328977af",
   "metadata": {},
   "source": [
    "Execution Start time: 22:51:09, End time: 22:51:09 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0305085",
   "metadata": {},
   "source": [
    "**Thought**: The evaluation process has completed successfully, and the Sentence-level and Document-level BLEU metrics have been obtained. The Sentence-level BLEU is 0.00, and the Document-level BLEU is 0.01. I will now submit these results as requested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd7fd21",
   "metadata": {},
   "source": [
    "**Action (submit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e203b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Sentence-level BLEU': 0.0, 'Document-level BLEU': 0.01}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
