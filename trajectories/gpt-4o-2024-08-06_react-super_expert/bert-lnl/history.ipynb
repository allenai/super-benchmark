{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d299bc51",
   "metadata": {},
   "source": [
    "### Query\n",
    "Train BERT-WN on the AG-News dataset with 20% single-flip label noise using the `main.py` script. Evaluate the model and report the resulting metrics.\n",
    "\n",
    "The repository does not provide the dataset. Use huggingface datasets to get it (ag_news) Report the accuracy and weighted average precision, recall, f1-score, and support, as a json structured as follows: {\"accuracy\": 0.0, \"weighted_avg\": {\"precision\": 0.0, \"recall\": 0.0, \"f1-score\": 0.0, \"support\": 0}} (replace 0.0 with the actual values).\n",
    "\n",
    "Additional instructions:\n",
    "1. Run for only 5 training steps. All other hyper-parameters should be taken from the readme example.\n",
    "2. Load these specific instances indices: from the train split [1,2,3,4,5,6,100,101,102,103,104,105,451,452,453,454,455,456,501,502,503,504,505,506], test split: [1,2,3,101,103,452,455,501,502,503,504,505], validation split: [0,1,2,6,7,8,12,13,14,18,19,20]\n",
    "\n",
    "Git repository: https://github.com/uds-lsv/BERT-LNL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d9609",
   "metadata": {},
   "source": [
    "### Prompt\n",
    "<details>\n",
    "[{'role': 'system', 'content': 'Interact in a jupyter notebook to solve the request.\\nOutput a thought and an action.\\nThought can reason about the current situation, and action allows you to interact with the Jupyter notebook. There are three types of actions:\\n(1) execute, which executes a notebook cell with the command under the \"content\" field. This could be a bash command (beginning with !), a python command, or magic command (beginning with %).\\n(2) edit, which allows you to replace existing lines in a file with new lines. To replace lines, you will need to provide the lines as they appear before the replacement, and the lines to replace them with.\\nIn the \"content\" field, format should be ```{filename}\\n<<<BEFORE_EDIT>>>\\nlines before edit\\nlines before edit\\n<<<AFTER_EDIT>>>\\nlines after edit\\nlines after edit```\\n  - Include the entire lines WITH indentation. After editing, make sure indentation is correct.\\n(3) submit, which submits the final answer (or null if there\\'s no answer to submit), formatted as JSON (make sure to use double quotes for keys and values).\\nAlways output exactly one \"thought\" and one \"action\", and encapsulate the content with <content>...</content> tags.\\nI will provide the cell output (observation) for you.\\n\\nTips:\\n- When a github repository is given, you should start by cloning it. You can read the readme file and browse the repo for installation and usage instructions.\\n- Avoid using conda, instead use pip for package management.\\n- Each execution has a 5-minute timeout. After this period, you can decide whether to interrupt the kernel or continue waiting.\\n  You should interrupt if: (1) you are prompted with an interactive message (e.g., \"Do you want to continue? [Y/n]\"). In that case, you can bypass it by executing echo \"y\" | command, or (2) the execution is taking longer than expected because the wrong task is being executed, such as a different model or incorrect number of epochs.\\n  You should continue to wait if the current execution is correct and proceeding as expected.\\n\\nHere are some examples.\\nGit repository: EleutherAI/lm-evaluation-harness\\nQuery: Evaluate EleutherAI/gpt-j-6B on hellaswag. What\\'s the score?\\nThought: First, I need to clone the GitHub repository \\'EleutherAI/lm-evaluation-harness\\'.\\nAction: execute\\n<content>\\n!git clone https://github.com/EleutherAI/lm-evaluation-harness.git\\n</content>\\nObservation: ```\\nCloning into \\'lm-evaluation-harness\\'...\\n```\\nThought: The repository has been cloned. Next, I should check the README file for installation and usage instructions to proceed with evaluating EleutherAI/gpt-j-6B on hellaswag.\\nAction: execute\\n<content>\\n!cat lm-evaluation-harness/README.md\\n</content>\\nObservation: ```# Language Model Evaluation Harness ... truncated ...\\n```\\nThought: The README provides detailed instructions for installing the `lm-eval` package and evaluating models like GPT-J-6B on tasks like hellaswag. I need to install the package and its dependencies first.\\nAction: execute\\n<content>\\n!pip install -e lm-evaluation-harness/.\\n</content>\\nObservation: ```\\nObtaining file:///home/nora/lm-evaluation-harness\\n  Installing build dependencies ... truncated ...\\n```\\nThought: The `lm-eval` package and its dependencies have been installed successfully. Now, I can proceed with evaluating the EleutherAI/gpt-j-6B model on the hellaswag task as per the instructions in the README.\\nAction: execute\\n<content>\\n!lm_eval --model hf --model_args pretrained=EleutherAI/gpt-j-6B --tasks hellaswag --device cuda:0 --batch_size 8\\n</content>\\nObservation: ```\\n{\\n  \"hellaswag\": {\\n    \"acc\": 0.24603658536585363,\\n    \"acc_norm\": 0.34436059706446426,\\n  },  ... truncated ...\\n```\\nThought: The `lm-eval` was executed successfully, providing the metrics I needed. The `acc` metric is 0.2460. The `acc_norm` metric is 0.3444\\nAction: submit\\n<content>\\n{\"acc\": 0.2460, \"acc_norm\": 0.3444}\\n</content>\\n\\nQuery: use pandas to read the file \\'data.csv\\' and display the first 2 rows.\\nThought: First, I need to read the file \\'data.csv\\' using the pandas library.\\nAction: execute\\n<content>\\nimport pandas as pd\\npd.read_csv(\\'data.csv\\').head()\\n</content>\\nObservation: ```\\n    name\\n  0  Alice\\n   1    Bob\\n  2  Charlie\\n```\\nThought: The file \\'data.csv\\' has been read successfully and the first 2 rows have been displayed.\\nAction: submit\\n<content>\\n[\"Alice\", \"Bob\"]\\n</content>\\n\\nQuery: Change the model name in the \\'config.json\\' file from \\'roberta-base\\' to \\'roberta-large\\'.\\nThought: First, I need to read the \\'config.json\\' file to find the location where I can replace the model name.\\nAction: execute\\n<content>\\n!cat config.json\\n</content>\\nObservation: ```\\n{\\n    \"model\": \"roberta-base\",\\n    \"batch_size\": 8,\\n    \"epochs\": 10\\n}\\n```\\nThought: The file has been read successfully. Now, I can replace the model name in the \\'config.json\\' file.\\nAction: edit\\n<content>\\nconfig.json\\n<<<BEFORE_EDIT>>>\\n{\\n    \"model\": \"roberta-base\",\\n    \"batch_size\": 8,\\n<<<AFTER_EDIT>>>\\n{\\n    \"model\": \"roberta-large\",\\n    \"batch_size\": 8,\\n</content>\\nObservation: \"editing file config.json\"\\nThought: The model name has been replaced in the \\'config.json\\' file.\\nAction: submit\\n<content>\\nnull\\n</content>\\n'}, {'role': 'user', 'content': 'Query: Train BERT-WN on the AG-News dataset with 20% single-flip label noise using the `main.py` script. Evaluate the model and report the resulting metrics.\\n\\nThe repository does not provide the dataset. Use huggingface datasets to get it (ag_news) Report the accuracy and weighted average precision, recall, f1-score, and support, as a json structured as follows: {\"accuracy\": 0.0, \"weighted_avg\": {\"precision\": 0.0, \"recall\": 0.0, \"f1-score\": 0.0, \"support\": 0}} (replace 0.0 with the actual values).\\n\\nAdditional instructions:\\n1. Run for only 5 training steps. All other hyper-parameters should be taken from the readme example.\\n2. Load these specific instances indices: from the train split [1,2,3,4,5,6,100,101,102,103,104,105,451,452,453,454,455,456,501,502,503,504,505,506], test split: [1,2,3,101,103,452,455,501,502,503,504,505], validation split: [0,1,2,6,7,8,12,13,14,18,19,20]\\n\\nGit repository: https://github.com/uds-lsv/BERT-LNL'}]\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e665437e",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a08d8",
   "metadata": {},
   "source": [
    "Execution Start time: 19:41:45, End time: 19:41:47 (duration: 2 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32bf1d8",
   "metadata": {},
   "source": [
    "**Thought**: First, I need to clone the GitHub repository 'uds-lsv/BERT-LNL' to access the `main.py` script and other necessary files. Then, I will check the README file for instructions on how to train the model and evaluate it. Additionally, I will need to install the Hugging Face datasets library to load the AG-News dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4ad6f5",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542aa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloning into 'BERT-LNL'...\nremote: Enumerating objects: 24, done.\u001b[K\nremote: Counting objects: 100% (24/24)\u001b[K\nremote: Counting objects: 100% (24/24), done.\u001b[K\nremote: Compressing objects: 100% (20/20)\u001b[K\nremote: Compressing objects: 100% (20/20), done.\u001b[K\nremote: Total 24 (delta 4), reused 20 (delta 4), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (24/24)\nReceiving objects: 100% (24/24), 22.55 KiB | 1.88 MiB/s, done.\nResolving deltas: 100% (4/4)\nResolving deltas: 100% (4/4), done.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/uds-lsv/BERT-LNL.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37edbcf5",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8cff3",
   "metadata": {},
   "source": [
    "Execution Start time: 19:41:48, End time: 19:41:50 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2be32cf",
   "metadata": {},
   "source": [
    "**Thought**: The repository has been cloned successfully. Next, I will check the README file for instructions on how to train the model using the `main.py` script and any specific requirements or dependencies that need to be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5f32a",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba17ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# BERT_LNL\nCode for paper [\"Is BERT Robust to Label Noise? A Study on Learning with Noisy Labels in\nText Classification\"](https://aclanthology.org/2022.insights-1.8.pdf).\n\n## Data Preparation\n### Datasets\nWe run our experiments on the following four datasets: AG-News, IMDB, Yorùbá, and Hausa.\n\n| Name | # train | # validation | # test | data source                                            |\n|:--------|:--------|:-------------|:-------|:-------------------------------------------------------|\n| AGNews | 108000  | 12000        | 7600   | [LINK](https://arxiv.org/abs/1509.01626)               | \n| IMDB | 21246   | 3754         | 2500   | [LINK](https://dl.acm.org/doi/10.5555/2002472.2002491) | \n| Yorùbá | 1340    | 189         | 379   | [LINK](https://github.com/uds-lsv/transfer-distant-transformer-african) | \n| Hausa | 2045    | 290         | 582   | [LINK](https://github.com/uds-lsv/transfer-distant-transformer-african) | \n\n### Preprocessing\nCreate a `data` directory as the home directory for all datasets, then create a folder for each dataset in the `data` directory.\n\nFor each dataset, create the following files:\n- `[train/validation/test].txt`: one document per line.\n- `[train/validation/test]_labels.pickle` files: list of labels (we assume that labels are already encoded in label ids, e.g., [0,0,1,2,3,...,4]).\n- If there is no validation data for a given dataset, then there is no need to create the corresponding `validation` files.\n- Save files in a `txt_data` directory inside the dataset folder. For example, the full path to the `train.txt` file of the AGNews dataset is `data/AGNews/txt_data/train.txt`.\n\n## Examples\nRun `BERT-WN` on AG-News, with 20% single-flip label noise:\n```\nCUDA_VISIBLE_DEVICES=[CUDA_ID] python3 ../main.py \\\n--dataset AG-NEWs \\\n--log_root [LOG_ROOT] \\\n--data_root [DATA_ROOT] \\\n--trainer_name bert_wn \\\n--model_name bert-base-uncased \\\n--gen_val \\\n--nl_batch_size 32 \\\n--eval_batch_size 32 \\\n--gradient_accumulation_steps 1 \\\n--max_sen_len 64 \\\n--lr 0.00002 \\\n--num_training_steps 3000 \\\n--patience 25 \\\n--eval_freq 50 \\\n--store_model $STORE_MODEL \\\n--noise_level 0.2 \\\n--noise_type sflip \\\n--manualSeed 1234\n```\n\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!cat BERT-LNL/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de08c8d4",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78d9ec8",
   "metadata": {},
   "source": [
    "Execution Start time: 19:41:52, End time: 19:42:17 (duration: 24 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f097b1",
   "metadata": {},
   "source": [
    "**Thought**: The README provides an example command to run `BERT-WN` on the AG-News dataset with 20% single-flip label noise. I need to modify this command to run for only 5 training steps and use the specific instance indices provided. Additionally, I need to install the Hugging Face datasets library to load the AG-News dataset. First, I'll install the necessary dependencies and the datasets library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dec18c2",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e34aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Requirement already satisfied: transformers in /usr/local/lib/python3.10/site-packages (4.40.2)\nCollecting datasets\n  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (1.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/site-packages (from transformers) (0.23.3)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers) (1.25.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers) (4.66.4)\nCollecting pyarrow>=15.0.0 (from datasets)\n  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nCollecting dill<0.3.9,>=0.3.0 (from datasets)\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from datasets) (2.0.3)\nCollecting requests (from transformers)\n  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\nCollecting xxhash (from datasets)\n  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting multiprocess (from datasets)\n  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets) (3.8.3)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.12.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (2.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/527.3 kB ? eta -:--:--\n\n\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/116.3 kB ? eta -:--:--\n\n\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/39.9 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/64.9 kB ? eta -:--:--\n\n\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/134.8 kB ? eta -:--:--\n\n\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/194.1 kB ? eta -:--:--\n\n\u001b[?25hInstalling collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n  Attempting uninstall: requests\n    Found existing installation: requests 2.31.0\n    Uninstalling requests-2.31.0:\n      Successfully uninstalled requests-2.31.0\nSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 xxhash-3.5.0\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install transformers datasets scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7cb3a",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88581f54",
   "metadata": {},
   "source": [
    "Execution Start time: 19:42:25, End time: 19:42:26 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a065ef8",
   "metadata": {},
   "source": [
    "**Thought**: The necessary dependencies have been installed successfully. Now, I need to modify the `main.py` script to load the specific instances from the AG-News dataset using the Hugging Face datasets library. I will create a new script to handle the dataset loading and then run the training with the specified parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c06c7fc",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1688448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: File BERT-LNL/load_ag_news.py does not exist."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "<<<AFTER_EDIT>>>\n",
    "from datasets import load_dataset\n",
    "\n",
    "def load_ag_news():\n",
    "    dataset = load_dataset('ag_news')\n",
    "    train_indices = [1,2,3,4,5,6,100,101,102,103,104,105,451,452,453,454,455,456,501,502,503,504,505,506]\n",
    "    test_indices = [1,2,3,101,103,452,455,501,502,503,504,505]\n",
    "    val_indices = [0,1,2,6,7,8,12,13,14,18,19,20]\n",
    "\n",
    "    train_data = dataset['train'].select(train_indices)\n",
    "    test_data = dataset['test'].select(test_indices)\n",
    "    val_data = dataset['validation'].select(val_indices)\n",
    "\n",
    "    return train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c341d703",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d85a5e",
   "metadata": {},
   "source": [
    "Execution Start time: 19:42:29, End time: 19:42:31 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dff2ade",
   "metadata": {},
   "source": [
    "**Thought**: It seems that the `load_ag_news.py` file does not exist in the repository. I will create a new Python script to load the AG-News dataset using the Hugging Face datasets library and select the specified instances. This script will be used to prepare the data for training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce1ca59",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6bfe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: File BERT-LNL/load_ag_news.py does not exist."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "<<<AFTER_EDIT>>>\n",
    "from datasets import load_dataset\n",
    "\n",
    "def load_ag_news():\n",
    "    dataset = load_dataset('ag_news')\n",
    "    train_indices = [1,2,3,4,5,6,100,101,102,103,104,105,451,452,453,454,455,456,501,502,503,504,505,506]\n",
    "    test_indices = [1,2,3,101,103,452,455,501,502,503,504,505]\n",
    "    val_indices = [0,1,2,6,7,8,12,13,14,18,19,20]\n",
    "\n",
    "    train_data = dataset['train'].select(train_indices)\n",
    "    test_data = dataset['test'].select(test_indices)\n",
    "    val_data = dataset['validation'].select(val_indices)\n",
    "\n",
    "    return train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd6de2",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f58f5",
   "metadata": {},
   "source": [
    "Execution Start time: 19:42:34, End time: 19:42:35 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff2fe1",
   "metadata": {},
   "source": [
    "**Thought**: \n",
    "Thought: I attempted to create a new file `load_ag_news.py` in the `BERT-LNL` directory, but it seems there was an error. I will try creating the file again to ensure the dataset is loaded correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b311e4f",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888f2474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: File BERT-LNL/load_ag_news.py does not exist."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "<<<AFTER_EDIT>>>\n",
    "from datasets import load_dataset\n",
    "\n",
    "def load_ag_news():\n",
    "    dataset = load_dataset('ag_news')\n",
    "    train_indices = [1,2,3,4,5,6,100,101,102,103,104,105,451,452,453,454,455,456,501,502,503,504,505,506]\n",
    "    test_indices = [1,2,3,101,103,452,455,501,502,503,504,505]\n",
    "    val_indices = [0,1,2,6,7,8,12,13,14,18,19,20]\n",
    "\n",
    "    train_data = dataset['train'].select(train_indices)\n",
    "    test_data = dataset['test'].select(test_indices)\n",
    "    val_data = dataset['validation'].select(val_indices)\n",
    "\n",
    "    return train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042a68b",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d15a7d0",
   "metadata": {},
   "source": [
    "Execution Start time: 19:42:38, End time: 19:42:38 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b5560",
   "metadata": {},
   "source": [
    "**Thought**: It seems there is an issue with creating the new file in the `BERT-LNL` directory. I will attempt to create the file again using a different approach to ensure it is saved correctly. This file will be used to load the AG-News dataset with the specified indices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1743e2a",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f11b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Error/Traceback: SyntaxError: unterminated string literal (detected at line 13) (3078003143.py, line 13)  Cell In[9], line 13\n    return train_data, test_data, val_data\" > BERT-LNL/load_ag_news.py\n                                          ^\nSyntaxError: unterminated string literal (detected at line 13)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!echo \"from datasets import load_dataset\n",
    "\n",
    "def load_ag_news():\n",
    "    dataset = load_dataset('ag_news')\n",
    "    train_indices = [1,2,3,4,5,6,100,101,102,103,104,105,451,452,453,454,455,456,501,502,503,504,505,506]\n",
    "    test_indices = [1,2,3,101,103,452,455,501,502,503,504,505]\n",
    "    val_indices = [0,1,2,6,7,8,12,13,14,18,19,20]\n",
    "\n",
    "    train_data = dataset['train'].select(train_indices)\n",
    "    test_data = dataset['test'].select(test_indices)\n",
    "    val_data = dataset['validation'].select(val_indices)\n",
    "\n",
    "    return train_data, test_data, val_data\" > BERT-LNL/load_ag_news.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291d0be",
   "metadata": {},
   "source": [
    "### Step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040afe4",
   "metadata": {},
   "source": [
    "Execution Start time: 19:42:43, End time: 19:42:43 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7011c3",
   "metadata": {},
   "source": [
    "**Thought**: The error occurred because the multi-line string was not formatted correctly for the shell command. I will use a different approach to create the `load_ag_news.py` file by writing the content directly in a Python cell. This will ensure the file is created correctly with the necessary content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf378ca",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33288b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('BERT-LNL/load_ag_news.py', 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "from datasets import load_dataset\n",
    "\n",
    "def load_ag_news():\n",
    "    dataset = load_dataset('ag_news')\n",
    "    train_indices = [1,2,3,4,5,6,100,101,102,103,104,105,451,452,453,454,455,456,501,502,503,504,505,506]\n",
    "    test_indices = [1,2,3,101,103,452,455,501,502,503,504,505]\n",
    "    val_indices = [0,1,2,6,7,8,12,13,14,18,19,20]\n",
    "\n",
    "    train_data = dataset['train'].select(train_indices)\n",
    "    test_data = dataset['test'].select(test_indices)\n",
    "    val_data = dataset['validation'].select(val_indices)\n",
    "\n",
    "    return train_data, test_data, val_data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e061c",
   "metadata": {},
   "source": [
    "### Step 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe7106",
   "metadata": {},
   "source": [
    "Execution Start time: 19:42:45, End time: 19:42:47 (duration: 2 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b50a3",
   "metadata": {},
   "source": [
    "**Thought**: The `load_ag_news.py` file has been successfully created with the necessary content to load the AG-News dataset using the specified indices. Now, I need to modify the `main.py` script to use this new data loading function and adjust the training parameters to run for only 5 training steps. I will check the `main.py` script to identify where to integrate the data loading function and adjust the training steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc0894",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f226d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import argparse\nfrom loading_utils import prepare_data, prepare_af_data\nfrom utils import create_logger, save_args, create_trainer, load_config, save_config\nimport numpy as np\nimport torch\nimport random\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--dataset', type=str, default='IMDB', choices=['SST-2', 'AG_News',\n                                                                        'TREC', 'IMDB', 'Yelp-5',\n                                                                        'Yoruba', 'Hausa'])\n    parser.add_argument('--data_root', type=str, default=\"\")\n    parser.add_argument('--log_root', type=str, default=\"\",\n                        help='output directory to save logs in training/testing')\n\n    parser.add_argument('--trainer_name', type=str, default='bert_wn',\n                        choices=['bert_wn', 'bert_ct', 'bert_cm', 'bert_cmgt', 'bert_smoothing'],\n                        help='trainer selection: '\n                             'bert_wn: without noise-handling,'\n                             'bert_ct: co-teaching, '\n                             'bert_cm: noise matrix, '\n                             'bert_cmgt: ground truth noise matrix,'\n                             'bert_smoothing: label smoothing')\n    parser.add_argument('--model_name', type=str, default='bert-base-uncased',\n                        choices=['bert-base-uncased', 'bert-base-cased',\n                                 'bert-large-uncased', 'bert-base-multilingual-cased'],\n                        help='backbone selection')\n    parser.add_argument('--exp_name', type=str, default='')\n\n\n    # Preprocessing Related\n    parser.add_argument('--max_sen_len', type=int, default=512,\n                        help='max sentence length, longer sentences will be truncated')\n    parser.add_argument('--special_token_offsets', type=int, default=2,\n                        help='number of special tokens used in bert tokenizer for text classification')\n    parser.add_argument('--truncate_mode', type=str, default='last',\n                        choices=['hybrid, last'], help='last: last 510 tokens, hybrid: first 128 + last 382')\n    parser.add_argument('--freeze_bert', action='store_true',\n                        help='freeze the bert backbone, i.e. use bert as feature extractor')\n\n    # BERT settings Related\n    parser.add_argument('--bert_dropout_rate', type=float, default=0.1)\n    parser.add_argument('--noise_level', type=float, default=0.0,\n                        help='noise level for injected noise')\n    parser.add_argument('--noise_type', default='uniform_m',\n                        choices=['uniform_m', 'sflip'],\n                        help='noise types: uniform_m: uniform noise, sflip: single-flip noise')\n    parser.add_argument('--val_fraction', type=float, default=0.1,\n                        help='if no validation set is provided, use this fraction of training set as validation set')\n\n    # training related\n    parser.add_argument('--num_epochs', type=int, default=1, help='set either num_epochs or num_training_steps')\n    parser.add_argument('--num_training_steps', type=int, default=-1, help='set it to -1 if num_epochs is set')\n    parser.add_argument('--train_eval_freq', type=int, default=10,\n                        help='evaluate the model on training set after every [train_eval_freq] training steps')\n    parser.add_argument('--eval_freq', type=int, default=50,\n                        help='evaluate the model on the validation and test sets'\n                             'after every [eval_freq] training steps')\n    parser.add_argument('--fast_eval', action='store_true',\n                        help='use 10% of the test set for evaluation, to speed up the evaluation prcoess')\n\n    parser.add_argument('--nl_batch_size', type=int, default=16,\n                        help='noisy labeled samples per batch, can be understood as the training batch size')\n    parser.add_argument('--eval_batch_size', type=int, default=50,\n                        help='evaluation batch size during testing')\n    parser.add_argument('--warmup_steps', type=int, default=0,\n                        help='warmup steps for learning rate scheduler')\n    parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n                        help=\"number of updates steps to accumulate before performing a backward/update pass.\")\n\n    parser.add_argument('--gen_val', action='store_true',\n                        help='generate validation set, enable it if there is no validation set')\n    parser.add_argument('--store_model', type=int, default=0, help='save models after training')\n\n\n    # co-teaching related\n    parser.add_argument('--forget_factor', type=float, default=1.0)\n    parser.add_argument('--T_k', type=int, default=10)\n    parser.add_argument('--c', type=float, default=1.0)\n\n\n    # smoothing trainer related\n    parser.add_argument('--smoothing_factor', type=float, default=0.2,\n                        help='label smoothing levels, 0.0 means no smoothing')\n\n\n    # cm trainer related\n    parser.add_argument('--cm_mse_weight', type=float, default=0.01,\n                        help='regularization factor for the mse loss, check https://aclanthology.org/N19-1328/')\n\n\n    # optimizer related\n    parser.add_argument('--lr', type=float, default=2e-5)\n    parser.add_argument(\"--weight_decay\", default=0.0, type=float,\n                        help=\"Weight deay if we apply some.\")\n    parser.add_argument('--exp_decay_rate', type=float, default=0.9998)\n    parser.add_argument('--max_grad_norm', type=float, default=1.0)\n    parser.add_argument('--patience', type=float, default=20, help='patience for early stopping')\n\n    # hardware related\n    parser.add_argument('--use_cuda', type=bool, default=True)\n    parser.add_argument('--num_workers', type=int, default=0)\n    parser.add_argument('--cuda_device', type=str, default=\"0\")\n    parser.add_argument('--manualSeed', type=int, default=1234, help='random seed for reproducibility')\n    parser.add_argument('--noisy_label_seed', type=int, default=1234, help='random seed for reproducibility')\n\n    args = parser.parse_args()\n\n    if args.manualSeed is None:\n        args.manualSeed = random.randint(1, 10000)\n    random.seed(args.manualSeed)\n    np.random.seed(args.manualSeed)\n    torch.manual_seed(args.manualSeed)\n    torch.backends.cudnn.benchmark = False\n    if args.use_cuda:\n        torch.cuda.manual_seed_all(args.manualSeed)\n        torch.backends.cudnn.deterministic = True\n\n    # Create the Handler for logging records/messages to a file\n    logger, log_dir = create_logger(args.log_root, args)\n    save_args(log_dir, args)\n    logger.info(\"Training started\")\n    num_classes_map = {'AG_News': 4, 'TREC': 6, 'SST-2': 2, 'IMDB': 2, 'Yelp-5': 5,\n                       'Yoruba':7, 'Hausa':5}\n\n    logger.info(f'log dir: {log_dir}')\n    num_classes = num_classes_map[args.dataset]\n    r_state = np.random.RandomState(args.noisy_label_seed)\n\n    if args.dataset in ['SST-2', 'AG_News', 'TREC', 'IMDB', 'Yelp-5']:\n        logger.info(f'loading {args.dataset}...')\n\n\n        if args.dataset in ['SST-2', 'AG_News', 'TREC', 'Yelp-5']:\n            has_val = False\n            has_ul = False\n        elif args.dataset in ['IMDB']:\n            has_val = True\n            has_ul = True\n        else:\n            raise ValueError('need to set has_val and has_ul')\n\n        nl_set, ul_set, v_set, t_set, l2id, id2l = prepare_data(args, logger, r_state, num_classes, has_val, has_ul)\n    elif args.dataset in ['Yoruba', 'Hausa']:\n        has_ul=False\n        nl_set, ul_set, v_set, t_set, l2id, id2l = prepare_af_data(args, logger,\n                                                                   num_classes, has_ul)\n    else:\n        raise NotImplementedError(f\"dataset {args.dataset} not supported\")\n\n\n    model_config = load_config(args)\n    model_config['num_classes'] = num_classes\n\n    trainer = create_trainer(args, logger, log_dir, model_config, (nl_set, ul_set, v_set, t_set, l2id, id2l), r_state)\n    trainer.train(args, logger, (nl_set, ul_set, v_set, t_set, l2id, id2l))\n    save_config(log_dir, 'model_config', trainer.model_config)  # model_config could be updated during model creation\n\n\nif __name__=='__main__':\n    main()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!cat BERT-LNL/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b336ae28",
   "metadata": {},
   "source": [
    "### Step 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfb6c6e",
   "metadata": {},
   "source": [
    "Execution Start time: 19:42:51, End time: 19:42:51 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599a6b0",
   "metadata": {},
   "source": [
    "**Thought**: The `main.py` script uses a function `prepare_data` to load the dataset. I need to modify this script to use the `load_ag_news` function from the newly created `load_ag_news.py` file. I will replace the call to `prepare_data` with the `load_ag_news` function and adjust the training parameters to run for only 5 training steps. Additionally, I will ensure that the script imports the new data loading function correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170b481",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e9fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Found multiple BEFORE_EDIT in the patch. Line 5: <<<BEFORE_EDIT>>>\nFormat of edit is:```\n{filename}\n[optional] preceding lines\n<<<BEFORE_EDIT>>>\nline to remove\nline to remove\n<<<AFTER_EDIT>>>\nline to add\nline to add\nline to add\n```"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/main.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "from loading_utils import prepare_data, prepare_af_data\n",
    "<<<AFTER_EDIT>>>\n",
    "from load_ag_news import load_ag_news\n",
    "<<<BEFORE_EDIT>>>\n",
    "        nl_set, ul_set, v_set, t_set, l2id, id2l = prepare_data(args, logger, r_state, num_classes, has_val, has_ul)\n",
    "<<<AFTER_EDIT>>>\n",
    "        nl_set, v_set, t_set = load_ag_news()\n",
    "        ul_set = None\n",
    "        l2id, id2l = {}, {}\n",
    "<<<BEFORE_EDIT>>>\n",
    "    parser.add_argument('--num_training_steps', type=int, default=-1, help='set it to -1 if num_epochs is set')\n",
    "<<<AFTER_EDIT>>>\n",
    "    parser.add_argument('--num_training_steps', type=int, default=5, help='set it to -1 if num_epochs is set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc455f",
   "metadata": {},
   "source": [
    "### Step 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d32ba5",
   "metadata": {},
   "source": [
    "Execution Start time: 19:42:55, End time: 19:42:55 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920dcce5",
   "metadata": {},
   "source": [
    "**Thought**: The edit attempt failed because there were multiple `BEFORE_EDIT` markers in the patch. I need to make the edits separately to ensure each change is applied correctly. I will first replace the import statement and the call to `prepare_data` with the `load_ag_news` function, and then adjust the training steps parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a37ccb",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3daf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Found multiple BEFORE_EDIT in the patch. Line 5: <<<BEFORE_EDIT>>>\nFormat of edit is:```\n{filename}\n[optional] preceding lines\n<<<BEFORE_EDIT>>>\nline to remove\nline to remove\n<<<AFTER_EDIT>>>\nline to add\nline to add\nline to add\n```"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/main.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "from loading_utils import prepare_data, prepare_af_data\n",
    "<<<AFTER_EDIT>>>\n",
    "from load_ag_news import load_ag_news\n",
    "<<<BEFORE_EDIT>>>\n",
    "        nl_set, ul_set, v_set, t_set, l2id, id2l = prepare_data(args, logger, r_state, num_classes, has_val, has_ul)\n",
    "<<<AFTER_EDIT>>>\n",
    "        nl_set, v_set, t_set = load_ag_news()\n",
    "        ul_set = None\n",
    "        l2id, id2l = {}, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fa6221",
   "metadata": {},
   "source": [
    "### Step 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada5cce",
   "metadata": {},
   "source": [
    "Execution Start time: 19:42:57, End time: 19:42:58 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f1039",
   "metadata": {},
   "source": [
    "**Thought**: The edit attempt failed again due to multiple `BEFORE_EDIT` markers. I will make the edits one at a time to ensure each change is applied correctly. First, I will replace the import statement to use the `load_ag_news` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d42bba",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85f53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\nimport argparse\nfrom load_ag_news import load_ag_news\nfrom utils import create_logger, save_args, create_trainer, load_config, save_config\nimport numpy as np\nimport torch\nimport random\n\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/main.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "from loading_utils import prepare_data, prepare_af_data\n",
    "<<<AFTER_EDIT>>>\n",
    "from load_ag_news import load_ag_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc6b6e",
   "metadata": {},
   "source": [
    "### Step 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8498eab",
   "metadata": {},
   "source": [
    "Execution Start time: 19:43:02, End time: 19:43:02 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2930",
   "metadata": {},
   "source": [
    "**Thought**: The import statement has been successfully replaced to use the `load_ag_news` function. Next, I will replace the call to `prepare_data` with the `load_ag_news` function and adjust the training steps parameter to 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f208c3",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90e124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Found multiple BEFORE_EDIT in the patch. Line 7: <<<BEFORE_EDIT>>>\nFormat of edit is:```\n{filename}\n[optional] preceding lines\n<<<BEFORE_EDIT>>>\nline to remove\nline to remove\n<<<AFTER_EDIT>>>\nline to add\nline to add\nline to add\n```"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/main.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "        nl_set, ul_set, v_set, t_set, l2id, id2l = prepare_data(args, logger, r_state, num_classes, has_val, has_ul)\n",
    "<<<AFTER_EDIT>>>\n",
    "        nl_set, v_set, t_set = load_ag_news()\n",
    "        ul_set = None\n",
    "        l2id, id2l = {}, {}\n",
    "<<<BEFORE_EDIT>>>\n",
    "    parser.add_argument('--num_training_steps', type=int, default=-1, help='set it to -1 if num_epochs is set')\n",
    "<<<AFTER_EDIT>>>\n",
    "    parser.add_argument('--num_training_steps', type=int, default=5, help='set it to -1 if num_epochs is set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f98b8e",
   "metadata": {},
   "source": [
    "### Step 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d4cb32",
   "metadata": {},
   "source": [
    "Execution Start time: 19:43:04, End time: 19:43:07 (duration: 2 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79532599",
   "metadata": {},
   "source": [
    "**Thought**: The edit attempt failed again due to multiple `BEFORE_EDIT` markers. I will make the edits one at a time to ensure each change is applied correctly. First, I will replace the call to `prepare_data` with the `load_ag_news` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ede324",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adf97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n            has_ul = False\n        elif args.dataset in ['IMDB']:\n            has_val = True\n            has_ul = True\n        else:\n            raise ValueError('need to set has_val and has_ul')\n\n        nl_set, v_set, t_set = load_ag_news()\n        ul_set = None\n        l2id, id2l = {}, {}\n    elif args.dataset in ['Yoruba', 'Hausa']:\n        has_ul=False\n        nl_set, ul_set, v_set, t_set, l2id, id2l = prepare_af_data(args, logger,\n                                                                   num_classes, has_ul)\n    else:\n        raise NotImplementedError(f\"dataset {args.dataset} not supported\")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/main.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "        nl_set, ul_set, v_set, t_set, l2id, id2l = prepare_data(args, logger, r_state, num_classes, has_val, has_ul)\n",
    "<<<AFTER_EDIT>>>\n",
    "        nl_set, v_set, t_set = load_ag_news()\n",
    "        ul_set = None\n",
    "        l2id, id2l = {}, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba458c",
   "metadata": {},
   "source": [
    "### Step 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84472ba0",
   "metadata": {},
   "source": [
    "Execution Start time: 19:43:10, End time: 19:43:10 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628cc4b2",
   "metadata": {},
   "source": [
    "**Thought**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762dca2d",
   "metadata": {},
   "source": [
    "**Action ()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aa7ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thought or action not provided in the correct format. Please retry while making sure the response is correctly formatted and does not exceed 1500 tokens."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d305f81",
   "metadata": {},
   "source": [
    "### Step 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccfeee7",
   "metadata": {},
   "source": [
    "Execution Start time: 19:43:12, End time: 19:43:13 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a078f2",
   "metadata": {},
   "source": [
    "**Thought**: The call to `prepare_data` has been successfully replaced with the `load_ag_news` function. Now, I will adjust the training steps parameter to 5 in the argument parser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ab131d",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522261bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n                        choices=['uniform_m', 'sflip'],\n                        help='noise types: uniform_m: uniform noise, sflip: single-flip noise')\n    parser.add_argument('--val_fraction', type=float, default=0.1,\n                        help='if no validation set is provided, use this fraction of training set as validation set')\n\n    # training related\n    parser.add_argument('--num_epochs', type=int, default=1, help='set either num_epochs or num_training_steps')\n    parser.add_argument('--num_training_steps', type=int, default=5, help='set it to -1 if num_epochs is set')\n    parser.add_argument('--train_eval_freq', type=int, default=10,\n                        help='evaluate the model on training set after every [train_eval_freq] training steps')\n    parser.add_argument('--eval_freq', type=int, default=50,\n                        help='evaluate the model on the validation and test sets'\n                             'after every [eval_freq] training steps')\n    parser.add_argument('--fast_eval', action='store_true',"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/main.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    parser.add_argument('--num_training_steps', type=int, default=-1, help='set it to -1 if num_epochs is set')\n",
    "<<<AFTER_EDIT>>>\n",
    "    parser.add_argument('--num_training_steps', type=int, default=5, help='set it to -1 if num_epochs is set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f0ea01",
   "metadata": {},
   "source": [
    "### Step 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d68bc2",
   "metadata": {},
   "source": [
    "Execution Start time: 19:43:16, End time: 19:43:44 (duration: 28 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a963191",
   "metadata": {},
   "source": [
    "**Thought**: The `main.py` script has been successfully modified to use the `load_ag_news` function and to run for only 5 training steps. Now, I will execute the script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e14987",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ef0064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 3, in <module>\n    from utils import create_logger, save_args, create_trainer, load_config, save_config\n  File \"/content/BERT-LNL/utils.py\", line 8, in <module>\n    from trainers.bert_wn_trainer import BertWN_Trainer\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 11, in <module>\n    from trainers.loss_noise_tracker import LossNoiseTracker\n  File \"/content/BERT-LNL/trainers/loss_noise_tracker.py\", line 6, in <module>\n    import wandb\nModuleNotFoundError: No module named 'wandb'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG-NEWs --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model False --noise_level 0.2 --noise_type sflip --manualSeed 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a462bd",
   "metadata": {},
   "source": [
    "### Step 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d62656",
   "metadata": {},
   "source": [
    "Execution Start time: 19:43:46, End time: 19:44:01 (duration: 15 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e921412",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `wandb` module is missing, which is required by the script. I need to install the `wandb` package to resolve this issue and then re-run the training script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a366ceb",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fc7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting wandb\n  Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/site-packages (from wandb) (8.1.7)\nCollecting docker-pycreds>=0.4.0 (from wandb)\n  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\nCollecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/site-packages (from wandb) (4.2.2)\nRequirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/site-packages (from wandb) (5.27.1)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/site-packages (from wandb) (5.9.8)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from wandb) (2.32.3)\nCollecting sentry-sdk>=1.0.0 (from wandb)\n  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting setproctitle (from wandb)\n  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from wandb) (68.1.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nCollecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\nCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\nDownloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/9.3 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\nDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/207.3 kB ? eta -:--:--\n\n\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/309.1 kB ? eta -:--:--\n\n\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\nDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/62.7 kB ? eta -:--:--\n\n\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\nInstalling collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\nSuccessfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.7\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2188e653",
   "metadata": {},
   "source": [
    "### Step 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e75079",
   "metadata": {},
   "source": [
    "Execution Start time: 19:44:02, End time: 19:44:02 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164dc0ef",
   "metadata": {},
   "source": [
    "**Thought**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1dfba4",
   "metadata": {},
   "source": [
    "**Action ()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a17479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thought or action not provided in the correct format. Please retry while making sure the response is correctly formatted and does not exceed 1500 tokens."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1648a6b",
   "metadata": {},
   "source": [
    "### Step 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae22a2",
   "metadata": {},
   "source": [
    "Execution Start time: 19:44:06, End time: 19:44:26 (duration: 20 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7fe062",
   "metadata": {},
   "source": [
    "**Thought**: The `wandb` package has been successfully installed. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d448083",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca174200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usage: main.py [-h] [--dataset {SST-2,AG_News,TREC,IMDB,Yelp-5,Yoruba,Hausa}]\n               [--data_root DATA_ROOT] [--log_root LOG_ROOT]\n               [--trainer_name {bert_wn,bert_ct,bert_cm,bert_cmgt,bert_smoothing}]\n               [--model_name {bert-base-uncased,bert-base-cased,bert-large-uncased,bert-base-multilingual-cased}]\n               [--exp_name EXP_NAME] [--max_sen_len MAX_SEN_LEN]\n               [--special_token_offsets SPECIAL_TOKEN_OFFSETS]\n               [--truncate_mode {hybrid, last}] [--freeze_bert]\n               [--bert_dropout_rate BERT_DROPOUT_RATE]\n               [--noise_level NOISE_LEVEL] [--noise_type {uniform_m,sflip}]\n               [--val_fraction VAL_FRACTION] [--num_epochs NUM_EPOCHS]\n               [--num_training_steps NUM_TRAINING_STEPS]\n               [--train_eval_freq TRAIN_EVAL_FREQ] [--eval_freq EVAL_FREQ]\n               [--fast_eval] [--nl_batch_size NL_BATCH_SIZE]\n               [--eval_batch_size EVAL_BATCH_SIZE]\n               [--warmup_steps WARMUP_STEPS]\n               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n               [--gen_val] [--store_model STORE_MODEL]\n               [--forget_factor FORGET_FACTOR] [--T_k T_K] [--c C]\n               [--smoothing_factor SMOOTHING_FACTOR]\n               [--cm_mse_weight CM_MSE_WEIGHT] [--lr LR]\n               [--weight_decay WEIGHT_DECAY] [--exp_decay_rate EXP_DECAY_RATE]\n               [--max_grad_norm MAX_GRAD_NORM] [--patience PATIENCE]\n               [--use_cuda USE_CUDA] [--num_workers NUM_WORKERS]\n               [--cuda_device CUDA_DEVICE] [--manualSeed MANUALSEED]\n               [--noisy_label_seed NOISY_LABEL_SEED]\nmain.py: error: argument --dataset: invalid choice: 'AG-NEWs' (choose from 'SST-2', 'AG_News', 'TREC', 'IMDB', 'Yelp-5', 'Yoruba', 'Hausa')\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG-NEWs --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model False --noise_level 0.2 --noise_type sflip --manualSeed 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618f19b",
   "metadata": {},
   "source": [
    "### Step 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ced56",
   "metadata": {},
   "source": [
    "Execution Start time: 19:44:29, End time: 19:44:51 (duration: 21 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b7c95",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the dataset name 'AG-NEWs' is invalid. The correct dataset name should be 'AG_News' as per the script's argument choices. I will correct the dataset name and re-run the training script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabebb02",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a86f7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usage: main.py [-h] [--dataset {SST-2,AG_News,TREC,IMDB,Yelp-5,Yoruba,Hausa}]\n               [--data_root DATA_ROOT] [--log_root LOG_ROOT]\n               [--trainer_name {bert_wn,bert_ct,bert_cm,bert_cmgt,bert_smoothing}]\n               [--model_name {bert-base-uncased,bert-base-cased,bert-large-uncased,bert-base-multilingual-cased}]\n               [--exp_name EXP_NAME] [--max_sen_len MAX_SEN_LEN]\n               [--special_token_offsets SPECIAL_TOKEN_OFFSETS]\n               [--truncate_mode {hybrid, last}] [--freeze_bert]\n               [--bert_dropout_rate BERT_DROPOUT_RATE]\n               [--noise_level NOISE_LEVEL] [--noise_type {uniform_m,sflip}]\n               [--val_fraction VAL_FRACTION] [--num_epochs NUM_EPOCHS]\n               [--num_training_steps NUM_TRAINING_STEPS]\n               [--train_eval_freq TRAIN_EVAL_FREQ] [--eval_freq EVAL_FREQ]\n               [--fast_eval] [--nl_batch_size NL_BATCH_SIZE]\n               [--eval_batch_size EVAL_BATCH_SIZE]\n               [--warmup_steps WARMUP_STEPS]\n               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n               [--gen_val] [--store_model STORE_MODEL]\n               [--forget_factor FORGET_FACTOR] [--T_k T_K] [--c C]\n               [--smoothing_factor SMOOTHING_FACTOR]\n               [--cm_mse_weight CM_MSE_WEIGHT] [--lr LR]\n               [--weight_decay WEIGHT_DECAY] [--exp_decay_rate EXP_DECAY_RATE]\n               [--max_grad_norm MAX_GRAD_NORM] [--patience PATIENCE]\n               [--use_cuda USE_CUDA] [--num_workers NUM_WORKERS]\n               [--cuda_device CUDA_DEVICE] [--manualSeed MANUALSEED]\n               [--noisy_label_seed NOISY_LABEL_SEED]\nmain.py: error: argument --store_model: invalid int value: 'False'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model False --noise_level 0.2 --noise_type sflip --manualSeed 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339451b2",
   "metadata": {},
   "source": [
    "### Step 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8521be",
   "metadata": {},
   "source": [
    "Execution Start time: 19:44:54, End time: 19:45:20 (duration: 26 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5220f3bd",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `--store_model` argument expects an integer value, not a boolean. I will change the `--store_model` argument to `0` (which typically represents `False` in command-line arguments) and re-run the training script. Additionally, I will ensure that all other arguments are correctly specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ad63a",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7839ccf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_45_16_sflip_nle0.2_nlb32\nINFO loading AG_News...\n\nDownloading readme:   0%|                           | 0.00/8.07k [00:00<?, ?B/s]\nDownloading readme: 100%|███████████████████| 8.07k/8.07k [00:00<00:00, 192kB/s]\n\nDownloading data:   0%|                             | 0.00/18.6M [00:00<?, ?B/s]\n\n\n\n\nDownloading data:   0%|                             | 0.00/1.23M [00:00<?, ?B/s]\n\n\nGenerating train split:   0%|                 | 0/120000 [00:00<?, ? examples/s]\nGenerating train split:  20%|▏| 24000/120000 [00:00<00:00, 185479.59 examples/s]\nGenerating train split:  49%|▍| 59000/120000 [00:00<00:00, 267657.56 examples/s]\nGenerating train split:  84%|▊| 101000/120000 [00:00<00:00, 322704.71 examples/s\nGenerating train split: 100%|█| 120000/120000 [00:00<00:00, 311126.68 examples/s\n\nGenerating test split:   0%|                    | 0/7600 [00:00<?, ? examples/s]\nGenerating test split: 100%|█████| 7600/7600 [00:00<00:00, 229742.06 examples/s]\nTraceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 165, in <module>\n    main()\n  File \"/content/BERT-LNL/main.py\", line 145, in main\n    nl_set, v_set, t_set = load_ag_news()\n  File \"/content/BERT-LNL/load_ag_news.py\", line 12, in load_ag_news\n    val_data = dataset['validation'].select(val_indices)\n  File \"/usr/local/lib/python3.10/site-packages/datasets/dataset_dict.py\", line 75, in __getitem__\n    return super().__getitem__(k)\nKeyError: 'validation'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea5f88",
   "metadata": {},
   "source": [
    "### Step 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639b658",
   "metadata": {},
   "source": [
    "Execution Start time: 19:45:23, End time: 19:45:24 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903ead7",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that there is no 'validation' split in the AG-News dataset. I need to adjust the `load_ag_news.py` script to handle this by using a different split for validation, such as splitting the train set manually. I will modify the script to select validation indices from the train set instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db098d6b",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634a707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    dataset = load_dataset('ag_news')\n    train_indices = [1,2,3,4,5,6,100,101,102,103,104,105,451,452,453,454,455,456,501,502,503,504,505,506]\n    test_indices = [1,2,3,101,103,452,455,501,502,503,504,505]\n    val_indices = [0,1,2,6,7,8,12,13,14,18,19,20]\n\n    train_data = dataset['train'].select(train_indices)\n    test_data = dataset['test'].select(test_indices)\n    val_data = dataset['train'].select(val_indices)\n\n    return train_data, test_data, val_data\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    val_data = dataset['validation'].select(val_indices)\n",
    "<<<AFTER_EDIT>>>\n",
    "    val_data = dataset['train'].select(val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f899be",
   "metadata": {},
   "source": [
    "### Step 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ca1201",
   "metadata": {},
   "source": [
    "Execution Start time: 19:45:27, End time: 19:45:55 (duration: 28 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3207bf59",
   "metadata": {},
   "source": [
    "**Thought**: The `load_ag_news.py` script has been successfully modified to select validation indices from the train set. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1e67a",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135154e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_45_40_sflip_nle0.2_nlb32\nINFO loading AG_News...\nINFO Bert WN Trainer: training started\nINFO training size: 24\nINFO validation size: 12\nINFO test size: 12\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n\nconfig.json:   0%|                                    | 0.00/570 [00:00<?, ?B/s]\n\n\nmodel.safetensors:   0%|                             | 0.00/440M [00:00<?, ?B/s]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nINFO Validation set is used here\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 165, in <module>\n    main()\n  File \"/content/BERT-LNL/main.py\", line 160, in main\n    trainer.train(args, logger, (nl_set, ul_set, v_set, t_set, l2id, id2l))\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 74, in train\n    loss_noise_tracker = LossNoiseTracker(args, logger, nl_set, noise_tracker_dir)\n  File \"/content/BERT-LNL/trainers/loss_noise_tracker.py\", line 16, in __init__\n    self.purity_list = np.array(self.d_set.purity_list.detach().numpy(), dtype=bool)\nAttributeError: 'Dataset' object has no attribute 'purity_list'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde99c4",
   "metadata": {},
   "source": [
    "### Step 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5368e67",
   "metadata": {},
   "source": [
    "Execution Start time: 19:45:57, End time: 19:45:59 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b630d5",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `Dataset` object does not have an attribute `purity_list`, which is likely expected by the `LossNoiseTracker` class. This suggests that the dataset or the way it is being used in the script might not be compatible with the current implementation. I need to investigate the `LossNoiseTracker` class to understand how it expects the dataset to be structured and make necessary adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b98742d",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372fcbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import numpy as np\nimport torch\nimport pickle\nimport copy\nimport os\nimport wandb\n\n\nclass LossNoiseTracker:\n    \"\"\"Track the losses during training and check whether samples with lower losses are cleaner\"\"\"\n\n    def __init__(self, args, logger, d_set, save_dir, **kwargs):\n        self.args = args\n        self.logger = logger\n        self.d_set = d_set\n        self.purity_list = np.array(self.d_set.purity_list.detach().numpy(), dtype=bool)\n        self.d_loader = torch.utils.data.DataLoader(d_set, batch_size=args.eval_batch_size,\n                                                shuffle=False,\n                                                num_workers=0)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n        self.save_dir = save_dir\n        self.save_path = os.path.join(self.save_dir, 'noise_distribution.pickle')\n        self.steps = []\n        self.loss_on_clean_samples_hist=[]\n        self.loss_on_wrong_samples_hist=[]\n\n    def skip_function(self):\n        if self.args.noise_level == 0.0:  # data is clean, no need to track the noise\n            return True\n        else:\n            return False\n\n    def normalize_data(self, data):\n        min_value = np.min(data)\n        max_value = np.max(data)\n\n        return (data - min_value) / (max_value - min_value)\n\n    def log_loss(self, model, global_step, device):\n        if self.skip_function():\n            return\n        loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n        loss_list = []\n        self.steps.append(global_step)\n\n        with torch.no_grad():\n            for idx, d_batch in enumerate(self.d_loader):\n\n                input_ids = d_batch['input_ids'].to(device)\n                attention_mask = d_batch['attention_mask'].to(device)\n                n_labels = d_batch['n_labels'].to(device)\n\n                y_pred = model(input_ids, attention_mask)['logits']\n\n                loss_batch = loss_fn(y_pred, n_labels).detach().cpu().numpy()\n                loss_list.append(loss_batch)\n\n        loss_list = np.concatenate(loss_list)\n        loss_on_clean_samples = loss_list[self.purity_list]\n        loss_on_wrong_samples = loss_list[~self.purity_list]\n\n        self.loss_on_clean_samples_hist.append(loss_on_clean_samples)\n        self.loss_on_wrong_samples_hist.append(loss_on_wrong_samples)\n\n    def save_logged_information(self):\n        if self.skip_function():\n            return\n\n        save_dict = {'steps': self.steps, 'loss_on_clean': self.loss_on_clean_samples_hist, 'loss_on_wrong': self.loss_on_wrong_samples_hist}\n        with open(self.save_path, 'wb') as handle:\n            pickle.dump(save_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\n\n    def log_last_histogram_to_wandb(self, step, normalize, tag):\n        if self.skip_function():\n            return\n\n        loss_clean = self.loss_on_clean_samples_hist[-1]\n        loss_wrong = self.loss_on_wrong_samples_hist[-1]\n\n        if normalize:\n            loss_clean = self.normalize_data(loss_clean)\n            loss_wrong = self.normalize_data(loss_wrong)\n\n        wandb.log({f\"{tag}/loss_clean\" : wandb.Histogram(loss_clean),\n                   f\"{tag}/loss_wrong\": wandb.Histogram(loss_wrong)}, step=step)\n\n\n\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!cat BERT-LNL/trainers/loss_noise_tracker.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a595d",
   "metadata": {},
   "source": [
    "### Step 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d8243a",
   "metadata": {},
   "source": [
    "Execution Start time: 19:46:03, End time: 19:46:05 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c69f9",
   "metadata": {},
   "source": [
    "**Thought**: The `LossNoiseTracker` class expects the dataset to have a `purity_list` attribute, which is not present in the Hugging Face dataset. This attribute is likely used to track which samples are clean or noisy. I need to modify the dataset to include this attribute or adjust the `LossNoiseTracker` class to handle datasets without it. Since the task involves using label noise, I will add a `purity_list` attribute to the dataset indicating all samples as noisy for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9737ca",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849f55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    test_indices = [1,2,3,101,103,452,455,501,502,503,504,505]\n    val_indices = [0,1,2,6,7,8,12,13,14,18,19,20]\n\n    train_data = dataset['train'].select(train_indices)\n    test_data = dataset['test'].select(test_indices)\n    val_data = dataset['train'].select(val_indices)\n\n    # Add a purity_list attribute to indicate all samples as noisy (False)\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n\n    return train_data, test_data, val_data\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    return train_data, test_data, val_data\n",
    "<<<AFTER_EDIT>>>\n",
    "    # Add a purity_list attribute to indicate all samples as noisy (False)\n",
    "    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n",
    "    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n",
    "    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n",
    "\n",
    "    return train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9891b4",
   "metadata": {},
   "source": [
    "### Step 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fdde26",
   "metadata": {},
   "source": [
    "Execution Start time: 19:46:08, End time: 19:46:35 (duration: 27 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d393cce5",
   "metadata": {},
   "source": [
    "**Thought**: The `load_ag_news.py` script has been successfully modified to add a `purity_list` attribute to the dataset, indicating all samples as noisy. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8dbd2",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d143344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_46_27_sflip_nle0.2_nlb32\nINFO loading AG_News...\n\nFlattening the indices:   0%|                     | 0/24 [00:00<?, ? examples/s]\nFlattening the indices: 100%|██████████| 24/24 [00:00<00:00, 1248.40 examples/s]\n\nFlattening the indices:   0%|                     | 0/12 [00:00<?, ? examples/s]\nFlattening the indices: 100%|███████████| 12/12 [00:00<00:00, 621.67 examples/s]\n\nFlattening the indices:   0%|                     | 0/12 [00:00<?, ? examples/s]\nFlattening the indices: 100%|███████████| 12/12 [00:00<00:00, 926.49 examples/s]\nINFO Bert WN Trainer: training started\nINFO training size: 24\nINFO validation size: 12\nINFO test size: 12\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nINFO Validation set is used here\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 165, in <module>\n    main()\n  File \"/content/BERT-LNL/main.py\", line 160, in main\n    trainer.train(args, logger, (nl_set, ul_set, v_set, t_set, l2id, id2l))\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 74, in train\n    loss_noise_tracker = LossNoiseTracker(args, logger, nl_set, noise_tracker_dir)\n  File \"/content/BERT-LNL/trainers/loss_noise_tracker.py\", line 16, in __init__\n    self.purity_list = np.array(self.d_set.purity_list.detach().numpy(), dtype=bool)\nAttributeError: 'Dataset' object has no attribute 'purity_list'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c93dc",
   "metadata": {},
   "source": [
    "### Step 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b836c18",
   "metadata": {},
   "source": [
    "Execution Start time: 19:46:39, End time: 19:46:40 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc5555",
   "metadata": {},
   "source": [
    "**Thought**: The error persists because the `purity_list` attribute is not being recognized as part of the dataset. This suggests that the attribute might not be accessible in the way the `LossNoiseTracker` class expects. Instead of adding the attribute directly to the dataset, I should modify the `LossNoiseTracker` class to handle datasets without this attribute. I will update the `LossNoiseTracker` class to bypass the use of `purity_list` for now, allowing the training to proceed without it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc9dca",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60229e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Could not find the following lines to replace in the file content:\n```\nself.purity_list = np.array(self.d_set.purity_list.detach().numpy(), dtype=bool)\n```\nDid you mean to replace the following lines (notice leading/trailing whitespaces difference)?\n```\n        self.purity_list = np.array(self.d_set.purity_list.detach().numpy(), dtype=bool)\n```"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/trainers/loss_noise_tracker.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "self.purity_list = np.array(self.d_set.purity_list.detach().numpy(), dtype=bool)\n",
    "<<<AFTER_EDIT>>>\n",
    "self.purity_list = np.array([False] * len(self.d_set), dtype=bool)  # Assume all samples are noisy for simplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d6c1d",
   "metadata": {},
   "source": [
    "### Step 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c27356",
   "metadata": {},
   "source": [
    "Execution Start time: 19:46:43, End time: 19:46:48 (duration: 5 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815646e7",
   "metadata": {},
   "source": [
    "**Thought**: The error occurred because the line I attempted to replace had leading whitespace. I will correct the indentation and try editing the `LossNoiseTracker` class again to bypass the use of `purity_list` by assuming all samples are noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8f0d7",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec04e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\nclass LossNoiseTracker:\n    \"\"\"Track the losses during training and check whether samples with lower losses are cleaner\"\"\"\n\n    def __init__(self, args, logger, d_set, save_dir, **kwargs):\n        self.args = args\n        self.logger = logger\n        self.d_set = d_set\n        self.purity_list = np.array([False] * len(self.d_set), dtype=bool)  # Assume all samples are noisy for simplicity\n        self.d_loader = torch.utils.data.DataLoader(d_set, batch_size=args.eval_batch_size,\n                                                shuffle=False,\n                                                num_workers=0)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/trainers/loss_noise_tracker.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "        self.purity_list = np.array(self.d_set.purity_list.detach().numpy(), dtype=bool)\n",
    "<<<AFTER_EDIT>>>\n",
    "        self.purity_list = np.array([False] * len(self.d_set), dtype=bool)  # Assume all samples are noisy for simplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f8b4a",
   "metadata": {},
   "source": [
    "### Step 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36059c96",
   "metadata": {},
   "source": [
    "Execution Start time: 19:46:49, End time: 19:46:49 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda24388",
   "metadata": {},
   "source": [
    "**Thought**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991f083",
   "metadata": {},
   "source": [
    "**Action ()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7173a46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thought or action not provided in the correct format. Please retry while making sure the response is correctly formatted and does not exceed 1500 tokens."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41027248",
   "metadata": {},
   "source": [
    "### Step 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57acc35",
   "metadata": {},
   "source": [
    "Execution Start time: 19:46:53, End time: 19:47:21 (duration: 28 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb853189",
   "metadata": {},
   "source": [
    "**Thought**: The `LossNoiseTracker` class has been successfully modified to assume all samples are noisy, bypassing the need for a `purity_list` attribute. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d799e2",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f562365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_47_14_sflip_nle0.2_nlb32\nINFO loading AG_News...\nINFO Bert WN Trainer: training started\nINFO training size: 24\nINFO validation size: 12\nINFO test size: 12\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nINFO Validation set is used here\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\n[Vannilla Trainer] training:   0%|                        | 0/5 [00:00<?, ?it/s]\n[Vannilla Trainer] training:   0%|                        | 0/5 [00:00<?, ?it/s]\nTraceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 165, in <module>\n    main()\n  File \"/content/BERT-LNL/main.py\", line 160, in main\n    trainer.train(args, logger, (nl_set, ul_set, v_set, t_set, l2id, id2l))\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 91, in train\n    self.forward_backward_noisy_batch(model, {'nl_batch': nl_batch}, ce_loss_fn, args, device)\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 140, in forward_backward_noisy_batch\n    input_ids = nl_databatch['input_ids']\nKeyError: 'input_ids'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744740e1",
   "metadata": {},
   "source": [
    "### Step 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd504e28",
   "metadata": {},
   "source": [
    "Execution Start time: 19:47:26, End time: 19:47:26 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7d30b",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `input_ids` key is missing from the `nl_databatch`. This suggests that the dataset is not being tokenized correctly before being passed to the model. I need to ensure that the dataset is tokenized using a BERT tokenizer before training. I will modify the `load_ag_news.py` script to tokenize the dataset using the `bert-base-uncased` tokenizer from the Hugging Face Transformers library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857e90ac",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887f777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Found multiple BEFORE_EDIT in the patch. Line 6: <<<BEFORE_EDIT>>>\nFormat of edit is:```\n{filename}\n[optional] preceding lines\n<<<BEFORE_EDIT>>>\nline to remove\nline to remove\n<<<AFTER_EDIT>>>\nline to add\nline to add\nline to add\n```"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "from datasets import load_dataset\n",
    "<<<AFTER_EDIT>>>\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer\n",
    "<<<BEFORE_EDIT>>>\n",
    "    # Add a purity_list attribute to indicate all samples as noisy (False)\n",
    "<<<AFTER_EDIT>>>\n",
    "    # Tokenize the dataset\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n",
    "    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n",
    "    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef7d53",
   "metadata": {},
   "source": [
    "### Step 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5629298b",
   "metadata": {},
   "source": [
    "Execution Start time: 19:47:28, End time: 19:47:30 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12751b62",
   "metadata": {},
   "source": [
    "**Thought**: The edit attempt failed due to multiple `BEFORE_EDIT` markers. I will make the edits one at a time to ensure each change is applied correctly. First, I will import the `BertTokenizer` from the Hugging Face Transformers library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93410c42",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb7f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n\nfrom datasets import load_dataset\nfrom transformers import BertTokenizer\n\ndef load_ag_news():\n    dataset = load_dataset('ag_news')\n    train_indices = [1,2,3,4,5,6,100,101,102,103,104,105,451,452,453,454,455,456,501,502,503,504,505,506]\n    test_indices = [1,2,3,101,103,452,455,501,502,503,504,505]\n    val_indices = [0,1,2,6,7,8,12,13,14,18,19,20]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "from datasets import load_dataset\n",
    "<<<AFTER_EDIT>>>\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a8b8e9",
   "metadata": {},
   "source": [
    "### Step 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b4cb46",
   "metadata": {},
   "source": [
    "Execution Start time: 19:47:35, End time: 19:47:37 (duration: 2 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1101cc6",
   "metadata": {},
   "source": [
    "**Thought**: The `BertTokenizer` has been successfully imported. Now, I will modify the `load_ag_news.py` script to tokenize the dataset using the `bert-base-uncased` tokenizer before returning the data splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479fbc3",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb4643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    test_indices = [1,2,3,101,103,452,455,501,502,503,504,505]\n    val_indices = [0,1,2,6,7,8,12,13,14,18,19,20]\n\n    train_data = dataset['train'].select(train_indices)\n    test_data = dataset['test'].select(test_indices)\n    val_data = dataset['train'].select(val_indices)\n\n    # Tokenize the dataset\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n\n    return train_data, test_data, val_data\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    # Add a purity_list attribute to indicate all samples as noisy (False)\n",
    "<<<AFTER_EDIT>>>\n",
    "    # Tokenize the dataset\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n",
    "    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n",
    "    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d7e8a",
   "metadata": {},
   "source": [
    "### Step 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430fafc",
   "metadata": {},
   "source": [
    "Execution Start time: 19:47:41, End time: 19:48:01 (duration: 20 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5279b7a",
   "metadata": {},
   "source": [
    "**Thought**: The `load_ag_news.py` script has been successfully modified to tokenize the dataset using the `bert-base-uncased` tokenizer. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0864d",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a9a7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_47_52_sflip_nle0.2_nlb32\nINFO loading AG_News...\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n\ntokenizer_config.json:   0%|                         | 0.00/48.0 [00:00<?, ?B/s]\ntokenizer_config.json: 100%|██████████████████| 48.0/48.0 [00:00<00:00, 265kB/s]\n\nvocab.txt:   0%|                                     | 0.00/232k [00:00<?, ?B/s]\n\n\ntokenizer.json:   0%|                                | 0.00/466k [00:00<?, ?B/s]\n\n\nMap:   0%|                                        | 0/24 [00:00<?, ? examples/s]\nMap: 100%|██████████████████████████████| 24/24 [00:00<00:00, 587.78 examples/s]\n\nMap:   0%|                                        | 0/12 [00:00<?, ? examples/s]\nMap: 100%|██████████████████████████████| 12/12 [00:00<00:00, 614.07 examples/s]\n\nMap:   0%|                                        | 0/12 [00:00<?, ? examples/s]\nMap: 100%|██████████████████████████████| 12/12 [00:00<00:00, 637.21 examples/s]\nINFO Bert WN Trainer: training started\nINFO training size: 24\nINFO validation size: 12\nINFO test size: 12\nINFO Validation set is used here\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\n[Vannilla Trainer] training:   0%|                        | 0/5 [00:00<?, ?it/s]\n[Vannilla Trainer] training:   0%|                        | 0/5 [00:00<?, ?it/s]\nTraceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 165, in <module>\n    main()\n  File \"/content/BERT-LNL/main.py\", line 160, in main\n    trainer.train(args, logger, (nl_set, ul_set, v_set, t_set, l2id, id2l))\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 91, in train\n    self.forward_backward_noisy_batch(model, {'nl_batch': nl_batch}, ce_loss_fn, args, device)\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 142, in forward_backward_noisy_batch\n    n_labels = nl_databatch['n_labels']\nKeyError: 'n_labels'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8070494a",
   "metadata": {},
   "source": [
    "### Step 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e888d",
   "metadata": {},
   "source": [
    "Execution Start time: 19:48:02, End time: 19:48:02 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e34e5c",
   "metadata": {},
   "source": [
    "**Thought**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c0e79",
   "metadata": {},
   "source": [
    "**Action ()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c4c5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thought or action not provided in the correct format. Please retry while making sure the response is correctly formatted and does not exceed 1500 tokens."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8031a688",
   "metadata": {},
   "source": [
    "### Step 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d5429",
   "metadata": {},
   "source": [
    "Execution Start time: 19:48:07, End time: 19:48:11 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775433d1",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `n_labels` key is missing from the `nl_databatch`. This suggests that the dataset is not being prepared with the necessary labels for training. I need to ensure that the dataset includes the labels in the format expected by the training script. I will modify the `load_ag_news.py` script to include the labels in the dataset before returning the data splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df08e3",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d0248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n\n    train_data = dataset['train'].select(train_indices)\n    test_data = dataset['test'].select(test_indices)\n    val_data = dataset['train'].select(val_indices)\n\n    # Tokenize the dataset\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    train_data = train_data.rename_column(\"label\", \"n_labels\")\n    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    test_data = test_data.rename_column(\"label\", \"n_labels\")\n    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    val_data = val_data.rename_column(\"label\", \"n_labels\")\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n\n    return train_data, test_data, val_data\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n",
    "    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n",
    "    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n",
    "<<<AFTER_EDIT>>>\n",
    "    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n",
    "    train_data = train_data.rename_column(\"label\", \"n_labels\")\n",
    "    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n",
    "    test_data = test_data.rename_column(\"label\", \"n_labels\")\n",
    "    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n",
    "    val_data = val_data.rename_column(\"label\", \"n_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbed6d9",
   "metadata": {},
   "source": [
    "### Step 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b0115",
   "metadata": {},
   "source": [
    "Execution Start time: 19:48:17, End time: 19:48:59 (duration: 42 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0021d52",
   "metadata": {},
   "source": [
    "**Thought**: The `load_ag_news.py` script has been successfully modified to include the labels in the dataset under the key `n_labels`, which is expected by the training script. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a6a7d9",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22b4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_48_45_sflip_nle0.2_nlb32\nINFO loading AG_News...\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nINFO Bert WN Trainer: training started\nINFO training size: 24\nINFO validation size: 12\nINFO test size: 12\nINFO Validation set is used here\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\n[Vannilla Trainer] training:   0%|                        | 0/5 [00:00<?, ?it/s]\n[Vannilla Trainer] training:   0%|                        | 0/5 [00:00<?, ?it/s]\nTraceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 165, in <module>\n    main()\n  File \"/content/BERT-LNL/main.py\", line 160, in main\n    trainer.train(args, logger, (nl_set, ul_set, v_set, t_set, l2id, id2l))\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 91, in train\n    self.forward_backward_noisy_batch(model, {'nl_batch': nl_batch}, ce_loss_fn, args, device)\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 143, in forward_backward_noisy_batch\n    input_ids = input_ids.to(device)\nAttributeError: 'list' object has no attribute 'to'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9edc04e",
   "metadata": {},
   "source": [
    "### Step 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5cc63b",
   "metadata": {},
   "source": [
    "Execution Start time: 19:49:05, End time: 19:49:05 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80148738",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `input_ids` are being treated as a list instead of a tensor, which is required for moving data to the device (e.g., GPU). This suggests that the tokenization process might not be returning the data in the expected format. I need to ensure that the tokenized data is returned as PyTorch tensors. I will modify the `load_ag_news.py` script to set the format of the dataset to return PyTorch tensors after tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a58c03",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1405e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Found multiple BEFORE_EDIT in the patch. Line 6: <<<BEFORE_EDIT>>>\nFormat of edit is:```\n{filename}\n[optional] preceding lines\n<<<BEFORE_EDIT>>>\nline to remove\nline to remove\n<<<AFTER_EDIT>>>\nline to add\nline to add\nline to add\n```"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    train_data = train_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    train_data = train_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<BEFORE_EDIT>>>\n",
    "    test_data = test_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    test_data = test_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<BEFORE_EDIT>>>\n",
    "    val_data = val_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    val_data = val_data.rename_column(\"label\", \"n_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae94a8",
   "metadata": {},
   "source": [
    "### Step 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a440082",
   "metadata": {},
   "source": [
    "Execution Start time: 19:49:07, End time: 19:49:18 (duration: 11 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600e412a",
   "metadata": {},
   "source": [
    "**Thought**: The edit attempt failed due to multiple `BEFORE_EDIT` markers. I will make the edits one at a time to ensure each change is applied correctly. First, I will set the format of the train dataset to return PyTorch tensors after tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70fd92",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb1d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    train_data = dataset['train'].select(train_indices)\n    test_data = dataset['test'].select(test_indices)\n    val_data = dataset['train'].select(val_indices)\n\n    # Tokenize the dataset\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    train_data = train_data.rename_column(\"label\", \"n_labels\")\n    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    test_data = test_data.rename_column(\"label\", \"n_labels\")\n    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    val_data = val_data.rename_column(\"label\", \"n_labels\")\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    train_data = train_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    train_data = train_data.rename_column(\"label\", \"n_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da3fb2e",
   "metadata": {},
   "source": [
    "### Step 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97d37e",
   "metadata": {},
   "source": [
    "Execution Start time: 19:49:22, End time: 19:49:24 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca0faf",
   "metadata": {},
   "source": [
    "**Thought**: The format of the train dataset has been successfully set to return PyTorch tensors. Now, I will set the format for the test and validation datasets as well to ensure they are returned as PyTorch tensors. This will help avoid the `AttributeError` when moving data to the device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac09f9c",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac8493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n\n    # Tokenize the dataset\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    train_data = train_data.rename_column(\"label\", \"n_labels\")\n    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    test_data = test_data.rename_column(\"label\", \"n_labels\")\n    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    val_data = val_data.rename_column(\"label\", \"n_labels\")\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    test_data = test_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    test_data = test_data.rename_column(\"label\", \"n_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9eb4b4",
   "metadata": {},
   "source": [
    "### Step 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f8319",
   "metadata": {},
   "source": [
    "Execution Start time: 19:49:27, End time: 19:49:32 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48349b7",
   "metadata": {},
   "source": [
    "**Thought**: The format of the test dataset has been successfully set to return PyTorch tensors. Now, I will set the format for the validation dataset as well to ensure it is returned as PyTorch tensors. This will help avoid the `AttributeError` when moving data to the device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a7247",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3ac64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    train_data = train_data.rename_column(\"label\", \"n_labels\")\n    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    test_data = test_data.rename_column(\"label\", \"n_labels\")\n    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    val_data = val_data.rename_column(\"label\", \"n_labels\")\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n\n    return train_data, test_data, val_data\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    val_data = val_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    val_data = val_data.rename_column(\"label\", \"n_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002cdc8e",
   "metadata": {},
   "source": [
    "### Step 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181954e5",
   "metadata": {},
   "source": [
    "Execution Start time: 19:49:39, End time: 19:50:21 (duration: 42 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144839e2",
   "metadata": {},
   "source": [
    "**Thought**: The format of the validation dataset has been successfully set to return PyTorch tensors. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics. This should resolve the previous `AttributeError` related to the `input_ids`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9d138",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8b3f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_50_18_sflip_nle0.2_nlb32\nINFO loading AG_News...\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 165, in <module>\n    main()\n  File \"/content/BERT-LNL/main.py\", line 145, in main\n    nl_set, v_set, t_set = load_ag_news()\n  File \"/content/BERT-LNL/load_ag_news.py\", line 18, in load_ag_news\n    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n  File \"/usr/local/lib/python3.10/site-packages/datasets/fingerprint.py\", line 482, in wrapper\n    out = func(dataset, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/datasets/arrow_dataset.py\", line 2602, in set_format\n    raise ValueError(\nValueError: Columns ['n_labels'] not in the dataset. Current columns in the dataset: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask']\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf350092",
   "metadata": {},
   "source": [
    "### Step 44"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75765a",
   "metadata": {},
   "source": [
    "Execution Start time: 19:50:28, End time: 19:50:28 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1871f63",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the column `n_labels` is not present in the dataset, which is causing the `set_format` function to fail. This happened because I attempted to rename the column before setting the format. I need to first rename the `label` column to `n_labels` and then set the format to include `n_labels`. I will correct this order in the `load_ag_news.py` script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82199af",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba64d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Found multiple BEFORE_EDIT in the patch. Line 7: <<<BEFORE_EDIT>>>\nFormat of edit is:```\n{filename}\n[optional] preceding lines\n<<<BEFORE_EDIT>>>\nline to remove\nline to remove\n<<<AFTER_EDIT>>>\nline to add\nline to add\nline to add\n```"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    train_data = train_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    train_data = train_data.rename_column(\"label\", \"n_labels\")\n",
    "    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "<<<BEFORE_EDIT>>>\n",
    "    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    test_data = test_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    test_data = test_data.rename_column(\"label\", \"n_labels\")\n",
    "    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "<<<BEFORE_EDIT>>>\n",
    "    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    val_data = val_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    val_data = val_data.rename_column(\"label\", \"n_labels\")\n",
    "    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d45b24b",
   "metadata": {},
   "source": [
    "### Step 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91687456",
   "metadata": {},
   "source": [
    "Execution Start time: 19:50:32, End time: 19:50:35 (duration: 2 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00870d",
   "metadata": {},
   "source": [
    "**Thought**: The edit attempt failed due to multiple `BEFORE_EDIT` markers. I will make the edits one at a time to ensure each change is applied correctly. First, I will correct the order for the train dataset by renaming the `label` column to `n_labels` before setting the format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57b2efb",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df3b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    train_data = dataset['train'].select(train_indices)\n    test_data = dataset['test'].select(test_indices)\n    val_data = dataset['train'].select(val_indices)\n\n    # Tokenize the dataset\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    train_data = train_data.rename_column(\"label\", \"n_labels\")\n    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    test_data = test_data.rename_column(\"label\", \"n_labels\")\n    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    val_data = val_data.rename_column(\"label\", \"n_labels\")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    train_data = train_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    train_data = train_data.rename_column(\"label\", \"n_labels\")\n",
    "    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa84a7d",
   "metadata": {},
   "source": [
    "### Step 46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723dfb00",
   "metadata": {},
   "source": [
    "Execution Start time: 19:50:38, End time: 19:50:43 (duration: 5 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9cc95",
   "metadata": {},
   "source": [
    "**Thought**: The order for the train dataset has been corrected by renaming the `label` column to `n_labels` before setting the format. Now, I will correct the order for the test and validation datasets as well by ensuring the `label` column is renamed before setting the format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6960b8b0",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a7a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n\n    # Tokenize the dataset\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    train_data = train_data.rename_column(\"label\", \"n_labels\")\n    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    test_data = test_data.rename_column(\"label\", \"n_labels\")\n    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    val_data = val_data.rename_column(\"label\", \"n_labels\")\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    test_data = test_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    test_data = test_data.rename_column(\"label\", \"n_labels\")\n",
    "    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ee74d",
   "metadata": {},
   "source": [
    "### Step 47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e8959b",
   "metadata": {},
   "source": [
    "Execution Start time: 19:50:47, End time: 19:50:49 (duration: 2 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d17a3",
   "metadata": {},
   "source": [
    "**Thought**: The order for the test dataset has been corrected by renaming the `label` column to `n_labels` before setting the format. Now, I will correct the order for the validation dataset as well by ensuring the `label` column is renamed before setting the format. This should resolve the previous `ValueError` related to the missing `n_labels` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244ab713",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a096ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    train_data = train_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    train_data = train_data.rename_column(\"label\", \"n_labels\")\n    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    test_data = test_data.rename_column(\"label\", \"n_labels\")\n    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    val_data = val_data.rename_column(\"label\", \"n_labels\")\n    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n\n    return train_data, test_data, val_data\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n",
    "    val_data = val_data.rename_column(\"label\", \"n_labels\")\n",
    "<<<AFTER_EDIT>>>\n",
    "    val_data = val_data.rename_column(\"label\", \"n_labels\")\n",
    "    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a5f82",
   "metadata": {},
   "source": [
    "### Step 48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acdea83",
   "metadata": {},
   "source": [
    "Execution Start time: 19:50:54, End time: 19:52:40 (duration: 105 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde064c",
   "metadata": {},
   "source": [
    "**Thought**: The `load_ag_news.py` script has been successfully modified to rename the `label` column to `n_labels` before setting the format to return PyTorch tensors. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics. This should resolve the previous `ValueError` related to the missing `n_labels` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad39c6e",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26a215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_51_13_sflip_nle0.2_nlb32\nINFO loading AG_News...\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nINFO Bert WN Trainer: training started\nINFO training size: 24\nINFO validation size: 12\nINFO test size: 12\nINFO Validation set is used here\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\n[Vannilla Trainer] training:   0%|                        | 0/5 [00:00<?, ?it/s]\n[Vannilla Trainer] training:  20%|███▏            | 1/5 [00:23<01:34, 23.63s/it]\n[Vannilla Trainer] training:  40%|██████▍         | 2/5 [00:38<00:55, 18.34s/it]\n[Vannilla Trainer] training:  60%|█████████▌      | 3/5 [00:50<00:31, 15.69s/it]\n[Vannilla Trainer] training:  80%|████████████▊   | 4/5 [01:02<00:14, 14.20s/it]\n[Vannilla Trainer] training: 100%|████████████████| 5/5 [01:14<00:00, 13.21s/it]\n[Vannilla Trainer] training: 100%|████████████████| 5/5 [01:14<00:00, 14.84s/it]\nTraceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 165, in <module>\n    main()\n  File \"/content/BERT-LNL/main.py\", line 160, in main\n    trainer.train(args, logger, (nl_set, ul_set, v_set, t_set, l2id, id2l))\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 120, in train\n    if args.save_loss_tracker_information:\nAttributeError: 'Namespace' object has no attribute 'save_loss_tracker_information'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25af857d",
   "metadata": {},
   "source": [
    "### Step 49"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4a7a2",
   "metadata": {},
   "source": [
    "Execution Start time: 19:52:45, End time: 19:52:47 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf022ec",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `save_loss_tracker_information` attribute is missing from the `args` object. This suggests that the script expects this argument to be provided, but it is not included in the command-line arguments. I will add this argument to the script with a default value to bypass this error and allow the training to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7fa808",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d10c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n                        choices=['uniform_m', 'sflip'],\n                        help='noise types: uniform_m: uniform noise, sflip: single-flip noise')\n    parser.add_argument('--val_fraction', type=float, default=0.1,\n                        help='if no validation set is provided, use this fraction of training set as validation set')\n\n    # training related\n    parser.add_argument('--num_epochs', type=int, default=1, help='set either num_epochs or num_training_steps')\n    parser.add_argument('--num_training_steps', type=int, default=5, help='set it to -1 if num_epochs is set')\n    parser.add_argument('--save_loss_tracker_information', action='store_true', help='Save loss tracker information')\n    parser.add_argument('--train_eval_freq', type=int, default=10,\n                        help='evaluate the model on training set after every [train_eval_freq] training steps')\n    parser.add_argument('--eval_freq', type=int, default=50,\n                        help='evaluate the model on the validation and test sets'\n                             'after every [eval_freq] training steps')\n    parser.add_argument('--fast_eval', action='store_true',"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/main.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    parser.add_argument('--num_training_steps', type=int, default=5, help='set it to -1 if num_epochs is set')\n",
    "<<<AFTER_EDIT>>>\n",
    "    parser.add_argument('--num_training_steps', type=int, default=5, help='set it to -1 if num_epochs is set')\n",
    "    parser.add_argument('--save_loss_tracker_information', action='store_true', help='Save loss tracker information')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a6396",
   "metadata": {},
   "source": [
    "### Step 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1439d1a0",
   "metadata": {},
   "source": [
    "Execution Start time: 19:52:51, End time: 19:54:19 (duration: 88 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771999f8",
   "metadata": {},
   "source": [
    "**Thought**: The `main.py` script has been successfully modified to include the `--save_loss_tracker_information` argument. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics. This should resolve the previous `AttributeError` related to the missing `save_loss_tracker_information` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ee1e7",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a14d1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_53_11_sflip_nle0.2_nlb32\nINFO loading AG_News...\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nINFO Bert WN Trainer: training started\nINFO training size: 24\nINFO validation size: 12\nINFO test size: 12\nINFO Validation set is used here\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\n[Vannilla Trainer] training:   0%|                        | 0/5 [00:00<?, ?it/s]\n[Vannilla Trainer] training:  20%|███▏            | 1/5 [00:12<00:49, 12.38s/it]\n[Vannilla Trainer] training:  40%|██████▍         | 2/5 [00:27<00:41, 13.89s/it]\n[Vannilla Trainer] training:  60%|█████████▌      | 3/5 [00:38<00:25, 12.54s/it]\n[Vannilla Trainer] training:  80%|████████████▊   | 4/5 [00:48<00:11, 11.72s/it]\n[Vannilla Trainer] training: 100%|████████████████| 5/5 [00:59<00:00, 11.51s/it]\n[Vannilla Trainer] training: 100%|████████████████| 5/5 [00:59<00:00, 11.98s/it]\nINFO [WN Trainer]: loss history saved\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 166, in <module>\n    main()\n  File \"/content/BERT-LNL/main.py\", line 161, in main\n    trainer.train(args, logger, (nl_set, ul_set, v_set, t_set, l2id, id2l))\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 125, in train\n    best_model.load_state_dict(best_model_weights)\n  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 2104, in load_state_dict\n    raise TypeError(f\"Expected state_dict to be dict-like, got {type(state_dict)}.\")\nTypeError: Expected state_dict to be dict-like, got <class 'NoneType'>.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234 --save_loss_tracker_information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cb8bf9",
   "metadata": {},
   "source": [
    "### Step 51"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d87e2",
   "metadata": {},
   "source": [
    "Execution Start time: 19:54:24, End time: 19:54:27 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff89ffa",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `best_model_weights` is `None`, which suggests that the model weights were not saved correctly during training. This could be due to the limited number of training steps or an issue with the model saving logic. Since the task requires only 5 training steps, I will proceed to evaluate the model using the available weights and report the metrics. I will modify the script to bypass loading the best model weights and directly evaluate the current model state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059d6e0",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e3c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Could not find the following lines to replace in the file content:\n```\nbest_model.load_state_dict(best_model_weights)\n```\nDid you mean to replace the following lines (notice leading/trailing whitespaces difference)?\n```\n        best_model.load_state_dict(best_model_weights)\n```"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/trainers/bert_wn_trainer.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "best_model.load_state_dict(best_model_weights)\n",
    "<<<AFTER_EDIT>>>\n",
    "if best_model_weights is not None:\n",
    "    best_model.load_state_dict(best_model_weights)\n",
    "else:\n",
    "    logger.info(\"Best model weights not found, using current model state for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f460015",
   "metadata": {},
   "source": [
    "### Step 52"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b60c37",
   "metadata": {},
   "source": [
    "Execution Start time: 19:54:30, End time: 19:54:37 (duration: 7 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2df91",
   "metadata": {},
   "source": [
    "**Thought**: The error occurred because the line I attempted to replace had leading whitespace. I will correct the indentation and try editing the `bert_wn_trainer.py` script again to bypass loading the best model weights if they are not available, allowing the evaluation to proceed with the current model state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218f798",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d1303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n                break\n\n        if args.save_loss_tracker_information:\n            loss_noise_tracker.save_logged_information()\n            self.logger.info(\"[WN Trainer]: loss history saved\")\n        best_model = self.create_model(args)\n        best_model_weights = early_stopper.get_final_res()[\"es_best_model\"]\n        if best_model_weights is not None:\n            best_model.load_state_dict(best_model_weights)\n        else:\n            logger.info(\"Best model weights not found, using current model state for evaluation.\")\n        best_model = best_model.to(device)\n\n        val_score = self.eval_model_with_both_labels(best_model, v_loader, device, fast_mode=False)\n        test_score = self.eval_model(args, logger, t_loader, best_model, device, fast_mode=False)\n        # wandb.run.summary[\"best_score_on_val_n\"] = test_score['score_dict']['accuracy']\n        # wandb.run.summary[\"best_val_n\"] = val_score['score_dict_n']['accuracy']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/trainers/bert_wn_trainer.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "        best_model.load_state_dict(best_model_weights)\n",
    "<<<AFTER_EDIT>>>\n",
    "        if best_model_weights is not None:\n",
    "            best_model.load_state_dict(best_model_weights)\n",
    "        else:\n",
    "            logger.info(\"Best model weights not found, using current model state for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc749562",
   "metadata": {},
   "source": [
    "### Step 53"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782a031",
   "metadata": {},
   "source": [
    "Execution Start time: 19:54:42, End time: 19:56:13 (duration: 91 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1801a4",
   "metadata": {},
   "source": [
    "**Thought**: The `bert_wn_trainer.py` script has been successfully modified to bypass loading the best model weights if they are not available, allowing the evaluation to proceed with the current model state. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics. This should resolve the previous `TypeError` related to the `NoneType` state_dict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0bb989",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53a8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_55_02_sflip_nle0.2_nlb32\nINFO loading AG_News...\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nINFO Bert WN Trainer: training started\nINFO training size: 24\nINFO validation size: 12\nINFO test size: 12\nINFO Validation set is used here\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\n[Vannilla Trainer] training:   0%|                        | 0/5 [00:00<?, ?it/s]\n[Vannilla Trainer] training:  20%|███▏            | 1/5 [00:13<00:53, 13.44s/it]\n[Vannilla Trainer] training:  40%|██████▍         | 2/5 [00:26<00:40, 13.47s/it]\n[Vannilla Trainer] training:  60%|█████████▌      | 3/5 [00:38<00:25, 12.80s/it]\n[Vannilla Trainer] training:  80%|████████████▊   | 4/5 [00:52<00:13, 13.26s/it]\n[Vannilla Trainer] training: 100%|████████████████| 5/5 [01:02<00:00, 11.93s/it]\n[Vannilla Trainer] training: 100%|████████████████| 5/5 [01:02<00:00, 12.50s/it]\nINFO [WN Trainer]: loss history saved\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nINFO Best model weights not found, using current model state for evaluation.\nTraceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 166, in <module>\n    main()\n  File \"/content/BERT-LNL/main.py\", line 161, in main\n    trainer.train(args, logger, (nl_set, ul_set, v_set, t_set, l2id, id2l))\n  File \"/content/BERT-LNL/trainers/bert_wn_trainer.py\", line 131, in train\n    val_score = self.eval_model_with_both_labels(best_model, v_loader, device, fast_mode=False)\n  File \"/content/BERT-LNL/trainers/trainer.py\", line 197, in eval_model_with_both_labels\n    c_labels = t_batch['c_labels'].to(device)\nKeyError: 'c_labels'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234 --save_loss_tracker_information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a26252",
   "metadata": {},
   "source": [
    "### Step 54"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d396fcb",
   "metadata": {},
   "source": [
    "Execution Start time: 19:56:21, End time: 19:56:22 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d62d71b",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `c_labels` key is missing from the validation batch, which suggests that the dataset is not being prepared with the necessary labels for evaluation. I need to ensure that the dataset includes the labels in the format expected by the evaluation function. I will modify the `load_ag_news.py` script to include the `c_labels` in the dataset before returning the data splits. This will involve duplicating the `n_labels` as `c_labels` for evaluation purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a21fc",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38804f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    test_data = test_data.rename_column(\"label\", \"n_labels\")\n    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    val_data = val_data.rename_column(\"label\", \"n_labels\")\n    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    train_data = train_data.add_column(\"c_labels\", train_data[\"n_labels\"])\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n    test_data = test_data.add_column(\"c_labels\", test_data[\"n_labels\"])\n    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n    val_data = val_data.add_column(\"c_labels\", val_data[\"n_labels\"])\n\n    return train_data, test_data, val_data\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n",
    "    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n",
    "    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n",
    "<<<AFTER_EDIT>>>\n",
    "    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n",
    "    train_data = train_data.add_column(\"c_labels\", train_data[\"n_labels\"])\n",
    "    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n",
    "    test_data = test_data.add_column(\"c_labels\", test_data[\"n_labels\"])\n",
    "    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n",
    "    val_data = val_data.add_column(\"c_labels\", val_data[\"n_labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a5d28b",
   "metadata": {},
   "source": [
    "### Step 55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f153a",
   "metadata": {},
   "source": [
    "Execution Start time: 19:56:30, End time: 19:56:45 (duration: 15 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d0a3ba",
   "metadata": {},
   "source": [
    "**Thought**: The `load_ag_news.py` script has been successfully modified to include the `c_labels` in the dataset, duplicating the `n_labels` for evaluation purposes. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics. This should resolve the previous `KeyError` related to the missing `c_labels`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef31bcc",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3fea0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_56_42_sflip_nle0.2_nlb32\nINFO loading AG_News...\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/content/BERT-LNL/main.py\", line 166, in <module>\n    main()\n  File \"/content/BERT-LNL/main.py\", line 146, in main\n    nl_set, v_set, t_set = load_ag_news()\n  File \"/content/BERT-LNL/load_ag_news.py\", line 27, in load_ag_news\n    train_data = train_data.add_column(\"c_labels\", train_data[\"n_labels\"])\n  File \"/usr/local/lib/python3.10/site-packages/datasets/arrow_dataset.py\", line 567, in wrapper\n    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/datasets/fingerprint.py\", line 482, in wrapper\n    out = func(dataset, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/datasets/arrow_dataset.py\", line 5916, in add_column\n    column_table = InMemoryTable.from_pydict({name: column})\n  File \"/usr/local/lib/python3.10/site-packages/datasets/table.py\", line 757, in from_pydict\n    return cls(pa.Table.from_pydict(*args, **kwargs))\n  File \"pyarrow/table.pxi\", line 1920, in pyarrow.lib._Tabular.from_pydict\n  File \"pyarrow/table.pxi\", line 6136, in pyarrow.lib._from_pydict\n  File \"pyarrow/array.pxi\", line 398, in pyarrow.lib.asarray\n  File \"pyarrow/array.pxi\", line 368, in pyarrow.lib.array\n  File \"pyarrow/array.pxi\", line 42, in pyarrow.lib._sequence_to_array\n  File \"pyarrow/error.pxi\", line 155, in pyarrow.lib.pyarrow_internal_check_status\n  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\npyarrow.lib.ArrowInvalid: Could not convert tensor(2) with type Tensor: did not recognize Python value type when inferring an Arrow data type\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234 --save_loss_tracker_information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c81d6",
   "metadata": {},
   "source": [
    "### Step 56"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff23a9b2",
   "metadata": {},
   "source": [
    "Execution Start time: 19:56:54, End time: 19:56:54 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e489a",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `add_column` method is having trouble converting PyTorch tensors to a format compatible with Arrow data types. This suggests that the `n_labels` column is still in tensor format, which is causing the issue. I need to convert the `n_labels` column to a list before adding it as `c_labels`. I will modify the `load_ag_news.py` script to convert the `n_labels` column to a list before duplicating it as `c_labels`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b99db",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad59dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Found multiple BEFORE_EDIT in the patch. Line 5: <<<BEFORE_EDIT>>>\nFormat of edit is:```\n{filename}\n[optional] preceding lines\n<<<BEFORE_EDIT>>>\nline to remove\nline to remove\n<<<AFTER_EDIT>>>\nline to add\nline to add\nline to add\n```"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    train_data = train_data.add_column(\"c_labels\", train_data[\"n_labels\"])\n",
    "<<<AFTER_EDIT>>>\n",
    "    train_data = train_data.add_column(\"c_labels\", train_data[\"n_labels\"].tolist())\n",
    "<<<BEFORE_EDIT>>>\n",
    "    test_data = test_data.add_column(\"c_labels\", test_data[\"n_labels\"])\n",
    "<<<AFTER_EDIT>>>\n",
    "    test_data = test_data.add_column(\"c_labels\", test_data[\"n_labels\"].tolist())\n",
    "<<<BEFORE_EDIT>>>\n",
    "    val_data = val_data.add_column(\"c_labels\", val_data[\"n_labels\"])\n",
    "<<<AFTER_EDIT>>>\n",
    "    val_data = val_data.add_column(\"c_labels\", val_data[\"n_labels\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ba34b",
   "metadata": {},
   "source": [
    "### Step 57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81304313",
   "metadata": {},
   "source": [
    "Execution Start time: 19:56:58, End time: 19:57:03 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0dd0c",
   "metadata": {},
   "source": [
    "**Thought**: The edit attempt failed due to multiple `BEFORE_EDIT` markers. I will make the edits one at a time to ensure each change is applied correctly. First, I will convert the `n_labels` column to a list before adding it as `c_labels` for the train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b14a5",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c29d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    test_data = test_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    test_data = test_data.rename_column(\"label\", \"n_labels\")\n    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    val_data = val_data.rename_column(\"label\", \"n_labels\")\n    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    train_data = train_data.add_column(\"c_labels\", train_data[\"n_labels\"].tolist())\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n    test_data = test_data.add_column(\"c_labels\", test_data[\"n_labels\"])\n    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n    val_data = val_data.add_column(\"c_labels\", val_data[\"n_labels\"])\n\n    return train_data, test_data, val_data"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    train_data = train_data.add_column(\"c_labels\", train_data[\"n_labels\"])\n",
    "<<<AFTER_EDIT>>>\n",
    "    train_data = train_data.add_column(\"c_labels\", train_data[\"n_labels\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3af48f",
   "metadata": {},
   "source": [
    "### Step 58"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f817c31",
   "metadata": {},
   "source": [
    "Execution Start time: 19:57:07, End time: 19:57:11 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3dbc9",
   "metadata": {},
   "source": [
    "**Thought**: The `n_labels` column for the train dataset has been successfully converted to a list before adding it as `c_labels`. Now, I will apply the same conversion for the test and validation datasets to ensure compatibility with Arrow data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ecf315",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a6b120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    val_data = val_data.map(lambda examples: tokenizer(examples['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n    val_data = val_data.rename_column(\"label\", \"n_labels\")\n    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    train_data = train_data.add_column(\"c_labels\", train_data[\"n_labels\"].tolist())\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n    test_data = test_data.add_column(\"c_labels\", test_data[\"n_labels\"].tolist())\n    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n    val_data = val_data.add_column(\"c_labels\", val_data[\"n_labels\"])\n\n    return train_data, test_data, val_data\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    test_data = test_data.add_column(\"c_labels\", test_data[\"n_labels\"])\n",
    "<<<AFTER_EDIT>>>\n",
    "    test_data = test_data.add_column(\"c_labels\", test_data[\"n_labels\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af62215",
   "metadata": {},
   "source": [
    "### Step 59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3615825",
   "metadata": {},
   "source": [
    "Execution Start time: 19:57:15, End time: 19:57:19 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1efc4f",
   "metadata": {},
   "source": [
    "**Thought**: The `n_labels` column for the test dataset has been successfully converted to a list before adding it as `c_labels`. Now, I will apply the same conversion for the validation dataset to ensure compatibility with Arrow data types. This should resolve the previous `ArrowInvalid` error related to the conversion of PyTorch tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acf2c95",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80dbcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    val_data = val_data.rename_column(\"label\", \"n_labels\")\n    val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'n_labels'])\n    train_data = train_data.add_column(\"purity_list\", [False] * len(train_data))\n    train_data = train_data.add_column(\"c_labels\", train_data[\"n_labels\"].tolist())\n    test_data = test_data.add_column(\"purity_list\", [False] * len(test_data))\n    test_data = test_data.add_column(\"c_labels\", test_data[\"n_labels\"].tolist())\n    val_data = val_data.add_column(\"purity_list\", [False] * len(val_data))\n    val_data = val_data.add_column(\"c_labels\", val_data[\"n_labels\"].tolist())\n\n    return train_data, test_data, val_data\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT-LNL/load_ag_news.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    val_data = val_data.add_column(\"c_labels\", val_data[\"n_labels\"])\n",
    "<<<AFTER_EDIT>>>\n",
    "    val_data = val_data.add_column(\"c_labels\", val_data[\"n_labels\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb697c2d",
   "metadata": {},
   "source": [
    "### Step 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d55a36",
   "metadata": {},
   "source": [
    "Execution Start time: 19:57:23, End time: 19:58:59 (duration: 95 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e736756",
   "metadata": {},
   "source": [
    "**Thought**: The `load_ag_news.py` script has been successfully modified to convert the `n_labels` column to a list before adding it as `c_labels` for all datasets. Now, I will re-run the training script to train the BERT-WN model on the AG-News dataset with the specified parameters and evaluate it to obtain the required metrics. This should resolve the previous `ArrowInvalid` error related to the conversion of PyTorch tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443a0be7",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9abf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO Training started\nINFO log dir: ./logs/08_19_19_57_48_sflip_nle0.2_nlb32\nINFO loading AG_News...\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nINFO Bert WN Trainer: training started\nINFO training size: 24\nINFO validation size: 12\nINFO test size: 12\nINFO Validation set is used here\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\n[Vannilla Trainer] training:   0%|                        | 0/5 [00:00<?, ?it/s]\n[Vannilla Trainer] training:  20%|███▏            | 1/5 [00:13<00:53, 13.33s/it]\n[Vannilla Trainer] training:  40%|██████▍         | 2/5 [00:26<00:40, 13.34s/it]\n[Vannilla Trainer] training:  60%|█████████▌      | 3/5 [00:43<00:29, 14.72s/it]\n[Vannilla Trainer] training:  80%|████████████▊   | 4/5 [00:51<00:12, 12.19s/it]\n[Vannilla Trainer] training: 100%|████████████████| 5/5 [00:59<00:00, 10.58s/it]\n[Vannilla Trainer] training: 100%|████████████████| 5/5 [00:59<00:00, 11.82s/it]\nINFO [WN Trainer]: loss history saved\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nINFO Best model weights not found, using current model state for evaluation.\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 BERT-LNL/main.py --dataset AG_News --log_root ./logs --data_root ./data --trainer_name bert_wn --model_name bert-base-uncased --gen_val --nl_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1 --max_sen_len 64 --lr 0.00002 --num_training_steps 5 --patience 25 --eval_freq 50 --store_model 0 --noise_level 0.2 --noise_type sflip --manualSeed 1234 --save_loss_tracker_information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40cbc9f",
   "metadata": {},
   "source": [
    "### Step 61"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e96b9",
   "metadata": {},
   "source": [
    "Execution Start time: 19:58:59, End time: 19:58:59 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6bd73c",
   "metadata": {},
   "source": [
    "**Thought**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d73c5",
   "metadata": {},
   "source": [
    "**Action (exception)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c38b29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total context tokens exceeded."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
