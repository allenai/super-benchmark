{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea090d9c",
   "metadata": {},
   "source": [
    "### Query\n",
    "Fine-tune roberta-base on a single-task, \"rotten tomatoes\" which is available on huggingface (under this name), using the default hyperparameters. Report the evaluation loss as a json structured as follows: {\"eval_loss\": 0.0} (replace 0.0 with the actual value).\n",
    "\n",
    "Additional instructions:\n",
    "1. Load only the first 10 rows of each set in the dataset\n",
    "2. Train only one epoch.\n",
    "3. Take hyperparemeters from the mnli.json configuraion file.\n",
    "\n",
    "Git repository: https://github.com/thunlp/mode-connectivity-plm\n",
    "\n",
    "I have already executed some of the required steps. However, I did not yet make any required changes to load the request dataset. Your goal is to successfully load the dataset and complete the remaining steps to achieve the user request. You can re-run any of the pre-executed steps, and finally should successfully run\n",
    "```\n",
    "%cd /content/mode-connectivity-plm/RoBERTa_model\n",
    "!TOKENIZERS_PARALLELISM=false python run_glue.py configs/roberta-base/rotten_tomatoes.json\n",
    "```\n",
    "to submit the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb5fff8",
   "metadata": {},
   "source": [
    "### Prompt\n",
    "<details>\n",
    "[{'role': 'system', 'content': 'Interact in a jupyter notebook to solve the request.\\nOutput a thought and an action.\\nThought can reason about the current situation, and action allows you to interact with the Jupyter notebook. There are three types of actions:\\n(1) execute, which executes a notebook cell with the command under the \"content\" field. This could be a bash command (beginning with !), a python command, or magic command (beginning with %).\\n(2) edit, which allows you to replace existing lines in a file with new lines. To replace lines, you will need to provide the lines as they appear before the replacement, and the lines to replace them with.\\nIn the \"content\" field, format should be ```{filename}\\n<<<BEFORE_EDIT>>>\\nlines before edit\\nlines before edit\\n<<<AFTER_EDIT>>>\\nlines after edit\\nlines after edit```\\n  - Include the entire lines WITH indentation. After editing, make sure indentation is correct.\\n(3) submit, which submits the final answer (or null if there\\'s no answer to submit), formatted as JSON (make sure to use double quotes for keys and values).\\nAlways output exactly one \"thought\" and one \"action\", and encapsulate the content with <content>...</content> tags.\\nI will provide the cell output (observation) for you.\\n\\nTips:\\n- When a github repository is given, you should start by cloning it. You can read the readme file and browse the repo for installation and usage instructions.\\n- Avoid using conda, instead use pip for package management.\\n- Each execution has a 5-minute timeout. After this period, you can decide whether to interrupt the kernel or continue waiting.\\n  You should interrupt if: (1) you are prompted with an interactive message (e.g., \"Do you want to continue? [Y/n]\"). In that case, you can bypass it by executing echo \"y\" | command, or (2) the execution is taking longer than expected because the wrong task is being executed, such as a different model or incorrect number of epochs.\\n  You should continue to wait if the current execution is correct and proceeding as expected.\\n\\nHere are some examples.\\nGit repository: EleutherAI/lm-evaluation-harness\\nQuery: Evaluate EleutherAI/gpt-j-6B on hellaswag. What\\'s the score?\\nThought: First, I need to clone the GitHub repository \\'EleutherAI/lm-evaluation-harness\\'.\\nAction: execute\\n<content>\\n!git clone https://github.com/EleutherAI/lm-evaluation-harness.git\\n</content>\\nObservation: ```\\nCloning into \\'lm-evaluation-harness\\'...\\n```\\nThought: The repository has been cloned. Next, I should check the README file for installation and usage instructions to proceed with evaluating EleutherAI/gpt-j-6B on hellaswag.\\nAction: execute\\n<content>\\n!cat lm-evaluation-harness/README.md\\n</content>\\nObservation: ```# Language Model Evaluation Harness ... truncated ...\\n```\\nThought: The README provides detailed instructions for installing the `lm-eval` package and evaluating models like GPT-J-6B on tasks like hellaswag. I need to install the package and its dependencies first.\\nAction: execute\\n<content>\\n!pip install -e lm-evaluation-harness/.\\n</content>\\nObservation: ```\\nObtaining file:///home/nora/lm-evaluation-harness\\n  Installing build dependencies ... truncated ...\\n```\\nThought: The `lm-eval` package and its dependencies have been installed successfully. Now, I can proceed with evaluating the EleutherAI/gpt-j-6B model on the hellaswag task as per the instructions in the README.\\nAction: execute\\n<content>\\n!lm_eval --model hf --model_args pretrained=EleutherAI/gpt-j-6B --tasks hellaswag --device cuda:0 --batch_size 8\\n</content>\\nObservation: ```\\n{\\n  \"hellaswag\": {\\n    \"acc\": 0.24603658536585363,\\n    \"acc_norm\": 0.34436059706446426,\\n  },  ... truncated ...\\n```\\nThought: The `lm-eval` was executed successfully, providing the metrics I needed. The `acc` metric is 0.2460. The `acc_norm` metric is 0.3444\\nAction: submit\\n<content>\\n{\"acc\": 0.2460, \"acc_norm\": 0.3444}\\n</content>\\n\\nQuery: use pandas to read the file \\'data.csv\\' and display the first 2 rows.\\nThought: First, I need to read the file \\'data.csv\\' using the pandas library.\\nAction: execute\\n<content>\\nimport pandas as pd\\npd.read_csv(\\'data.csv\\').head()\\n</content>\\nObservation: ```\\n    name\\n  0  Alice\\n   1    Bob\\n  2  Charlie\\n```\\nThought: The file \\'data.csv\\' has been read successfully and the first 2 rows have been displayed.\\nAction: submit\\n<content>\\n[\"Alice\", \"Bob\"]\\n</content>\\n\\nQuery: Change the model name in the \\'config.json\\' file from \\'roberta-base\\' to \\'roberta-large\\'.\\nThought: First, I need to read the \\'config.json\\' file to find the location where I can replace the model name.\\nAction: execute\\n<content>\\n!cat config.json\\n</content>\\nObservation: ```\\n{\\n    \"model\": \"roberta-base\",\\n    \"batch_size\": 8,\\n    \"epochs\": 10\\n}\\n```\\nThought: The file has been read successfully. Now, I can replace the model name in the \\'config.json\\' file.\\nAction: edit\\n<content>\\nconfig.json\\n<<<BEFORE_EDIT>>>\\n{\\n    \"model\": \"roberta-base\",\\n    \"batch_size\": 8,\\n<<<AFTER_EDIT>>>\\n{\\n    \"model\": \"roberta-large\",\\n    \"batch_size\": 8,\\n</content>\\nObservation: \"editing file config.json\"\\nThought: The model name has been replaced in the \\'config.json\\' file.\\nAction: submit\\n<content>\\nnull\\n</content>\\n'}, {'role': 'user', 'content': 'Query: Fine-tune roberta-base on a single-task, \"rotten tomatoes\" which is available on huggingface (under this name), using the default hyperparameters. Report the evaluation loss as a json structured as follows: {\"eval_loss\": 0.0} (replace 0.0 with the actual value).\\n\\nAdditional instructions:\\n1. Load only the first 10 rows of each set in the dataset\\n2. Train only one epoch.\\n3. Take hyperparemeters from the mnli.json configuraion file.\\n\\nGit repository: https://github.com/thunlp/mode-connectivity-plm\\n\\nI have already executed some of the required steps. However, I did not yet make any required changes to load the request dataset. Your goal is to successfully load the dataset and complete the remaining steps to achieve the user request. You can re-run any of the pre-executed steps, and finally should successfully run\\n```\\n%cd /content/mode-connectivity-plm/RoBERTa_model\\n!TOKENIZERS_PARALLELISM=false python run_glue.py configs/roberta-base/rotten_tomatoes.json\\n```\\nto submit the answer.'}]\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ccb4a6",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017d3ed",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:31, End time: 23:12:31 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dd7eeb",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48984f19",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a9262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Task instructions\n",
    "# \n",
    "# \"Fine-tune roberta-base on a single-task, rotten tomatoes (direct link to the dataset directory is https://drive.google.com/drive/folders/1oik2ItXUEG0Q49k6XOy6bguD4Jp0Voet), using the default hyperparameters.\n",
    "# \n",
    "# Additional instructions:\n",
    "# 1. Load only the first 10 rows of each set in the dataset\n",
    "# 2. Train only one epoch.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5abb80",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd0865",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:31, End time: 23:12:31 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f81160",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc352f5",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844745f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b9647",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95043224",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:31, End time: 23:12:32 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e793bb6",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f068b",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba368109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clone repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4c9a35",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ce7d4",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:32, End time: 23:12:32 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b982fb3f",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94c3da",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb27f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloning into 'mode-connectivity-plm'...\nremote: Enumerating objects: 147, done.\u001b[K\nremote: Counting objects: 100% (147/147)\u001b[K\nremote: Counting objects: 100% (147/147), done.\u001b[K\nremote: Compressing objects: 100% (97/97)\u001b[K\nremote: Compressing objects: 100% (97/97), done.\u001b[K\nremote: Total 147 (delta 66), reused 118 (delta 47), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (147/147)\nReceiving objects: 100% (147/147), 267.98 KiB | 13.40 MiB/s, done.\nResolving deltas: 100% (66/66)\nResolving deltas: 100% (66/66), done.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/thunlp/mode-connectivity-plm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607c7da2",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc0d00",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:32, End time: 23:12:32 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6f983",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048000c",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7194d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/mode-connectivity-plm\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/mode-connectivity-plm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6763e",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1fa2d",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:32, End time: 23:12:32 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044f14cc",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35b365",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bcc4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db79fae",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb13c4b",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:32, End time: 23:12:44 (duration: 11 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e88c17",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82edd002",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897731d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\nRetrieving folder contents\n/content/mode-connectivity-plm/data\nProcessing file 1xYQPyN6VBvnOXSK5O3NcFTnvuopkUj8B rotten_tomatoes_dev.tsv\nProcessing file 14RbCyHs2goLh7s2wAN24tlR6_OG3ZuMG rotten_tomatoes_test.tsv\nProcessing file 1FF9m0NUiVmeaIGhG2VV2sxAtUtw1qMrA rotten_tomatoes_train.tsv\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=1xYQPyN6VBvnOXSK5O3NcFTnvuopkUj8B\nTo: /content/mode-connectivity-plm/data/rotten_tomatoes/rotten_tomatoes_dev.tsv\n\n  0%|          | 0.00/133k [00:00<?, ?B/s]\n\nDownloading...\nFrom: https://drive.google.com/uc?id=14RbCyHs2goLh7s2wAN24tlR6_OG3ZuMG\nTo: /content/mode-connectivity-plm/data/rotten_tomatoes/rotten_tomatoes_test.tsv\n\n  0%|          | 0.00/134k [00:00<?, ?B/s]\n\nDownloading...\nFrom: https://drive.google.com/uc?id=1FF9m0NUiVmeaIGhG2VV2sxAtUtw1qMrA\nTo: /content/mode-connectivity-plm/data/rotten_tomatoes/rotten_tomatoes_train.tsv\n\n  0%|          | 0.00/1.06M [00:00<?, ?B/s]\n\nDownload completed\n['/content/mode-connectivity-plm/data/rotten_tomatoes/rotten_tomatoes_dev.tsv',\n '/content/mode-connectivity-plm/data/rotten_tomatoes/rotten_tomatoes_test.tsv',\n '/content/mode-connectivity-plm/data/rotten_tomatoes/rotten_tomatoes_train.tsv']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "%cd /content/mode-connectivity-plm/data/\n",
    "gdown.download_folder(\"https://drive.google.com/drive/folders/1oik2ItXUEG0Q49k6XOy6bguD4Jp0Voet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f5a2d",
   "metadata": {},
   "source": [
    "### Step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea5dde",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:44, End time: 23:12:44 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f0be96",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8010ce2",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6ae80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download checkpoint model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589485a0",
   "metadata": {},
   "source": [
    "### Step 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9031e5cf",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:44, End time: 23:12:44 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651a2a3e",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5beb00e",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3bfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/mode-connectivity-plm/RoBERTa_model\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\nTraceback (most recent call last):\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 31, in <module>\n    import datasets\nModuleNotFoundError: No module named 'datasets'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/mode-connectivity-plm/RoBERTa_model\n",
    "!TOKENIZERS_PARALLELISM=false python run_glue.py configs/roberta-base/rotten_tomatoes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf981f",
   "metadata": {},
   "source": [
    "### Step 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5282a",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:45, End time: 23:12:45 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dec0a01",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb626ba9",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecac88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install missing dependency (I select the package version stated in the requirements file to avoid errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d598198",
   "metadata": {},
   "source": [
    "### Step 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f08934",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:45, End time: 23:12:51 (duration: 6 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff3f22",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f9dd2",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad929df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting datasets==2.6.1\n  Downloading datasets-2.6.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.1) (1.25.2)\nCollecting pyarrow>=6.0.0 (from datasets==2.6.1)\n  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nCollecting dill<0.3.6 (from datasets==2.6.1)\n  Downloading dill-0.3.5.1-py2.py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from datasets==2.6.1) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.1) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.1) (4.66.4)\nCollecting xxhash (from datasets==2.6.1)\n  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting multiprocess (from datasets==2.6.1)\n  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets==2.6.1) (2023.6.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets==2.6.1) (3.8.3)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.1) (0.23.3)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from datasets==2.6.1) (24.1)\nCollecting responses<0.19 (from datasets==2.6.1)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.1) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.1) (23.2.0)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.1) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.1) (6.0.5)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.1) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.1) (1.9.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.1) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.1) (1.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.6.1) (3.15.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.6.1) (4.12.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.6.1) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.6.1) (2.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.6.1) (2024.6.2)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.6.1)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n  Downloading multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n  Downloading multiprocess-0.70.13-py310-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->datasets==2.6.1) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets==2.6.1) (2024.1)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets==2.6.1) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.6.1) (1.16.0)\nDownloading datasets-2.6.1-py3-none-any.whl (441 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/441.9 kB ? eta -:--:--\n\n\u001b[?25hDownloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/95.8 kB ? eta -:--:--\n\n\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/39.9 MB ? eta -:--:--\n\n\n\n\n\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nDownloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/133.1 kB ? eta -:--:--\n\n\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/194.1 kB ? eta -:--:--\n\n\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, responses, multiprocess, datasets\nSuccessfully installed datasets-2.6.1 dill-0.3.5.1 multiprocess-0.70.13 pyarrow-17.0.0 responses-0.18.0 xxhash-3.5.0\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Task:Dependencies\n",
    "!pip install datasets==2.6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90993d",
   "metadata": {},
   "source": [
    "### Step 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a0748b",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:51, End time: 23:12:51 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ee6c4",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf78792",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097339f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First attempt to run fine-tuning script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95368417",
   "metadata": {},
   "source": [
    "### Step 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ae468",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:51, End time: 23:12:57 (duration: 5 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6473fe",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a31043",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d7a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/mode-connectivity-plm/RoBERTa_model\nTraceback (most recent call last):\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 599, in <module>\n    main()\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 228, in main\n    model_args, data_args, training_args, delta_args = parser.parse_json_file(json_file, return_remaining_args=True) #args = arg_string, return_remaining_strings=True) #parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 203, in parse_json_file\n    data = json.loads(Path(json_file).read_text())\n  File \"/usr/local/lib/python3.10/pathlib.py\", line 1134, in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\n  File \"/usr/local/lib/python3.10/pathlib.py\", line 1119, in open\n    return self._accessor.open(self, mode, buffering, encoding, errors,\nFileNotFoundError: [Errno 2] No such file or directory: '/content/mode-connectivity-plm/RoBERTa_model/configs/roberta-base/rotten_tomatoes.json'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/mode-connectivity-plm/RoBERTa_model\n",
    "!TOKENIZERS_PARALLELISM=false python run_glue.py configs/roberta-base/rotten_tomatoes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c1a31",
   "metadata": {},
   "source": [
    "### Step 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621812c1",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:57, End time: 23:12:57 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b5979",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ec850",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3893e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The script reads the configuration parameters from a config file. I create it based on the config file from the `mnli` task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc8230",
   "metadata": {},
   "source": [
    "### Step 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d7c7e",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:57, End time: 23:12:57 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ad13a",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b095f28",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162adb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "config_dict = {\n",
    "    \"dataset_config_name\": [\n",
    "        \"en\"\n",
    "    ],\n",
    "    \"delta_type\": \"none\",\n",
    "    \"do_eval\": True,\n",
    "    \"do_test\": True,\n",
    "    \"do_train\": True,\n",
    "    \"eval_dataset_config_name\": [\n",
    "        \"en\"\n",
    "    ],\n",
    "    \"eval_dataset_name\": \"rotten_tomatoes\",\n",
    "    \"eval_steps\": 10000,\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"greater_is_better\": True,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"max_source_length\": 128,\n",
    "    \"metric_for_best_model\": \"eval_accuracy\",\n",
    "    \"model_name_or_path\": \"./checkpoint/ckpt_15000\",\n",
    "    # \"max_steps\": 50000,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"output_dir\": \"roberta-base_output/rotten_tomatoes-ckpt15000-seed20/\",\n",
    "    \"config_name\": \"roberta-base\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 32,\n",
    "    \"per_device_train_batch_size\": 32,\n",
    "    \"predict_with_generate\": True,\n",
    "    \"push_to_hub\": False,\n",
    "    \"save_steps\": 10000,\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"seed\": 20,\n",
    "    \"task_name\": None,\n",
    "    \"dataset_name\": \"rotten_tomatoes\",\n",
    "    \"test_dataset_config_name\": [\n",
    "        \"en\"\n",
    "    ],\n",
    "    \"test_dataset_name\": \"rotten_tomatoes\",\n",
    "    \"tokenizer_name\": \"roberta-base\",\n",
    "    \"warmup_steps\": 0\n",
    "}\n",
    "filename = \"/content/mode-connectivity-plm/RoBERTa_model/configs/roberta-base/rotten_tomatoes.json\"\n",
    "json.dump(config_dict, open(filename, \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8badc28d",
   "metadata": {},
   "source": [
    "### Step 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc58fb",
   "metadata": {},
   "source": [
    "Execution Start time: 23:12:57, End time: 23:13:02 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933ccab",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dec409",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81dd86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/mode-connectivity-plm/RoBERTa_model\nTraceback (most recent call last):\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 599, in <module>\n    main()\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 228, in main\n    model_args, data_args, training_args, delta_args = parser.parse_json_file(json_file, return_remaining_args=True) #args = arg_string, return_remaining_strings=True) #parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 208, in parse_json_file\n    obj = dtype(**inputs)\n  File \"<string>\", line 125, in __init__\n  File \"/usr/local/lib/python3.10/site-packages/transformers/training_args.py\", line 1605, in __post_init__\n    and (self.device.type != \"cuda\")\n  File \"/usr/local/lib/python3.10/site-packages/transformers/training_args.py\", line 2094, in device\n    return self._setup_devices\n  File \"/usr/local/lib/python3.10/site-packages/transformers/utils/generic.py\", line 63, in __get__\n    cached = self.fget(obj)\n  File \"/usr/local/lib/python3.10/site-packages/transformers/training_args.py\", line 2000, in _setup_devices\n    raise ImportError(\nImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/mode-connectivity-plm/RoBERTa_model\n",
    "!TOKENIZERS_PARALLELISM=false python run_glue.py configs/roberta-base/rotten_tomatoes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bdafc4",
   "metadata": {},
   "source": [
    "### Step 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4650f3",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:02, End time: 23:13:02 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bb974e",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d9ec1b",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8ae0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rotten_tomatoes is not a defined task. I manually add it to the `run_glue.py` script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380015ee",
   "metadata": {},
   "source": [
    "### Step 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e95878",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:02, End time: 23:13:02 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8236a6",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7144280",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ff5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\ntask_to_keys = {\n    \"cola\": (\"sentence\", None),\n    \"mnli\": (\"premise\", \"hypothesis\"),\n    \"mrpc\": (\"sentence1\", \"sentence2\"),\n    \"qnli\": (\"question\", \"sentence\"),\n    \"qqp\": (\"question1\", \"question2\"),\n    \"rte\": (\"sentence1\", \"sentence2\"),\n    \"sst2\": (\"sentence\", None),\n    \"stsb\": (\"sentence1\", \"sentence2\"),\n    \"wnli\": (\"sentence1\", \"sentence2\"),\n    \"rotten_tomatoes\": (\"sentence1\", \"sentence2\"),\n}\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass DataTrainingArguments:\n    \"\"\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "\n",
    "<<<AFTER_EDIT>>>\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "    \"rotten_tomatoes\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c28aa2",
   "metadata": {},
   "source": [
    "### Step 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf1cf2",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:02, End time: 23:13:03 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa58cc",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f79991f",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e6336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n\n        if data_args.train_file.endswith(\".csv\"):\n            # Loading a dataset from local csv files\n            raw_datasets = load_dataset(\"csv\", data_files=data_files, cache_dir=model_args.cache_dir)\n        else:\n            # Loading a dataset from local json files\n            raw_datasets = load_dataset(\"json\", data_files=data_files, cache_dir=model_args.cache_dir)\n    # See more about loading any type of standard or custom dataset at\n    # https://huggingface.co/docs/datasets/loading_datasets.html.\n\n    from datasets import Dataset\n\n    for split in [\"train\", \"validation\", \"test\"]:\n        df = raw_datasets[split].to_pandas().head(10)\n        raw_datasets[split] = Dataset.from_pandas(df)\n\n    # Labels\n    if data_args.task_name is not None:\n        is_regression = data_args.task_name == \"stsb\"\n        if not is_regression:\n            label_list = raw_datasets[\"train\"].features[\"label\"].names\n            num_labels = len(label_list)\n        else:\n            num_labels = 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    # See more about loading any type of standard or custom dataset at\n",
    "    # https://huggingface.co/docs/datasets/loading_datasets.html.\n",
    "\n",
    "    # Labels\n",
    "    if data_args.task_name is not None:\n",
    "<<<AFTER_EDIT>>>\n",
    "    # See more about loading any type of standard or custom dataset at\n",
    "    # https://huggingface.co/docs/datasets/loading_datasets.html.\n",
    "\n",
    "    from datasets import Dataset\n",
    "\n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "        df = raw_datasets[split].to_pandas().head(10)\n",
    "        raw_datasets[split] = Dataset.from_pandas(df)\n",
    "\n",
    "    # Labels\n",
    "    if data_args.task_name is not None:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a64f6fe",
   "metadata": {},
   "source": [
    "### Step 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d367ab1",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:03, End time: 23:13:07 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda93b8a",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eba2d2",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10523043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/mode-connectivity-plm/RoBERTa_model\nTraceback (most recent call last):\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 605, in <module>\n    main()\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 228, in main\n    model_args, data_args, training_args, delta_args = parser.parse_json_file(json_file, return_remaining_args=True) #args = arg_string, return_remaining_strings=True) #parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 208, in parse_json_file\n    obj = dtype(**inputs)\n  File \"<string>\", line 125, in __init__\n  File \"/usr/local/lib/python3.10/site-packages/transformers/training_args.py\", line 1605, in __post_init__\n    and (self.device.type != \"cuda\")\n  File \"/usr/local/lib/python3.10/site-packages/transformers/training_args.py\", line 2094, in device\n    return self._setup_devices\n  File \"/usr/local/lib/python3.10/site-packages/transformers/utils/generic.py\", line 63, in __get__\n    cached = self.fget(obj)\n  File \"/usr/local/lib/python3.10/site-packages/transformers/training_args.py\", line 2000, in _setup_devices\n    raise ImportError(\nImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/mode-connectivity-plm/RoBERTa_model\n",
    "!TOKENIZERS_PARALLELISM=false python run_glue.py configs/roberta-base/rotten_tomatoes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a472d11",
   "metadata": {},
   "source": [
    "### Step 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b4412",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:07, End time: 23:13:07 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bef7c10",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5831786c",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17ffbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install missing dependency and try again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0e6bfa",
   "metadata": {},
   "source": [
    "### Step 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce92baec",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:07, End time: 23:13:11 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca2eb6",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38889ae3",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05084467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting accelerate\n  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/site-packages (from accelerate) (1.25.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from accelerate) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate) (5.9.8)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/site-packages (from accelerate) (2.2.1+cpu)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/site-packages (from accelerate) (0.23.3)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.6.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.6.2)\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/315.1 kB ? eta -:--:--\n\n\u001b[?25hInstalling collected packages: accelerate\nSuccessfully installed accelerate-0.33.0\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Task:Dependencies\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2d8d",
   "metadata": {},
   "source": [
    "### Step 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71ff9e",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:11, End time: 23:13:16 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84bd612",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c00e3",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5090a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/mode-connectivity-plm/RoBERTa_model\n08/20/2024 23:13:15 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: True, 16-bits training: False\n\nDownloading readme:   0%|                           | 0.00/7.46k [00:00<?, ?B/s]\n\nTraceback (most recent call last):\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 605, in <module>\n    main()\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 294, in main\n    raw_datasets = load_dataset(\n  File \"/usr/local/lib/python3.10/site-packages/datasets/load.py\", line 1719, in load_dataset\n    builder_instance = load_dataset_builder(\n  File \"/usr/local/lib/python3.10/site-packages/datasets/load.py\", line 1497, in load_dataset_builder\n    dataset_module = dataset_module_factory(\n  File \"/usr/local/lib/python3.10/site-packages/datasets/load.py\", line 1222, in dataset_module_factory\n    raise e1 from None\n  File \"/usr/local/lib/python3.10/site-packages/datasets/load.py\", line 1208, in dataset_module_factory\n    ).get_module()\n  File \"/usr/local/lib/python3.10/site-packages/datasets/load.py\", line 838, in get_module\n    builder_kwargs[\"info\"] = DatasetInfo._from_yaml_dict(dataset_info_dict)\n  File \"/usr/local/lib/python3.10/site-packages/datasets/info.py\", line 332, in _from_yaml_dict\n    yaml_data[\"features\"] = Features._from_yaml_list(yaml_data[\"features\"])\n  File \"/usr/local/lib/python3.10/site-packages/datasets/features/features.py\", line 1745, in _from_yaml_list\n    return cls.from_dict(from_yaml_inner(yaml_data))\n  File \"/usr/local/lib/python3.10/site-packages/datasets/features/features.py\", line 1741, in from_yaml_inner\n    return {name: from_yaml_inner(_feature) for name, _feature in zip(names, obj)}\n  File \"/usr/local/lib/python3.10/site-packages/datasets/features/features.py\", line 1741, in <dictcomp>\n    return {name: from_yaml_inner(_feature) for name, _feature in zip(names, obj)}\n  File \"/usr/local/lib/python3.10/site-packages/datasets/features/features.py\", line 1736, in from_yaml_inner\n    return from_yaml_inner(obj[\"dtype\"])\n  File \"/usr/local/lib/python3.10/site-packages/datasets/features/features.py\", line 1738, in from_yaml_inner\n    return {\"_type\": snakecase_to_camelcase(_type), **unsimplify(obj)[_type]}\n  File \"/usr/local/lib/python3.10/site-packages/datasets/features/features.py\", line 1706, in unsimplify\n    if label_ids and label_ids != list(range(label_ids[-1] + 1)):\nTypeError: can only concatenate str (not \"int\") to str\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/mode-connectivity-plm/RoBERTa_model\n",
    "!TOKENIZERS_PARALLELISM=false python run_glue.py configs/roberta-base/rotten_tomatoes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061637b1",
   "metadata": {},
   "source": [
    "### Step 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2382bb",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:16, End time: 23:13:16 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca9837",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d61e027",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd506540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The error `TypeError: can only concatenate str (not \"int\") to str` was apparently patched in `datasets==2.6.2`, so I update this package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be832a31",
   "metadata": {},
   "source": [
    "### Step 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3edf46",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:16, End time: 23:13:19 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608654bc",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3500df",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6941cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting datasets==2.6.2\n  Downloading datasets-2.6.2-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (1.25.2)\nRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (17.0.0)\nRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (0.3.5.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (4.66.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (0.70.13)\nRequirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets==2.6.2) (2023.6.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (3.8.3)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (0.23.3)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (24.1)\nRequirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (0.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from datasets==2.6.2) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.2) (23.2.0)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.2) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.2) (6.0.5)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.2) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.2) (1.9.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.2) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets==2.6.2) (1.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.6.2) (3.15.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.6.2) (4.12.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.6.2) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.6.2) (2.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.6.2) (2024.6.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->datasets==2.6.2) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets==2.6.2) (2024.1)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets==2.6.2) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.6.2) (1.16.0)\nDownloading datasets-2.6.2-py3-none-any.whl (445 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/445.2 kB ? eta -:--:--\n\n\u001b[?25hInstalling collected packages: datasets\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.6.1\n    Uninstalling datasets-2.6.1:\n      Successfully uninstalled datasets-2.6.1\nSuccessfully installed datasets-2.6.2\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Task:Dependencies\n",
    "!pip install datasets==2.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac64ff",
   "metadata": {},
   "source": [
    "### Step 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf7abf3",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:20, End time: 23:13:25 (duration: 5 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5602cc",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c8a79",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c31f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/mode-connectivity-plm/RoBERTa_model\n08/20/2024 23:13:23 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: True, 16-bits training: False\n08/20/2024 23:13:23 - WARNING - datasets.builder - Using custom data configuration rotten_tomatoes-cf1f5867fcc8408a\nDownloading and preparing dataset None/None to /root/.cache/huggingface/datasets/parquet/rotten_tomatoes-cf1f5867fcc8408a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n\nDownloading data files:   0%|                             | 0/3 [00:00<?, ?it/s]\n\nDownloading data:   0%|                              | 0.00/699k [00:00<?, ?B/s]\u001b[A\n\n\nDownloading data files:  33%|███████              | 1/3 [00:00<00:00,  3.84it/s]\n\nDownloading data:   0%|                             | 0.00/92.2k [00:00<?, ?B/s]\u001b[A\n\n\nDownloading data files:  67%|██████████████       | 2/3 [00:00<00:00,  4.50it/s]\n\nDownloading data:   0%|                             | 0.00/90.0k [00:00<?, ?B/s]\u001b[A\n\n\nDownloading data files: 100%|█████████████████████| 3/3 [00:00<00:00,  4.27it/s]\nDownloading data files: 100%|█████████████████████| 3/3 [00:00<00:00,  4.26it/s]\n\nExtracting data files:   0%|                              | 0/3 [00:00<?, ?it/s]\nExtracting data files: 100%|████████████████████| 3/3 [00:00<00:00, 1255.78it/s]\n\n0 tables [00:00, ? tables/s]\n                            \n\n0 tables [00:00, ? tables/s]\n                            \n\n0 tables [00:00, ? tables/s]\n                            \nDataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/rotten_tomatoes-cf1f5867fcc8408a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\n100%|███████████████████████████████████████████| 3/3 [00:00<00:00, 1009.14it/s]\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n\nconfig.json:   0%|                                    | 0.00/481 [00:00<?, ?B/s]\n\n\ntokenizer_config.json:   0%|                         | 0.00/25.0 [00:00<?, ?B/s]\ntokenizer_config.json: 100%|██████████████████| 25.0/25.0 [00:00<00:00, 243kB/s]\n\nvocab.json:   0%|                                    | 0.00/899k [00:00<?, ?B/s]\n\n\nmerges.txt:   0%|                                    | 0.00/456k [00:00<?, ?B/s]\n\n\ntokenizer.json:   0%|                               | 0.00/1.36M [00:00<?, ?B/s]\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 3306, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/transformers/utils/hub.py\", line 384, in cached_file\n    resolved_file = try_to_load_from_cache(\n  File \"/usr/local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n    validate_repo_id(arg_value)\n  File \"/usr/local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n    raise HFValidationError(\nhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './checkpoint/ckpt_15000'. Use `repo_type` argument if needed.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 605, in <module>\n    main()\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 372, in main\n    model = AutoModelForSequenceClassification.from_pretrained(\n  File \"/usr/local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 563, in from_pretrained\n    return model_class.from_pretrained(\n  File \"/usr/local/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 3417, in from_pretrained\n    raise EnvironmentError(\nOSError: Can't load the model for './checkpoint/ckpt_15000'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './checkpoint/ckpt_15000' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/mode-connectivity-plm/RoBERTa_model\n",
    "!TOKENIZERS_PARALLELISM=false python run_glue.py configs/roberta-base/rotten_tomatoes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534b6a6",
   "metadata": {},
   "source": [
    "### Step 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7a8ed",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:26, End time: 23:13:26 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe33885",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7900d76c",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac7c4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The datset datatypes differs from the model datatypes. This can be solved by casting the \"label\" column to `float`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c5ba48",
   "metadata": {},
   "source": [
    "### Step 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770401f4",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:26, End time: 23:13:26 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe768dc3",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e89e277",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d8827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Updated 1 path from the index\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git checkout run_glue.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23487074",
   "metadata": {},
   "source": [
    "### Step 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf9acf",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:26, End time: 23:13:26 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f4191",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb4e4d",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe9261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\ntask_to_keys = {\n    \"cola\": (\"sentence\", None),\n    \"mnli\": (\"premise\", \"hypothesis\"),\n    \"mrpc\": (\"sentence1\", \"sentence2\"),\n    \"qnli\": (\"question\", \"sentence\"),\n    \"qqp\": (\"question1\", \"question2\"),\n    \"rte\": (\"sentence1\", \"sentence2\"),\n    \"sst2\": (\"sentence\", None),\n    \"stsb\": (\"sentence1\", \"sentence2\"),\n    \"wnli\": (\"sentence1\", \"sentence2\"),\n    \"rotten_tomatoes\": (\"sentence1\", \"sentence2\"),\n}\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass DataTrainingArguments:\n    \"\"\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "\n",
    "<<<AFTER_EDIT>>>\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "    \"rotten_tomatoes\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa318209",
   "metadata": {},
   "source": [
    "### Step 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da04b764",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:26, End time: 23:13:27 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ad793",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1519b25",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394bf8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n\n        if data_args.train_file.endswith(\".csv\"):\n            # Loading a dataset from local csv files\n            raw_datasets = load_dataset(\"csv\", data_files=data_files, cache_dir=model_args.cache_dir)\n        else:\n            # Loading a dataset from local json files\n            raw_datasets = load_dataset(\"json\", data_files=data_files, cache_dir=model_args.cache_dir)\n    # See more about loading any type of standard or custom dataset at\n    # https://huggingface.co/docs/datasets/loading_datasets.html.\n\n    from datasets import Dataset\n\n    for split in [\"train\", \"validation\", \"test\"]:\n        df = raw_datasets[split].to_pandas().head(10)\n        df[\"label\"] = df[\"label\"].astype(float)\n        raw_datasets[split] = Dataset.from_pandas(df)\n\n    # Labels\n    if data_args.task_name is not None:\n        is_regression = data_args.task_name == \"stsb\"\n        if not is_regression:\n            label_list = raw_datasets[\"train\"].features[\"label\"].names\n            num_labels = len(label_list)\n        else:\n            num_labels = 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\n",
    "<<<BEFORE_EDIT>>>\n",
    "    # See more about loading any type of standard or custom dataset at\n",
    "    # https://huggingface.co/docs/datasets/loading_datasets.html.\n",
    "\n",
    "    # Labels\n",
    "    if data_args.task_name is not None:\n",
    "<<<AFTER_EDIT>>>\n",
    "    # See more about loading any type of standard or custom dataset at\n",
    "    # https://huggingface.co/docs/datasets/loading_datasets.html.\n",
    "\n",
    "    from datasets import Dataset\n",
    "\n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "        df = raw_datasets[split].to_pandas().head(10)\n",
    "        df[\"label\"] = df[\"label\"].astype(float)\n",
    "        raw_datasets[split] = Dataset.from_pandas(df)\n",
    "\n",
    "    # Labels\n",
    "    if data_args.task_name is not None:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e574e332",
   "metadata": {},
   "source": [
    "### Step 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9046ff0e",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:29, End time: 23:13:34 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71cee8",
   "metadata": {},
   "source": [
    "**Thought**: The script has been modified to load only the first 10 rows of each dataset split and to cast the \"label\" column to `float`. Now, I will try running the fine-tuning script again to see if the changes resolve the issue and allow the model to be trained and evaluated on the \"rotten tomatoes\" dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5fe965",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd78821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/mode-connectivity-plm/RoBERTa_model\n08/20/2024 23:13:33 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: True, 16-bits training: False\n08/20/2024 23:13:33 - WARNING - datasets.builder - Using custom data configuration rotten_tomatoes-cf1f5867fcc8408a\n08/20/2024 23:13:33 - WARNING - datasets.builder - Found cached dataset parquet (/root/.cache/huggingface/datasets/parquet/rotten_tomatoes-cf1f5867fcc8408a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\n100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 914.19it/s]\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 3306, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/transformers/utils/hub.py\", line 384, in cached_file\n    resolved_file = try_to_load_from_cache(\n  File \"/usr/local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n    validate_repo_id(arg_value)\n  File \"/usr/local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n    raise HFValidationError(\nhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './checkpoint/ckpt_15000'. Use `repo_type` argument if needed.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 606, in <module>\n    main()\n  File \"/content/mode-connectivity-plm/RoBERTa_model/run_glue.py\", line 373, in main\n    model = AutoModelForSequenceClassification.from_pretrained(\n  File \"/usr/local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 563, in from_pretrained\n    return model_class.from_pretrained(\n  File \"/usr/local/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 3417, in from_pretrained\n    raise EnvironmentError(\nOSError: Can't load the model for './checkpoint/ckpt_15000'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './checkpoint/ckpt_15000' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/mode-connectivity-plm/RoBERTa_model\n",
    "!TOKENIZERS_PARALLELISM=false python run_glue.py configs/roberta-base/rotten_tomatoes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5713e502",
   "metadata": {},
   "source": [
    "### Step 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4868e8e",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:36, End time: 23:13:36 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a37ba7d",
   "metadata": {},
   "source": [
    "**Thought**: \n",
    "Thought: The error indicates that the model checkpoint path './checkpoint/ckpt_15000' is incorrect or does not exist. I need to modify the configuration to use the correct model path, which should be 'roberta-base' from Hugging Face's model hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800daf6d",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b678f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    \"eval_dataset_name\": \"rotten_tomatoes\",\n    \"eval_steps\": 10000,\n    \"evaluation_strategy\": \"steps\",\n    \"greater_is_better\": true,\n    \"load_best_model_at_end\": true,\n    \"max_source_length\": 128,\n    \"metric_for_best_model\": \"eval_accuracy\",\n    \"model_name_or_path\": \"roberta-base\",\n    \"num_train_epochs\": 1,\n    \"output_dir\": \"roberta-base_output/rotten_tomatoes-ckpt15000-seed20/\",\n    \"config_name\": \"roberta-base\",\n    \"overwrite_output_dir\": true,\n    \"per_device_eval_batch_size\": 32,\n    \"per_device_train_batch_size\": 32,"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/content/mode-connectivity-plm/RoBERTa_model/configs/roberta-base/rotten_tomatoes.json\n",
    "<<<BEFORE_EDIT>>>\n",
    "    \"model_name_or_path\": \"./checkpoint/ckpt_15000\",\n",
    "<<<AFTER_EDIT>>>\n",
    "    \"model_name_or_path\": \"roberta-base\","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9f4d6",
   "metadata": {},
   "source": [
    "### Step 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a773b",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:38, End time: 23:13:56 (duration: 17 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117db2d2",
   "metadata": {},
   "source": [
    "**Thought**: The configuration file has been updated to use the 'roberta-base' model from Hugging Face's model hub. Now, I will try running the fine-tuning script again to see if the changes resolve the issue and allow the model to be trained and evaluated on the \"rotten tomatoes\" dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5368ced9",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffc4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/mode-connectivity-plm/RoBERTa_model\n08/20/2024 23:13:42 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: True, 16-bits training: False\n08/20/2024 23:13:42 - WARNING - datasets.builder - Using custom data configuration rotten_tomatoes-cf1f5867fcc8408a\n08/20/2024 23:13:42 - WARNING - datasets.builder - Found cached dataset parquet (/root/.cache/huggingface/datasets/parquet/rotten_tomatoes-cf1f5867fcc8408a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\n100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 885.25it/s]\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n\nmodel.safetensors:   0%|                             | 0.00/499M [00:00<?, ?B/s]\n\n\n\n\n\n\n\n\n\n\n\n\n\n[WARNING|modeling_utils.py:4172] 2024-08-20 23:13:45,922 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\nRunning tokenizer on dataset:   0%|                       | 0/1 [00:00<?, ?ba/s]\nRunning tokenizer on dataset:   0%|                       | 0/1 [00:00<?, ?ba/s]\n\nRunning tokenizer on dataset:   0%|                       | 0/1 [00:00<?, ?ba/s]\nRunning tokenizer on dataset:   0%|                       | 0/1 [00:00<?, ?ba/s]\n\nRunning tokenizer on dataset:   0%|                       | 0/1 [00:00<?, ?ba/s]\nRunning tokenizer on dataset:   0%|                       | 0/1 [00:00<?, ?ba/s]\n/content/mode-connectivity-plm/RoBERTa_model/run_glue.py:496: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"accuracy\")\n\nDownloading builder script:   0%|                   | 0.00/1.65k [00:00<?, ?B/s]\n\n08/20/2024 23:13:46 - WARNING - accelerate.utils.other - Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.40s/it]\n                                                                                \n{'train_runtime': 6.4101, 'train_samples_per_second': 1.56, 'train_steps_per_second': 0.156, 'train_loss': 0.8054221868515015, 'epoch': 1.0}\n\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.40s/it]\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.41s/it]\n***** train metrics *****\n  epoch                    =        1.0\n  total_flos               =      612GF\n  train_loss               =     0.8054\n  train_runtime            = 0:00:06.41\n  train_samples            =         10\n  train_samples_per_second =       1.56\n  train_steps_per_second   =      0.156\n\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 418.80it/s]\n***** eval metrics *****\n  epoch                   =        1.0\n  eval_loss               =      0.553\n  eval_mse                =      0.553\n  eval_runtime            = 0:00:01.51\n  eval_samples            =         10\n  eval_samples_per_second =      6.617\n  eval_steps_per_second   =      0.662\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/mode-connectivity-plm/RoBERTa_model\n",
    "!TOKENIZERS_PARALLELISM=false python run_glue.py configs/roberta-base/rotten_tomatoes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bae658",
   "metadata": {},
   "source": [
    "### Step 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75b017",
   "metadata": {},
   "source": [
    "Execution Start time: 23:13:57, End time: 23:13:57 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20699032",
   "metadata": {},
   "source": [
    "**Thought**: The fine-tuning process has been completed successfully, and the evaluation loss is reported as 0.553. I will now submit this result in the required JSON format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39c525",
   "metadata": {},
   "source": [
    "**Action (submit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71853ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'eval_loss': 0.553}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
