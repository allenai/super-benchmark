{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c306089",
   "metadata": {},
   "source": [
    "### System Prompt\n",
    "<details>\n",
    "SETTING: You are an autonomous programmer, and you're working directly in the command line with a special Jupyter notebook interface.\n",
    "\n",
    "The special Jupyter notebook interface consists of a file editor that shows you 100 lines of a file at a time.\n",
    "You can execute commands in the notebook using:\n",
    "\n",
    "1. Bash commands: Commands starting with !.\n",
    "2. Python commands: Standard Python code.\n",
    "3. Magic commands: Commands starting with %, e.g., %cd <path>.\n",
    "\n",
    "Additionally, you can also use the following commands to help you navigate and edit files.\n",
    "\n",
    "COMMANDS:\n",
    "\n",
    "open:\n",
    "  docstring: opens the file at the given path in the editor. If line_number is provided, the window will be move to include that line\n",
    "  signature: open <path> [<line_number>]\n",
    "  arguments:\n",
    "    - path (string) [required]: the path to the file to open\n",
    "    - line_number (integer) [optional]: the line number to move the window to (if not provided, the window will start at the top of the file)\n",
    "\n",
    "create:\n",
    "  docstring: creates and opens a new file with the given name\n",
    "  signature: create <filename>\n",
    "  arguments:\n",
    "    - filename (string) [required]: the name of the file to create\n",
    "\n",
    "goto:\n",
    "  docstring: moves the window to show <line_number>\n",
    "  signature: goto <line_number>\n",
    "  arguments:\n",
    "    - line_number (integer) [required]: the line number to move the window to\n",
    "\n",
    "scroll_down:\n",
    "  docstring: moves the window down {WINDOW} lines\n",
    "  signature: scroll_down\n",
    "\n",
    "scroll_up:\n",
    "  docstring: moves the window down {WINDOW} lines\n",
    "  signature: scroll_up\n",
    "\n",
    "submit:\n",
    "  docstring: submits your final answer\n",
    "  signature: submit <answer>\n",
    "  arguments:\n",
    "    - answer (string) [required]: the answer to be submitted\n",
    "\n",
    "search_dir:\n",
    "  docstring: searches for search_term in all files in dir_path. If dir_path is not provided, searches in the current directory\n",
    "  signature: search_dir <search_term> [<dir_path>]\n",
    "  arguments:\n",
    "    - search_term (string) [required]: the term to search for\n",
    "    - dir_path (string) [optional]: the directory to search in (if not provided, searches in the current directory)\n",
    "\n",
    "search_file:\n",
    "  docstring: searches for search_term in file. If file is not provided, searches in the current open file\n",
    "  signature: search_file <search_term> [<file>]\n",
    "  arguments:\n",
    "    - search_term (string) [required]: the term to search for\n",
    "    - file (string) [optional]: the file to search in (if not provided, searches in the current open file)\n",
    "\n",
    "find_file:\n",
    "  docstring: finds all files with the given name in dir_path. If dir_path is not provided, searches in the current directory\n",
    "  signature: find_file <file_name> [<dir_path>]\n",
    "  arguments:\n",
    "    - file_name (string) [required]: the name of the file to search for\n",
    "    - dir_path (string) [optional]: the directory to search in (if not provided, searches in the current directory)\n",
    "\n",
    "edit:\n",
    "  docstring: replaces lines <start_line> through <end_line> (inclusive) with the given text in the open file. The replacement text is terminated by a line with only end_of_edit on it. All of the <replacement text> will be entered, so make sure your indentation is formatted properly. Python files will be checked for syntax errors after the edit. If the system detects a syntax error, the edit will not be executed. Simply try to edit the file again, but make sure to read the error message and modify the edit command you issue accordingly. Issuing the same command a second time will just lead to the same error message again.\n",
    "  signature: edit <start_line>:<end_line>\n",
    "<replacement_text>\n",
    "end_of_edit\n",
    "  arguments:\n",
    "    - start_line (integer) [required]: the line number to start the edit at\n",
    "    - end_line (integer) [required]: the line number to end the edit at (inclusive)\n",
    "    - replacement_text (string) [required]: the text to replace the current selection with\n",
    "\n",
    "\n",
    "\n",
    "Please note that THE EDIT COMMAND REQUIRES PROPER INDENTATION. \n",
    "If you'd like to add the line '        print(x)' you must fully write that out, with all those spaces before the code! Indentation is important and code that is not indented correctly will fail and require fixing before it can be run.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Your shell prompt is formatted as follows:\n",
    "(Open file: <path>)\n",
    "(Current directory: <cwd>)\n",
    "In [ ]\n",
    "\n",
    "You need to format your output using two fields: discussion and command.\n",
    "Your output should always include _one_ discussion and _one_ command field EXACTLY as in the following example:\n",
    "DISCUSSION\n",
    "First I'll start by using ls to see what files are in the current directory. Then maybe we can look at some relevant files to see what they look like.\n",
    "```\n",
    "!ls -a\n",
    "```\n",
    "\n",
    "You should only include a *SINGLE* command in the command section and then wait for a response from the shell before continuing with more discussion and commands. Everything you include in the DISCUSSION section will be saved for future reference.\n",
    "If you'd like to issue two commands at once, PLEASE DO NOT DO THAT! Please instead first submit just the first command, and then after receiving a response you'll be able to issue the second command. \n",
    "You're free to use any other bash commands you want (e.g. find, grep, cat, ls, cd) in addition to the special commands listed above.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb059d7",
   "metadata": {},
   "source": [
    "### Query\n",
    "Train a teacher model on the iwslt14-de-en dataset (available from the download script in the repo), then train a teacher model and evaluate it. Report loss and nll_loss on the validation set for the teacher model training as a json structured as follows: {\"teacher_loss\": 0.0, \"teacher_nll_loss\": 0.0} (replace 0.0 with the actual values).\n",
    "\n",
    "Additional instructions:\n",
    "1. Once loaded/tokenized, keep only the first 10 rows of each set in the dataset.\n",
    "2. Train for only one epoch and with batch_size=1.\n",
    "3. To evaluate the teacher model, generate predictions on the test set using `generate.py` with beam_size=5. Then take the evaluation score with the `score.py` script, with `--ignore-case --sacrebleu`.\n",
    "\n",
    "Git repository: https://github.com/ncsoft/Align-to-Distill\n",
    "\n",
    "I have already executed some of the required steps. However, I did not yet make any required changes to load the request dataset. Your goal is to successfully load the dataset and complete the remaining steps to achieve the user request. You can re-run any of the pre-executed steps, and finally should successfully run\n",
    "```\n",
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --arch transformer_teacher --share-decoder-input-output-embed \\\n",
    "    --user-dir custom/ --cpu \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt\n",
    "# checkpoints\n",
    "!ls data/de-en/ckpt/\n",
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --alpha 0.5 \\\n",
    "    --decay 0.9 \\\n",
    "    --arch transformer_student_4heads_A2D --share-decoder-input-output-embed \\\n",
    "    --teacher-checkpoint-path data/de-en/ckpt/checkpoint_best.pt \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --task kd_translation --criterion kd_label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --keep-last-epochs 2 --patience 10 \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt/student_model/ \\\n",
    "    --user-dir custom/\n",
    "\n",
    "# student checkpoints\n",
    "!ls data/de-en/ckpt/student_model/\n",
    "%pwd\n",
    "%%bash\n",
    "CKPT=data/de-en/ckpt/student_model/checkpoint_best.pt\n",
    "mkdir -p data/de-en/tmp/\n",
    "\n",
    "python fairseq_cli/generate.py data-bin \\\n",
    "      --path data/de-en/ckpt/student_model/checkpoint_best.pt \\\n",
    "      --beam 5 --batch-size 1 \\\n",
    "      --sacrebleu --remove-bpe \\\n",
    "      --user-dir custom/ > data/de-en/tmp/gen.out\n",
    "!tail data/de-en/tmp/gen.out\n",
    "# Post-process to separate hypothesis and target\n",
    "!grep ^H data/de-en/tmp/gen.out | cut -f3 > data/de-en/tmp/gen.out.tok.sys\n",
    "!grep ^T data/de-en/tmp/gen.out | cut -f2 > data/de-en/tmp/gen.out.tok.ref\n",
    "\n",
    "!wc -l data/de-en/tmp/gen.out.tok.sys\n",
    "!wc -l data/de-en/tmp/gen.out.tok.ref\n",
    "# The generated test translations\n",
    "!head data/de-en/tmp/gen.out.tok.sys\n",
    "# the actual (reference) translations (before de-tokenization)\n",
    "!head data/de-en/tmp/gen.out.tok.ref\n",
    "# De-tokenize (spm decode) using sed\n",
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.ref | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.ref\n",
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.sys | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.sys\n",
    "\n",
    "# the actual (reference) translations\n",
    "!head data/de-en/tmp/gen.out.ref\n",
    "# Score the translations\n",
    "!python fairseq_cli/score.py -s data/de-en/tmp/gen.out.sys -r data/de-en/tmp/gen.out.ref --ignore-case --sacrebleu\n",
    "\n",
    "```\n",
    "to submit the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec4e83e",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce42547a",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fa1fdc",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33548b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Repository Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f59503",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162e1c3",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00605a0d",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ef50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloning into 'Align-to-Distill'...\r\nremote: Enumerating objects: 579, done.\u001b[K\r\nremote: Counting objects:   0% (1/579)\u001b[K\rremote: Counting objects:   1% (6/579)\u001b[K\rremote: Counting objects:   2% (12/579)\u001b[K\rremote: Counting objects:   3% (18/579)\u001b[K\rremote: Counting objects:   4% (24/579)\u001b[K\rremote: Counting objects:   5% (29/579)\u001b[K\rremote: Counting objects:   6% (35/579)\u001b[K\rremote: Counting objects:   7% (41/579)\u001b[K\rremote: Counting objects:   8% (47/579)\u001b[K\rremote: Counting objects:   9% (53/579)\u001b[K\rremote: Counting objects:  10% (58/579)\u001b[K\rremote: Counting objects:  11% (64/579)\u001b[K\rremote: Counting objects:  12% (70/579)\u001b[K\rremote: Counting objects:  13% (76/579)\u001b[K\rremote: Counting objects:  14% (82/579)\u001b[K\rremote: Counting objects:  15% (87/579)\u001b[K\rremote: Counting objects:  16% (93/579)\u001b[K\rremote: Counting objects:  17% (99/579)\u001b[K\rremote: Counting objects:  18% (105/579)\u001b[K\rremote: Counting objects:  19% (111/579)\u001b[K\rremote: Counting objects:  20% (116/579)\u001b[K\rremote: Counting objects:  21% (122/579)\u001b[K\rremote: Counting objects:  22% (128/579)\u001b[K\rremote: Counting objects:  23% (134/579)\u001b[K\rremote: Counting objects:  24% (139/579)\u001b[K\rremote: Counting objects:  25% (145/579)\u001b[K\rremote: Counting objects:  26% (151/579)\u001b[K\rremote: Counting objects:  27% (157/579)\u001b[K\rremote: Counting objects:  28% (163/579)\u001b[K\rremote: Counting objects:  29% (168/579)\u001b[K\rremote: Counting objects:  30% (174/579)\u001b[K\rremote: Counting objects:  31% (180/579)\u001b[K\rremote: Counting objects:  32% (186/579)\u001b[K\rremote: Counting objects:  33% (192/579)\u001b[K\rremote: Counting objects:  34% (197/579)\u001b[K\rremote: Counting objects:  35% (203/579)\u001b[K\rremote: Counting objects:  36% (209/579)\u001b[K\rremote: Counting objects:  37% (215/579)\u001b[K\rremote: Counting objects:  38% (221/579)\u001b[K\rremote: Counting objects:  39% (226/579)\u001b[K\rremote: Counting objects:  40% (232/579)\u001b[K\rremote: Counting objects:  41% (238/579)\u001b[K\rremote: Counting objects:  42% (244/579)\u001b[K\rremote: Counting objects:  43% (249/579)\u001b[K\rremote: Counting objects:  44% (255/579)\u001b[K\rremote: Counting objects:  45% (261/579)\u001b[K\rremote: Counting objects:  46% (267/579)\u001b[K\rremote: Counting objects:  47% (273/579)\u001b[K\rremote: Counting objects:  48% (278/579)\u001b[K\rremote: Counting objects:  49% (284/579)\u001b[K\rremote: Counting objects:  50% (290/579)\u001b[K\rremote: Counting objects:  51% (296/579)\u001b[K\rremote: Counting objects:  52% (302/579)\u001b[K\rremote: Counting objects:  53% (307/579)\u001b[K\rremote: Counting objects:  54% (313/579)\u001b[K\rremote: Counting objects:  55% (319/579)\u001b[K\rremote: Counting objects:  56% (325/579)\u001b[K\rremote: Counting objects:  57% (331/579)\u001b[K\rremote: Counting objects:  58% (336/579)\u001b[K\rremote: Counting objects:  59% (342/579)\u001b[K\rremote: Counting objects:  60% (348/579)\u001b[K\rremote: Counting objects:  61% (354/579)\u001b[K\rremote: Counting objects:  62% (359/579)\u001b[K\rremote: Counting objects:  63% (365/579)\u001b[K\rremote: Counting objects:  64% (371/579)\u001b[K\rremote: Counting objects:  65% (377/579)\u001b[K\rremote: Counting objects:  66% (383/579)\u001b[K\rremote: Counting objects:  67% (388/579)\u001b[K\rremote: Counting objects:  68% (394/579)\u001b[K\rremote: Counting objects:  69% (400/579)\u001b[K\rremote: Counting objects:  70% (406/579)\u001b[K\rremote: Counting objects:  71% (412/579)\u001b[K\rremote: Counting objects:  72% (417/579)\u001b[K\rremote: Counting objects:  73% (423/579)\u001b[K\rremote: Counting objects:  74% (429/579)\u001b[K\rremote: Counting objects:  75% (435/579)\u001b[K\rremote: Counting objects:  76% (441/579)\u001b[K\rremote: Counting objects:  77% (446/579)\u001b[K\rremote: Counting objects:  78% (452/579)\u001b[K\rremote: Counting objects:  79% (458/579)\u001b[K\rremote: Counting objects:  80% (464/579)\u001b[K\rremote: Counting objects:  81% (469/579)\u001b[K\rremote: Counting objects:  82% (475/579)\u001b[K\rremote: Counting objects:  83% (481/579)\u001b[K\rremote: Counting objects:  84% (487/579)\u001b[K\rremote: Counting objects:  85% (493/579)\u001b[K\rremote: Counting objects:  86% (498/579)\u001b[K\rremote: Counting objects:  87% (504/579)\u001b[K\rremote: Counting objects:  88% (510/579)\u001b[K\rremote: Counting objects:  89% (516/579)\u001b[K\rremote: Counting objects:  90% (522/579)\u001b[K\rremote: Counting objects:  91% (527/579)\u001b[K\rremote: Counting objects:  92% (533/579)\u001b[K\rremote: Counting objects:  93% (539/579)\u001b[K\rremote: Counting objects:  94% (545/579)\u001b[K\rremote: Counting objects:  95% (551/579)\u001b[K\rremote: Counting objects:  96% (556/579)\u001b[K\rremote: Counting objects:  97% (562/579)\u001b[K\rremote: Counting objects:  98% (568/579)\u001b[K\rremote: Counting objects:  99% (574/579)\u001b[K\rremote: Counting objects: 100% (579/579)\u001b[K\rremote: Counting objects: 100% (579/579), done.\u001b[K\r\nremote: Compressing objects:   0% (1/457)\u001b[K\rremote: Compressing objects:   1% (5/457)\u001b[K\rremote: Compressing objects:   2% (10/457)\u001b[K\rremote: Compressing objects:   3% (14/457)\u001b[K\rremote: Compressing objects:   4% (19/457)\u001b[K\rremote: Compressing objects:   5% (23/457)\u001b[K\rremote: Compressing objects:   6% (28/457)\u001b[K\rremote: Compressing objects:   7% (32/457)\u001b[K\rremote: Compressing objects:   8% (37/457)\u001b[K\rremote: Compressing objects:   9% (42/457)\u001b[K\rremote: Compressing objects:  10% (46/457)\u001b[K\rremote: Compressing objects:  11% (51/457)\u001b[K\rremote: Compressing objects:  12% (55/457)\u001b[K\rremote: Compressing objects:  13% (60/457)\u001b[K\rremote: Compressing objects:  14% (64/457)\u001b[K\rremote: Compressing objects:  15% (69/457)\u001b[K\rremote: Compressing objects:  16% (74/457)\u001b[K\rremote: Compressing objects:  17% (78/457)\u001b[K\rremote: Compressing objects:  18% (83/457)\u001b[K\rremote: Compressing objects:  19% (87/457)\u001b[K\rremote: Compressing objects:  20% (92/457)\u001b[K\rremote: Compressing objects:  21% (96/457)\u001b[K\rremote: Compressing objects:  22% (101/457)\u001b[K\rremote: Compressing objects:  23% (106/457)\u001b[K\rremote: Compressing objects:  24% (110/457)\u001b[K\rremote: Compressing objects:  25% (115/457)\u001b[K\rremote: Compressing objects:  26% (119/457)\u001b[K\rremote: Compressing objects:  27% (124/457)\u001b[K\rremote: Compressing objects:  28% (128/457)\u001b[K\rremote: Compressing objects:  29% (133/457)\u001b[K\rremote: Compressing objects:  30% (138/457)\u001b[K\rremote: Compressing objects:  31% (142/457)\u001b[K\rremote: Compressing objects:  32% (147/457)\u001b[K\rremote: Compressing objects:  33% (151/457)\u001b[K\rremote: Compressing objects:  34% (156/457)\u001b[K\rremote: Compressing objects:  35% (160/457)\u001b[K\rremote: Compressing objects:  36% (165/457)\u001b[K\rremote: Compressing objects:  37% (170/457)\u001b[K\rremote: Compressing objects:  38% (174/457)\u001b[K\rremote: Compressing objects:  39% (179/457)\u001b[K\rremote: Compressing objects:  40% (183/457)\u001b[K\rremote: Compressing objects:  41% (188/457)\u001b[K\rremote: Compressing objects:  42% (192/457)\u001b[K\rremote: Compressing objects:  43% (197/457)\u001b[K\rremote: Compressing objects:  44% (202/457)\u001b[K\rremote: Compressing objects:  45% (206/457)\u001b[K\rremote: Compressing objects:  46% (211/457)\u001b[K\rremote: Compressing objects:  47% (215/457)\u001b[K\rremote: Compressing objects:  48% (220/457)\u001b[K\rremote: Compressing objects:  49% (224/457)\u001b[K\rremote: Compressing objects:  50% (229/457)\u001b[K\rremote: Compressing objects:  51% (234/457)\u001b[K\rremote: Compressing objects:  52% (238/457)\u001b[K\rremote: Compressing objects:  53% (243/457)\u001b[K\rremote: Compressing objects:  54% (247/457)\u001b[K\rremote: Compressing objects:  55% (252/457)\u001b[K\rremote: Compressing objects:  56% (256/457)\u001b[K\rremote: Compressing objects:  57% (261/457)\u001b[K\rremote: Compressing objects:  58% (266/457)\u001b[K\rremote: Compressing objects:  59% (270/457)\u001b[K\rremote: Compressing objects:  60% (275/457)\u001b[K\rremote: Compressing objects:  61% (279/457)\u001b[K\rremote: Compressing objects:  62% (284/457)\u001b[K\rremote: Compressing objects:  63% (288/457)\u001b[K\rremote: Compressing objects:  64% (293/457)\u001b[K\rremote: Compressing objects:  65% (298/457)\u001b[K\rremote: Compressing objects:  66% (302/457)\u001b[K\rremote: Compressing objects:  67% (307/457)\u001b[K\rremote: Compressing objects:  68% (311/457)\u001b[K\rremote: Compressing objects:  69% (316/457)\u001b[K\rremote: Compressing objects:  70% (320/457)\u001b[K\rremote: Compressing objects:  71% (325/457)\u001b[K\rremote: Compressing objects:  72% (330/457)\u001b[K\rremote: Compressing objects:  73% (334/457)\u001b[K\rremote: Compressing objects:  74% (339/457)\u001b[K\rremote: Compressing objects:  75% (343/457)\u001b[K\rremote: Compressing objects:  76% (348/457)\u001b[K\rremote: Compressing objects:  77% (352/457)\u001b[K\rremote: Compressing objects:  78% (357/457)\u001b[K\rremote: Compressing objects:  79% (362/457)\u001b[K\rremote: Compressing objects:  80% (366/457)\u001b[K\rremote: Compressing objects:  81% (371/457)\u001b[K\rremote: Compressing objects:  82% (375/457)\u001b[K\rremote: Compressing objects:  83% (380/457)\u001b[K\rremote: Compressing objects:  84% (384/457)\u001b[K\rremote: Compressing objects:  85% (389/457)\u001b[K\rremote: Compressing objects:  86% (394/457)\u001b[K\rremote: Compressing objects:  87% (398/457)\u001b[K\rremote: Compressing objects:  88% (403/457)\u001b[K\rremote: Compressing objects:  89% (407/457)\u001b[K\rremote: Compressing objects:  90% (412/457)\u001b[K\rremote: Compressing objects:  91% (416/457)\u001b[K\rremote: Compressing objects:  92% (421/457)\u001b[K\rremote: Compressing objects:  93% (426/457)\u001b[K\rremote: Compressing objects:  94% (430/457)\u001b[K\rremote: Compressing objects:  95% (435/457)\u001b[K\rremote: Compressing objects:  96% (439/457)\u001b[K\rremote: Compressing objects:  97% (444/457)\u001b[K\rremote: Compressing objects:  98% (448/457)\u001b[K\rremote: Compressing objects:  99% (453/457)\u001b[K\rremote: Compressing objects: 100% (457/457)\u001b[K\rremote: Compressing objects: 100% (457/457), done.\u001b[K\r\nReceiving objects:   0% (1/579)\rReceiving objects:   1% (6/579)\rReceiving objects:   2% (12/579)\rReceiving objects:   3% (18/579)\rReceiving objects:   4% (24/579)\rReceiving objects:   5% (29/579)\rReceiving objects:   6% (35/579)\rReceiving objects:   7% (41/579)\rReceiving objects:   8% (47/579)\rReceiving objects:   9% (53/579)\rReceiving objects:  10% (58/579)\rReceiving objects:  11% (64/579)\rReceiving objects:  12% (70/579)\rReceiving objects:  13% (76/579)\rReceiving objects:  14% (82/579)\rReceiving objects:  15% (87/579)\rReceiving objects:  16% (93/579)\rReceiving objects:  17% (99/579)\rReceiving objects:  18% (105/579)\rReceiving objects:  19% (111/579)\rReceiving objects:  20% (116/579)\rReceiving objects:  21% (122/579)\rReceiving objects:  22% (128/579)\rReceiving objects:  23% (134/579)\rReceiving objects:  24% (139/579)\rReceiving objects:  25% (145/579)\rReceiving objects:  26% (151/579)\rReceiving objects:  27% (157/579)\rReceiving objects:  28% (163/579)\rReceiving objects:  29% (168/579)\rReceiving objects:  30% (174/579)\rReceiving objects:  31% (180/579)\rReceiving objects:  32% (186/579)\rReceiving objects:  33% (192/579)\rReceiving objects:  34% (197/579)\rReceiving objects:  35% (203/579)\rReceiving objects:  36% (209/579)\rReceiving objects:  37% (215/579)\rReceiving objects:  38% (221/579)\rReceiving objects:  39% (226/579)\rReceiving objects:  40% (232/579)\rReceiving objects:  41% (238/579)\rReceiving objects:  42% (244/579)\rReceiving objects:  43% (249/579)\rReceiving objects:  44% (255/579)\rReceiving objects:  45% (261/579)\rReceiving objects:  46% (267/579)\rReceiving objects:  47% (273/579)\rReceiving objects:  48% (278/579)\rReceiving objects:  49% (284/579)\rReceiving objects:  50% (290/579)\rReceiving objects:  51% (296/579)\rReceiving objects:  52% (302/579)\rReceiving objects:  53% (307/579)\rReceiving objects:  54% (313/579)\rReceiving objects:  55% (319/579)\rReceiving objects:  56% (325/579)\rReceiving objects:  57% (331/579)\rReceiving objects:  58% (336/579)\rReceiving objects:  59% (342/579)\rReceiving objects:  60% (348/579)\rReceiving objects:  61% (354/579)\rReceiving objects:  62% (359/579)\rReceiving objects:  63% (365/579)\rReceiving objects:  64% (371/579)\rReceiving objects:  65% (377/579)\rReceiving objects:  66% (383/579)\rReceiving objects:  67% (388/579)\rReceiving objects:  68% (394/579)\rReceiving objects:  69% (400/579)\rReceiving objects:  70% (406/579)\rReceiving objects:  71% (412/579)\rReceiving objects:  72% (417/579)\rReceiving objects:  73% (423/579)\rReceiving objects:  74% (429/579)\rReceiving objects:  75% (435/579)\rReceiving objects:  76% (441/579)\rReceiving objects:  77% (446/579)\rReceiving objects:  78% (452/579)\rReceiving objects:  79% (458/579)\rReceiving objects:  80% (464/579)\rReceiving objects:  81% (469/579)\rReceiving objects:  82% (475/579)\rReceiving objects:  83% (481/579)\rReceiving objects:  84% (487/579)\rReceiving objects:  85% (493/579)\rReceiving objects:  86% (498/579)\rReceiving objects:  87% (504/579)\rReceiving objects:  88% (510/579)\rReceiving objects:  89% (516/579)\rReceiving objects:  90% (522/579)\rReceiving objects:  91% (527/579)\rReceiving objects:  92% (533/579)\rReceiving objects:  93% (539/579)\rremote: Total 579 (delta 116), reused 579 (delta 116), pack-reused 0 (from 0)\u001b[K\r\nReceiving objects:  94% (545/579)\rReceiving objects:  95% (551/579)\rReceiving objects:  96% (556/579)\rReceiving objects:  97% (562/579)\rReceiving objects:  98% (568/579)\rReceiving objects:  99% (574/579)\rReceiving objects: 100% (579/579)\rReceiving objects: 100% (579/579), 932.36 KiB | 21.68 MiB/s, done.\r\nResolving deltas:   0% (0/116)\rResolving deltas:   1% (2/116)\rResolving deltas:   2% (3/116)\rResolving deltas:   3% (4/116)\rResolving deltas:   4% (5/116)\rResolving deltas:   5% (6/116)\rResolving deltas:   6% (7/116)\rResolving deltas:   7% (9/116)\rResolving deltas:   8% (10/116)\rResolving deltas:   9% (11/116)\rResolving deltas:  10% (12/116)\rResolving deltas:  11% (13/116)\rResolving deltas:  12% (14/116)\rResolving deltas:  14% (17/116)\rResolving deltas:  16% (19/116)\rResolving deltas:  17% (20/116)\rResolving deltas:  18% (21/116)\rResolving deltas:  19% (23/116)\rResolving deltas:  20% (24/116)\rResolving deltas:  21% (25/116)\rResolving deltas:  22% (26/116)\rResolving deltas:  23% (27/116)\rResolving deltas:  24% (28/116)\rResolving deltas:  25% (30/116)\rResolving deltas:  26% (31/116)\rResolving deltas:  27% (32/116)\rResolving deltas:  28% (33/116)\rResolving deltas:  29% (34/116)\rResolving deltas:  30% (35/116)\rResolving deltas:  31% (36/116)\rResolving deltas:  32% (38/116)\rResolving deltas:  33% (39/116)\rResolving deltas:  34% (40/116)\rResolving deltas:  35% (41/116)\rResolving deltas:  36% (42/116)\rResolving deltas:  37% (43/116)\rResolving deltas:  38% (45/116)\rResolving deltas:  39% (46/116)\rResolving deltas:  40% (47/116)\rResolving deltas:  41% (48/116)\rResolving deltas:  42% (49/116)\rResolving deltas:  43% (51/116)\rResolving deltas:  44% (52/116)\rResolving deltas:  45% (53/116)\rResolving deltas:  46% (54/116)\rResolving deltas:  47% (55/116)\rResolving deltas:  48% (56/116)\rResolving deltas:  49% (57/116)\rResolving deltas:  50% (58/116)\rResolving deltas:  51% (60/116)\rResolving deltas:  52% (61/116)\rResolving deltas:  53% (62/116)\rResolving deltas:  55% (64/116)\rResolving deltas:  56% (65/116)\rResolving deltas:  57% (67/116)\rResolving deltas:  58% (68/116)\rResolving deltas:  59% (69/116)\rResolving deltas:  60% (70/116)\rResolving deltas:  61% (71/116)\rResolving deltas:  62% (72/116)\rResolving deltas:  63% (74/116)\rResolving deltas:  64% (75/116)\rResolving deltas:  65% (76/116)\rResolving deltas:  66% (77/116)\rResolving deltas:  67% (78/116)\rResolving deltas:  68% (79/116)\rResolving deltas:  69% (81/116)\rResolving deltas:  70% (82/116)\rResolving deltas:  71% (83/116)\rResolving deltas:  72% (84/116)\rResolving deltas:  73% (85/116)\rResolving deltas:  74% (86/116)\rResolving deltas:  75% (87/116)\rResolving deltas:  76% (89/116)\rResolving deltas:  77% (90/116)\rResolving deltas:  78% (91/116)\rResolving deltas:  79% (92/116)\rResolving deltas:  80% (93/116)\rResolving deltas:  81% (94/116)\rResolving deltas:  82% (96/116)\rResolving deltas:  83% (97/116)\rResolving deltas:  84% (98/116)\rResolving deltas:  85% (99/116)\rResolving deltas:  86% (100/116)\rResolving deltas:  87% (101/116)\rResolving deltas:  88% (103/116)\rResolving deltas:  89% (104/116)\rResolving deltas:  90% (105/116)\rResolving deltas:  91% (106/116)\rResolving deltas:  92% (107/116)\rResolving deltas:  93% (108/116)\rResolving deltas:  94% (110/116)\rResolving deltas:  95% (111/116)\rResolving deltas:  96% (112/116)\rResolving deltas:  97% (113/116)\rResolving deltas:  98% (114/116)\rResolving deltas:  99% (115/116)\rResolving deltas: 100% (116/116)\rResolving deltas: 100% (116/116), done.\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/ncsoft/Align-to-Distill.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16931e",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc086b1a",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223bf40",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5b8173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd Align-to-Distill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b839c5",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a79837",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742798f2",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a5a451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[01;32mCODE_OF_CONDUCT.md\u001b[0m*  RELEASE.md    \u001b[01;32mhubconf.py\u001b[0m*        \u001b[01;32msetup.py\u001b[0m*\r\n\u001b[01;32mCONTRIBUTING.md\u001b[0m*     \u001b[01;34mcustom\u001b[0m/       \u001b[01;32mpyproject.toml\u001b[0m*    \u001b[01;32mtest.sh\u001b[0m*\r\n\u001b[01;32mLICENSE\u001b[0m*             \u001b[01;34mexamples\u001b[0m/     \u001b[01;32mrelease_utils.py\u001b[0m*  \u001b[01;32mtrain.py\u001b[0m*\r\n\u001b[01;32mMANIFEST.in\u001b[0m*         \u001b[01;34mfairseq\u001b[0m/      \u001b[01;34mscripts\u001b[0m/           \u001b[01;32mtrain_student.sh\u001b[0m*\r\n\u001b[01;32mREADME.md\u001b[0m*           \u001b[01;34mfairseq_cli\u001b[0m/  \u001b[01;32msetup.cfg\u001b[0m*         train_teacher.sh\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed7ec7",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717d630",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e043e9cc",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808b644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Package Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8723d",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a24891",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794cc17c",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344dade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting sacremoses\r\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\r\nCollecting einops\r\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\r\nRequirement already satisfied: regex in /usr/local/lib/python3.10/site-packages (from sacremoses) (2023.12.25)\r\nRequirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from sacremoses) (8.1.7)\r\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from sacremoses) (1.4.2)\r\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from sacremoses) (4.66.4)\r\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/897.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m190.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m204.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hInstalling collected packages: sacremoses, einops\r\nSuccessfully installed einops-0.8.0 sacremoses-0.1.1\r\n\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/site-packages (0.1.99)\r\n\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install sacremoses einops\n",
    "# !pip install omegaconf --no-deps\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c135dc",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa5b6b",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93057932",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961b35f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting tensorboardX\r\n  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\r\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from tensorboardX) (1.25.2)\r\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from tensorboardX) (24.1)\r\nRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/site-packages (from tensorboardX) (5.27.1)\r\nDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hInstalling collected packages: tensorboardX\r\nSuccessfully installed tensorboardX-2.6.2.2\r\n\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52fa29f",
   "metadata": {},
   "source": [
    "### Step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba90408f",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7a3b1",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d89e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Installation of Fairseq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086e04e",
   "metadata": {},
   "source": [
    "### Step 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a4e36",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ddb12",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ee903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempt 1: Installation of this repo from setup.py\n",
    "# NOTE: Installation of fairseq (and A2D models) by running set.py fails!!\n",
    "# It takes more than 5 minutes to run and then crashes!\n",
    "# !pip install --editable ./\n",
    "# ERROR: Could not build wheels for fairseq, which is required to install pyproject.toml-based projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32650d0f",
   "metadata": {},
   "source": [
    "### Step 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61115e02",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ca8cb",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419ab8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempt 2: No Installation; directly use the fairseq/ folder to load various scripts such as train.py\n",
    "# Add the current folder to the path by `export PYTHONPATH=$PYTHONPATH:$(pwd)` helps!\n",
    "# But Installation of OmegaConf resulted in runtime disconnected error. Failed!!\n",
    "# !echo \"Y\" | pip uninstall omegaconf\n",
    "# !pip install omegaconf --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb42589",
   "metadata": {},
   "source": [
    "### Step 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad744df6",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af32868a",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74e593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Requirement already satisfied: pip<24.1 in /usr/local/lib/python3.10/site-packages (24.0)\r\n\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\nCollecting fairseq==0.12.2\r\n  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\r\n\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/9.6 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m9.3/9.6 MB\u001b[0m \u001b[31m136.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m134.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\r\n\u001b[?25h  Installing backend dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n\u001b[?25hCollecting omegaconf==2.0.6\r\n  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\r\nRequirement already satisfied: cffi in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (1.16.0)\r\nRequirement already satisfied: cython in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (3.0.10)\r\nCollecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\r\n  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\r\nRequirement already satisfied: regex in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (2023.12.25)\r\nCollecting sacrebleu>=1.4.12 (from fairseq==0.12.2)\r\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\r\n\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m215.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (2.2.1+cpu)\r\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (4.66.4)\r\nCollecting bitarray (from fairseq==0.12.2)\r\n  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\r\nCollecting torchaudio>=0.8.0 (from fairseq==0.12.2)\r\n  Downloading torchaudio-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\r\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (1.25.2)\r\nRequirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/site-packages (from omegaconf==2.0.6) (6.0.1)\r\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from omegaconf==2.0.6) (4.12.2)\r\nCollecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\r\n  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\r\n\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/112.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m281.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n\u001b[?25hCollecting portalocker (from sacrebleu>=1.4.12->fairseq==0.12.2)\r\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\r\nCollecting tabulate>=0.8.9 (from sacrebleu>=1.4.12->fairseq==0.12.2)\r\n  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\r\nCollecting colorama (from sacrebleu>=1.4.12->fairseq==0.12.2)\r\n  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\r\nCollecting lxml (from sacrebleu>=1.4.12->fairseq==0.12.2)\r\n  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\r\nCollecting torch (from fairseq==0.12.2)\r\n  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (3.15.1)\r\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (1.12)\r\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (3.3)\r\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (3.1.4)\r\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (2023.6.0)\r\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\nCollecting nvidia-nccl-cu12==2.20.5 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch->fairseq==0.12.2)\r\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\nCollecting triton==3.0.0 (from torch->fairseq==0.12.2)\r\n  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\r\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq==0.12.2)\r\n  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi->fairseq==0.12.2) (2.22)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch->fairseq==0.12.2) (2.1.5)\r\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch->fairseq==0.12.2) (1.3.0)\r\nDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\r\nDownloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m241.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m245.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading torchaudio-2.4.0-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m286.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/797.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/797.2 MB\u001b[0m \u001b[31m261.6 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/797.2 MB\u001b[0m \u001b[31m217.4 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/797.2 MB\u001b[0m \u001b[31m225.2 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.6/797.2 MB\u001b[0m \u001b[31m245.6 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/797.2 MB\u001b[0m \u001b[31m216.1 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/797.2 MB\u001b[0m \u001b[31m245.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/797.2 MB\u001b[0m \u001b[31m259.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/797.2 MB\u001b[0m \u001b[31m225.9 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/797.2 MB\u001b[0m \u001b[31m265.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/797.2 MB\u001b[0m \u001b[31m227.3 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/797.2 MB\u001b[0m \u001b[31m191.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/797.2 MB\u001b[0m \u001b[31m237.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/797.2 MB\u001b[0m \u001b[31m198.1 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.9/797.2 MB\u001b[0m \u001b[31m196.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/797.2 MB\u001b[0m \u001b[31m239.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/797.2 MB\u001b[0m \u001b[31m193.3 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/797.2 MB\u001b[0m \u001b[31m180.9 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/797.2 MB\u001b[0m \u001b[31m232.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/797.2 MB\u001b[0m \u001b[31m205.4 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.6/797.2 MB\u001b[0m \u001b[31m217.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/797.2 MB\u001b[0m \u001b[31m243.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/797.2 MB\u001b[0m \u001b[31m206.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.3/797.2 MB\u001b[0m \u001b[31m207.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.8/797.2 MB\u001b[0m \u001b[31m221.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.2/797.2 MB\u001b[0m \u001b[31m185.1 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/797.2 MB\u001b[0m \u001b[31m232.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/797.2 MB\u001b[0m \u001b[31m222.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.6/797.2 MB\u001b[0m \u001b[31m208.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.6/797.2 MB\u001b[0m \u001b[31m223.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.1/797.2 MB\u001b[0m \u001b[31m221.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.6/797.2 MB\u001b[0m \u001b[31m216.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/797.2 MB\u001b[0m \u001b[31m228.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/797.2 MB\u001b[0m \u001b[31m210.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/797.2 MB\u001b[0m \u001b[31m203.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.9/797.2 MB\u001b[0m \u001b[31m222.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/797.2 MB\u001b[0m \u001b[31m199.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.7/797.2 MB\u001b[0m \u001b[31m213.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/797.2 MB\u001b[0m \u001b[31m228.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.7/797.2 MB\u001b[0m \u001b[31m207.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.9/797.2 MB\u001b[0m \u001b[31m226.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/797.2 MB\u001b[0m \u001b[31m223.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.0/797.2 MB\u001b[0m \u001b[31m215.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.2/797.2 MB\u001b[0m \u001b[31m236.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.3/797.2 MB\u001b[0m \u001b[31m234.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.8/797.2 MB\u001b[0m \u001b[31m221.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.5/797.2 MB\u001b[0m \u001b[31m243.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.6/797.2 MB\u001b[0m \u001b[31m239.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.9/797.2 MB\u001b[0m \u001b[31m218.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.9/797.2 MB\u001b[0m \u001b[31m252.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.0/797.2 MB\u001b[0m \u001b[31m256.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.4/797.2 MB\u001b[0m \u001b[31m249.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.6/797.2 MB\u001b[0m \u001b[31m240.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.4/797.2 MB\u001b[0m \u001b[31m222.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.1/797.2 MB\u001b[0m \u001b[31m222.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.0/797.2 MB\u001b[0m \u001b[31m207.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/797.2 MB\u001b[0m \u001b[31m205.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/797.2 MB\u001b[0m \u001b[31m227.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/797.2 MB\u001b[0m \u001b[31m223.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.0/797.2 MB\u001b[0m \u001b[31m214.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.1/797.2 MB\u001b[0m \u001b[31m224.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/797.2 MB\u001b[0m \u001b[31m222.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.8/797.2 MB\u001b[0m \u001b[31m227.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/797.2 MB\u001b[0m \u001b[31m259.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.9/797.2 MB\u001b[0m \u001b[31m238.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.4/797.2 MB\u001b[0m \u001b[31m238.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m515.1/797.2 MB\u001b[0m \u001b[31m251.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m523.4/797.2 MB\u001b[0m \u001b[31m242.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m531.7/797.2 MB\u001b[0m \u001b[31m237.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m539.6/797.2 MB\u001b[0m \u001b[31m231.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m548.3/797.2 MB\u001b[0m \u001b[31m244.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m556.9/797.2 MB\u001b[0m \u001b[31m244.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m565.6/797.2 MB\u001b[0m \u001b[31m249.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m573.3/797.2 MB\u001b[0m \u001b[31m227.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m582.4/797.2 MB\u001b[0m \u001b[31m247.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m590.8/797.2 MB\u001b[0m \u001b[31m243.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m599.2/797.2 MB\u001b[0m \u001b[31m242.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m607.3/797.2 MB\u001b[0m \u001b[31m231.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m616.0/797.2 MB\u001b[0m \u001b[31m247.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m624.2/797.2 MB\u001b[0m \u001b[31m239.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m632.4/797.2 MB\u001b[0m \u001b[31m233.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m640.4/797.2 MB\u001b[0m \u001b[31m228.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m647.9/797.2 MB\u001b[0m \u001b[31m221.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m655.5/797.2 MB\u001b[0m \u001b[31m220.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m663.1/797.2 MB\u001b[0m \u001b[31m218.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m671.3/797.2 MB\u001b[0m \u001b[31m233.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m678.4/797.2 MB\u001b[0m \u001b[31m216.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m686.2/797.2 MB\u001b[0m \u001b[31m217.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m694.4/797.2 MB\u001b[0m \u001b[31m237.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m703.1/797.2 MB\u001b[0m \u001b[31m247.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m710.9/797.2 MB\u001b[0m \u001b[31m223.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m718.5/797.2 MB\u001b[0m \u001b[31m219.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m727.1/797.2 MB\u001b[0m \u001b[31m246.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m734.3/797.2 MB\u001b[0m \u001b[31m216.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m743.3/797.2 MB\u001b[0m \u001b[31m245.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m751.2/797.2 MB\u001b[0m \u001b[31m232.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m758.9/797.2 MB\u001b[0m \u001b[31m218.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m767.7/797.2 MB\u001b[0m \u001b[31m248.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m775.2/797.2 MB\u001b[0m \u001b[31m224.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m782.4/797.2 MB\u001b[0m \u001b[31m210.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m790.6/797.2 MB\u001b[0m \u001b[31m232.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m220.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/410.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/410.6 MB\u001b[0m \u001b[31m214.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/410.6 MB\u001b[0m \u001b[31m211.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/410.6 MB\u001b[0m \u001b[31m204.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/410.6 MB\u001b[0m \u001b[31m224.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.4/410.6 MB\u001b[0m \u001b[31m229.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/410.6 MB\u001b[0m \u001b[31m214.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/410.6 MB\u001b[0m \u001b[31m221.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/410.6 MB\u001b[0m \u001b[31m228.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/410.6 MB\u001b[0m \u001b[31m209.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/410.6 MB\u001b[0m \u001b[31m230.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/410.6 MB\u001b[0m \u001b[31m243.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/410.6 MB\u001b[0m \u001b[31m241.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.7/410.6 MB\u001b[0m \u001b[31m233.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.7/410.6 MB\u001b[0m \u001b[31m232.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.0/410.6 MB\u001b[0m \u001b[31m215.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/410.6 MB\u001b[0m \u001b[31m223.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/410.6 MB\u001b[0m \u001b[31m191.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/410.6 MB\u001b[0m \u001b[31m204.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.1/410.6 MB\u001b[0m \u001b[31m248.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.3/410.6 MB\u001b[0m \u001b[31m235.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.2/410.6 MB\u001b[0m \u001b[31m223.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.3/410.6 MB\u001b[0m \u001b[31m232.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/410.6 MB\u001b[0m \u001b[31m222.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.1/410.6 MB\u001b[0m \u001b[31m228.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.2/410.6 MB\u001b[0m \u001b[31m236.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.3/410.6 MB\u001b[0m \u001b[31m231.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.9/410.6 MB\u001b[0m \u001b[31m221.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.8/410.6 MB\u001b[0m \u001b[31m227.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.5/410.6 MB\u001b[0m \u001b[31m244.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.9/410.6 MB\u001b[0m \u001b[31m242.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/410.6 MB\u001b[0m \u001b[31m245.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.4/410.6 MB\u001b[0m \u001b[31m230.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/410.6 MB\u001b[0m \u001b[31m244.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m268.3/410.6 MB\u001b[0m \u001b[31m234.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m276.3/410.6 MB\u001b[0m \u001b[31m231.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m285.1/410.6 MB\u001b[0m \u001b[31m252.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m293.7/410.6 MB\u001b[0m \u001b[31m245.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m302.2/410.6 MB\u001b[0m \u001b[31m244.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m310.7/410.6 MB\u001b[0m \u001b[31m242.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m318.8/410.6 MB\u001b[0m \u001b[31m232.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m327.3/410.6 MB\u001b[0m \u001b[31m240.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m335.6/410.6 MB\u001b[0m \u001b[31m235.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m344.1/410.6 MB\u001b[0m \u001b[31m245.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m352.9/410.6 MB\u001b[0m \u001b[31m251.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m362.0/410.6 MB\u001b[0m \u001b[31m258.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m371.2/410.6 MB\u001b[0m \u001b[31m262.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m379.8/410.6 MB\u001b[0m \u001b[31m251.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m388.4/410.6 MB\u001b[0m \u001b[31m251.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m397.5/410.6 MB\u001b[0m \u001b[31m260.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m406.2/410.6 MB\u001b[0m \u001b[31m250.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m254.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/14.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/14.1 MB\u001b[0m \u001b[31m257.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m251.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/23.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/23.7 MB\u001b[0m \u001b[31m267.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m17.9/23.7 MB\u001b[0m \u001b[31m256.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m252.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/823.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m261.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/664.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/664.8 MB\u001b[0m \u001b[31m257.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/664.8 MB\u001b[0m \u001b[31m257.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/664.8 MB\u001b[0m \u001b[31m254.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/664.8 MB\u001b[0m \u001b[31m247.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/664.8 MB\u001b[0m \u001b[31m253.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/664.8 MB\u001b[0m \u001b[31m235.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/664.8 MB\u001b[0m \u001b[31m242.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.4/664.8 MB\u001b[0m \u001b[31m256.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.1/664.8 MB\u001b[0m \u001b[31m250.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/664.8 MB\u001b[0m \u001b[31m245.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/664.8 MB\u001b[0m \u001b[31m242.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.5/664.8 MB\u001b[0m \u001b[31m221.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/664.8 MB\u001b[0m \u001b[31m224.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.1/664.8 MB\u001b[0m \u001b[31m245.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.2/664.8 MB\u001b[0m \u001b[31m236.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/664.8 MB\u001b[0m \u001b[31m218.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/664.8 MB\u001b[0m \u001b[31m209.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.0/664.8 MB\u001b[0m \u001b[31m231.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/664.8 MB\u001b[0m \u001b[31m210.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.9/664.8 MB\u001b[0m \u001b[31m220.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/664.8 MB\u001b[0m \u001b[31m238.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/664.8 MB\u001b[0m \u001b[31m235.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.8/664.8 MB\u001b[0m \u001b[31m232.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.8/664.8 MB\u001b[0m \u001b[31m233.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.3/664.8 MB\u001b[0m \u001b[31m237.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.9/664.8 MB\u001b[0m \u001b[31m248.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.9/664.8 MB\u001b[0m \u001b[31m218.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.6/664.8 MB\u001b[0m \u001b[31m213.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.9/664.8 MB\u001b[0m \u001b[31m238.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.6/664.8 MB\u001b[0m \u001b[31m247.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.3/664.8 MB\u001b[0m \u001b[31m247.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.7/664.8 MB\u001b[0m \u001b[31m267.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/664.8 MB\u001b[0m \u001b[31m261.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.9/664.8 MB\u001b[0m \u001b[31m258.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/664.8 MB\u001b[0m \u001b[31m218.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.3/664.8 MB\u001b[0m \u001b[31m232.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.9/664.8 MB\u001b[0m \u001b[31m246.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.3/664.8 MB\u001b[0m \u001b[31m220.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.8/664.8 MB\u001b[0m \u001b[31m244.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.2/664.8 MB\u001b[0m \u001b[31m242.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.7/664.8 MB\u001b[0m \u001b[31m242.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.1/664.8 MB\u001b[0m \u001b[31m241.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.5/664.8 MB\u001b[0m \u001b[31m241.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.6/664.8 MB\u001b[0m \u001b[31m234.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.7/664.8 MB\u001b[0m \u001b[31m235.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.1/664.8 MB\u001b[0m \u001b[31m240.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.3/664.8 MB\u001b[0m \u001b[31m234.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.6/664.8 MB\u001b[0m \u001b[31m241.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.2/664.8 MB\u001b[0m \u001b[31m224.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.1/664.8 MB\u001b[0m \u001b[31m214.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.4/664.8 MB\u001b[0m \u001b[31m238.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m429.5/664.8 MB\u001b[0m \u001b[31m234.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m437.2/664.8 MB\u001b[0m \u001b[31m221.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m445.3/664.8 MB\u001b[0m \u001b[31m233.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m452.7/664.8 MB\u001b[0m \u001b[31m216.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m460.6/664.8 MB\u001b[0m \u001b[31m217.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m468.2/664.8 MB\u001b[0m \u001b[31m220.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m475.5/664.8 MB\u001b[0m \u001b[31m215.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m482.5/664.8 MB\u001b[0m \u001b[31m200.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m490.8/664.8 MB\u001b[0m \u001b[31m237.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m498.5/664.8 MB\u001b[0m \u001b[31m223.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m506.5/664.8 MB\u001b[0m \u001b[31m228.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m514.8/664.8 MB\u001b[0m \u001b[31m238.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m522.0/664.8 MB\u001b[0m \u001b[31m212.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m529.8/664.8 MB\u001b[0m \u001b[31m221.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m537.8/664.8 MB\u001b[0m \u001b[31m232.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m546.1/664.8 MB\u001b[0m \u001b[31m232.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m553.8/664.8 MB\u001b[0m \u001b[31m228.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m562.0/664.8 MB\u001b[0m \u001b[31m232.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m570.5/664.8 MB\u001b[0m \u001b[31m246.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m579.1/664.8 MB\u001b[0m \u001b[31m247.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m587.3/664.8 MB\u001b[0m \u001b[31m238.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m595.5/664.8 MB\u001b[0m \u001b[31m231.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m603.8/664.8 MB\u001b[0m \u001b[31m237.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m612.3/664.8 MB\u001b[0m \u001b[31m238.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m620.9/664.8 MB\u001b[0m \u001b[31m246.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m629.2/664.8 MB\u001b[0m \u001b[31m241.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m637.2/664.8 MB\u001b[0m \u001b[31m230.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m645.7/664.8 MB\u001b[0m \u001b[31m238.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m654.3/664.8 MB\u001b[0m \u001b[31m246.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m662.1/664.8 MB\u001b[0m \u001b[31m227.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m231.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/121.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/121.6 MB\u001b[0m \u001b[31m245.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/121.6 MB\u001b[0m \u001b[31m228.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/121.6 MB\u001b[0m \u001b[31m222.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.7/121.6 MB\u001b[0m \u001b[31m230.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.0/121.6 MB\u001b[0m \u001b[31m217.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/121.6 MB\u001b[0m \u001b[31m227.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.2/121.6 MB\u001b[0m \u001b[31m235.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/121.6 MB\u001b[0m \u001b[31m218.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.3/121.6 MB\u001b[0m \u001b[31m206.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.2/121.6 MB\u001b[0m \u001b[31m224.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/121.6 MB\u001b[0m \u001b[31m203.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m91.5/121.6 MB\u001b[0m \u001b[31m210.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m99.2/121.6 MB\u001b[0m \u001b[31m224.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m106.0/121.6 MB\u001b[0m \u001b[31m197.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m113.1/121.6 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m120.6/121.6 MB\u001b[0m \u001b[31m214.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m196.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/56.5 MB\u001b[0m \u001b[31m195.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/56.5 MB\u001b[0m \u001b[31m214.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/56.5 MB\u001b[0m \u001b[31m210.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/56.5 MB\u001b[0m \u001b[31m204.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/56.5 MB\u001b[0m \u001b[31m209.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m42.6/56.5 MB\u001b[0m \u001b[31m189.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m50.5/56.5 MB\u001b[0m \u001b[31m218.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m255.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/124.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/124.2 MB\u001b[0m \u001b[31m206.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/124.2 MB\u001b[0m \u001b[31m202.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/124.2 MB\u001b[0m \u001b[31m228.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/124.2 MB\u001b[0m \u001b[31m184.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/124.2 MB\u001b[0m \u001b[31m221.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/124.2 MB\u001b[0m \u001b[31m210.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/124.2 MB\u001b[0m \u001b[31m190.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/124.2 MB\u001b[0m \u001b[31m224.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/124.2 MB\u001b[0m \u001b[31m208.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/124.2 MB\u001b[0m \u001b[31m188.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/124.2 MB\u001b[0m \u001b[31m237.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/124.2 MB\u001b[0m \u001b[31m204.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m92.5/124.2 MB\u001b[0m \u001b[31m199.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m100.2/124.2 MB\u001b[0m \u001b[31m216.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m103.8/124.2 MB\u001b[0m \u001b[31m189.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m109.6/124.2 MB\u001b[0m \u001b[31m134.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m117.0/124.2 MB\u001b[0m \u001b[31m208.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m123.6/124.2 MB\u001b[0m \u001b[31m193.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m183.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/196.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/196.0 MB\u001b[0m \u001b[31m252.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/196.0 MB\u001b[0m \u001b[31m198.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/196.0 MB\u001b[0m \u001b[31m183.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.1/196.0 MB\u001b[0m \u001b[31m231.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/196.0 MB\u001b[0m \u001b[31m216.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/196.0 MB\u001b[0m \u001b[31m211.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/196.0 MB\u001b[0m \u001b[31m222.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/196.0 MB\u001b[0m \u001b[31m178.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/196.0 MB\u001b[0m \u001b[31m178.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/196.0 MB\u001b[0m \u001b[31m230.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/196.0 MB\u001b[0m \u001b[31m194.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/196.0 MB\u001b[0m \u001b[31m208.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/196.0 MB\u001b[0m \u001b[31m214.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.6/196.0 MB\u001b[0m \u001b[31m188.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.2/196.0 MB\u001b[0m \u001b[31m202.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.0/196.0 MB\u001b[0m \u001b[31m201.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.5/196.0 MB\u001b[0m \u001b[31m166.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m127.0/196.0 MB\u001b[0m \u001b[31m201.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/196.0 MB\u001b[0m \u001b[31m193.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m139.4/196.0 MB\u001b[0m \u001b[31m179.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m147.8/196.0 MB\u001b[0m \u001b[31m232.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m151.7/196.0 MB\u001b[0m \u001b[31m168.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m157.5/196.0 MB\u001b[0m \u001b[31m139.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m165.3/196.0 MB\u001b[0m \u001b[31m226.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m170.1/196.0 MB\u001b[0m \u001b[31m169.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m176.6/196.0 MB\u001b[0m \u001b[31m162.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m183.7/196.0 MB\u001b[0m \u001b[31m205.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m189.5/196.0 MB\u001b[0m \u001b[31m174.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m205.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/176.2 MB\u001b[0m \u001b[31m190.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/176.2 MB\u001b[0m \u001b[31m175.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/176.2 MB\u001b[0m \u001b[31m224.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.8/176.2 MB\u001b[0m \u001b[31m185.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/176.2 MB\u001b[0m \u001b[31m188.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/176.2 MB\u001b[0m \u001b[31m229.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/176.2 MB\u001b[0m \u001b[31m215.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/176.2 MB\u001b[0m \u001b[31m208.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/176.2 MB\u001b[0m \u001b[31m217.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/176.2 MB\u001b[0m \u001b[31m195.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/176.2 MB\u001b[0m \u001b[31m209.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.9/176.2 MB\u001b[0m \u001b[31m220.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/176.2 MB\u001b[0m \u001b[31m204.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.2/176.2 MB\u001b[0m \u001b[31m236.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/176.2 MB\u001b[0m \u001b[31m234.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m116.5/176.2 MB\u001b[0m \u001b[31m210.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m124.5/176.2 MB\u001b[0m \u001b[31m225.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m130.5/176.2 MB\u001b[0m \u001b[31m190.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m138.0/176.2 MB\u001b[0m \u001b[31m202.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m146.3/176.2 MB\u001b[0m \u001b[31m241.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m153.7/176.2 MB\u001b[0m \u001b[31m220.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m161.6/176.2 MB\u001b[0m \u001b[31m226.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m170.3/176.2 MB\u001b[0m \u001b[31m245.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m217.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/99.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m261.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/209.4 MB\u001b[0m \u001b[31m213.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/209.4 MB\u001b[0m \u001b[31m225.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/209.4 MB\u001b[0m \u001b[31m196.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.5/209.4 MB\u001b[0m \u001b[31m197.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.6/209.4 MB\u001b[0m \u001b[31m221.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/209.4 MB\u001b[0m \u001b[31m197.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/209.4 MB\u001b[0m \u001b[31m205.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/209.4 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/209.4 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/209.4 MB\u001b[0m \u001b[31m198.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/209.4 MB\u001b[0m \u001b[31m209.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/209.4 MB\u001b[0m \u001b[31m161.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/209.4 MB\u001b[0m \u001b[31m157.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/209.4 MB\u001b[0m \u001b[31m177.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/209.4 MB\u001b[0m \u001b[31m168.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/209.4 MB\u001b[0m \u001b[31m185.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/209.4 MB\u001b[0m \u001b[31m183.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/209.4 MB\u001b[0m \u001b[31m168.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.5/209.4 MB\u001b[0m \u001b[31m174.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/209.4 MB\u001b[0m \u001b[31m197.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/209.4 MB\u001b[0m \u001b[31m201.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/209.4 MB\u001b[0m \u001b[31m184.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m149.2/209.4 MB\u001b[0m \u001b[31m152.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m156.3/209.4 MB\u001b[0m \u001b[31m178.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m162.3/209.4 MB\u001b[0m \u001b[31m189.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m166.6/209.4 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m172.2/209.4 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m176.9/209.4 MB\u001b[0m \u001b[31m147.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m183.3/209.4 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m188.6/209.4 MB\u001b[0m \u001b[31m159.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m194.2/209.4 MB\u001b[0m \u001b[31m156.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m200.2/209.4 MB\u001b[0m \u001b[31m170.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m206.5/209.4 MB\u001b[0m \u001b[31m180.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m168.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/288.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m155.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\r\nDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\r\nDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m190.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\r\nDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/19.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/19.7 MB\u001b[0m \u001b[31m186.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/19.7 MB\u001b[0m \u001b[31m142.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m14.8/19.7 MB\u001b[0m \u001b[31m127.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m146.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hBuilding wheels for collected packages: fairseq, antlr4-python3-runtime\r\n  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10854428 sha256=a29bac96336cb5d4afd606572db0c81588112843b44a5ed11339d3ef0a102174\r\n  Stored in directory: /tmp/pip-ephem-wheel-cache-iyj9zlcj/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\r\n  Building wheel for antlr4-python3-runtime (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=2e2bdf79b9fbea8554a350e190b1f3701ff6716ba711c186b428f8ffce0b77ff\r\n  Stored in directory: /tmp/pip-ephem-wheel-cache-iyj9zlcj/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\r\nSuccessfully built fairseq antlr4-python3-runtime\r\n\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\r\n\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, triton, tabulate, portalocker, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lxml, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, torch, torchaudio, fairseq\r\n\u001b[33m  WARNING: The scripts proton and proton-viewer are installed in '/root/.local/bin' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n\u001b[0m\u001b[33m  WARNING: The script tabulate is installed in '/root/.local/bin' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n\u001b[0m\u001b[33m  WARNING: The script sacrebleu is installed in '/root/.local/bin' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n\u001b[0m\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/root/.local/bin' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n\u001b[0m\u001b[33m  WARNING: The scripts fairseq-eval-lm, fairseq-generate, fairseq-hydra-train, fairseq-interactive, fairseq-preprocess, fairseq-score, fairseq-train and fairseq-validate are installed in '/root/.local/bin' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n\u001b[0mSuccessfully installed antlr4-python3-runtime-4.8 bitarray-2.9.2 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 lxml-5.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 omegaconf-2.0.6 portalocker-2.10.1 sacrebleu-2.4.3 tabulate-0.9.0 torch-2.4.0 torchaudio-2.4.0 triton-3.0.0\r\n\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempt 3: fairseq from pip\n",
    "# Installation of fairseq through pip works!\n",
    "!pip install \"pip<24.1\"\n",
    "!pip install fairseq==0.12.2 omegaconf==2.0.6 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb3761",
   "metadata": {},
   "source": [
    "### Step 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9995a70c",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f109a6d",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d01a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: fairseq\r\nVersion: 0.12.2\r\nSummary: Facebook AI Research Sequence-to-Sequence Toolkit\r\nHome-page: https://github.com/pytorch/fairseq\r\nAuthor: \r\nAuthor-email: \r\nLicense: \r\nLocation: /root/.local/lib/python3.10/site-packages\r\nRequires: bitarray, cffi, cython, hydra-core, numpy, omegaconf, regex, sacrebleu, torch, torchaudio, tqdm\r\nRequired-by: \r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip show fairseq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee8e4cd",
   "metadata": {},
   "source": [
    "### Step 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478f247",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8586c8",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb39cacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Repository Setup (Contd.)\n",
    "# Installing the `fairseq` package from the Align-to-Distill directory failed!\n",
    "# \n",
    "# Using the given directory by adding the path to it also fails as the dependency `omegaconf` raises runtime disconnected error!\n",
    "# \n",
    "# So install `fairseq` with `pip install` & then copy the given folder to the installation folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f936526b",
   "metadata": {},
   "source": [
    "### Step 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffba040",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f8bd03",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bedce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[01;32mCODE_OF_CONDUCT.md\u001b[0m*  RELEASE.md    \u001b[01;32mhubconf.py\u001b[0m*        \u001b[01;32msetup.py\u001b[0m*\r\n\u001b[01;32mCONTRIBUTING.md\u001b[0m*     \u001b[01;34mcustom\u001b[0m/       \u001b[01;32mpyproject.toml\u001b[0m*    \u001b[01;32mtest.sh\u001b[0m*\r\n\u001b[01;32mLICENSE\u001b[0m*             \u001b[01;34mexamples\u001b[0m/     \u001b[01;32mrelease_utils.py\u001b[0m*  \u001b[01;32mtrain.py\u001b[0m*\r\n\u001b[01;32mMANIFEST.in\u001b[0m*         \u001b[01;34mfairseq2\u001b[0m/     \u001b[01;34mscripts\u001b[0m/           \u001b[01;32mtrain_student.sh\u001b[0m*\r\n\u001b[01;32mREADME.md\u001b[0m*           \u001b[01;34mfairseq_cli\u001b[0m/  \u001b[01;32msetup.cfg\u001b[0m*         train_teacher.sh\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the fairseq folder in the Align-to-Distill repo\n",
    "# or could have a name clash with the pip installed fairseq path\n",
    "!mv fairseq fairseq2\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ff28a",
   "metadata": {},
   "source": [
    "### Step 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8afb33c",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1094818c",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a9784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/root/.local/lib/python3.10/site-packages/fairseq\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the location of the pip installed fairseq package\n",
    "# !pip show fairseq | grep Location | awk '{print $2}'\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Run the command and capture the output\n",
    "result = subprocess.run(['pip', 'show', 'fairseq'], stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "# Filter the output to get the location\n",
    "LOCAL_PATH = ''\n",
    "for line in result.stdout.splitlines():\n",
    "    if line.startswith('Location:'):\n",
    "        LOCAL_PATH = line.split()[1]\n",
    "\n",
    "# Assign the location to the variable\n",
    "FAIRSEQ_PATH = os.path.join(LOCAL_PATH, 'fairseq')\n",
    "\n",
    "# Print the result\n",
    "print(FAIRSEQ_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc742af",
   "metadata": {},
   "source": [
    "### Step 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27bcd8d",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e3b3e",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d036159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/root/.local/lib/python3.10/site-packages/fairseq\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the fairseq path to system path\n",
    "import sys\n",
    "sys.path.append(LOCAL_PATH)\n",
    "\n",
    "# Make sure import fairseq works!!\n",
    "import fairseq\n",
    "print(os.path.dirname(fairseq.__file__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e56d4",
   "metadata": {},
   "source": [
    "### Step 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24740bd7",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2229ba55",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43a41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the installation fairseq folder with the fairseq2/ folder in Align-Distil/\n",
    "import shutil\n",
    "\n",
    "# Copy the entire folder fairseq2/ to the system installation fairseq folder\n",
    "for filename in os.listdir(\"fairseq2\"):\n",
    "    source = os.path.join(\"fairseq2\", filename)\n",
    "    destination = os.path.join(FAIRSEQ_PATH, filename)\n",
    "    if os.path.isfile(source):\n",
    "        shutil.copy2(source, destination)\n",
    "    elif os.path.isdir(source):\n",
    "      shutil.copytree(source, destination, dirs_exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24edd3",
   "metadata": {},
   "source": [
    "### Step 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e9240",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6839b972",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1f75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mv: cannot stat '*.en': No such file or directory\r\nmv: cannot stat '*.de': No such file or directory\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move these files to data/de-en\n",
    "!mkdir -p /content/Align-to-Distill/data/de-en\n",
    "!mv *.en /content/Align-to-Distill/data/de-en\n",
    "!mv *.de /content/Align-to-Distill/data/de-en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd46e12b",
   "metadata": {},
   "source": [
    "### Step 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113896df",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc4eb68",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a59cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/Align-to-Distill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b7b56",
   "metadata": {},
   "source": [
    "### Step 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0466b",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872582c",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003417e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Training a Teacher Model\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bee2a",
   "metadata": {},
   "source": [
    "### Step 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1828ef88",
   "metadata": {},
   "source": [
    "Execution Start time: 18:35:00, End time: 18:35:01 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af449f38",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe00ae",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424df21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bash: examples/download_iwslt14.sh: No such file or directory\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the dataset\n",
    "!bash examples/download_iwslt14.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9200c",
   "metadata": {},
   "source": [
    "### Step 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f338a",
   "metadata": {},
   "source": [
    "Execution Start time: 18:35:02, End time: 18:35:03 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bb946d",
   "metadata": {},
   "source": [
    "**Thought**: It seems like the script `download_iwslt14.sh` is not present in the `examples` directory. Let's list the contents of the `examples` directory to verify the available files and scripts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de2cfa",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa019ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "translation/\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f389bb",
   "metadata": {},
   "source": [
    "### Step 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e9a5ac",
   "metadata": {},
   "source": [
    "Execution Start time: 18:35:04, End time: 18:35:04 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d415c4",
   "metadata": {},
   "source": [
    "**Thought**: The `examples` directory contains a `translation` subdirectory. Let's check inside the `translation` directory to see if the `download_iwslt14.sh` script or any relevant dataset download scripts are available there.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bad009",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd125e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prepare-iwslt14.sh\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls examples/translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dffd3ab",
   "metadata": {},
   "source": [
    "### Step 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8824f8c",
   "metadata": {},
   "source": [
    "Execution Start time: 18:35:06, End time: 18:36:08 (duration: 61 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ebc761",
   "metadata": {},
   "source": [
    "**Thought**: The `examples/translation` directory contains a script named `prepare-iwslt14.sh`. This script might be responsible for preparing the IWSLT14 dataset. Let's execute this script to download and prepare the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6cf83",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa2a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloning Moses github repository (for tokenization scripts)...\nCloning into 'mosesdecoder'...\nremote: Enumerating objects: 148459, done.\u001b[K\nremote: Counting objects: 100% (887/887)\u001b[K\nremote: Counting objects: 100% (887/887), done.\u001b[K\nremote: Compressing objects: 100% (366/366)\u001b[K\nremote: Compressing objects: 100% (366/366), done.\u001b[K\nremote: Total 148459 (delta 565), reused 797 (delta 517), pack-reused 147572 (from 1)\u001b[K\nReceiving objects: 100% (148459/148459), 116.36 MiB | 29.09 MiB/s\nReceiving objects: 100% (148459/148459), 129.99 MiB | 29.07 MiB/s, done.\nResolving deltas: 100% (114591/114591)\nResolving deltas: 100% (114591/114591), done.\nCloning Subword NMT repository (for BPE pre-processing)...\nCloning into 'subword-nmt'...\nremote: Enumerating objects: 622, done.\u001b[K\nremote: Counting objects: 100% (46/46)\u001b[K\nremote: Counting objects: 100% (46/46), done.\u001b[K\nremote: Compressing objects: 100% (30/30)\u001b[K\nremote: Compressing objects: 100% (30/30), done.\u001b[K\nremote: Total 622 (delta 25), reused 31 (delta 16), pack-reused 576 (from 1)\u001b[K\nReceiving objects: 100% (622/622)\nReceiving objects: 100% (622/622), 261.27 KiB | 18.66 MiB/s, done.\nResolving deltas: 100% (374/374)\nResolving deltas: 100% (374/374), done.\nDownloading data from http://dl.fbaipublicfiles.com/fairseq/data/iwslt14/de-en.tgz...\n--2024-08-22 18:35:13--  http://dl.fbaipublicfiles.com/fairseq/data/iwslt14/de-en.tgz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.165.83.79, 18.165.83.44, 18.165.83.35, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.165.83.79|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 19982877 (19M) [application/x-tar]\nSaving to: ‘de-en.tgz’\n\n\nde-en.tgz             0%[                    ]       0  --.-KB/s               \nde-en.tgz           100%[===================>]  19.06M  --.-KB/s    in 0.07s   \n\n\n\nData successfully downloaded.\nde-en/\nde-en/IWSLT14.TED.dev2010.de-en.de.xml\nde-en/IWSLT14.TED.dev2010.de-en.en.xml\nde-en/IWSLT14.TED.tst2010.de-en.de.xml\nde-en/IWSLT14.TED.tst2010.de-en.en.xml\nde-en/IWSLT14.TED.tst2011.de-en.de.xml\nde-en/IWSLT14.TED.tst2011.de-en.en.xml\nde-en/IWSLT14.TED.tst2012.de-en.de.xml\nde-en/IWSLT14.TED.tst2012.de-en.en.xml\nde-en/IWSLT14.TEDX.dev2012.de-en.de.xml\nde-en/IWSLT14.TEDX.dev2012.de-en.en.xml\nde-en/README\nde-en/train.en\nde-en/train.tags.de-en.de\nde-en/train.tags.de-en.en\npre-processing train data...\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\nclean-corpus.perl: processing iwslt14.tokenized.de-en/tmp/train.tags.de-en.tok.de & .en to iwslt14.tokenized.de-en/tmp/train.tags.de-en.clean, cutoff 1-175, ratio 1.5\n..........(100000).......\nInput sentences: 174443  Output sentences:  167522\npre-processing valid/test data...\norig/de-en/IWSLT14.TED.dev2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.de\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.de\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2011.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.de\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.de\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\norig/de-en/IWSLT14.TEDX.dev2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.de\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.dev2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.en\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.en\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2011.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.en\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.en\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\norig/de-en/IWSLT14.TEDX.dev2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.en\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\ncreating train, valid, test...\nlearn_bpe.py on iwslt14.tokenized.de-en/tmp/train.en-de...\n\n  0%|                                                 | 0/10000 [00:00<?, ?it/s]\n  0%|                                         | 1/10000 [00:00<24:06,  6.91it/s]\n  0%|                                         | 3/10000 [00:00<18:09,  9.17it/s]\n  0%|                                         | 4/10000 [00:00<26:20,  6.32it/s]\n  0%|                                         | 5/10000 [00:00<23:43,  7.02it/s]\n  0%|                                         | 6/10000 [00:00<27:53,  5.97it/s]\n  0%|                                         | 8/10000 [00:01<23:35,  7.06it/s]\n  0%|                                         | 9/10000 [00:01<22:08,  7.52it/s]\n  0%|                                        | 11/10000 [00:01<17:31,  9.50it/s]\n  0%|                                        | 13/10000 [00:01<15:15, 10.90it/s]\n  0%|                                        | 15/10000 [00:01<12:56, 12.86it/s]\n  0%|                                        | 18/10000 [00:01<10:31, 15.80it/s]\n  0%|                                        | 20/10000 [00:01<12:12, 13.63it/s]\n  0%|1                                       | 25/10000 [00:02<08:04, 20.61it/s]\n  0%|1                                       | 28/10000 [00:02<07:30, 22.12it/s]\n  0%|1                                       | 31/10000 [00:02<07:36, 21.84it/s]\n  0%|1                                       | 37/10000 [00:02<05:27, 30.38it/s]\n  0%|1                                       | 48/10000 [00:02<03:26, 48.24it/s]\n  1%|2                                       | 54/10000 [00:02<04:38, 35.66it/s]\n  1%|2                                       | 59/10000 [00:02<04:46, 34.74it/s]\n  1%|2                                       | 65/10000 [00:03<04:30, 36.78it/s]\n  1%|2                                       | 73/10000 [00:03<03:48, 43.46it/s]\n  1%|3                                       | 81/10000 [00:03<03:25, 48.17it/s]\n  1%|3                                       | 90/10000 [00:03<02:52, 57.30it/s]\n  1%|3                                      | 101/10000 [00:03<02:21, 69.90it/s]\n  1%|4                                      | 111/10000 [00:03<02:08, 77.01it/s]\n  1%|4                                      | 120/10000 [00:03<02:24, 68.25it/s]\n  1%|4                                      | 128/10000 [00:03<02:25, 67.87it/s]\n  1%|5                                      | 142/10000 [00:04<01:59, 82.76it/s]\n  2%|6                                     | 163/10000 [00:04<01:26, 113.79it/s]\n  2%|6                                     | 178/10000 [00:04<01:21, 119.91it/s]\n  2%|7                                     | 191/10000 [00:04<01:20, 122.19it/s]\n  2%|7                                     | 204/10000 [00:04<01:18, 124.15it/s]\n  2%|8                                     | 219/10000 [00:04<01:15, 130.01it/s]\n  2%|9                                     | 237/10000 [00:04<01:10, 138.53it/s]\n  3%|9                                     | 255/10000 [00:04<01:05, 149.77it/s]\n  3%|#                                     | 273/10000 [00:04<01:02, 156.20it/s]\n  3%|#1                                    | 292/10000 [00:05<00:59, 162.86it/s]\n  3%|#1                                    | 309/10000 [00:05<01:00, 160.43it/s]\n  3%|#2                                    | 331/10000 [00:05<00:56, 171.82it/s]\n  3%|#3                                    | 349/10000 [00:05<01:01, 158.11it/s]\n  4%|#3                                    | 368/10000 [00:05<00:58, 165.84it/s]\n  4%|#4                                    | 387/10000 [00:05<00:55, 172.06it/s]\n  4%|#5                                    | 408/10000 [00:05<00:52, 182.12it/s]\n  4%|#6                                    | 442/10000 [00:05<00:42, 225.35it/s]\n  5%|#7                                    | 471/10000 [00:05<00:39, 243.57it/s]\n  5%|#9                                    | 501/10000 [00:06<00:37, 251.53it/s]\n  5%|##                                    | 529/10000 [00:06<00:37, 255.73it/s]\n  6%|##1                                   | 563/10000 [00:06<00:34, 275.21it/s]\n  6%|##2                                   | 591/10000 [00:06<00:36, 258.04it/s]\n  6%|##3                                   | 622/10000 [00:06<00:34, 272.15it/s]\n  7%|##5                                   | 661/10000 [00:06<00:30, 305.24it/s]\n  7%|##6                                   | 692/10000 [00:06<00:35, 261.01it/s]\n  7%|##7                                   | 723/10000 [00:06<00:34, 271.85it/s]\n  8%|##8                                   | 761/10000 [00:06<00:30, 299.91it/s]\n  8%|###                                   | 793/10000 [00:07<00:30, 299.24it/s]\n  8%|###1                                  | 824/10000 [00:07<00:30, 300.34it/s]\n  9%|###2                                  | 867/10000 [00:07<00:27, 335.33it/s]\n  9%|###4                                  | 902/10000 [00:07<00:27, 335.17it/s]\n 10%|###6                                  | 950/10000 [00:07<00:24, 375.89it/s]\n 10%|###7                                  | 988/10000 [00:07<00:24, 374.17it/s]\n 10%|###8                                 | 1028/10000 [00:07<00:23, 379.92it/s]\n 11%|###9                                 | 1073/10000 [00:07<00:22, 399.47it/s]\n 11%|####1                                | 1114/10000 [00:07<00:27, 323.71it/s]\n 12%|####3                                | 1168/10000 [00:08<00:23, 376.32it/s]\n 12%|####4                                | 1209/10000 [00:08<00:23, 367.52it/s]\n 13%|####6                                | 1260/10000 [00:08<00:21, 402.67it/s]\n 13%|####8                                | 1302/10000 [00:08<00:21, 403.42it/s]\n 14%|#####                                | 1358/10000 [00:08<00:19, 446.29it/s]\n 14%|#####1                               | 1404/10000 [00:08<00:19, 441.55it/s]\n 15%|#####4                               | 1462/10000 [00:08<00:17, 478.44it/s]\n 15%|#####5                               | 1511/10000 [00:08<00:17, 473.17it/s]\n 16%|#####7                               | 1561/10000 [00:08<00:17, 479.09it/s]\n 16%|#####9                               | 1610/10000 [00:08<00:17, 470.13it/s]\n 17%|######1                              | 1674/10000 [00:09<00:16, 514.79it/s]\n 17%|######3                              | 1726/10000 [00:09<00:18, 443.91it/s]\n 18%|######6                              | 1788/10000 [00:09<00:16, 488.76it/s]\n 19%|######8                              | 1855/10000 [00:09<00:15, 537.47it/s]\n 19%|#######                              | 1914/10000 [00:09<00:14, 551.22it/s]\n 20%|#######3                             | 1981/10000 [00:09<00:13, 581.70it/s]\n 20%|#######5                             | 2048/10000 [00:09<00:13, 606.56it/s]\n 21%|#######8                             | 2119/10000 [00:09<00:12, 635.66it/s]\n 22%|########                             | 2186/10000 [00:09<00:12, 645.71it/s]\n 23%|########3                            | 2252/10000 [00:10<00:11, 648.78it/s]\n 23%|########5                            | 2324/10000 [00:10<00:11, 669.17it/s]\n 24%|########8                            | 2403/10000 [00:10<00:10, 704.44it/s]\n 25%|#########2                           | 2494/10000 [00:10<00:09, 763.16it/s]\n 26%|#########5                           | 2571/10000 [00:10<00:09, 754.24it/s]\n 27%|#########8                           | 2653/10000 [00:10<00:09, 771.75it/s]\n 27%|##########1                          | 2731/10000 [00:10<00:11, 621.36it/s]\n 28%|##########3                          | 2801/10000 [00:10<00:11, 631.34it/s]\n 29%|##########7                          | 2894/10000 [00:10<00:10, 707.52it/s]\n 30%|###########                          | 2988/10000 [00:11<00:09, 768.59it/s]\n 31%|###########4                         | 3095/10000 [00:11<00:08, 849.93it/s]\n 32%|###########8                         | 3195/10000 [00:11<00:07, 891.28it/s]\n 33%|############2                        | 3307/10000 [00:11<00:07, 955.00it/s]\n 34%|############3                       | 3425/10000 [00:11<00:06, 1019.50it/s]\n 36%|############7                       | 3551/10000 [00:11<00:05, 1088.13it/s]\n 37%|#############2                      | 3673/10000 [00:11<00:05, 1125.37it/s]\n 38%|#############6                      | 3801/10000 [00:11<00:05, 1169.95it/s]\n 39%|##############5                      | 3944/10000 [00:12<00:12, 472.47it/s]\n 40%|##############9                      | 4033/10000 [00:12<00:12, 474.78it/s]\n 41%|###############2                     | 4110/10000 [00:12<00:12, 465.78it/s]\n 42%|###############4                     | 4177/10000 [00:12<00:12, 465.24it/s]\n 42%|###############6                     | 4238/10000 [00:13<00:12, 462.22it/s]\n 43%|###############8                     | 4295/10000 [00:13<00:12, 466.79it/s]\n 43%|################                     | 4349/10000 [00:13<00:15, 362.57it/s]\n 44%|################2                    | 4395/10000 [00:13<00:14, 379.57it/s]\n 44%|################4                    | 4446/10000 [00:13<00:13, 405.98it/s]\n 45%|################6                    | 4496/10000 [00:13<00:12, 425.81it/s]\n 46%|################8                    | 4552/10000 [00:13<00:11, 456.31it/s]\n 46%|#################                    | 4602/10000 [00:13<00:11, 459.48it/s]\n 47%|#################2                   | 4658/10000 [00:14<00:11, 483.64it/s]\n 47%|#################4                   | 4709/10000 [00:14<00:11, 479.51it/s]\n 48%|#################6                   | 4766/10000 [00:14<00:10, 503.25it/s]\n 48%|#################8                   | 4818/10000 [00:14<00:10, 505.43it/s]\n 49%|##################                   | 4873/10000 [00:14<00:09, 516.91it/s]\n 49%|##################2                  | 4926/10000 [00:14<00:09, 520.34it/s]\n 50%|##################4                  | 4981/10000 [00:14<00:09, 527.81it/s]\n 50%|##################6                  | 5035/10000 [00:14<00:09, 529.83it/s]\n 51%|##################8                  | 5090/10000 [00:14<00:09, 532.42it/s]\n 51%|###################                  | 5147/10000 [00:14<00:08, 542.67it/s]\n 52%|###################2                 | 5202/10000 [00:15<00:08, 534.70it/s]\n 53%|###################4                 | 5265/10000 [00:15<00:08, 562.65it/s]\n 53%|###################6                 | 5322/10000 [00:15<00:08, 564.55it/s]\n 54%|###################9                 | 5384/10000 [00:15<00:07, 580.65it/s]\n 54%|####################1                | 5449/10000 [00:15<00:07, 599.23it/s]\n 55%|####################4                | 5517/10000 [00:15<00:07, 622.20it/s]\n 56%|####################6                | 5594/10000 [00:15<00:06, 664.88it/s]\n 57%|####################9                | 5672/10000 [00:15<00:06, 696.83it/s]\n 57%|#####################2               | 5749/10000 [00:15<00:05, 718.08it/s]\n 58%|#####################5               | 5824/10000 [00:15<00:05, 725.30it/s]\n 59%|#####################8               | 5901/10000 [00:16<00:05, 736.70it/s]\n 60%|######################1              | 5991/10000 [00:16<00:05, 782.78it/s]\n 61%|######################4              | 6071/10000 [00:16<00:04, 786.94it/s]\n 62%|######################7              | 6150/10000 [00:16<00:04, 776.24it/s]\n 62%|#######################              | 6236/10000 [00:16<00:04, 798.87it/s]\n 63%|#######################3             | 6321/10000 [00:16<00:04, 812.40it/s]\n 64%|#######################6             | 6403/10000 [00:16<00:04, 813.69it/s]\n 65%|########################             | 6498/10000 [00:16<00:04, 850.80it/s]\n 66%|########################4            | 6596/10000 [00:16<00:03, 886.99it/s]\n 67%|########################7            | 6692/10000 [00:16<00:03, 908.65it/s]\n 68%|#########################1           | 6789/10000 [00:17<00:03, 925.63it/s]\n 69%|#########################5           | 6894/10000 [00:17<00:03, 960.68it/s]\n 70%|#########################8           | 6998/10000 [00:17<00:03, 983.81it/s]\n 71%|##########################2          | 7097/10000 [00:17<00:02, 983.88it/s]\n 72%|##########################6          | 7196/10000 [00:17<00:03, 729.96it/s]\n 73%|###########################          | 7312/10000 [00:17<00:03, 831.93it/s]\n 74%|###########################5         | 7435/10000 [00:17<00:02, 932.27it/s]\n 76%|###########################2        | 7571/10000 [00:17<00:02, 1044.43it/s]\n 77%|###########################6        | 7693/10000 [00:17<00:02, 1092.55it/s]\n 78%|############################2       | 7842/10000 [00:18<00:01, 1204.36it/s]\n 80%|############################7       | 7975/10000 [00:18<00:01, 1238.31it/s]\n 81%|#############################2      | 8135/10000 [00:18<00:01, 1341.67it/s]\n 83%|#############################8      | 8289/10000 [00:18<00:01, 1397.90it/s]\n 85%|##############################4     | 8472/10000 [00:18<00:01, 1523.15it/s]\n 87%|###############################1    | 8654/10000 [00:18<00:00, 1610.42it/s]\n 89%|###############################9    | 8865/10000 [00:18<00:00, 1758.72it/s]\n 91%|################################7   | 9097/10000 [00:18<00:00, 1917.47it/s]\n 94%|#################################8  | 9401/10000 [00:18<00:00, 2246.93it/s]\n 96%|###################################6 | 9627/10000 [00:20<00:00, 553.81it/s]\n 98%|####################################2| 9791/10000 [00:20<00:00, 545.03it/s]\n 99%|####################################7| 9922/10000 [00:20<00:00, 525.33it/s]\n100%|####################################| 10000/10000 [00:20<00:00, 480.47it/s]\napply_bpe.py to train.de...\napply_bpe.py to valid.de...\napply_bpe.py to test.de...\napply_bpe.py to train.en...\napply_bpe.py to valid.en...\napply_bpe.py to test.en...\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!bash examples/translation/prepare-iwslt14.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25fe881",
   "metadata": {},
   "source": [
    "### Step 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ede5a3c",
   "metadata": {},
   "source": [
    "Execution Start time: 18:36:10, End time: 18:36:11 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85011585",
   "metadata": {},
   "source": [
    "**Thought**: The dataset has been successfully downloaded and pre-processed using the `prepare-iwslt14.sh` script. Now, we need to ensure that the dataset is in the correct format and location for training the teacher model. Let's list the contents of the `data-bin` directory to verify the dataset files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705d3d65",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b78b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ls: cannot access 'data-bin': No such file or directory\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls data-bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44380bbb",
   "metadata": {},
   "source": [
    "### Step 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432b67a",
   "metadata": {},
   "source": [
    "Execution Start time: 18:36:12, End time: 18:36:12 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda1b00",
   "metadata": {},
   "source": [
    "**Thought**: It seems the `data-bin` directory does not exist. The dataset might have been stored in a different directory. Let's check the `data` directory to see if the dataset files are located there.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7595461",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d3669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de-en/\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a9ff6",
   "metadata": {},
   "source": [
    "### Step 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2470af5b",
   "metadata": {},
   "source": [
    "Execution Start time: 18:36:14, End time: 18:36:14 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb9698",
   "metadata": {},
   "source": [
    "**Thought**: The `data` directory contains a `de-en` subdirectory, which likely holds the dataset files for the IWSLT14 German-English translation task. Let's list the contents of the `data/de-en` directory to verify the presence of the dataset files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb56b9",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3c0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls data/de-en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8526f9",
   "metadata": {},
   "source": [
    "### Step 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce475ee",
   "metadata": {},
   "source": [
    "Execution Start time: 18:36:16, End time: 18:36:16 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d66096b",
   "metadata": {},
   "source": [
    "**Thought**: The `data/de-en` directory is present, but it seems there are no visible files listed. This might be due to the files being hidden or the directory being empty. Let's use a command to list all files, including hidden ones, to ensure we capture everything.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdedbc7",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601747e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "./  ../\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls -a data/de-en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236e213",
   "metadata": {},
   "source": [
    "### Step 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710304bb",
   "metadata": {},
   "source": [
    "Execution Start time: 18:36:18, End time: 18:36:18 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8d0de",
   "metadata": {},
   "source": [
    "**Thought**: The `data/de-en` directory is empty. It seems like the dataset files were not placed in this directory. Let's check the script `prepare-iwslt14.sh` to understand where the dataset files are being stored or if there are any additional steps required to move them to the correct location.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6337757",
   "metadata": {},
   "source": [
    "**Action (open)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689bf637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/Align-to-Distill/examples/translation/prepare-iwslt14.sh (115 lines total)]\n1:#!/usr/bin/env bash\n2:#\n3:# Adapted from https://github.com/facebookresearch/MIXER/blob/master/prepareData.sh\n4:\n5:echo 'Cloning Moses github repository (for tokenization scripts)...'\n6:git clone https://github.com/moses-smt/mosesdecoder.git\n7:\n8:echo 'Cloning Subword NMT repository (for BPE pre-processing)...'\n9:git clone https://github.com/rsennrich/subword-nmt.git\n10:\n11:SCRIPTS=mosesdecoder/scripts\n12:TOKENIZER=$SCRIPTS/tokenizer/tokenizer.perl\n13:LC=$SCRIPTS/tokenizer/lowercase.perl\n14:CLEAN=$SCRIPTS/training/clean-corpus-n.perl\n15:BPEROOT=subword-nmt/subword_nmt\n16:BPE_TOKENS=10000\n17:\n18:URL=\"http://dl.fbaipublicfiles.com/fairseq/data/iwslt14/de-en.tgz\"\n19:GZ=de-en.tgz\n20:\n21:if [ ! -d \"$SCRIPTS\" ]; then\n22:    echo \"Please set SCRIPTS variable correctly to point to Moses scripts.\"\n23:    exit\n24:fi\n25:\n26:src=de\n27:tgt=en\n28:lang=de-en\n29:prep=iwslt14.tokenized.de-en\n30:tmp=$prep/tmp\n31:orig=orig\n32:\n33:mkdir -p $orig $tmp $prep\n34:\n35:echo \"Downloading data from ${URL}...\"\n36:cd $orig\n37:wget \"$URL\"\n38:\n39:if [ -f $GZ ]; then\n40:    echo \"Data successfully downloaded.\"\n41:else\n42:    echo \"Data not successfully downloaded.\"\n43:    exit\n44:fi\n45:\n46:tar zxvf $GZ\n47:cd ..\n48:\n49:echo \"pre-processing train data...\"\n50:for l in $src $tgt; do\n51:    f=train.tags.$lang.$l\n52:    tok=train.tags.$lang.tok.$l\n53:\n54:    cat $orig/$lang/$f | \\\n55:    grep -v '<url>' | \\\n56:    grep -v '<talkid>' | \\\n57:    grep -v '<keywords>' | \\\n58:    sed -e 's/<title>//g' | \\\n59:    sed -e 's/<\\/title>//g' | \\\n60:    sed -e 's/<description>//g' | \\\n61:    sed -e 's/<\\/description>//g' | \\\n62:    perl $TOKENIZER -threads 8 -l $l > $tmp/$tok\n63:    echo \"\"\n64:done\n65:perl $CLEAN -ratio 1.5 $tmp/train.tags.$lang.tok $src $tgt $tmp/train.tags.$lang.clean 1 175\n66:for l in $src $tgt; do\n67:    perl $LC < $tmp/train.tags.$lang.clean.$l > $tmp/train.tags.$lang.$l\n68:done\n69:\n70:echo \"pre-processing valid/test data...\"\n71:for l in $src $tgt; do\n72:    for o in `ls $orig/$lang/IWSLT14.TED*.$l.xml`; do\n73:    fname=${o##*/}\n74:    f=$tmp/${fname%.*}\n75:    echo $o $f\n76:    grep '<seg id' $o | \\\n77:        sed -e 's/<seg id=\"[0-9]*\">\\s*//g' | \\\n78:        sed -e 's/\\s*<\\/seg>\\s*//g' | \\\n79:        sed -e \"s/\\’/\\'/g\" | \\\n80:    perl $TOKENIZER -threads 8 -l $l | \\\n81:    perl $LC > $f\n82:    echo \"\"\n83:    done\n84:done\n85:\n86:\n87:echo \"creating train, valid, test...\"\n88:for l in $src $tgt; do\n89:    awk '{if (NR%23 == 0)  print $0; }' $tmp/train.tags.de-en.$l > $tmp/valid.$l\n90:    awk '{if (NR%23 != 0)  print $0; }' $tmp/train.tags.de-en.$l > $tmp/train.$l\n91:\n92:    cat $tmp/IWSLT14.TED.dev2010.de-en.$l \\\n93:        $tmp/IWSLT14.TEDX.dev2012.de-en.$l \\\n94:        $tmp/IWSLT14.TED.tst2010.de-en.$l \\\n95:        $tmp/IWSLT14.TED.tst2011.de-en.$l \\\n96:        $tmp/IWSLT14.TED.tst2012.de-en.$l \\\n97:        > $tmp/test.$l\n98:done\n99:\n100:TRAIN=$tmp/train.en-de\n(15 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open examples/translation/prepare-iwslt14.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b8b036",
   "metadata": {},
   "source": [
    "### Step 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac6654f",
   "metadata": {},
   "source": [
    "Execution Start time: 18:36:20, End time: 18:36:21 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a74730",
   "metadata": {},
   "source": [
    "**Thought**: The script `prepare-iwslt14.sh` downloads and processes the dataset, storing the processed files in the `iwslt14.tokenized.de-en` directory. Let's list the contents of this directory to verify the presence of the dataset files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e184e9fb",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2656da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code  test.de  test.en  tmp/  train.de  train.en  valid.de  valid.en\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls iwslt14.tokenized.de-en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6d1e2f",
   "metadata": {},
   "source": [
    "### Step 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a855cd",
   "metadata": {},
   "source": [
    "Execution Start time: 18:36:23, End time: 18:36:23 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7522facd",
   "metadata": {},
   "source": [
    "**Thought**: The `iwslt14.tokenized.de-en` directory contains the dataset files: `train.de`, `train.en`, `valid.de`, `valid.en`, `test.de`, and `test.en`. We need to move these files to the `data/de-en` directory for training the teacher model. Let's proceed with moving these files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cef02c5",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07352817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mv iwslt14.tokenized.de-en/* data/de-en/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ebc598",
   "metadata": {},
   "source": [
    "### Step 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c11bcf",
   "metadata": {},
   "source": [
    "Execution Start time: 18:36:26, End time: 18:36:26 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd718c",
   "metadata": {},
   "source": [
    "**Thought**: The dataset files have been successfully moved to the `data/de-en` directory. Now, we need to preprocess the dataset to ensure it is ready for training. This typically involves binarizing the dataset using Fairseq's preprocessing tools. Let's check the Fairseq documentation or scripts to determine the exact preprocessing steps required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987f498",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d1a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__init__.py*  generate.py*     interactive.py*  score.py*  validate.py*\neval_lm.py*   hydra_train.py*  preprocess.py*   train.py*\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls fairseq_cli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ba7de",
   "metadata": {},
   "source": [
    "### Step 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9c5168",
   "metadata": {},
   "source": [
    "Execution Start time: 18:36:28, End time: 18:37:25 (duration: 56 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52950b08",
   "metadata": {},
   "source": [
    "**Thought**: The `fairseq_cli` directory contains a `preprocess.py` script, which is typically used to preprocess and binarize datasets for Fairseq training. Let's use this script to preprocess the dataset in the `data/de-en` directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4eca1f",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391afa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 18:36:33 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='de', target_lang='en', trainpref='data/de-en/train', validpref='data/de-en/valid', testpref='data/de-en/test', align_suffix=None, destdir='data-bin', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=2, dict_only=False)\n2024-08-22 18:36:37 | INFO | fairseq_cli.preprocess | [de] Dictionary: 8848 types\n2024-08-22 18:37:00 | INFO | fairseq_cli.preprocess | [de] data/de-en/train.de: 160239 sents, 4035591 tokens, 0.0% replaced (by <unk>)\n2024-08-22 18:37:00 | INFO | fairseq_cli.preprocess | [de] Dictionary: 8848 types\n2024-08-22 18:37:01 | INFO | fairseq_cli.preprocess | [de] data/de-en/valid.de: 7283 sents, 182592 tokens, 0.0192% replaced (by <unk>)\n2024-08-22 18:37:01 | INFO | fairseq_cli.preprocess | [de] Dictionary: 8848 types\n2024-08-22 18:37:02 | INFO | fairseq_cli.preprocess | [de] data/de-en/test.de: 6750 sents, 161838 tokens, 0.0636% replaced (by <unk>)\n2024-08-22 18:37:02 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6632 types\n2024-08-22 18:37:22 | INFO | fairseq_cli.preprocess | [en] data/de-en/train.en: 160239 sents, 3949114 tokens, 0.0% replaced (by <unk>)\n2024-08-22 18:37:22 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6632 types\n2024-08-22 18:37:23 | INFO | fairseq_cli.preprocess | [en] data/de-en/valid.en: 7283 sents, 178622 tokens, 0.00448% replaced (by <unk>)\n2024-08-22 18:37:23 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6632 types\n2024-08-22 18:37:24 | INFO | fairseq_cli.preprocess | [en] data/de-en/test.en: 6750 sents, 156928 tokens, 0.00892% replaced (by <unk>)\n2024-08-22 18:37:24 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python fairseq_cli/preprocess.py --source-lang de --target-lang en --trainpref data/de-en/train --validpref data/de-en/valid --testpref data/de-en/test --destdir data-bin --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be793ef",
   "metadata": {},
   "source": [
    "### Step 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dead31",
   "metadata": {},
   "source": [
    "Execution Start time: 18:37:30, End time: 18:42:31 (duration: 300 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ea161",
   "metadata": {},
   "source": [
    "**Thought**: The dataset has been successfully preprocessed and binarized, with the output stored in the `data-bin` directory. Now, we can proceed to train the teacher model using the preprocessed dataset. Let's execute the training command provided in the task description.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd72df",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83365b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 18:37:35 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': True, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'custom/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 0, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'data/de-en/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=True, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='custom/', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=1, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=1, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_teacher', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='data/de-en/ckpt', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='data-bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, alignment_module=True, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_layers=6, encoder_attention_heads=4, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_teacher'), 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n2024-08-22 18:37:35 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types\n2024-08-22 18:37:35 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types\ntask\nsentence_avg\nlabel_smoothing\nignore_prefix_size\nreport_accuracy\n2024-08-22 18:37:36 | INFO | fairseq_cli.train | TransformerModel(\n  (encoder): TransformerEncoderBase(\n    (alignment_module): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))\n    (dropout_module): FairseqDropout()\n    (embed_tokens): Embedding(8848, 512, padding_idx=1)\n    (embed_positions): SinusoidalPositionalEmbedding()\n    (layers): ModuleList(\n      (0-5): 6 x TransformerEncoderLayerBase(\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n        (dropout_module): FairseqDropout()\n        (activation_dropout_module): FairseqDropout()\n      )\n    )\n  )\n  (decoder): TransformerDecoderBase(\n    (self_alignment_module): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))\n    (cross_alignment_module): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))\n    (dropout_module): FairseqDropout()\n    (embed_tokens): Embedding(6632, 512, padding_idx=1)\n    (embed_positions): SinusoidalPositionalEmbedding()\n    (layers): ModuleList(\n      (0-5): 6 x TransformerDecoderLayerBase(\n        (dropout_module): FairseqDropout()\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n        (activation_dropout_module): FairseqDropout()\n        (encoder_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n      )\n    )\n  )\n)\n2024-08-22 18:37:36 | INFO | fairseq_cli.train | task: TranslationTask\n2024-08-22 18:37:36 | INFO | fairseq_cli.train | model: TransformerModel\n2024-08-22 18:37:36 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n2024-08-22 18:37:36 | INFO | fairseq_cli.train | num. shared model params: 39,470,856 (num. trained: 39,470,856)\n2024-08-22 18:37:36 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n2024-08-22 18:37:36 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/valid.de-en.de\n2024-08-22 18:37:36 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/valid.de-en.en\n2024-08-22 18:37:36 | INFO | fairseq.tasks.translation | data-bin valid de-en 7283 examples\n2024-08-22 18:37:36 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n2024-08-22 18:37:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n2024-08-22 18:37:36 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = 1\n2024-08-22 18:37:36 | INFO | fairseq.trainer | Preparing to load checkpoint data/de-en/ckpt/checkpoint_last.pt\n2024-08-22 18:37:36 | INFO | fairseq.trainer | No existing checkpoint found data/de-en/ckpt/checkpoint_last.pt\n2024-08-22 18:37:36 | INFO | fairseq.trainer | loading train data for epoch 1\n2024-08-22 18:37:36 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/train.de-en.de\n2024-08-22 18:37:36 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/train.de-en.en\n2024-08-22 18:37:36 | INFO | fairseq.tasks.translation | data-bin train de-en 160239 examples\n2024-08-22 18:37:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 160239\n\nepoch 001:   0%|                                     | 0/160239 [00:00<?, ?it/s]2024-08-22 18:37:37 | INFO | fairseq.trainer | begin training epoch 1\n2024-08-22 18:37:37 | INFO | fairseq_cli.train | Start iterating over samples\n/root/.local/lib/python3.10/site-packages/fairseq/tasks/fairseq_task.py:499: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):\n\nepoch 001:   0%|                          | 1/160239 [00:02<95:52:03,  2.15s/it]\nepoch 001:   0%|                          | 2/160239 [00:03<74:42:59,  1.68s/it]\nepoch 001:   0%|                          | 3/160239 [00:04<64:39:09,  1.45s/it]\nepoch 001:   0%|                          | 4/160239 [00:05<61:32:02,  1.38s/it]\nepoch 001:   0%|                          | 5/160239 [00:07<58:27:07,  1.31s/it]\nepoch 001:   0%|                          | 6/160239 [00:08<57:49:08,  1.30s/it]\nepoch 001:   0%|                          | 7/160239 [00:09<57:39:10,  1.30s/it]\nepoch 001:   0%|                          | 8/160239 [00:10<56:25:43,  1.27s/it]\nepoch 001:   0%|                          | 9/160239 [00:12<56:06:56,  1.26s/it]\nepoch 001:   0%|                         | 10/160239 [00:13<55:13:36,  1.24s/it]\nepoch 001:   0%|                         | 11/160239 [00:14<54:12:29,  1.22s/it]\nepoch 001:   0%|                         | 12/160239 [00:15<53:14:18,  1.20s/it]\nepoch 001:   0%|                         | 13/160239 [00:16<53:29:52,  1.20s/it]\nepoch 001:   0%|                         | 14/160239 [00:18<57:33:19,  1.29s/it]\nepoch 001:   0%|                         | 15/160239 [00:19<56:53:25,  1.28s/it]\nepoch 001:   0%|                         | 16/160239 [00:20<54:53:52,  1.23s/it]\nepoch 001:   0%|                         | 17/160239 [00:21<53:58:58,  1.21s/it]\nepoch 001:   0%|                         | 18/160239 [00:23<53:21:17,  1.20s/it]\nepoch 001:   0%|                         | 19/160239 [00:24<57:00:58,  1.28s/it]\nepoch 001:   0%|                         | 20/160239 [00:25<56:23:46,  1.27s/it]\nepoch 001:   0%|                         | 21/160239 [00:26<55:14:34,  1.24s/it]\nepoch 001:   0%|                         | 22/160239 [00:28<53:58:50,  1.21s/it]\nepoch 001:   0%|                         | 23/160239 [00:29<52:27:01,  1.18s/it]\nepoch 001:   0%|                         | 24/160239 [00:30<51:45:04,  1.16s/it]\nepoch 001:   0%|                         | 25/160239 [00:31<53:44:58,  1.21s/it]\nepoch 001:   0%|                         | 26/160239 [00:32<53:06:00,  1.19s/it]\nepoch 001:   0%|                         | 27/160239 [00:33<52:16:11,  1.17s/it]\nepoch 001:   0%|                         | 28/160239 [00:35<50:58:25,  1.15s/it]\nepoch 001:   0%|                         | 29/160239 [00:36<52:31:59,  1.18s/it]\nepoch 001:   0%|                         | 30/160239 [00:37<51:40:25,  1.16s/it]\nepoch 001:   0%|                         | 31/160239 [00:38<50:54:08,  1.14s/it]\nepoch 001:   0%|                         | 32/160239 [00:39<52:04:58,  1.17s/it]\nepoch 001:   0%|                         | 33/160239 [00:41<53:41:45,  1.21s/it]\nepoch 001:   0%|                         | 34/160239 [00:42<53:39:49,  1.21s/it]\nepoch 001:   0%|                         | 35/160239 [00:43<53:23:13,  1.20s/it]\nepoch 001:   0%|                         | 36/160239 [00:44<54:48:27,  1.23s/it]\nepoch 001:   0%|                         | 37/160239 [00:45<53:33:32,  1.20s/it]\nepoch 001:   0%|                         | 38/160239 [00:47<56:23:09,  1.27s/it]\nepoch 001:   0%|                         | 39/160239 [00:48<56:34:53,  1.27s/it]\nepoch 001:   0%|                         | 40/160239 [00:49<56:36:57,  1.27s/it]\nepoch 001:   0%|                         | 41/160239 [00:51<56:09:29,  1.26s/it]\nepoch 001:   0%|                         | 42/160239 [00:52<55:39:54,  1.25s/it]\nepoch 001:   0%|                         | 43/160239 [00:53<55:06:26,  1.24s/it]\nepoch 001:   0%|                         | 44/160239 [00:54<54:32:31,  1.23s/it]\nepoch 001:   0%|                         | 45/160239 [00:55<53:51:57,  1.21s/it]\nepoch 001:   0%|                         | 46/160239 [00:57<53:42:02,  1.21s/it]\nepoch 001:   0%|                         | 47/160239 [00:58<52:32:27,  1.18s/it]\nepoch 001:   0%|                         | 48/160239 [00:59<52:27:59,  1.18s/it]\nepoch 001:   0%|                         | 49/160239 [01:00<53:17:33,  1.20s/it]\nepoch 001:   0%|                         | 50/160239 [01:01<52:31:18,  1.18s/it]\nepoch 001:   0%|                         | 51/160239 [01:02<52:49:50,  1.19s/it]\nepoch 001:   0%|                         | 52/160239 [01:04<51:42:30,  1.16s/it]\nepoch 001:   0%|                         | 53/160239 [01:05<51:17:44,  1.15s/it]\nepoch 001:   0%|                         | 54/160239 [01:06<50:20:28,  1.13s/it]\nepoch 001:   0%|                         | 55/160239 [01:07<51:47:20,  1.16s/it]\nepoch 001:   0%|                         | 56/160239 [01:08<50:59:57,  1.15s/it]\nepoch 001:   0%|                         | 57/160239 [01:09<50:40:50,  1.14s/it]\nepoch 001:   0%|                         | 58/160239 [01:10<50:55:26,  1.14s/it]\nepoch 001:   0%|                         | 59/160239 [01:12<52:56:34,  1.19s/it]\nepoch 001:   0%|                         | 60/160239 [01:13<52:01:54,  1.17s/it]\nepoch 001:   0%|                         | 61/160239 [01:14<51:54:41,  1.17s/it]\nepoch 001:   0%|                         | 62/160239 [01:15<51:23:43,  1.16s/it]\nepoch 001:   0%|                         | 63/160239 [01:16<51:44:10,  1.16s/it]\nepoch 001:   0%|                         | 64/160239 [01:18<54:17:11,  1.22s/it]\nepoch 001:   0%|                         | 65/160239 [01:19<53:27:21,  1.20s/it]\nepoch 001:   0%|                         | 66/160239 [01:20<52:53:20,  1.19s/it]\nepoch 001:   0%|                         | 67/160239 [01:21<52:21:58,  1.18s/it]\nepoch 001:   0%|                         | 68/160239 [01:22<51:48:05,  1.16s/it]\nepoch 001:   0%|                         | 69/160239 [01:23<52:42:27,  1.18s/it]\nepoch 001:   0%|                         | 70/160239 [01:25<52:40:47,  1.18s/it]\nepoch 001:   0%|                         | 71/160239 [01:26<53:03:46,  1.19s/it]\nepoch 001:   0%|                         | 72/160239 [01:27<53:35:11,  1.20s/it]\nepoch 001:   0%|                         | 73/160239 [01:28<52:55:11,  1.19s/it]\nepoch 001:   0%|                         | 74/160239 [01:29<51:56:02,  1.17s/it]\nepoch 001:   0%|                         | 75/160239 [01:31<54:05:19,  1.22s/it]\nepoch 001:   0%|                         | 76/160239 [01:32<53:09:18,  1.19s/it]\nepoch 001:   0%|                         | 77/160239 [01:33<52:07:53,  1.17s/it]\nepoch 001:   0%|                         | 78/160239 [01:34<54:32:16,  1.23s/it]\nepoch 001:   0%|                         | 79/160239 [01:36<54:02:47,  1.21s/it]\nepoch 001:   0%|                         | 80/160239 [01:37<53:28:32,  1.20s/it]\nepoch 001:   0%|                         | 81/160239 [01:38<53:48:15,  1.21s/it]\nepoch 001:   0%|                         | 82/160239 [01:39<52:49:59,  1.19s/it]\nepoch 001:   0%|                         | 83/160239 [01:40<53:22:15,  1.20s/it]\nepoch 001:   0%|                         | 84/160239 [01:41<53:29:21,  1.20s/it]\nepoch 001:   0%|                         | 85/160239 [01:43<53:10:46,  1.20s/it]\nepoch 001:   0%|                         | 86/160239 [01:44<52:26:39,  1.18s/it]\nepoch 001:   0%|                         | 87/160239 [01:45<52:19:31,  1.18s/it]\nepoch 001:   0%|                         | 88/160239 [01:46<51:43:33,  1.16s/it]\nepoch 001:   0%|                         | 89/160239 [01:47<51:01:45,  1.15s/it]\nepoch 001:   0%|                         | 90/160239 [01:48<50:31:37,  1.14s/it]\nepoch 001:   0%|                         | 91/160239 [01:49<50:57:12,  1.15s/it]\nepoch 001:   0%|                         | 92/160239 [01:51<50:29:49,  1.14s/it]\nepoch 001:   0%|                         | 93/160239 [01:52<50:11:26,  1.13s/it]\nepoch 001:   0%|                         | 94/160239 [01:53<49:42:34,  1.12s/it]\nepoch 001:   0%|                         | 95/160239 [01:54<49:55:14,  1.12s/it]\nepoch 001:   0%|                         | 96/160239 [01:55<51:31:00,  1.16s/it]\nepoch 001:   0%|                         | 97/160239 [01:56<52:01:26,  1.17s/it]\nepoch 001:   0%|                         | 98/160239 [01:58<51:40:37,  1.16s/it]\nepoch 001:   0%|                         | 99/160239 [01:59<51:11:00,  1.15s/it]\nepoch 001:   0%| | 100/160239 [02:00<50:43:32,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 101/160239 [02:01<50:14:23,  1.13s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 102/160239 [02:02<50:53:00,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 103/160239 [02:03<53:39:32,  1.21s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 104/160239 [02:05<53:27:31,  1.20s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 105/160239 [02:06<52:44:50,  1.19s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 106/160239 [02:07<52:24:50,  1.18s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 107/160239 [02:08<52:15:23,  1.17s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 108/160239 [02:09<53:45:16,  1.21s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 109/160239 [02:11<53:03:54,  1.19s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 110/160239 [02:12<52:58:06,  1.19s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 111/160239 [02:13<52:35:55,  1.18s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 112/160239 [02:14<51:42:04,  1.16s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 113/160239 [02:15<51:31:58,  1.16s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 114/160239 [02:16<51:20:48,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 115/160239 [02:17<50:35:39,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 116/160239 [02:19<51:08:15,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 117/160239 [02:20<50:51:26,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 118/160239 [02:21<51:07:56,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 119/160239 [02:22<50:25:25,  1.13s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 120/160239 [02:23<49:57:25,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 121/160239 [02:24<51:02:57,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 122/160239 [02:25<51:01:07,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 123/160239 [02:27<52:11:45,  1.17s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 124/160239 [02:28<51:47:53,  1.16s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 125/160239 [02:29<51:24:32,  1.16s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 126/160239 [02:30<51:19:44,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 127/160239 [02:31<50:54:37,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 128/160239 [02:32<51:01:48,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 129/160239 [02:33<50:55:56,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 130/160239 [02:35<50:39:12,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 131/160239 [02:36<50:12:13,  1.13s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 132/160239 [02:37<50:30:55,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 133/160239 [02:38<51:14:38,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 134/160239 [02:39<51:03:04,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 135/160239 [02:40<51:39:04,  1.16s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 136/160239 [02:42<51:55:39,  1.17s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 137/160239 [02:43<51:37:28,  1.16s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 138/160239 [02:44<54:13:26,  1.22s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 139/160239 [02:45<56:07:25,  1.26s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 140/160239 [02:47<56:10:33,  1.26s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 141/160239 [02:48<55:04:19,  1.24s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 142/160239 [02:49<55:29:12,  1.25s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 143/160239 [02:50<53:23:53,  1.20s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 144/160239 [02:51<51:53:23,  1.17s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 145/160239 [02:52<51:55:39,  1.17s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 146/160239 [02:54<51:40:36,  1.16s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 147/160239 [02:55<51:34:05,  1.16s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 148/160239 [02:56<50:41:48,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 149/160239 [02:57<50:53:34,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 150/160239 [02:58<50:41:27,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 151/160239 [02:59<51:13:17,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 152/160239 [03:00<51:06:51,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 153/160239 [03:02<51:01:03,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 154/160239 [03:03<51:11:21,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 155/160239 [03:04<51:45:18,  1.16s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 156/160239 [03:05<52:02:53,  1.17s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 157/160239 [03:06<51:27:06,  1.16s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 158/160239 [03:07<51:17:08,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 159/160239 [03:09<50:32:49,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 160/160239 [03:10<50:27:09,  1.13s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 161/160239 [03:11<50:43:33,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 162/160239 [03:12<49:46:24,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 163/160239 [03:13<49:51:50,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 164/160239 [03:14<49:59:32,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 165/160239 [03:15<49:47:39,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 166/160239 [03:16<51:22:03,  1.16s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 167/160239 [03:18<50:56:31,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 168/160239 [03:19<50:33:30,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 169/160239 [03:20<52:46:24,  1.19s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 170/160239 [03:21<52:25:36,  1.18s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 171/160239 [03:22<52:44:48,  1.19s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 172/160239 [03:24<52:05:49,  1.17s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 173/160239 [03:25<52:19:10,  1.18s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 174/160239 [03:26<52:07:12,  1.17s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 175/160239 [03:27<51:52:28,  1.17s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 176/160239 [03:28<51:20:56,  1.15s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 177/160239 [03:29<50:28:31,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 178/160239 [03:30<50:23:00,  1.13s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 179/160239 [03:31<49:58:06,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 180/160239 [03:33<50:44:38,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 181/160239 [03:34<50:28:39,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 182/160239 [03:35<50:24:16,  1.13s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 183/160239 [03:36<49:46:57,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 184/160239 [03:37<50:08:51,  1.13s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 185/160239 [03:38<50:20:58,  1.13s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 186/160239 [03:39<50:03:44,  1.13s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 187/160239 [03:41<50:34:21,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 188/160239 [03:42<50:08:06,  1.13s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 189/160239 [03:43<49:35:11,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 190/160239 [03:44<49:50:13,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 191/160239 [03:45<49:42:56,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 192/160239 [03:46<49:31:39,  1.11s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 193/160239 [03:47<49:42:24,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 194/160239 [03:48<49:37:55,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 195/160239 [03:49<49:40:30,  1.12s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 196/160239 [03:51<50:34:17,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 197/160239 [03:52<50:50:32,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 198/160239 [03:53<50:53:58,  1.14s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 199/160239 [03:54<53:41:29,  1.21s/it, loss=12.68, nll_loss=1\nepoch 001:   0%| | 200/160239 [03:55<52:56:28,  1.19s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 201/160239 [03:57<51:40:38,  1.16s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 202/160239 [03:58<50:12:29,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 203/160239 [03:59<49:54:19,  1.12s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 204/160239 [04:00<51:03:09,  1.15s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 205/160239 [04:01<50:36:07,  1.14s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 206/160239 [04:02<50:11:52,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 207/160239 [04:03<52:11:50,  1.17s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 208/160239 [04:05<51:02:39,  1.15s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 209/160239 [04:06<50:32:10,  1.14s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 210/160239 [04:07<50:10:03,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 211/160239 [04:08<49:29:50,  1.11s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 212/160239 [04:09<49:19:36,  1.11s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 213/160239 [04:10<49:46:04,  1.12s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 214/160239 [04:11<50:16:23,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 215/160239 [04:12<49:49:48,  1.12s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 216/160239 [04:13<50:06:40,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 217/160239 [04:15<50:22:18,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 218/160239 [04:16<49:20:24,  1.11s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 219/160239 [04:17<50:00:38,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 220/160239 [04:18<51:18:21,  1.15s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 221/160239 [04:19<51:19:05,  1.15s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 222/160239 [04:20<51:18:11,  1.15s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 223/160239 [04:21<50:48:31,  1.14s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 224/160239 [04:23<49:47:57,  1.12s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 225/160239 [04:24<49:28:02,  1.11s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 226/160239 [04:25<49:38:31,  1.12s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 227/160239 [04:26<49:40:24,  1.12s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 228/160239 [04:27<50:36:30,  1.14s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 229/160239 [04:28<50:17:34,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 230/160239 [04:29<50:02:07,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 231/160239 [04:31<51:12:52,  1.15s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 232/160239 [04:32<52:47:01,  1.19s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 233/160239 [04:33<52:29:27,  1.18s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 234/160239 [04:34<51:40:15,  1.16s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 235/160239 [04:35<52:16:01,  1.18s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 236/160239 [04:37<53:00:07,  1.19s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 237/160239 [04:38<52:10:25,  1.17s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 238/160239 [04:39<51:23:47,  1.16s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 239/160239 [04:40<50:56:49,  1.15s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 240/160239 [04:41<50:59:22,  1.15s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 241/160239 [04:42<51:03:03,  1.15s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 242/160239 [04:43<50:41:16,  1.14s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 243/160239 [04:44<50:19:57,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 244/160239 [04:46<49:52:55,  1.12s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 245/160239 [04:47<50:17:11,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 246/160239 [04:48<49:57:13,  1.12s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 247/160239 [04:49<50:24:39,  1.13s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 248/160239 [04:50<50:38:47,  1.14s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 249/160239 [04:51<52:02:55,  1.17s/it, loss=11.266, nll_loss=\nepoch 001:   0%| | 250/160239 [04:53<52:44:23,  1.19s/it, loss=11.266, nll_loss=\n\nYour command has already run for 300 seconds. It is still running. You can continue to wait or interrupt it with \"action\": {\"type\": \"interrupt\"} or \"action\": {\"type\": \"continue_wait\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python fairseq_cli/train.py data-bin \\\n",
    "    --arch transformer_teacher --share-decoder-input-output-embed \\\n",
    "    --user-dir custom/ --cpu \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c0bf4",
   "metadata": {},
   "source": [
    "### Step 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeee434a",
   "metadata": {},
   "source": [
    "Execution Start time: 18:42:40, End time: 18:42:41 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158277c7",
   "metadata": {},
   "source": [
    "**Thought**: The training process was taking too long, likely due to the large dataset size. To address this, we need to modify the dataset to only include the first 10 rows of each set, as specified in the task instructions. This will significantly reduce the training time. Let's edit the dataset files to only keep the first 10 rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1725e4c",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c16470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!head -n 10 data/de-en/train.de > data/de-en/train_10.de\n",
    "!head -n 10 data/de-en/train.en > data/de-en/train_10.en\n",
    "!head -n 10 data/de-en/valid.de > data/de-en/valid_10.de\n",
    "!head -n 10 data/de-en/valid.en > data/de-en/valid_10.en\n",
    "!head -n 10 data/de-en/test.de > data/de-en/test_10.de\n",
    "!head -n 10 data/de-en/test.en > data/de-en/test_10.en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b051479e",
   "metadata": {},
   "source": [
    "### Step 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f89902",
   "metadata": {},
   "source": [
    "Execution Start time: 18:42:43, End time: 18:42:47 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a59a9f",
   "metadata": {},
   "source": [
    "**Thought**: The dataset files have been successfully truncated to only include the first 10 rows. Now, we need to preprocess these truncated files to prepare them for training. Let's run the preprocessing step again using the truncated dataset files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1c173",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f005201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 18:42:47 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='de', target_lang='en', trainpref='data/de-en/train_10', validpref='data/de-en/valid_10', testpref='data/de-en/test_10', align_suffix=None, destdir='data-bin', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=2, dict_only=False)\nTraceback (most recent call last):\n  File \"/content/Align-to-Distill/fairseq_cli/preprocess.py\", line 396, in <module>\n    cli_main()\n  File \"/content/Align-to-Distill/fairseq_cli/preprocess.py\", line 392, in cli_main\n    main(args)\n  File \"/content/Align-to-Distill/fairseq_cli/preprocess.py\", line 302, in main\n    raise FileExistsError(_dict_path(args.source_lang, args.destdir))\nFileExistsError: data-bin/dict.de.txt\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python fairseq_cli/preprocess.py --source-lang de --target-lang en --trainpref data/de-en/train_10 --validpref data/de-en/valid_10 --testpref data/de-en/test_10 --destdir data-bin --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09aae3b",
   "metadata": {},
   "source": [
    "### Step 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1ef499",
   "metadata": {},
   "source": [
    "Execution Start time: 18:42:49, End time: 18:42:50 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ef3f3",
   "metadata": {},
   "source": [
    "**Thought**: The preprocessing step failed because the dictionary files already exist in the `data-bin` directory. We need to remove the existing preprocessed files in `data-bin` before running the preprocessing step again. Let's clear the `data-bin` directory and then retry the preprocessing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89377b5a",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a48147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -rf data-bin/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70ca65c",
   "metadata": {},
   "source": [
    "### Step 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e4478",
   "metadata": {},
   "source": [
    "Execution Start time: 18:42:51, End time: 18:42:56 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b9c68",
   "metadata": {},
   "source": [
    "**Thought**: The `data-bin` directory has been cleared. Now, let's preprocess the truncated dataset files again to prepare them for training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff28820",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c7960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='de', target_lang='en', trainpref='data/de-en/train_10', validpref='data/de-en/valid_10', testpref='data/de-en/test_10', align_suffix=None, destdir='data-bin', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=2, dict_only=False)\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [de] Dictionary: 128 types\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [de] data/de-en/train_10.de: 10 sents, 207 tokens, 0.0% replaced (by <unk>)\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [de] Dictionary: 128 types\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [de] data/de-en/valid_10.de: 10 sents, 174 tokens, 60.9% replaced (by <unk>)\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [de] Dictionary: 128 types\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [de] data/de-en/test_10.de: 10 sents, 494 tokens, 63.6% replaced (by <unk>)\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [en] Dictionary: 120 types\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [en] data/de-en/train_10.en: 10 sents, 234 tokens, 0.0% replaced (by <unk>)\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [en] Dictionary: 120 types\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [en] data/de-en/valid_10.en: 10 sents, 175 tokens, 54.9% replaced (by <unk>)\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [en] Dictionary: 120 types\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | [en] data/de-en/test_10.en: 10 sents, 474 tokens, 53.6% replaced (by <unk>)\n2024-08-22 18:42:55 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python fairseq_cli/preprocess.py --source-lang de --target-lang en --trainpref data/de-en/train_10 --validpref data/de-en/valid_10 --testpref data/de-en/test_10 --destdir data-bin --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038770f4",
   "metadata": {},
   "source": [
    "### Step 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e97b6",
   "metadata": {},
   "source": [
    "Execution Start time: 18:43:04, End time: 18:43:30 (duration: 25 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3f04e",
   "metadata": {},
   "source": [
    "**Thought**: The truncated dataset has been successfully preprocessed and stored in the `data-bin` directory. Now, let's proceed to train the teacher model using this preprocessed dataset with the specified parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8b4917",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6e65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-22 18:43:09 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': True, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'custom/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 0, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'data/de-en/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=True, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='custom/', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=1, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=1, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_teacher', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='data/de-en/ckpt', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='data-bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, alignment_module=True, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_layers=6, encoder_attention_heads=4, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_teacher'), 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n2024-08-22 18:43:09 | INFO | fairseq.tasks.translation | [de] dictionary: 128 types\n2024-08-22 18:43:09 | INFO | fairseq.tasks.translation | [en] dictionary: 120 types\ntask\nsentence_avg\nlabel_smoothing\nignore_prefix_size\nreport_accuracy\n2024-08-22 18:43:10 | INFO | fairseq_cli.train | TransformerModel(\n  (encoder): TransformerEncoderBase(\n    (alignment_module): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))\n    (dropout_module): FairseqDropout()\n    (embed_tokens): Embedding(128, 512, padding_idx=1)\n    (embed_positions): SinusoidalPositionalEmbedding()\n    (layers): ModuleList(\n      (0-5): 6 x TransformerEncoderLayerBase(\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n        (dropout_module): FairseqDropout()\n        (activation_dropout_module): FairseqDropout()\n      )\n    )\n  )\n  (decoder): TransformerDecoderBase(\n    (self_alignment_module): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))\n    (cross_alignment_module): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))\n    (dropout_module): FairseqDropout()\n    (embed_tokens): Embedding(120, 512, padding_idx=1)\n    (embed_positions): SinusoidalPositionalEmbedding()\n    (layers): ModuleList(\n      (0-5): 6 x TransformerDecoderLayerBase(\n        (dropout_module): FairseqDropout()\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n        (activation_dropout_module): FairseqDropout()\n        (encoder_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n      )\n    )\n  )\n)\n2024-08-22 18:43:10 | INFO | fairseq_cli.train | task: TranslationTask\n2024-08-22 18:43:10 | INFO | fairseq_cli.train | model: TransformerModel\n2024-08-22 18:43:10 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n2024-08-22 18:43:10 | INFO | fairseq_cli.train | num. shared model params: 31,672,072 (num. trained: 31,672,072)\n2024-08-22 18:43:10 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n2024-08-22 18:43:10 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/valid.de-en.de\n2024-08-22 18:43:10 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/valid.de-en.en\n2024-08-22 18:43:10 | INFO | fairseq.tasks.translation | data-bin valid de-en 10 examples\n2024-08-22 18:43:10 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n2024-08-22 18:43:10 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n2024-08-22 18:43:10 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = 1\n2024-08-22 18:43:10 | INFO | fairseq.trainer | Preparing to load checkpoint data/de-en/ckpt/checkpoint_last.pt\n2024-08-22 18:43:10 | INFO | fairseq.trainer | No existing checkpoint found data/de-en/ckpt/checkpoint_last.pt\n2024-08-22 18:43:10 | INFO | fairseq.trainer | loading train data for epoch 1\n2024-08-22 18:43:10 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/train.de-en.de\n2024-08-22 18:43:10 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/train.de-en.en\n2024-08-22 18:43:10 | INFO | fairseq.tasks.translation | data-bin train de-en 10 examples\n2024-08-22 18:43:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 10\n\nepoch 001:   0%|                                         | 0/10 [00:00<?, ?it/s]2024-08-22 18:43:10 | INFO | fairseq.trainer | begin training epoch 1\n2024-08-22 18:43:10 | INFO | fairseq_cli.train | Start iterating over samples\n/root/.local/lib/python3.10/site-packages/fairseq/tasks/fairseq_task.py:499: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):\n\nepoch 001:  10%|███▎                             | 1/10 [00:01<00:12,  1.41s/it]\nepoch 001:  20%|██████▌                          | 2/10 [00:02<00:09,  1.15s/it]\nepoch 001:  30%|█████████▉                       | 3/10 [00:03<00:07,  1.08s/it]\nepoch 001:  40%|█████████████▏                   | 4/10 [00:04<00:06,  1.02s/it]\nepoch 001:  50%|████████████████▌                | 5/10 [00:05<00:05,  1.02s/it]\nepoch 001:  60%|███████████████████▊             | 6/10 [00:06<00:03,  1.00it/s]\nepoch 001:  70%|███████████████████████          | 7/10 [00:07<00:02,  1.01it/s]\nepoch 001:  80%|██████████████████████████▍      | 8/10 [00:08<00:01,  1.00it/s]\nepoch 001:  90%|█████████████████████████████▋   | 9/10 [00:09<00:01,  1.03s/it]2024-08-22 18:43:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n\n\nepoch 001 | valid on 'valid' subset:   0%|               | 0/10 [00:00<?, ?it/s]\u001b[A2024-08-22 18:43:21 | INFO | fairseq.tasks.translation | example hypothesis: there there there then then then then then then then then then then then then then then then\n2024-08-22 18:43:21 | INFO | fairseq.tasks.translation | example reference: in UNKNOWNTOKENINREF's UNKNOWNTOKENINREF.\n\n\nepoch 001 | valid on 'valid' subset:  10%|▋      | 1/10 [00:00<00:03,  2.36it/s]\u001b[A2024-08-22 18:43:22 | INFO | fairseq.tasks.translation | example hypothesis: there there there there there there madeupword0001 madeupword0001 madeupword0001 madeupword0001 madeupword0001 madeupword0001 madeupword0001 madeupword0001 madeupword0001 madeupword0001 madeupword0001 madeupword0001\n2024-08-22 18:43:22 | INFO | fairseq.tasks.translation | example reference: it's that UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n\n\nepoch 001 | valid on 'valid' subset:  20%|█▍     | 2/10 [00:00<00:02,  2.88it/s]\u001b[A2024-08-22 18:43:22 | INFO | fairseq.tasks.translation | example hypothesis: then then then then then then then then then then then then then then then then then then then\n2024-08-22 18:43:22 | INFO | fairseq.tasks.translation | example reference: i really UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n\n\nepoch 001 | valid on 'valid' subset:  30%|██     | 3/10 [00:01<00:02,  3.00it/s]\u001b[A2024-08-22 18:43:22 | INFO | fairseq.tasks.translation | example hypothesis: then then then then then then then then then then then then then then then then then then then then then then\n2024-08-22 18:43:22 | INFO | fairseq.tasks.translation | example reference: and UNKNOWNTOKENINREF we UNKNOWNTOKENINREF UNKNOWNTOKENINREF to UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF to UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n\n\nepoch 001 | valid on 'valid' subset:  40%|██▊    | 4/10 [00:01<00:02,  2.92it/s]\u001b[A2024-08-22 18:43:23 | INFO | fairseq.tasks.translation | example hypothesis: then then then then then then then then then then then then then then then then then then then then then then then then then\n2024-08-22 18:43:23 | INFO | fairseq.tasks.translation | example reference: UNKNOWNTOKENINREF what UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF is UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n\n\nepoch 001 | valid on 'valid' subset:  50%|███▌   | 5/10 [00:01<00:01,  2.75it/s]\u001b[A2024-08-22 18:43:23 | INFO | fairseq.tasks.translation | example hypothesis: there there then then then then then then then then then then then then then then then then then then then then then then then then then then then\n2024-08-22 18:43:23 | INFO | fairseq.tasks.translation | example reference: UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF: UNKNOWNTOKENINREF the UNKNOWNTOKENINREF UNKNOWNTOKENINREF y UNKNOWNTOKENINREF UNKNOWNTOKENINREF\n\n\nepoch 001 | valid on 'valid' subset:  60%|████▏  | 6/10 [00:02<00:01,  2.55it/s]\u001b[A2024-08-22 18:43:24 | INFO | fairseq.tasks.translation | example hypothesis: then then then then then then then then then then then then then then then then then then then then then then then then then then then then then\n2024-08-22 18:43:24 | INFO | fairseq.tasks.translation | example reference: what UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF this UNKNOWNTOKENINREF of UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF?\n\n\nepoch 001 | valid on 'valid' subset:  70%|████▉  | 7/10 [00:02<00:01,  2.43it/s]\u001b[A2024-08-22 18:43:24 | INFO | fairseq.tasks.translation | example hypothesis: then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then\n2024-08-22 18:43:24 | INFO | fairseq.tasks.translation | example reference: UNKNOWNTOKENINREF UNKNOWNTOKENINREF: and UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF, in UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF, the UNKNOWNTOKENINREF to move the UNKNOWNTOKENINREF from UNKNOWNTOKENINREF to right, and UNKNOWNTOKENINREF and UNKNOWNTOKENINREF with the UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n\n\nepoch 001 | valid on 'valid' subset:  80%|█████▌ | 8/10 [00:03<00:00,  2.02it/s]\u001b[A2024-08-22 18:43:25 | INFO | fairseq.tasks.translation | example hypothesis: there there then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then\n2024-08-22 18:43:25 | INFO | fairseq.tasks.translation | example reference: it had UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF the UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF the UNKNOWNTOKENINREF a.\n\n\nepoch 001 | valid on 'valid' subset:  90%|██████▎| 9/10 [00:04<00:00,  1.74it/s]\u001b[A2024-08-22 18:43:26 | INFO | fairseq.tasks.translation | example hypothesis: there there there there there then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then\n2024-08-22 18:43:26 | INFO | fairseq.tasks.translation | example reference: but we UNKNOWNTOKENINREF't UNKNOWNTOKENINREF at the time that we UNKNOWNTOKENINREF UNKNOWNTOKENINREF a UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF, UNKNOWNTOKENINREF we UNKNOWNTOKENINREF't UNKNOWNTOKENINREF UNKNOWNTOKENINREF the UNKNOWNTOKENINREF UNKNOWNTOKENINREF from UNKNOWNTOKENINREF and UNKNOWNTOKENINREF the UNKNOWNTOKENINREF at the UNKNOWNTOKENINREF time.\n\n\nepoch 001 | valid on 'valid' subset: 100%|██████| 10/10 [00:04<00:00,  1.51it/s]\u001b[A\n\n                                                                                \u001b[A2024-08-22 18:43:26 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.711 | nll_loss 6.601 | ppl 97.07 | bleu 0 | wps 37.2 | wpb 17.5 | bsz 1 | num_updates 10\n2024-08-22 18:43:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 10 updates\n2024-08-22 18:43:26 | INFO | fairseq.trainer | Saving checkpoint to /content/Align-to-Distill/data/de-en/ckpt/checkpoint1.pt\n2024-08-22 18:43:26 | INFO | fairseq.trainer | Finished saving checkpoint to /content/Align-to-Distill/data/de-en/ckpt/checkpoint1.pt\n2024-08-22 18:43:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint data/de-en/ckpt/checkpoint1.pt (epoch 1 @ 10 updates, score 0.0) (writing took 0.8295421650000208 seconds)\n\nepoch 001: 100%|████████████████████████████████| 10/10 [00:16<00:00,  2.82s/it]\n                                                                                \n2024-08-22 18:43:27 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n2024-08-22 18:43:27 | INFO | train | epoch 001 | loss 7.763 | nll_loss 7.781 | ppl 219.99 | wps 14.9 | ups 0.61 | wpb 23.4 | bsz 1 | num_updates 10 | lr 1.25e-06 | gnorm 20.773 | train_wall 10 | wall 16\n2024-08-22 18:43:27 | INFO | fairseq_cli.train | done training in 16.2 seconds\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python fairseq_cli/train.py data-bin \\\n",
    "    --arch transformer_teacher --share-decoder-input-output-embed \\\n",
    "    --user-dir custom/ --cpu \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547fd682",
   "metadata": {},
   "source": [
    "### Step 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ad4f7",
   "metadata": {},
   "source": [
    "Execution Start time: 18:43:33, End time: 18:43:33 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb286c26",
   "metadata": {},
   "source": [
    "**Thought**: The teacher model has been successfully trained for one epoch using the truncated dataset. The training process has provided the loss and nll_loss values on the validation set. Let's extract these values and format them as a JSON object to submit as the final answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1a5d34",
   "metadata": {},
   "source": [
    "**Action (submit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2999a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{teacher_loss: 6.711, teacher_nll_loss: 6.601}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit {\"teacher_loss\": 6.711, \"teacher_nll_loss\": 6.601}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
