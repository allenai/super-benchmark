{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e12f5a3",
   "metadata": {},
   "source": [
    "### System Prompt\n",
    "<details>\n",
    "SETTING: You are an autonomous programmer, and you're working directly in the command line with a special Jupyter notebook interface.\n",
    "\n",
    "The special Jupyter notebook interface consists of a file editor that shows you 100 lines of a file at a time.\n",
    "You can execute commands in the notebook using:\n",
    "\n",
    "1. Bash commands: Commands starting with !.\n",
    "2. Python commands: Standard Python code.\n",
    "3. Magic commands: Commands starting with %, e.g., %cd <path>.\n",
    "\n",
    "Additionally, you can also use the following commands to help you navigate and edit files.\n",
    "\n",
    "COMMANDS:\n",
    "\n",
    "open:\n",
    "  docstring: opens the file at the given path in the editor. If line_number is provided, the window will be move to include that line\n",
    "  signature: open <path> [<line_number>]\n",
    "  arguments:\n",
    "    - path (string) [required]: the path to the file to open\n",
    "    - line_number (integer) [optional]: the line number to move the window to (if not provided, the window will start at the top of the file)\n",
    "\n",
    "create:\n",
    "  docstring: creates and opens a new file with the given name\n",
    "  signature: create <filename>\n",
    "  arguments:\n",
    "    - filename (string) [required]: the name of the file to create\n",
    "\n",
    "goto:\n",
    "  docstring: moves the window to show <line_number>\n",
    "  signature: goto <line_number>\n",
    "  arguments:\n",
    "    - line_number (integer) [required]: the line number to move the window to\n",
    "\n",
    "scroll_down:\n",
    "  docstring: moves the window down {WINDOW} lines\n",
    "  signature: scroll_down\n",
    "\n",
    "scroll_up:\n",
    "  docstring: moves the window down {WINDOW} lines\n",
    "  signature: scroll_up\n",
    "\n",
    "submit:\n",
    "  docstring: submits your final answer\n",
    "  signature: submit <answer>\n",
    "  arguments:\n",
    "    - answer (string) [required]: the answer to be submitted\n",
    "\n",
    "search_dir:\n",
    "  docstring: searches for search_term in all files in dir_path. If dir_path is not provided, searches in the current directory\n",
    "  signature: search_dir <search_term> [<dir_path>]\n",
    "  arguments:\n",
    "    - search_term (string) [required]: the term to search for\n",
    "    - dir_path (string) [optional]: the directory to search in (if not provided, searches in the current directory)\n",
    "\n",
    "search_file:\n",
    "  docstring: searches for search_term in file. If file is not provided, searches in the current open file\n",
    "  signature: search_file <search_term> [<file>]\n",
    "  arguments:\n",
    "    - search_term (string) [required]: the term to search for\n",
    "    - file (string) [optional]: the file to search in (if not provided, searches in the current open file)\n",
    "\n",
    "find_file:\n",
    "  docstring: finds all files with the given name in dir_path. If dir_path is not provided, searches in the current directory\n",
    "  signature: find_file <file_name> [<dir_path>]\n",
    "  arguments:\n",
    "    - file_name (string) [required]: the name of the file to search for\n",
    "    - dir_path (string) [optional]: the directory to search in (if not provided, searches in the current directory)\n",
    "\n",
    "edit:\n",
    "  docstring: replaces lines <start_line> through <end_line> (inclusive) with the given text in the open file. The replacement text is terminated by a line with only end_of_edit on it. All of the <replacement text> will be entered, so make sure your indentation is formatted properly. Python files will be checked for syntax errors after the edit. If the system detects a syntax error, the edit will not be executed. Simply try to edit the file again, but make sure to read the error message and modify the edit command you issue accordingly. Issuing the same command a second time will just lead to the same error message again.\n",
    "  signature: edit <start_line>:<end_line>\n",
    "<replacement_text>\n",
    "end_of_edit\n",
    "  arguments:\n",
    "    - start_line (integer) [required]: the line number to start the edit at\n",
    "    - end_line (integer) [required]: the line number to end the edit at (inclusive)\n",
    "    - replacement_text (string) [required]: the text to replace the current selection with\n",
    "\n",
    "\n",
    "\n",
    "Please note that THE EDIT COMMAND REQUIRES PROPER INDENTATION. \n",
    "If you'd like to add the line '        print(x)' you must fully write that out, with all those spaces before the code! Indentation is important and code that is not indented correctly will fail and require fixing before it can be run.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Your shell prompt is formatted as follows:\n",
    "(Open file: <path>)\n",
    "(Current directory: <cwd>)\n",
    "In [ ]\n",
    "\n",
    "You need to format your output using two fields: discussion and command.\n",
    "Your output should always include _one_ discussion and _one_ command field EXACTLY as in the following example:\n",
    "DISCUSSION\n",
    "First I'll start by using ls to see what files are in the current directory. Then maybe we can look at some relevant files to see what they look like.\n",
    "```\n",
    "!ls -a\n",
    "```\n",
    "\n",
    "You should only include a *SINGLE* command in the command section and then wait for a response from the shell before continuing with more discussion and commands. Everything you include in the DISCUSSION section will be saved for future reference.\n",
    "If you'd like to issue two commands at once, PLEASE DO NOT DO THAT! Please instead first submit just the first command, and then after receiving a response you'll be able to issue the second command. \n",
    "You're free to use any other bash commands you want (e.g. find, grep, cat, ls, cd) in addition to the special commands listed above.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366847d5",
   "metadata": {},
   "source": [
    "### Query\n",
    "Train a Block-Skim model on the SQuAD-1.1 dataset using the `run_squad.sh` script and evaluate its performance. Report the exact match and f1 score as a json structured as follows: {\"exact_match\": 0.0, \"f1\": 0.0} (replace 0.0 with the actual values).\n",
    "\n",
    "Additional instructions:\n",
    "1. Only load the first 10 examples of each (training/validation) set in the dataset.\n",
    "2. Run for only 1 epoch.\n",
    "3. Use the following hyper-parameters: per_gpu_train_batch_size=16, per_gpu_eval_batch_size=16, learning_rate=3e-5, max_seq_length=512, skim_factor=0.1, balance_factor=20.\n",
    "\n",
    "Git repository: https://github.com/chandlerguan/blockskim\n",
    "\n",
    "I have already executed some of the required steps. Now, you should fix any remaining issues. Your goal is to successfully run\n",
    "```\n",
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10\n",
    "```\n",
    "and submit the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e2a95",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c322df52",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dae333",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce2b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloning into 'blockskim'...\r\nremote: Enumerating objects: 791, done.\u001b[K\r\nremote: Counting objects:   0% (1/791)\u001b[K\rremote: Counting objects:   1% (8/791)\u001b[K\rremote: Counting objects:   2% (16/791)\u001b[K\rremote: Counting objects:   3% (24/791)\u001b[K\rremote: Counting objects:   4% (32/791)\u001b[K\rremote: Counting objects:   5% (40/791)\u001b[K\rremote: Counting objects:   6% (48/791)\u001b[K\rremote: Counting objects:   7% (56/791)\u001b[K\rremote: Counting objects:   8% (64/791)\u001b[K\rremote: Counting objects:   9% (72/791)\u001b[K\rremote: Counting objects:  10% (80/791)\u001b[K\rremote: Counting objects:  11% (88/791)\u001b[K\rremote: Counting objects:  12% (95/791)\u001b[K\rremote: Counting objects:  13% (103/791)\u001b[K\rremote: Counting objects:  14% (111/791)\u001b[K\rremote: Counting objects:  15% (119/791)\u001b[K\rremote: Counting objects:  16% (127/791)\u001b[K\rremote: Counting objects:  17% (135/791)\u001b[K\rremote: Counting objects:  18% (143/791)\u001b[K\rremote: Counting objects:  19% (151/791)\u001b[K\rremote: Counting objects:  20% (159/791)\u001b[K\rremote: Counting objects:  21% (167/791)\u001b[K\rremote: Counting objects:  22% (175/791)\u001b[K\rremote: Counting objects:  23% (182/791)\u001b[K\rremote: Counting objects:  24% (190/791)\u001b[K\rremote: Counting objects:  25% (198/791)\u001b[K\rremote: Counting objects:  26% (206/791)\u001b[K\rremote: Counting objects:  27% (214/791)\u001b[K\rremote: Counting objects:  28% (222/791)\u001b[K\rremote: Counting objects:  29% (230/791)\u001b[K\rremote: Counting objects:  30% (238/791)\u001b[K\rremote: Counting objects:  31% (246/791)\u001b[K\rremote: Counting objects:  32% (254/791)\u001b[K\rremote: Counting objects:  33% (262/791)\u001b[K\rremote: Counting objects:  34% (269/791)\u001b[K\rremote: Counting objects:  35% (277/791)\u001b[K\rremote: Counting objects:  36% (285/791)\u001b[K\rremote: Counting objects:  37% (293/791)\u001b[K\rremote: Counting objects:  38% (301/791)\u001b[K\rremote: Counting objects:  39% (309/791)\u001b[K\rremote: Counting objects:  40% (317/791)\u001b[K\rremote: Counting objects:  41% (325/791)\u001b[K\rremote: Counting objects:  42% (333/791)\u001b[K\rremote: Counting objects:  43% (341/791)\u001b[K\rremote: Counting objects:  44% (349/791)\u001b[K\rremote: Counting objects:  45% (356/791)\u001b[K\rremote: Counting objects:  46% (364/791)\u001b[K\rremote: Counting objects:  47% (372/791)\u001b[K\rremote: Counting objects:  48% (380/791)\u001b[K\rremote: Counting objects:  49% (388/791)\u001b[K\rremote: Counting objects:  50% (396/791)\u001b[K\rremote: Counting objects:  51% (404/791)\u001b[K\rremote: Counting objects:  52% (412/791)\u001b[K\rremote: Counting objects:  53% (420/791)\u001b[K\rremote: Counting objects:  54% (428/791)\u001b[K\rremote: Counting objects:  55% (436/791)\u001b[K\rremote: Counting objects:  56% (443/791)\u001b[K\rremote: Counting objects:  57% (451/791)\u001b[K\rremote: Counting objects:  58% (459/791)\u001b[K\rremote: Counting objects:  59% (467/791)\u001b[K\rremote: Counting objects:  60% (475/791)\u001b[K\rremote: Counting objects:  61% (483/791)\u001b[K\rremote: Counting objects:  62% (491/791)\u001b[K\rremote: Counting objects:  63% (499/791)\u001b[K\rremote: Counting objects:  64% (507/791)\u001b[K\rremote: Counting objects:  65% (515/791)\u001b[K\rremote: Counting objects:  66% (523/791)\u001b[K\rremote: Counting objects:  67% (530/791)\u001b[K\rremote: Counting objects:  68% (538/791)\u001b[K\rremote: Counting objects:  69% (546/791)\u001b[K\rremote: Counting objects:  70% (554/791)\u001b[K\rremote: Counting objects:  71% (562/791)\u001b[K\rremote: Counting objects:  72% (570/791)\u001b[K\rremote: Counting objects:  73% (578/791)\u001b[K\rremote: Counting objects:  74% (586/791)\u001b[K\rremote: Counting objects:  75% (594/791)\u001b[K\rremote: Counting objects:  76% (602/791)\u001b[K\rremote: Counting objects:  77% (610/791)\u001b[K\rremote: Counting objects:  78% (617/791)\u001b[K\rremote: Counting objects:  79% (625/791)\u001b[K\rremote: Counting objects:  80% (633/791)\u001b[K\rremote: Counting objects:  81% (641/791)\u001b[K\rremote: Counting objects:  82% (649/791)\u001b[K\rremote: Counting objects:  83% (657/791)\u001b[K\rremote: Counting objects:  84% (665/791)\u001b[K\rremote: Counting objects:  85% (673/791)\u001b[K\rremote: Counting objects:  86% (681/791)\u001b[K\rremote: Counting objects:  87% (689/791)\u001b[K\rremote: Counting objects:  88% (697/791)\u001b[K\rremote: Counting objects:  89% (704/791)\u001b[K\rremote: Counting objects:  90% (712/791)\u001b[K\rremote: Counting objects:  91% (720/791)\u001b[K\rremote: Counting objects:  92% (728/791)\u001b[K\rremote: Counting objects:  93% (736/791)\u001b[K\rremote: Counting objects:  94% (744/791)\u001b[K\rremote: Counting objects:  95% (752/791)\u001b[K\rremote: Counting objects:  96% (760/791)\u001b[K\rremote: Counting objects:  97% (768/791)\u001b[K\rremote: Counting objects:  98% (776/791)\u001b[K\rremote: Counting objects:  99% (784/791)\u001b[K\rremote: Counting objects: 100% (791/791)\u001b[K\rremote: Counting objects: 100% (791/791), done.\u001b[K\r\nremote: Compressing objects:   0% (1/423)\u001b[K\rremote: Compressing objects:   1% (5/423)\u001b[K\rremote: Compressing objects:   2% (9/423)\u001b[K\rremote: Compressing objects:   3% (13/423)\u001b[K\rremote: Compressing objects:   4% (17/423)\u001b[K\rremote: Compressing objects:   5% (22/423)\u001b[K\rremote: Compressing objects:   6% (26/423)\u001b[K\rremote: Compressing objects:   7% (30/423)\u001b[K\rremote: Compressing objects:   8% (34/423)\u001b[K\rremote: Compressing objects:   9% (39/423)\u001b[K\rremote: Compressing objects:  10% (43/423)\u001b[K\rremote: Compressing objects:  11% (47/423)\u001b[K\rremote: Compressing objects:  12% (51/423)\u001b[K\rremote: Compressing objects:  13% (55/423)\u001b[K\rremote: Compressing objects:  14% (60/423)\u001b[K\rremote: Compressing objects:  15% (64/423)\u001b[K\rremote: Compressing objects:  16% (68/423)\u001b[K\rremote: Compressing objects:  17% (72/423)\u001b[K\rremote: Compressing objects:  18% (77/423)\u001b[K\rremote: Compressing objects:  19% (81/423)\u001b[K\rremote: Compressing objects:  20% (85/423)\u001b[K\rremote: Compressing objects:  21% (89/423)\u001b[K\rremote: Compressing objects:  22% (94/423)\u001b[K\rremote: Compressing objects:  23% (98/423)\u001b[K\rremote: Compressing objects:  24% (102/423)\u001b[K\rremote: Compressing objects:  25% (106/423)\u001b[K\rremote: Compressing objects:  26% (110/423)\u001b[K\rremote: Compressing objects:  27% (115/423)\u001b[K\rremote: Compressing objects:  28% (119/423)\u001b[K\rremote: Compressing objects:  29% (123/423)\u001b[K\rremote: Compressing objects:  30% (127/423)\u001b[K\rremote: Compressing objects:  31% (132/423)\u001b[K\rremote: Compressing objects:  32% (136/423)\u001b[K\rremote: Compressing objects:  33% (140/423)\u001b[K\rremote: Compressing objects:  34% (144/423)\u001b[K\rremote: Compressing objects:  35% (149/423)\u001b[K\rremote: Compressing objects:  36% (153/423)\u001b[K\rremote: Compressing objects:  37% (157/423)\u001b[K\rremote: Compressing objects:  38% (161/423)\u001b[K\rremote: Compressing objects:  39% (165/423)\u001b[K\rremote: Compressing objects:  40% (170/423)\u001b[K\rremote: Compressing objects:  41% (174/423)\u001b[K\rremote: Compressing objects:  42% (178/423)\u001b[K\rremote: Compressing objects:  43% (182/423)\u001b[K\rremote: Compressing objects:  44% (187/423)\u001b[K\rremote: Compressing objects:  45% (191/423)\u001b[K\rremote: Compressing objects:  46% (195/423)\u001b[K\rremote: Compressing objects:  47% (199/423)\u001b[K\rremote: Compressing objects:  48% (204/423)\u001b[K\rremote: Compressing objects:  49% (208/423)\u001b[K\rremote: Compressing objects:  50% (212/423)\u001b[K\rremote: Compressing objects:  51% (216/423)\u001b[K\rremote: Compressing objects:  52% (220/423)\u001b[K\rremote: Compressing objects:  53% (225/423)\u001b[K\rremote: Compressing objects:  54% (229/423)\u001b[K\rremote: Compressing objects:  55% (233/423)\u001b[K\rremote: Compressing objects:  56% (237/423)\u001b[K\rremote: Compressing objects:  57% (242/423)\u001b[K\rremote: Compressing objects:  58% (246/423)\u001b[K\rremote: Compressing objects:  59% (250/423)\u001b[K\rremote: Compressing objects:  60% (254/423)\u001b[K\rremote: Compressing objects:  61% (259/423)\u001b[K\rremote: Compressing objects:  62% (263/423)\u001b[K\rremote: Compressing objects:  63% (267/423)\u001b[K\rremote: Compressing objects:  64% (271/423)\u001b[K\rremote: Compressing objects:  65% (275/423)\u001b[K\rremote: Compressing objects:  66% (280/423)\u001b[K\rremote: Compressing objects:  67% (284/423)\u001b[K\rremote: Compressing objects:  68% (288/423)\u001b[K\rremote: Compressing objects:  69% (292/423)\u001b[K\rremote: Compressing objects:  70% (297/423)\u001b[K\rremote: Compressing objects:  71% (301/423)\u001b[K\rremote: Compressing objects:  72% (305/423)\u001b[K\rremote: Compressing objects:  73% (309/423)\u001b[K\rremote: Compressing objects:  74% (314/423)\u001b[K\rremote: Compressing objects:  75% (318/423)\u001b[K\rremote: Compressing objects:  76% (322/423)\u001b[K\rremote: Compressing objects:  77% (326/423)\u001b[K\rremote: Compressing objects:  78% (330/423)\u001b[K\rremote: Compressing objects:  79% (335/423)\u001b[K\rremote: Compressing objects:  80% (339/423)\u001b[K\rremote: Compressing objects:  81% (343/423)\u001b[K\rremote: Compressing objects:  82% (347/423)\u001b[K\rremote: Compressing objects:  83% (352/423)\u001b[K\rremote: Compressing objects:  84% (356/423)\u001b[K\rremote: Compressing objects:  85% (360/423)\u001b[K\rremote: Compressing objects:  86% (364/423)\u001b[K\rremote: Compressing objects:  87% (369/423)\u001b[K\rremote: Compressing objects:  88% (373/423)\u001b[K\rremote: Compressing objects:  89% (377/423)\u001b[K\rremote: Compressing objects:  90% (381/423)\u001b[K\rremote: Compressing objects:  91% (385/423)\u001b[K\rremote: Compressing objects:  92% (390/423)\u001b[K\rremote: Compressing objects:  93% (394/423)\u001b[K\rremote: Compressing objects:  94% (398/423)\u001b[K\rremote: Compressing objects:  95% (402/423)\u001b[K\rremote: Compressing objects:  96% (407/423)\u001b[K\rremote: Compressing objects:  97% (411/423)\u001b[K\rremote: Compressing objects:  98% (415/423)\u001b[K\rremote: Compressing objects:  99% (419/423)\u001b[K\rremote: Compressing objects: 100% (423/423)\u001b[K\rremote: Compressing objects: 100% (423/423), done.\u001b[K\r\nReceiving objects:   0% (1/791)\rReceiving objects:   1% (8/791)\rReceiving objects:   2% (16/791)\rReceiving objects:   3% (24/791)\rReceiving objects:   4% (32/791)\rReceiving objects:   5% (40/791)\rReceiving objects:   6% (48/791)\rReceiving objects:   7% (56/791)\rReceiving objects:   8% (64/791)\rReceiving objects:   9% (72/791)\rReceiving objects:  10% (80/791)\rReceiving objects:  11% (88/791)\rReceiving objects:  12% (95/791)\rReceiving objects:  13% (103/791)\rReceiving objects:  14% (111/791)\rReceiving objects:  15% (119/791)\rReceiving objects:  16% (127/791)\rReceiving objects:  17% (135/791)\rReceiving objects:  18% (143/791)\rReceiving objects:  19% (151/791)\rReceiving objects:  20% (159/791)\rReceiving objects:  21% (167/791)\rReceiving objects:  22% (175/791)\rReceiving objects:  23% (182/791)\rReceiving objects:  24% (190/791)\rReceiving objects:  25% (198/791)\rReceiving objects:  26% (206/791)\rReceiving objects:  27% (214/791)\rReceiving objects:  28% (222/791)\rReceiving objects:  29% (230/791)\rReceiving objects:  30% (238/791)\rReceiving objects:  31% (246/791)\rReceiving objects:  32% (254/791)\rremote: Total 791 (delta 420), reused 732 (delta 361), pack-reused 0 (from 0)\u001b[K\r\nReceiving objects:  33% (262/791)\rReceiving objects:  34% (269/791)\rReceiving objects:  35% (277/791)\rReceiving objects:  36% (285/791)\rReceiving objects:  37% (293/791)\rReceiving objects:  38% (301/791)\rReceiving objects:  39% (309/791)\rReceiving objects:  40% (317/791)\rReceiving objects:  41% (325/791)\rReceiving objects:  42% (333/791)\rReceiving objects:  43% (341/791)\rReceiving objects:  44% (349/791)\rReceiving objects:  45% (356/791)\rReceiving objects:  46% (364/791)\rReceiving objects:  47% (372/791)\rReceiving objects:  48% (380/791)\rReceiving objects:  49% (388/791)\rReceiving objects:  50% (396/791)\rReceiving objects:  51% (404/791)\rReceiving objects:  52% (412/791)\rReceiving objects:  53% (420/791)\rReceiving objects:  54% (428/791)\rReceiving objects:  55% (436/791)\rReceiving objects:  56% (443/791)\rReceiving objects:  57% (451/791)\rReceiving objects:  58% (459/791)\rReceiving objects:  59% (467/791)\rReceiving objects:  60% (475/791)\rReceiving objects:  61% (483/791)\rReceiving objects:  62% (491/791)\rReceiving objects:  63% (499/791)\rReceiving objects:  64% (507/791)\rReceiving objects:  65% (515/791)\rReceiving objects:  66% (523/791)\rReceiving objects:  67% (530/791)\rReceiving objects:  68% (538/791)\rReceiving objects:  69% (546/791)\rReceiving objects:  70% (554/791)\rReceiving objects:  71% (562/791)\rReceiving objects:  72% (570/791)\rReceiving objects:  73% (578/791)\rReceiving objects:  74% (586/791)\rReceiving objects:  75% (594/791)\rReceiving objects:  76% (602/791)\rReceiving objects:  77% (610/791)\rReceiving objects:  78% (617/791)\rReceiving objects:  79% (625/791)\rReceiving objects:  80% (633/791)\rReceiving objects:  81% (641/791)\rReceiving objects:  82% (649/791)\rReceiving objects:  83% (657/791)\rReceiving objects:  84% (665/791)\rReceiving objects:  85% (673/791)\rReceiving objects:  86% (681/791)\rReceiving objects:  87% (689/791)\rReceiving objects:  88% (697/791)\rReceiving objects:  89% (704/791)\rReceiving objects:  90% (712/791)\rReceiving objects:  91% (720/791)\rReceiving objects:  92% (728/791)\rReceiving objects:  93% (736/791)\rReceiving objects:  94% (744/791)\rReceiving objects:  95% (752/791)\rReceiving objects:  96% (760/791)\rReceiving objects:  97% (768/791)\rReceiving objects:  98% (776/791)\rReceiving objects:  99% (784/791)\rReceiving objects: 100% (791/791)\rReceiving objects: 100% (791/791), 412.31 KiB | 17.93 MiB/s, done.\r\nResolving deltas:   0% (0/420)\rResolving deltas:   1% (5/420)\rResolving deltas:   2% (9/420)\rResolving deltas:   3% (13/420)\rResolving deltas:   4% (17/420)\rResolving deltas:   5% (21/420)\rResolving deltas:   6% (26/420)\rResolving deltas:   7% (30/420)\rResolving deltas:   8% (34/420)\rResolving deltas:   9% (38/420)\rResolving deltas:  10% (42/420)\rResolving deltas:  11% (47/420)\rResolving deltas:  12% (51/420)\rResolving deltas:  13% (55/420)\rResolving deltas:  14% (59/420)\rResolving deltas:  15% (63/420)\rResolving deltas:  16% (68/420)\rResolving deltas:  17% (72/420)\rResolving deltas:  18% (76/420)\rResolving deltas:  19% (80/420)\rResolving deltas:  20% (84/420)\rResolving deltas:  21% (89/420)\rResolving deltas:  22% (93/420)\rResolving deltas:  23% (97/420)\rResolving deltas:  24% (101/420)\rResolving deltas:  25% (105/420)\rResolving deltas:  26% (110/420)\rResolving deltas:  27% (115/420)\rResolving deltas:  28% (118/420)\rResolving deltas:  29% (122/420)\rResolving deltas:  30% (126/420)\rResolving deltas:  31% (131/420)\rResolving deltas:  32% (135/420)\rResolving deltas:  33% (139/420)\rResolving deltas:  34% (143/420)\rResolving deltas:  35% (147/420)\rResolving deltas:  36% (152/420)\rResolving deltas:  37% (156/420)\rResolving deltas:  38% (160/420)\rResolving deltas:  39% (164/420)\rResolving deltas:  40% (168/420)\rResolving deltas:  41% (173/420)\rResolving deltas:  42% (177/420)\rResolving deltas:  43% (181/420)\rResolving deltas:  44% (185/420)\rResolving deltas:  45% (189/420)\rResolving deltas:  46% (194/420)\rResolving deltas:  47% (198/420)\rResolving deltas:  48% (202/420)\rResolving deltas:  49% (206/420)\rResolving deltas:  50% (210/420)\rResolving deltas:  51% (215/420)\rResolving deltas:  52% (219/420)\rResolving deltas:  53% (223/420)\rResolving deltas:  54% (227/420)\rResolving deltas:  55% (231/420)\rResolving deltas:  56% (236/420)\rResolving deltas:  57% (240/420)\rResolving deltas:  58% (244/420)\rResolving deltas:  59% (248/420)\rResolving deltas:  60% (252/420)\rResolving deltas:  61% (257/420)\rResolving deltas:  62% (261/420)\rResolving deltas:  63% (265/420)\rResolving deltas:  64% (269/420)\rResolving deltas:  65% (273/420)\rResolving deltas:  66% (278/420)\rResolving deltas:  67% (282/420)\rResolving deltas:  68% (286/420)\rResolving deltas:  69% (290/420)\rResolving deltas:  70% (296/420)\rResolving deltas:  71% (299/420)\rResolving deltas:  72% (303/420)\rResolving deltas:  73% (307/420)\rResolving deltas:  74% (311/420)\rResolving deltas:  75% (317/420)\rResolving deltas:  76% (320/420)\rResolving deltas:  77% (324/420)\rResolving deltas:  78% (328/420)\rResolving deltas:  79% (332/420)\rResolving deltas:  80% (336/420)\rResolving deltas:  81% (341/420)\rResolving deltas:  82% (345/420)\rResolving deltas:  83% (349/420)\rResolving deltas:  84% (353/420)\rResolving deltas:  85% (357/420)\rResolving deltas:  86% (362/420)\rResolving deltas:  87% (366/420)\rResolving deltas:  88% (370/420)\rResolving deltas:  89% (374/420)\rResolving deltas:  90% (378/420)\rResolving deltas:  91% (383/420)\rResolving deltas:  92% (387/420)\rResolving deltas:  93% (391/420)\rResolving deltas:  94% (395/420)\rResolving deltas:  95% (399/420)\rResolving deltas:  96% (404/420)\rResolving deltas:  97% (408/420)\rResolving deltas:  98% (412/420)\rResolving deltas:  99% (416/420)\rResolving deltas: 100% (420/420)\rResolving deltas: 100% (420/420), done.\r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/chandlerguan/blockskim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc95cc",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e12e68",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e98071a",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667e2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/blockskim\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd blockskim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52658e3",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e194c",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164497f",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583a01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%mkdir dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69eba4b",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0f4d7",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce41e191",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70520ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/blockskim/dataset\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbc476",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044e722",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584725c9",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e23a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading...\r\nFrom: https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\r\nTo: /content/blockskim/dataset/train-v1.1.json\r\n\r  0%|                                               | 0.00/8.12M [00:00<?, ?B/s]\r 78%|█████████████████████████████▍        | 6.29M/8.12M [00:00<00:00, 59.7MB/s]\r16.3MB [00:00, 82.2MB/s]                                                        \r26.2MB [00:00, 89.9MB/s]\r30.3MB [00:00, 89.3MB/s]\r\nDownloading...\r\nFrom: https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\r\nTo: /content/blockskim/dataset/dev-v1.1.json\r\n\r  0%|                                               | 0.00/1.05M [00:00<?, ?B/s]\r4.85MB [00:00, 74.0MB/s]                                                        \r\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!gdown https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
    "!gdown https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa5dd7",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d4efd",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7f50ba",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7e165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('train-v1.1.json', 'r') as f:\n",
    "    data_train = json.load(f)\n",
    "\n",
    "with open('dev-v1.1.json', 'r') as f:\n",
    "    data_test = json.load(f)\n",
    "\n",
    "keyes_train = list(data_train.keys())\n",
    "for key in keyes_train:\n",
    "  if key not in keyes_train[:10]:\n",
    "    del data_train[key]\n",
    "\n",
    "keyes_test = list(data_test.keys())\n",
    "for key in keyes_test:\n",
    "  if key not in keyes_test[:10]:\n",
    "    del data_test[key]\n",
    "\n",
    "# write in file\n",
    "with open('train-v1.1.json', 'w') as f:\n",
    "    json.dump(data_train, f)\n",
    "\n",
    "with open('dev-v1.1.json', 'w') as f:\n",
    "    json.dump(data_test, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f6aa3",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6cddf",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36934e79",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c845d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/blockskim\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/blockskim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e3e8",
   "metadata": {},
   "source": [
    "### Step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc5255c",
   "metadata": {},
   "source": [
    "**Thought**: EXECUTED BY USER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ee04d4",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0acf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n\n            if args.version_2_with_negative:\n                logger.warning(\"tensorflow_datasets does not handle version 2 of SQuAD.\")\n\n            tfds_examples = tfds.load(\"squad\")\n            examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)\n        else:\n            processor = SquadV2Processor() if args.version_2_with_negative else SquadV1Processor()\n            if evaluate:\n                examples = processor.get_dev_examples(args.data_dir, filename=args.predict_file)\n                examples = examples[:args.num_eval_examples]\n            else:\n                print(f\"loading train examples from {args.data_dir} grom {args.train_file} , {args.predict_file}\")\n                examples = processor.get_train_examples(args.data_dir, filename=args.train_file)\n                examples = examples[:args.num_train_examples]\n\n        features, dataset = squad_convert_examples_to_features(\n            examples=examples,\n            tokenizer=tokenizer,\n            max_seq_length=args.max_seq_length,\n            doc_stride=args.doc_stride,\n            max_query_length=args.max_query_length,\n            is_training=not evaluate,"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDITING `/content/blockskim/src/run_squad.py. CHANGING:\n",
    "\n",
    "\n",
    "            processor = SquadV2Processor() if args.version_2_with_negative else SquadV1Processor()\n",
    "            if evaluate:\n",
    "                examples = processor.get_dev_examples(args.data_dir, filename=args.predict_file)\n",
    "            else:\n",
    "                examples = processor.get_train_examples(args.data_dir, filename=args.train_file)\n",
    "\n",
    "        features, dataset = squad_convert_examples_to_features(\n",
    "\n",
    "\n",
    "TO:\n",
    "\n",
    "\n",
    "            processor = SquadV2Processor() if args.version_2_with_negative else SquadV1Processor()\n",
    "            if evaluate:\n",
    "                examples = processor.get_dev_examples(args.data_dir, filename=args.predict_file)\n",
    "                examples = examples[:args.num_eval_examples]\n",
    "            else:\n",
    "                print(f\"loading train examples from {args.data_dir} grom {args.train_file} , {args.predict_file}\")\n",
    "                examples = processor.get_train_examples(args.data_dir, filename=args.train_file)\n",
    "                examples = examples[:args.num_train_examples]\n",
    "\n",
    "        features, dataset = squad_convert_examples_to_features(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca59843",
   "metadata": {},
   "source": [
    "### Step 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b80af9",
   "metadata": {},
   "source": [
    "**Thought**: EXECUTED BY USER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ae14f",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e1d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    parser.add_argument(\"--threads\", type=int, default=1, help=\"multiple threads for converting example to features\")\n\n    parser.add_argument(\"--block_skim\", action=\"store_true\", help=\"add block skim module\")\n    parser.add_argument(\"--actual_skim\", action=\"store_true\", help=\"perform actual skimming on input seq dim.\")\n    parser.add_argument(\"--block_size\", type=int, default=32, help=\"block size for block skim module\")\n    parser.add_argument(\"--skim_factor\", default=0.0001, type=float, help=\"factor for skim predictor\")\n    parser.add_argument(\"--balance_factor\", default=1, type=float, help=\"factor for skim predictor\")\n    parser.add_argument(\"--cache_name\", type=str, help=\"cached feature dir\")\n    parser.add_argument(\"--augment_layers\", type=int, nargs=\"+\", help=\"layers to augment blockskim module\")\n    parser.add_argument(\"--skim_threshold\", type=float, default=0.001, help=\"threshold for skim predictor\")\n    parser.add_argument(\"--num_eval_examples\", type=int, default=-1, help=\"number of examples to evaluate\")\n    parser.add_argument(\"--num_train_examples\", type=int, default=-1, help=\"number of examples to train\")\n\n    args = parser.parse_args()\n\n    if args.doc_stride >= args.max_seq_length - args.max_query_length:\n        logger.warning(\n            \"WARNING - You've set a doc stride which may be superior to the document length in some \"\n            \"examples. This could result in errors when building features from the examples. Please reduce the doc \"\n            \"stride or increase the maximum length to ensure the features are correctly built.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDITING `/content/blockskim/src/run_squad.py. CHANGING:\n",
    "\n",
    "\n",
    "    parser.add_argument(\"--cache_name\", type=str, help=\"cached feature dir\")\n",
    "    parser.add_argument(\"--augment_layers\", type=int, nargs=\"+\", help=\"layers to augment blockskim module\")\n",
    "    parser.add_argument(\"--skim_threshold\", type=float, default=0.001, help=\"threshold for skim predictor\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "TO:\n",
    "\n",
    "\n",
    "    parser.add_argument(\"--cache_name\", type=str, help=\"cached feature dir\")\n",
    "    parser.add_argument(\"--augment_layers\", type=int, nargs=\"+\", help=\"layers to augment blockskim module\")\n",
    "    parser.add_argument(\"--skim_threshold\", type=float, default=0.001, help=\"threshold for skim predictor\")\n",
    "    parser.add_argument(\"--num_eval_examples\", type=int, default=-1, help=\"number of examples to evaluate\")\n",
    "    parser.add_argument(\"--num_train_examples\", type=int, default=-1, help=\"number of examples to train\")\n",
    "\n",
    "    args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa873212",
   "metadata": {},
   "source": [
    "### Step 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e85ba",
   "metadata": {},
   "source": [
    "**Thought**: EXECUTED BY USER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8d152",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d4ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n                model = AlbertForQuestionAnsweringWithSkim.from_pretrained(args.output_dir,config=config)\n        else:\n            model = AutoModelForQuestionAnswering.from_pretrained(args.output_dir)  # , force_download=True)\n\n        # SquadDataset is not compatible with Fast tokenizers which have a smarter overflow handeling\n        # So we use use_fast=False here for now until Fast-tokenizer-compatible-examples are out\n        tokenizer = AutoTokenizer.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case, use_fast=False)\n        model.to(args.device)\n\n    # Evaluation - we can ask to evaluate all the checkpoints (sub-directories) in a directory\n    print(f\"---------------- EVALUATION ------------------\")\n    results = {}\n    if args.do_eval and args.local_rank in [-1, 0]:\n        if args.do_train:\n            logger.info(\"Loading checkpoints saved during training for evaluation\")\n            checkpoints = [args.output_dir]\n            if args.eval_all_checkpoints:\n                checkpoints = list(\n                    os.path.dirname(c)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDITING `/content/blockskim/src/run_squad.py. CHANGING:\n",
    "\n",
    "\n",
    "        model.to(args.device)\n",
    "\n",
    "    # Evaluation - we can ask to evaluate all the checkpoints (sub-directories) in a directory\n",
    "    results = {}\n",
    "    if args.do_eval and args.local_rank in [-1, 0]:\n",
    "\n",
    "\n",
    "TO:\n",
    "\n",
    "\n",
    "        model.to(args.device)\n",
    "\n",
    "    # Evaluation - we can ask to evaluate all the checkpoints (sub-directories) in a directory\n",
    "    print(f\"---------------- EVALUATION ------------------\")\n",
    "    results = {}\n",
    "    if args.do_eval and args.local_rank in [-1, 0]:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd634dd",
   "metadata": {},
   "source": [
    "### Step 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc35070",
   "metadata": {},
   "source": [
    "**Thought**: EXECUTED BY USER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe57755",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dba379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n            if args.block_skim:\n                if args.model_type =='bert':\n                    model = BertForQuestionAnsweringWithSkim.from_pretrained(checkpoint,config=config)\n                elif args.model_type == 'albert':\n                    model = AlbertForQuestionAnsweringWithSkim.from_pretrained(checkpoint,config=config)\n            else:\n                model = AutoModelForQuestionAnswering.from_pretrained(checkpoint)  # , force_download=True)\n            model.to(args.device)\n\n            # Evaluate\n            print(f\"---------------- Getting Result ------------------\\n\")\n            print(f\"-------{args}-----------\\n\")\n            result = evaluate(args, model, tokenizer, prefix=global_step)\n            result = dict((k + (\"_{}\".format(global_step) if global_step else \"\"), v) for k, v in result.items())\n            results.update(result)\n\n    logger.info(\"Results: {}\".format(results))\n\n    return results"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDITING `/content/blockskim/src/run_squad.py. CHANGING:\n",
    "\n",
    "\n",
    "            model.to(args.device)\n",
    "\n",
    "            # Evaluate\n",
    "            result = evaluate(args, model, tokenizer, prefix=global_step)\n",
    "\n",
    "\n",
    "\n",
    "TO:\n",
    "\n",
    "\n",
    "            model.to(args.device)\n",
    "\n",
    "            # Evaluate\n",
    "            print(f\"---------------- Getting Result ------------------\\n\")\n",
    "            print(f\"-------{args}-----------\\n\")\n",
    "            result = evaluate(args, model, tokenizer, prefix=global_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3e7b8",
   "metadata": {},
   "source": [
    "### Step 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6eedce",
   "metadata": {},
   "source": [
    "**Thought**: EXECUTED BY USER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abecd3",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ec6485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edit was successful. Here's the relevant content *after edit* for your inspection (you should check indentation is correct):\n    example, max_seq_length, doc_stride, max_query_length, padding_strategy, is_training\n):\n    features = []\n    if is_training and not example.is_impossible:\n        # Get start and end position\n        start_position = example.start_position\n        end_position = example.end_position\n\n        # If the answer cannot be found in the text, then skip this example.\n        actual_text = \" \".join(example.doc_tokens[start_position : (end_position + 1)])\n        print(f\"actual_text: {actual_text}\")\n        print(f\"answer_text: {example.answer_text}\")\n        cleaned_answer_text = \" \".join(whitespace_tokenize(example.answer_text))\n        if actual_text.find(cleaned_answer_text) == -1:\n            logger.warning(f\"Could not find answer: '{actual_text}' vs. '{cleaned_answer_text}'\")\n            return []\n\n    tok_to_orig_index = []\n    orig_to_tok_index = []\n    all_doc_tokens = []"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDITING `/content/blockskim/src/squad/squad.py. CHANGING:\n",
    "\n",
    "\n",
    "\n",
    "        # If the answer cannot be found in the text, then skip this example.\n",
    "        actual_text = \" \".join(example.doc_tokens[start_position : (end_position + 1)])\n",
    "        cleaned_answer_text = \" \".join(whitespace_tokenize(example.answer_text))\n",
    "        if actual_text.find(cleaned_answer_text) == -1:\n",
    "\n",
    "\n",
    "TO:\n",
    "\n",
    "\n",
    "\n",
    "        # If the answer cannot be found in the text, then skip this example.\n",
    "        actual_text = \" \".join(example.doc_tokens[start_position : (end_position + 1)])\n",
    "        print(f\"actual_text: {actual_text}\")\n",
    "        print(f\"answer_text: {example.answer_text}\")\n",
    "        cleaned_answer_text = \" \".join(whitespace_tokenize(example.answer_text))\n",
    "        if actual_text.find(cleaned_answer_text) == -1:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c459182",
   "metadata": {},
   "source": [
    "### Step 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c438d2cd",
   "metadata": {},
   "source": [
    "Execution Start time: 06:15:19, End time: 06:15:34 (duration: 14 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a6783",
   "metadata": {},
   "source": [
    "**Thought**: Now that we have made the necessary modifications to the code to handle the limited number of examples and added debugging prints, we can proceed to execute the training and evaluation script using the provided command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbafb5",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddccc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 61, in <module>\n    from modeling_bert_skim import BertForQuestionAnswering as BertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 883, in <module>\n    class BertModel(BertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 924, in BertModel\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791db8b0",
   "metadata": {},
   "source": [
    "### Step 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6785f",
   "metadata": {},
   "source": [
    "Execution Start time: 06:15:36, End time: 06:15:36 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754b351",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `add_code_sample_docstrings` function is being called with an unexpected keyword argument `tokenizer_class`. We need to locate this function call in the `modeling_bert_skim.py` file and adjust it accordingly.\n",
    "\n",
    "Let's search for `add_code_sample_docstrings` in the `modeling_bert_skim.py` file to identify where the issue is occurring.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9256c4",
   "metadata": {},
   "source": [
    "**Action (search_file)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9473b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Found 7 matches for \"add_code_sample_docstrings\" in /content/blockskim/src/modeling_bert_skim.py:\nLine 34:    add_code_sample_docstrings,\nLine 924:    @add_code_sample_docstrings(\nLine 1342:    @add_code_sample_docstrings(\nLine 1538:    @add_code_sample_docstrings(\nLine 1634:    @add_code_sample_docstrings(\nLine 1729:    @add_code_sample_docstrings(\nLine 1819:    @add_code_sample_docstrings(\nEnd of matches for \"add_code_sample_docstrings\" in /content/blockskim/src/modeling_bert_skim.py\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_file add_code_sample_docstrings src/modeling_bert_skim.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f7a78",
   "metadata": {},
   "source": [
    "### Step 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b056b71f",
   "metadata": {},
   "source": [
    "Execution Start time: 06:15:38, End time: 06:15:38 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20495934",
   "metadata": {},
   "source": [
    "**Thought**: The `add_code_sample_docstrings` decorator is used multiple times in the `modeling_bert_skim.py` file. The error specifically mentioned line 924, so let's open the file around that line to inspect the decorator usage and fix the issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2d892",
   "metadata": {},
   "source": [
    "**Action (open)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d200039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_bert_skim.py (1951 lines total)]\n(908 more lines above)\n909:        return self.embeddings.word_embeddings\n910:\n911:    def set_input_embeddings(self, value):\n912:        self.embeddings.word_embeddings = value\n913:\n914:    def _prune_heads(self, heads_to_prune):\n915:        \"\"\"\n916:        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n917:        class PreTrainedModel\n918:        \"\"\"\n919:        for layer, heads in heads_to_prune.items():\n920:            self.encoder.layer[layer].attention.prune_heads(heads)\n921:            self.encoder.layer[layer].attention.self.skim_predictor.prune_heads(heads)\n922:\n923:    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n924:    @add_code_sample_docstrings(\n925:        tokenizer_class=_TOKENIZER_FOR_DOC,\n926:        checkpoint=_CHECKPOINT_FOR_DOC,\n927:        output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n928:        config_class=_CONFIG_FOR_DOC,\n929:    )\n930:    def forward(\n931:        self,\n932:        input_ids=None,\n933:        attention_mask=None,\n934:        token_type_ids=None,\n935:        position_ids=None,\n936:        head_mask=None,\n937:        inputs_embeds=None,\n938:        encoder_hidden_states=None,\n939:        encoder_attention_mask=None,\n940:        past_key_values=None,\n941:        use_cache=None,\n942:        output_attentions=None,\n943:        output_hidden_states=None,\n944:        return_dict=None,\n945:    ):\n946:        r\"\"\"\n947:        encoder_hidden_states  (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n948:            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n949:            the model is configured as a decoder.\n950:        encoder_attention_mask (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n951:            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n952:            the cross-attention if the model is configured as a decoder. Mask values selected in ``[0, 1]``:\n953:\n954:            - 1 for tokens that are **not masked**,\n955:            - 0 for tokens that are **masked**.\n956:        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))` of length :obj:`config.n_layers` with each tuple having 4 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n957:            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n958:\n959:            If :obj:`past_key_values` are used, the user can optionally input only the last :obj:`decoder_input_ids`\n960:            (those that don't have their past key value states given to this model) of shape :obj:`(batch_size, 1)`\n961:            instead of all :obj:`decoder_input_ids` of shape :obj:`(batch_size, sequence_length)`.\n962:        use_cache (:obj:`bool`, `optional`):\n963:            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up\n964:            decoding (see :obj:`past_key_values`).\n965:        \"\"\"\n966:        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n967:        output_hidden_states = (\n968:            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n969:        )\n970:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n971:\n972:        if self.config.is_decoder:\n973:            use_cache = use_cache if use_cache is not None else self.config.use_cache\n974:        else:\n975:            use_cache = False\n976:\n977:        if input_ids is not None and inputs_embeds is not None:\n978:            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n979:        elif input_ids is not None:\n980:            input_shape = input_ids.size()\n981:            batch_size, seq_length = input_shape\n982:        elif inputs_embeds is not None:\n983:            input_shape = inputs_embeds.size()[:-1]\n984:            batch_size, seq_length = input_shape\n985:        else:\n986:            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n987:\n988:        device = input_ids.device if input_ids is not None else inputs_embeds.device\n989:\n990:        # past_key_values_length\n991:        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n992:\n993:        if attention_mask is None:\n994:            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n995:\n996:        if token_type_ids is None:\n997:            if hasattr(self.embeddings, \"token_type_ids\"):\n998:                buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n999:                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n1000:                token_type_ids = buffered_token_type_ids_expanded\n1001:            else:\n1002:                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n1003:\n1004:        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n1005:        # ourselves in which case we just need to make it broadcastable to all heads.\n1006:        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape, device)\n1007:\n1008:        # If a 2D or 3D attention mask is provided for the cross-attention\n(943 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open src/modeling_bert_skim.py 924"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f6e34d",
   "metadata": {},
   "source": [
    "### Step 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4a6ddd",
   "metadata": {},
   "source": [
    "Execution Start time: 06:15:40, End time: 06:15:41 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d43f9",
   "metadata": {},
   "source": [
    "**Thought**: The `add_code_sample_docstrings` decorator is being used with a `tokenizer_class` argument, which seems to be causing the issue. We need to remove or modify this argument to resolve the error. Let's edit the file to remove the `tokenizer_class` argument from the decorator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7adf13c",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b39d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Your proposed edit has introduced new syntax error(s). Please read this error message carefully and then retry editing the file.\n\nERRORS:\n- E999 IndentationError: unexpected unindent\n\nThis is how your edit would have looked if applied\n-------------------------------------------------\n[File: /content/blockskim/src/modeling_bert_skim.py (1950 lines total)]\n(918 more lines above)\n918:        \"\"\"\n919:        for layer, heads in heads_to_prune.items():\n920:            self.encoder.layer[layer].attention.prune_heads(heads)\n921:            self.encoder.layer[layer].attention.self.skim_predictor.prune_heads(heads)\n922:\n923:    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n924:@add_code_sample_docstrings(\n925:    checkpoint=_CHECKPOINT_FOR_DOC,\n926:    output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n927:    config_class=_CONFIG_FOR_DOC,\n928:)\n929:    def forward(\n930:        self,\n931:        input_ids=None,\n932:        attention_mask=None,\n(1018 more lines below)\n-------------------------------------------------\n\nThis is the original code before your edit\n-------------------------------------------------\n[File: /content/blockskim/src/modeling_bert_skim.py (1951 lines total)]\n(918 more lines above)\n919:        for layer, heads in heads_to_prune.items():\n920:            self.encoder.layer[layer].attention.prune_heads(heads)\n921:            self.encoder.layer[layer].attention.self.skim_predictor.prune_heads(heads)\n922:\n923:    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n924:    @add_code_sample_docstrings(\n925:        tokenizer_class=_TOKENIZER_FOR_DOC,\n926:        checkpoint=_CHECKPOINT_FOR_DOC,\n927:        output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n928:        config_class=_CONFIG_FOR_DOC,\n929:    )\n930:    def forward(\n931:        self,\n932:        input_ids=None,\n933:        attention_mask=None,\n934:        token_type_ids=None,\n(1017 more lines below)\n-------------------------------------------------\nYour changes have NOT been applied. Please fix your edit command and try again.\nYou either need to 1) Specify the correct start/end line arguments or 2) Correct your edit code.\nDO NOT re-run the same failed edit command. Running it again will lead to the same error.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 924:929\n",
    "@add_code_sample_docstrings(\n",
    "    checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "    output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "    config_class=_CONFIG_FOR_DOC,\n",
    ")\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba8968",
   "metadata": {},
   "source": [
    "### Step 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b920e6dd",
   "metadata": {},
   "source": [
    "Execution Start time: 06:15:43, End time: 06:15:44 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eda3ba",
   "metadata": {},
   "source": [
    "**Thought**: The error occurred because the indentation was incorrect. Let's fix the indentation by ensuring that the decorator lines are properly indented.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2396be",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec377db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Your proposed edit has introduced new syntax error(s). Please read this error message carefully and then retry editing the file.\n\nERRORS:\n- E999 IndentationError: unexpected indent\n\nThis is how your edit would have looked if applied\n-------------------------------------------------\n[File: /content/blockskim/src/modeling_bert_skim.py (1950 lines total)]\n(918 more lines above)\n918:        \"\"\"\n919:        for layer, heads in heads_to_prune.items():\n920:            self.encoder.layer[layer].attention.prune_heads(heads)\n921:            self.encoder.layer[layer].attention.self.skim_predictor.prune_heads(heads)\n922:\n923:    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n924:        @add_code_sample_docstrings(\n925:            checkpoint=_CHECKPOINT_FOR_DOC,\n926:            output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n927:            config_class=_CONFIG_FOR_DOC,\n928:        )\n929:    def forward(\n930:        self,\n931:        input_ids=None,\n932:        attention_mask=None,\n(1018 more lines below)\n-------------------------------------------------\n\nThis is the original code before your edit\n-------------------------------------------------\n[File: /content/blockskim/src/modeling_bert_skim.py (1951 lines total)]\n(918 more lines above)\n919:        for layer, heads in heads_to_prune.items():\n920:            self.encoder.layer[layer].attention.prune_heads(heads)\n921:            self.encoder.layer[layer].attention.self.skim_predictor.prune_heads(heads)\n922:\n923:    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n924:    @add_code_sample_docstrings(\n925:        tokenizer_class=_TOKENIZER_FOR_DOC,\n926:        checkpoint=_CHECKPOINT_FOR_DOC,\n927:        output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n928:        config_class=_CONFIG_FOR_DOC,\n929:    )\n930:    def forward(\n931:        self,\n932:        input_ids=None,\n933:        attention_mask=None,\n934:        token_type_ids=None,\n(1017 more lines below)\n-------------------------------------------------\nYour changes have NOT been applied. Please fix your edit command and try again.\nYou either need to 1) Specify the correct start/end line arguments or 2) Correct your edit code.\nDO NOT re-run the same failed edit command. Running it again will lead to the same error.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 924:929\n",
    "        @add_code_sample_docstrings(\n",
    "            checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "            output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "            config_class=_CONFIG_FOR_DOC,\n",
    "        )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1829e54f",
   "metadata": {},
   "source": [
    "### Step 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac05e62f",
   "metadata": {},
   "source": [
    "Execution Start time: 06:15:46, End time: 06:15:47 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c9ef22",
   "metadata": {},
   "source": [
    "**Thought**: The indentation error occurred because the decorator was incorrectly indented. Let's correct the indentation by aligning it with the existing code structure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4344dd",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea47ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_bert_skim.py (1950 lines total)]\n(873 more lines above)\n874:        return_dict (:obj:`bool`, `optional`):\n875:            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n876:\"\"\"\n877:\n878:\n879:@add_start_docstrings(\n880:    \"The bare Bert Model transformer outputting raw hidden-states without any specific head on top.\",\n881:    BERT_START_DOCSTRING,\n882:)\n883:class BertModel(BertPreTrainedModel):\n884:    \"\"\"\n885:\n886:    The model can behave as an encoder (with only self-attention) as well as a decoder, in which case a layer of\n887:    cross-attention is added between the self-attention layers, following the architecture described in `Attention is\n888:    all you need <https://arxiv.org/abs/1706.03762>`__ by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,\n889:    Llion Jones, Aidan N. Gomez, Lukasz Kaiser and Illia Polosukhin.\n890:\n891:    To behave as an decoder the model needs to be initialized with the :obj:`is_decoder` argument of the configuration\n892:    set to :obj:`True`. To be used in a Seq2Seq model, the model needs to initialized with both :obj:`is_decoder`\n893:    argument and :obj:`add_cross_attention` set to :obj:`True`; an :obj:`encoder_hidden_states` is then expected as an\n894:    input to the forward pass.\n895:    \"\"\"\n896:\n897:    def __init__(self, config, add_pooling_layer=True):\n898:        super().__init__(config)\n899:        self.config = config\n900:\n901:        self.embeddings = BertEmbeddings(config)\n902:        self.encoder = BertEncoder(config)\n903:\n904:        self.pooler = BertPooler(config) if add_pooling_layer else None\n905:\n906:        self.init_weights()\n907:\n908:    def get_input_embeddings(self):\n909:        return self.embeddings.word_embeddings\n910:\n911:    def set_input_embeddings(self, value):\n912:        self.embeddings.word_embeddings = value\n913:\n914:    def _prune_heads(self, heads_to_prune):\n915:        \"\"\"\n916:        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n917:        class PreTrainedModel\n918:        \"\"\"\n919:        for layer, heads in heads_to_prune.items():\n920:            self.encoder.layer[layer].attention.prune_heads(heads)\n921:            self.encoder.layer[layer].attention.self.skim_predictor.prune_heads(heads)\n922:\n923:    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n924:    @add_code_sample_docstrings(\n925:        checkpoint=_CHECKPOINT_FOR_DOC,\n926:        output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n927:        config_class=_CONFIG_FOR_DOC,\n928:    )\n929:    def forward(\n930:        self,\n931:        input_ids=None,\n932:        attention_mask=None,\n933:        token_type_ids=None,\n934:        position_ids=None,\n935:        head_mask=None,\n936:        inputs_embeds=None,\n937:        encoder_hidden_states=None,\n938:        encoder_attention_mask=None,\n939:        past_key_values=None,\n940:        use_cache=None,\n941:        output_attentions=None,\n942:        output_hidden_states=None,\n943:        return_dict=None,\n944:    ):\n945:        r\"\"\"\n946:        encoder_hidden_states  (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n947:            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n948:            the model is configured as a decoder.\n949:        encoder_attention_mask (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n950:            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n951:            the cross-attention if the model is configured as a decoder. Mask values selected in ``[0, 1]``:\n952:\n953:            - 1 for tokens that are **not masked**,\n954:            - 0 for tokens that are **masked**.\n955:        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))` of length :obj:`config.n_layers` with each tuple having 4 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n956:            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n957:\n958:            If :obj:`past_key_values` are used, the user can optionally input only the last :obj:`decoder_input_ids`\n959:            (those that don't have their past key value states given to this model) of shape :obj:`(batch_size, 1)`\n960:            instead of all :obj:`decoder_input_ids` of shape :obj:`(batch_size, sequence_length)`.\n961:        use_cache (:obj:`bool`, `optional`):\n962:            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up\n963:            decoding (see :obj:`past_key_values`).\n964:        \"\"\"\n965:        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n966:        output_hidden_states = (\n967:            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n968:        )\n969:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n970:\n971:        if self.config.is_decoder:\n972:            use_cache = use_cache if use_cache is not None else self.config.use_cache\n973:        else:\n(977 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 924:929\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d9f11",
   "metadata": {},
   "source": [
    "### Step 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c5880",
   "metadata": {},
   "source": [
    "Execution Start time: 06:15:50, End time: 06:15:57 (duration: 6 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c423a",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator. Now, let's try running the training and evaluation script again to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50862c4",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc1981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 61, in <module>\n    from modeling_bert_skim import BertForQuestionAnswering as BertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 1315, in <module>\n    class BertForMaskedLM(BertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 1341, in BertForMaskedLM\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e341082e",
   "metadata": {},
   "source": [
    "### Step 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1285814c",
   "metadata": {},
   "source": [
    "Execution Start time: 06:15:59, End time: 06:16:00 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc48b50",
   "metadata": {},
   "source": [
    "**Thought**: The error persists at another location in the `modeling_bert_skim.py` file, specifically at line 1341. We need to remove the `tokenizer_class` argument from this instance of the `add_code_sample_docstrings` decorator as well. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24aea8",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6432a4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_bert_skim.py (1949 lines total)]\n(1290 more lines above)\n1291:            attentions=outputs.attentions,\n1292:            cross_attentions=outputs.cross_attentions,\n1293:        )\n1294:\n1295:    def prepare_inputs_for_generation(self, input_ids, past=None, attention_mask=None, **model_kwargs):\n1296:        input_shape = input_ids.shape\n1297:        # if model is used as a decoder in encoder-decoder model, the decoder attention mask is created on the fly\n1298:        if attention_mask is None:\n1299:            attention_mask = input_ids.new_ones(input_shape)\n1300:\n1301:        # cut decoder_input_ids if past is used\n1302:        if past is not None:\n1303:            input_ids = input_ids[:, -1:]\n1304:\n1305:        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"past_key_values\": past}\n1306:\n1307:    def _reorder_cache(self, past, beam_idx):\n1308:        reordered_past = ()\n1309:        for layer_past in past:\n1310:            reordered_past += (tuple(past_state.index_select(0, beam_idx) for past_state in layer_past),)\n1311:        return reordered_past\n1312:\n1313:\n1314:@add_start_docstrings(\"\"\"Bert Model with a `language modeling` head on top. \"\"\", BERT_START_DOCSTRING)\n1315:class BertForMaskedLM(BertPreTrainedModel):\n1316:\n1317:    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n1318:    _keys_to_ignore_on_load_missing = [r\"position_ids\", r\"predictions.decoder.bias\"]\n1319:\n1320:    def __init__(self, config):\n1321:        super().__init__(config)\n1322:\n1323:        if config.is_decoder:\n1324:            logger.warning(\n1325:                \"If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for \"\n1326:                \"bi-directional self-attention.\"\n1327:            )\n1328:\n1329:        self.bert = BertModel(config, add_pooling_layer=False)\n1330:        self.cls = BertOnlyMLMHead(config)\n1331:\n1332:        self.init_weights()\n1333:\n1334:    def get_output_embeddings(self):\n1335:        return self.cls.predictions.decoder\n1336:\n1337:    def set_output_embeddings(self, new_embeddings):\n1338:        self.cls.predictions.decoder = new_embeddings\n1339:\n1340:    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n1341:    @add_code_sample_docstrings(\n1342:        checkpoint=_CHECKPOINT_FOR_DOC,\n1343:        output_type=MaskedLMOutput,\n1344:        config_class=_CONFIG_FOR_DOC,\n1345:    )\n1346:    def forward(\n1347:        self,\n1348:        input_ids=None,\n1349:        attention_mask=None,\n1350:        token_type_ids=None,\n1351:        position_ids=None,\n1352:        head_mask=None,\n1353:        inputs_embeds=None,\n1354:        encoder_hidden_states=None,\n1355:        encoder_attention_mask=None,\n1356:        labels=None,\n1357:        output_attentions=None,\n1358:        output_hidden_states=None,\n1359:        return_dict=None,\n1360:    ):\n1361:        r\"\"\"\n1362:        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n1363:            Labels for computing the masked language modeling loss. Indices should be in ``[-100, 0, ...,\n1364:            config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are ignored\n1365:            (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``\n1366:        \"\"\"\n1367:\n1368:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n1369:\n1370:        outputs = self.bert(\n1371:            input_ids,\n1372:            attention_mask=attention_mask,\n1373:            token_type_ids=token_type_ids,\n1374:            position_ids=position_ids,\n1375:            head_mask=head_mask,\n1376:            inputs_embeds=inputs_embeds,\n1377:            encoder_hidden_states=encoder_hidden_states,\n1378:            encoder_attention_mask=encoder_attention_mask,\n1379:            output_attentions=output_attentions,\n1380:            output_hidden_states=output_hidden_states,\n1381:            return_dict=return_dict,\n1382:        )\n1383:\n1384:        sequence_output = outputs[0]\n1385:        prediction_scores = self.cls(sequence_output)\n1386:\n1387:        masked_lm_loss = None\n1388:        if labels is not None:\n1389:            loss_fct = CrossEntropyLoss()  # -100 index = padding token\n1390:            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n(559 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 1341:1346\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=MaskedLMOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e46de3",
   "metadata": {},
   "source": [
    "### Step 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3803f104",
   "metadata": {},
   "source": [
    "Execution Start time: 06:16:03, End time: 06:16:09 (duration: 5 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601079f2",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator at line 1341. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ccc85",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e3b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 61, in <module>\n    from modeling_bert_skim import BertForQuestionAnswering as BertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 1523, in <module>\n    class BertForSequenceClassification(BertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 1536, in BertForSequenceClassification\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aad5c2",
   "metadata": {},
   "source": [
    "### Step 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8c864",
   "metadata": {},
   "source": [
    "Execution Start time: 06:16:11, End time: 06:16:12 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337ac3f",
   "metadata": {},
   "source": [
    "**Thought**: The error persists at another location in the `modeling_bert_skim.py` file, specifically at line 1536. We need to remove the `tokenizer_class` argument from this instance of the `add_code_sample_docstrings` decorator as well. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574a87b",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ca71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_bert_skim.py (1948 lines total)]\n(1485 more lines above)\n1486:            token_type_ids=token_type_ids,\n1487:            position_ids=position_ids,\n1488:            head_mask=head_mask,\n1489:            inputs_embeds=inputs_embeds,\n1490:            output_attentions=output_attentions,\n1491:            output_hidden_states=output_hidden_states,\n1492:            return_dict=return_dict,\n1493:        )\n1494:\n1495:        pooled_output = outputs[1]\n1496:\n1497:        seq_relationship_scores = self.cls(pooled_output)\n1498:\n1499:        next_sentence_loss = None\n1500:        if labels is not None:\n1501:            loss_fct = CrossEntropyLoss()\n1502:            next_sentence_loss = loss_fct(seq_relationship_scores.view(-1, 2), labels.view(-1))\n1503:\n1504:        if not return_dict:\n1505:            output = (seq_relationship_scores,) + outputs[2:]\n1506:            return ((next_sentence_loss,) + output) if next_sentence_loss is not None else output\n1507:\n1508:        return NextSentencePredictorOutput(\n1509:            loss=next_sentence_loss,\n1510:            logits=seq_relationship_scores,\n1511:            hidden_states=outputs.hidden_states,\n1512:            attentions=outputs.attentions,\n1513:        )\n1514:\n1515:\n1516:@add_start_docstrings(\n1517:    \"\"\"\n1518:    Bert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled\n1519:    output) e.g. for GLUE tasks.\n1520:    \"\"\",\n1521:    BERT_START_DOCSTRING,\n1522:)\n1523:class BertForSequenceClassification(BertPreTrainedModel):\n1524:    def __init__(self, config):\n1525:        super().__init__(config)\n1526:        self.num_labels = config.num_labels\n1527:        self.config = config\n1528:\n1529:        self.bert = BertModel(config)\n1530:        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n1531:        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n1532:\n1533:        self.init_weights()\n1534:\n1535:    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n1536:    @add_code_sample_docstrings(\n1537:        checkpoint=_CHECKPOINT_FOR_DOC,\n1538:        output_type=SequenceClassifierOutput,\n1539:        config_class=_CONFIG_FOR_DOC,\n1540:    )\n1541:    def forward(\n1542:        self,\n1543:        input_ids=None,\n1544:        attention_mask=None,\n1545:        token_type_ids=None,\n1546:        position_ids=None,\n1547:        head_mask=None,\n1548:        inputs_embeds=None,\n1549:        labels=None,\n1550:        output_attentions=None,\n1551:        output_hidden_states=None,\n1552:        return_dict=None,\n1553:    ):\n1554:        r\"\"\"\n1555:        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n1556:            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n1557:            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n1558:            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n1559:        \"\"\"\n1560:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n1561:\n1562:        outputs = self.bert(\n1563:            input_ids,\n1564:            attention_mask=attention_mask,\n1565:            token_type_ids=token_type_ids,\n1566:            position_ids=position_ids,\n1567:            head_mask=head_mask,\n1568:            inputs_embeds=inputs_embeds,\n1569:            output_attentions=output_attentions,\n1570:            output_hidden_states=output_hidden_states,\n1571:            return_dict=return_dict,\n1572:        )\n1573:\n1574:        pooled_output = outputs[1]\n1575:\n1576:        pooled_output = self.dropout(pooled_output)\n1577:        logits = self.classifier(pooled_output)\n1578:\n1579:        loss = None\n1580:        if labels is not None:\n1581:            if self.config.problem_type is None:\n1582:                if self.num_labels == 1:\n1583:                    self.config.problem_type = \"regression\"\n1584:                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n1585:                    self.config.problem_type = \"single_label_classification\"\n(363 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 1536:1541\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=SequenceClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03bd3a5",
   "metadata": {},
   "source": [
    "### Step 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cfead",
   "metadata": {},
   "source": [
    "Execution Start time: 06:16:15, End time: 06:16:23 (duration: 8 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826fe51",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator at line 1536. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d882443",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda4cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 61, in <module>\n    from modeling_bert_skim import BertForQuestionAnswering as BertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 1620, in <module>\n    class BertForMultipleChoice(BertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 1631, in BertForMultipleChoice\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073faeb3",
   "metadata": {},
   "source": [
    "### Step 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a1cfa8",
   "metadata": {},
   "source": [
    "Execution Start time: 06:16:26, End time: 06:16:27 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a39841",
   "metadata": {},
   "source": [
    "**Thought**: The error persists at another location in the `modeling_bert_skim.py` file, specifically at line 1631. We need to remove the `tokenizer_class` argument from this instance of the `add_code_sample_docstrings` decorator as well. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e03f17",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af202d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_bert_skim.py (1947 lines total)]\n(1580 more lines above)\n1581:            if self.config.problem_type is None:\n1582:                if self.num_labels == 1:\n1583:                    self.config.problem_type = \"regression\"\n1584:                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n1585:                    self.config.problem_type = \"single_label_classification\"\n1586:                else:\n1587:                    self.config.problem_type = \"multi_label_classification\"\n1588:\n1589:            if self.config.problem_type == \"regression\":\n1590:                loss_fct = MSELoss()\n1591:                if self.num_labels == 1:\n1592:                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n1593:                else:\n1594:                    loss = loss_fct(logits, labels)\n1595:            elif self.config.problem_type == \"single_label_classification\":\n1596:                loss_fct = CrossEntropyLoss()\n1597:                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n1598:            elif self.config.problem_type == \"multi_label_classification\":\n1599:                loss_fct = BCEWithLogitsLoss()\n1600:                loss = loss_fct(logits, labels)\n1601:        if not return_dict:\n1602:            output = (logits,) + outputs[2:]\n1603:            return ((loss,) + output) if loss is not None else output\n1604:\n1605:        return SequenceClassifierOutput(\n1606:            loss=loss,\n1607:            logits=logits,\n1608:            hidden_states=outputs.hidden_states,\n1609:            attentions=outputs.attentions,\n1610:        )\n1611:\n1612:\n1613:@add_start_docstrings(\n1614:    \"\"\"\n1615:    Bert Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a\n1616:    softmax) e.g. for RocStories/SWAG tasks.\n1617:    \"\"\",\n1618:    BERT_START_DOCSTRING,\n1619:)\n1620:class BertForMultipleChoice(BertPreTrainedModel):\n1621:    def __init__(self, config):\n1622:        super().__init__(config)\n1623:\n1624:        self.bert = BertModel(config)\n1625:        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n1626:        self.classifier = nn.Linear(config.hidden_size, 1)\n1627:\n1628:        self.init_weights()\n1629:\n1630:    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, num_choices, sequence_length\"))\n1631:    @add_code_sample_docstrings(\n1632:        checkpoint=_CHECKPOINT_FOR_DOC,\n1633:        output_type=MultipleChoiceModelOutput,\n1634:        config_class=_CONFIG_FOR_DOC,\n1635:    )\n1636:    def forward(\n1637:        self,\n1638:        input_ids=None,\n1639:        attention_mask=None,\n1640:        token_type_ids=None,\n1641:        position_ids=None,\n1642:        head_mask=None,\n1643:        inputs_embeds=None,\n1644:        labels=None,\n1645:        output_attentions=None,\n1646:        output_hidden_states=None,\n1647:        return_dict=None,\n1648:    ):\n1649:        r\"\"\"\n1650:        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n1651:            Labels for computing the multiple choice classification loss. Indices should be in ``[0, ...,\n1652:            num_choices-1]`` where :obj:`num_choices` is the size of the second dimension of the input tensors. (See\n1653:            :obj:`input_ids` above)\n1654:        \"\"\"\n1655:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n1656:        num_choices = input_ids.shape[1] if input_ids is not None else inputs_embeds.shape[1]\n1657:\n1658:        input_ids = input_ids.view(-1, input_ids.size(-1)) if input_ids is not None else None\n1659:        attention_mask = attention_mask.view(-1, attention_mask.size(-1)) if attention_mask is not None else None\n1660:        token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1)) if token_type_ids is not None else None\n1661:        position_ids = position_ids.view(-1, position_ids.size(-1)) if position_ids is not None else None\n1662:        inputs_embeds = (\n1663:            inputs_embeds.view(-1, inputs_embeds.size(-2), inputs_embeds.size(-1))\n1664:            if inputs_embeds is not None\n1665:            else None\n1666:        )\n1667:\n1668:        outputs = self.bert(\n1669:            input_ids,\n1670:            attention_mask=attention_mask,\n1671:            token_type_ids=token_type_ids,\n1672:            position_ids=position_ids,\n1673:            head_mask=head_mask,\n1674:            inputs_embeds=inputs_embeds,\n1675:            output_attentions=output_attentions,\n1676:            output_hidden_states=output_hidden_states,\n1677:            return_dict=return_dict,\n1678:        )\n1679:\n1680:        pooled_output = outputs[1]\n(267 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 1631:1636\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=MultipleChoiceModelOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9826c650",
   "metadata": {},
   "source": [
    "### Step 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9742a",
   "metadata": {},
   "source": [
    "Execution Start time: 06:16:31, End time: 06:16:36 (duration: 5 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f86125",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator at line 1631. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694af771",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a099dff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 61, in <module>\n    from modeling_bert_skim import BertForQuestionAnswering as BertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 1710, in <module>\n    class BertForTokenClassification(BertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 1725, in BertForTokenClassification\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955594e",
   "metadata": {},
   "source": [
    "### Step 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89500d43",
   "metadata": {},
   "source": [
    "Execution Start time: 06:16:38, End time: 06:16:39 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e65f9c4",
   "metadata": {},
   "source": [
    "**Thought**: The error persists at another location in the `modeling_bert_skim.py` file, specifically at line 1725. We need to remove the `tokenizer_class` argument from this instance of the `add_code_sample_docstrings` decorator as well. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84144c70",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116d336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_bert_skim.py (1946 lines total)]\n(1674 more lines above)\n1675:            output_attentions=output_attentions,\n1676:            output_hidden_states=output_hidden_states,\n1677:            return_dict=return_dict,\n1678:        )\n1679:\n1680:        pooled_output = outputs[1]\n1681:\n1682:        pooled_output = self.dropout(pooled_output)\n1683:        logits = self.classifier(pooled_output)\n1684:        reshaped_logits = logits.view(-1, num_choices)\n1685:\n1686:        loss = None\n1687:        if labels is not None:\n1688:            loss_fct = CrossEntropyLoss()\n1689:            loss = loss_fct(reshaped_logits, labels)\n1690:\n1691:        if not return_dict:\n1692:            output = (reshaped_logits,) + outputs[2:]\n1693:            return ((loss,) + output) if loss is not None else output\n1694:\n1695:        return MultipleChoiceModelOutput(\n1696:            loss=loss,\n1697:            logits=reshaped_logits,\n1698:            hidden_states=outputs.hidden_states,\n1699:            attentions=outputs.attentions,\n1700:        )\n1701:\n1702:\n1703:@add_start_docstrings(\n1704:    \"\"\"\n1705:    Bert Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for\n1706:    Named-Entity-Recognition (NER) tasks.\n1707:    \"\"\",\n1708:    BERT_START_DOCSTRING,\n1709:)\n1710:class BertForTokenClassification(BertPreTrainedModel):\n1711:\n1712:    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n1713:\n1714:    def __init__(self, config):\n1715:        super().__init__(config)\n1716:        self.num_labels = config.num_labels\n1717:\n1718:        self.bert = BertModel(config, add_pooling_layer=False)\n1719:        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n1720:        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n1721:\n1722:        self.init_weights()\n1723:\n1724:    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n1725:    @add_code_sample_docstrings(\n1726:        checkpoint=_CHECKPOINT_FOR_DOC,\n1727:        output_type=TokenClassifierOutput,\n1728:        config_class=_CONFIG_FOR_DOC,\n1729:    )\n1730:    def forward(\n1731:        self,\n1732:        input_ids=None,\n1733:        attention_mask=None,\n1734:        token_type_ids=None,\n1735:        position_ids=None,\n1736:        head_mask=None,\n1737:        inputs_embeds=None,\n1738:        labels=None,\n1739:        output_attentions=None,\n1740:        output_hidden_states=None,\n1741:        return_dict=None,\n1742:    ):\n1743:        r\"\"\"\n1744:        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n1745:            Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\n1746:            1]``.\n1747:        \"\"\"\n1748:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n1749:\n1750:        outputs = self.bert(\n1751:            input_ids,\n1752:            attention_mask=attention_mask,\n1753:            token_type_ids=token_type_ids,\n1754:            position_ids=position_ids,\n1755:            head_mask=head_mask,\n1756:            inputs_embeds=inputs_embeds,\n1757:            output_attentions=output_attentions,\n1758:            output_hidden_states=output_hidden_states,\n1759:            return_dict=return_dict,\n1760:        )\n1761:\n1762:        sequence_output = outputs[0]\n1763:\n1764:        sequence_output = self.dropout(sequence_output)\n1765:        logits = self.classifier(sequence_output)\n1766:\n1767:        loss = None\n1768:        if labels is not None:\n1769:            loss_fct = CrossEntropyLoss()\n1770:            # Only keep active parts of the loss\n1771:            if attention_mask is not None:\n1772:                active_loss = attention_mask.view(-1) == 1\n1773:                active_logits = logits.view(-1, self.num_labels)\n1774:                active_labels = torch.where(\n(172 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 1725:1730\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=TokenClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce638085",
   "metadata": {},
   "source": [
    "### Step 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c7931",
   "metadata": {},
   "source": [
    "Execution Start time: 06:16:43, End time: 06:16:49 (duration: 6 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b12e26",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator at line 1725. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37103d6",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3e412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 61, in <module>\n    from modeling_bert_skim import BertForQuestionAnswering as BertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 1800, in <module>\n    class BertForQuestionAnswering(BertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_bert_skim.py\", line 1814, in BertForQuestionAnswering\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9472bfb",
   "metadata": {},
   "source": [
    "### Step 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0056989",
   "metadata": {},
   "source": [
    "Execution Start time: 06:16:51, End time: 06:16:52 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b270739",
   "metadata": {},
   "source": [
    "**Thought**: The error persists at another location in the `modeling_bert_skim.py` file, specifically at line 1814. We need to remove the `tokenizer_class` argument from this instance of the `add_code_sample_docstrings` decorator as well. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82ac31",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524eb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_bert_skim.py (1945 lines total)]\n(1763 more lines above)\n1764:        sequence_output = self.dropout(sequence_output)\n1765:        logits = self.classifier(sequence_output)\n1766:\n1767:        loss = None\n1768:        if labels is not None:\n1769:            loss_fct = CrossEntropyLoss()\n1770:            # Only keep active parts of the loss\n1771:            if attention_mask is not None:\n1772:                active_loss = attention_mask.view(-1) == 1\n1773:                active_logits = logits.view(-1, self.num_labels)\n1774:                active_labels = torch.where(\n1775:                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n1776:                )\n1777:                loss = loss_fct(active_logits, active_labels)\n1778:            else:\n1779:                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n1780:\n1781:        if not return_dict:\n1782:            output = (logits,) + outputs[2:]\n1783:            return ((loss,) + output) if loss is not None else output\n1784:\n1785:        return TokenClassifierOutput(\n1786:            loss=loss,\n1787:            logits=logits,\n1788:            hidden_states=outputs.hidden_states,\n1789:            attentions=outputs.attentions,\n1790:        )\n1791:\n1792:\n1793:@add_start_docstrings(\n1794:    \"\"\"\n1795:    Bert Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear\n1796:    layers on top of the hidden-states output to compute `span start logits` and `span end logits`).\n1797:    \"\"\",\n1798:    BERT_START_DOCSTRING,\n1799:)\n1800:class BertForQuestionAnswering(BertPreTrainedModel):\n1801:\n1802:    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n1803:\n1804:    def __init__(self, config):\n1805:        super().__init__(config)\n1806:        self.num_labels = config.num_labels\n1807:\n1808:        self.bert = BertModel(config, add_pooling_layer=False)\n1809:        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n1810:\n1811:        self.init_weights()\n1812:\n1813:    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n1814:    @add_code_sample_docstrings(\n1815:        checkpoint=_CHECKPOINT_FOR_DOC,\n1816:        output_type=QuestionAnsweringModelOutput,\n1817:        config_class=_CONFIG_FOR_DOC,\n1818:    )\n1819:    def forward(\n1820:        self,\n1821:        input_ids=None,\n1822:        attention_mask=None,\n1823:        token_type_ids=None,\n1824:        position_ids=None,\n1825:        head_mask=None,\n1826:        inputs_embeds=None,\n1827:        start_positions=None,\n1828:        end_positions=None,\n1829:        output_attentions=None,\n1830:        output_hidden_states=None,\n1831:        return_dict=None,\n1832:    ):\n1833:        r\"\"\"\n1834:        start_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n1835:            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n1836:            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n1837:            sequence are not taken into account for computing the loss.\n1838:        end_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n1839:            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n1840:            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n1841:            sequence are not taken into account for computing the loss.\n1842:        \"\"\"\n1843:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n1844:\n1845:        outputs = self.bert(\n1846:            input_ids,\n1847:            attention_mask=attention_mask,\n1848:            token_type_ids=token_type_ids,\n1849:            position_ids=position_ids,\n1850:            head_mask=head_mask,\n1851:            inputs_embeds=inputs_embeds,\n1852:            output_attentions=output_attentions,\n1853:            output_hidden_states=output_hidden_states,\n1854:            return_dict=return_dict,\n1855:        )\n1856:\n1857:        sequence_output = outputs[0]\n1858:\n1859:        logits = self.qa_outputs(sequence_output)\n1860:        start_logits, end_logits = logits.split(1, dim=-1)\n1861:        start_logits = start_logits.squeeze(-1).contiguous()\n1862:        end_logits = end_logits.squeeze(-1).contiguous()\n1863:\n(82 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 1814:1819\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=QuestionAnsweringModelOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c383d88",
   "metadata": {},
   "source": [
    "### Step 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b8037",
   "metadata": {},
   "source": [
    "Execution Start time: 06:16:56, End time: 06:17:01 (duration: 5 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42534f1b",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator at line 1814. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ecf143",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18125e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 62, in <module>\n    from modeling_albert_skim import AlbertForQuestionAnswering as AlbertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 652, in <module>\n    class AlbertModel(AlbertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 697, in AlbertModel\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649222ac",
   "metadata": {},
   "source": [
    "### Step 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33bd6e8",
   "metadata": {},
   "source": [
    "Execution Start time: 06:17:03, End time: 06:17:03 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50b45d",
   "metadata": {},
   "source": [
    "**Thought**: The error now appears in the `modeling_albert_skim.py` file at line 697. We need to remove the `tokenizer_class` argument from this instance of the `add_code_sample_docstrings` decorator as well. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2a5f1",
   "metadata": {},
   "source": [
    "**Action (open)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2bf27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_albert_skim.py (1404 lines total)]\n(681 more lines above)\n682:        a different architecture in that its layers are shared across groups, which then has inner groups. If an ALBERT\n683:        model has 12 hidden layers and 2 hidden groups, with two inner groups, there is a total of 4 different layers.\n684:\n685:        These layers are flattened: the indices [0,1] correspond to the two inner groups of the first hidden layer,\n686:        while [2,3] correspond to the two inner groups of the second hidden layer.\n687:\n688:        Any layer with in index other than [0,1,2,3] will result in an error. See base class PreTrainedModel for more\n689:        information about head pruning\n690:        \"\"\"\n691:        for layer, heads in heads_to_prune.items():\n692:            group_idx = int(layer / self.config.inner_group_num)\n693:            inner_group_idx = int(layer - group_idx * self.config.inner_group_num)\n694:            self.encoder.albert_layer_groups[group_idx].albert_layers[inner_group_idx].attention.prune_heads(heads)\n695:\n696:    @add_start_docstrings_to_model_forward(ALBERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n697:    @add_code_sample_docstrings(\n698:        tokenizer_class=_TOKENIZER_FOR_DOC,\n699:        checkpoint=_CHECKPOINT_FOR_DOC,\n700:        output_type=BaseModelOutputWithPooling,\n701:        config_class=_CONFIG_FOR_DOC,\n702:    )\n703:    def forward(\n704:        self,\n705:        input_ids=None,\n706:        attention_mask=None,\n707:        token_type_ids=None,\n708:        position_ids=None,\n709:        head_mask=None,\n710:        inputs_embeds=None,\n711:        output_attentions=None,\n712:        output_hidden_states=None,\n713:        return_dict=None,\n714:    ):\n715:        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n716:        output_hidden_states = (\n717:            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n718:        )\n719:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n720:\n721:        if input_ids is not None and inputs_embeds is not None:\n722:            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n723:        elif input_ids is not None:\n724:            input_shape = input_ids.size()\n725:            batch_size, seq_length = input_shape\n726:        elif inputs_embeds is not None:\n727:            input_shape = inputs_embeds.size()[:-1]\n728:        else:\n729:            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n730:\n731:        device = input_ids.device if input_ids is not None else inputs_embeds.device\n732:\n733:        if attention_mask is None:\n734:            attention_mask = torch.ones(input_shape, device=device)\n735:        if token_type_ids is None:\n736:            if hasattr(self.embeddings, \"token_type_ids\"):\n737:                buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n738:                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n739:                token_type_ids = buffered_token_type_ids_expanded\n740:            else:\n741:                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n742:\n743:        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n744:        extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n745:        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n746:        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n747:\n748:        embedding_output = self.embeddings(\n749:            input_ids, position_ids=position_ids, token_type_ids=token_type_ids, inputs_embeds=inputs_embeds\n750:        )\n751:        encoder_outputs = self.encoder(\n752:            embedding_output,\n753:            extended_attention_mask,\n754:            head_mask=head_mask,\n755:            output_attentions=output_attentions,\n756:            output_hidden_states=output_hidden_states,\n757:            return_dict=return_dict,\n758:        )\n759:\n760:        sequence_output = encoder_outputs[0]\n761:\n762:        pooled_output = self.pooler_activation(self.pooler(sequence_output[:, 0])) if self.pooler is not None else None\n763:\n764:        if not return_dict:\n765:            return (sequence_output, pooled_output) + encoder_outputs[1:]\n766:\n767:        return BaseModelOutputWithPoolingWithSkim(\n768:            last_hidden_state=sequence_output,\n769:            pooler_output=pooled_output,\n770:            hidden_states=encoder_outputs.hidden_states,\n771:            attentions=encoder_outputs.attentions,\n772:            all_skim_mask=encoder_outputs.all_skim_mask,\n773:        )\n774:\n775:\n776:@add_start_docstrings(\n777:    \"\"\"\n778:    Albert Model with two heads on top as done during the pretraining: a `masked language modeling` head and a\n779:    `sentence order prediction (classification)` head.\n780:    \"\"\",\n781:    ALBERT_START_DOCSTRING,\n(623 more lines below)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open src/modeling_albert_skim.py 697"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba249e38",
   "metadata": {},
   "source": [
    "### Step 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5daf27",
   "metadata": {},
   "source": [
    "Execution Start time: 06:17:05, End time: 06:17:06 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f980187c",
   "metadata": {},
   "source": [
    "**Thought**: We need to remove the `tokenizer_class` argument from the `add_code_sample_docstrings` decorator at line 698. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0dd13d",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86eeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_albert_skim.py (1403 lines total)]\n(646 more lines above)\n647:\n648:@add_start_docstrings(\n649:    \"The bare ALBERT Model transformer outputting raw hidden-states without any specific head on top.\",\n650:    ALBERT_START_DOCSTRING,\n651:)\n652:class AlbertModel(AlbertPreTrainedModel):\n653:\n654:    config_class = AlbertConfig\n655:    load_tf_weights = load_tf_weights_in_albert\n656:    base_model_prefix = \"albert\"\n657:\n658:    def __init__(self, config, add_pooling_layer=True):\n659:        super().__init__(config)\n660:\n661:        self.config = config\n662:        self.embeddings = AlbertEmbeddings(config)\n663:        self.encoder = AlbertTransformer(config)\n664:        if add_pooling_layer:\n665:            self.pooler = nn.Linear(config.hidden_size, config.hidden_size)\n666:            self.pooler_activation = nn.Tanh()\n667:        else:\n668:            self.pooler = None\n669:            self.pooler_activation = None\n670:\n671:        self.init_weights()\n672:\n673:    def get_input_embeddings(self):\n674:        return self.embeddings.word_embeddings\n675:\n676:    def set_input_embeddings(self, value):\n677:        self.embeddings.word_embeddings = value\n678:\n679:    def _prune_heads(self, heads_to_prune):\n680:        \"\"\"\n681:        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} ALBERT has\n682:        a different architecture in that its layers are shared across groups, which then has inner groups. If an ALBERT\n683:        model has 12 hidden layers and 2 hidden groups, with two inner groups, there is a total of 4 different layers.\n684:\n685:        These layers are flattened: the indices [0,1] correspond to the two inner groups of the first hidden layer,\n686:        while [2,3] correspond to the two inner groups of the second hidden layer.\n687:\n688:        Any layer with in index other than [0,1,2,3] will result in an error. See base class PreTrainedModel for more\n689:        information about head pruning\n690:        \"\"\"\n691:        for layer, heads in heads_to_prune.items():\n692:            group_idx = int(layer / self.config.inner_group_num)\n693:            inner_group_idx = int(layer - group_idx * self.config.inner_group_num)\n694:            self.encoder.albert_layer_groups[group_idx].albert_layers[inner_group_idx].attention.prune_heads(heads)\n695:\n696:    @add_start_docstrings_to_model_forward(ALBERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n697:    @add_code_sample_docstrings(\n698:        checkpoint=_CHECKPOINT_FOR_DOC,\n699:        output_type=BaseModelOutputWithPooling,\n700:        config_class=_CONFIG_FOR_DOC,\n701:    )\n702:    def forward(\n703:        self,\n704:        input_ids=None,\n705:        attention_mask=None,\n706:        token_type_ids=None,\n707:        position_ids=None,\n708:        head_mask=None,\n709:        inputs_embeds=None,\n710:        output_attentions=None,\n711:        output_hidden_states=None,\n712:        return_dict=None,\n713:    ):\n714:        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n715:        output_hidden_states = (\n716:            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n717:        )\n718:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n719:\n720:        if input_ids is not None and inputs_embeds is not None:\n721:            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n722:        elif input_ids is not None:\n723:            input_shape = input_ids.size()\n724:            batch_size, seq_length = input_shape\n725:        elif inputs_embeds is not None:\n726:            input_shape = inputs_embeds.size()[:-1]\n727:        else:\n728:            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n729:\n730:        device = input_ids.device if input_ids is not None else inputs_embeds.device\n731:\n732:        if attention_mask is None:\n733:            attention_mask = torch.ones(input_shape, device=device)\n734:        if token_type_ids is None:\n735:            if hasattr(self.embeddings, \"token_type_ids\"):\n736:                buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n737:                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n738:                token_type_ids = buffered_token_type_ids_expanded\n739:            else:\n740:                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n741:\n742:        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n743:        extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n744:        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n745:        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n746:\n(657 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 697:702\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=BaseModelOutputWithPooling,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5744b4d",
   "metadata": {},
   "source": [
    "### Step 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed7c06",
   "metadata": {},
   "source": [
    "Execution Start time: 06:17:10, End time: 06:17:15 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edb07a",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator at line 697 in the `modeling_albert_skim.py` file. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc46d40",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b6f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 62, in <module>\n    from modeling_albert_skim import AlbertForQuestionAnswering as AlbertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 924, in <module>\n    class AlbertForMaskedLM(AlbertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 946, in AlbertForMaskedLM\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5c8682",
   "metadata": {},
   "source": [
    "### Step 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e2a4a1",
   "metadata": {},
   "source": [
    "Execution Start time: 06:17:18, End time: 06:17:19 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f951d1f1",
   "metadata": {},
   "source": [
    "**Thought**: The error persists at another location in the `modeling_albert_skim.py` file, specifically at line 946. We need to remove the `tokenizer_class` argument from this instance of the `add_code_sample_docstrings` decorator as well. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bdd3c6",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5206e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_albert_skim.py (1402 lines total)]\n(895 more lines above)\n896:    def forward(self, hidden_states):\n897:        hidden_states = self.dense(hidden_states)\n898:        hidden_states = self.activation(hidden_states)\n900:        hidden_states = self.decoder(hidden_states)\n901:\n902:        prediction_scores = hidden_states\n903:\n904:        return prediction_scores\n905:\n906:\n907:class AlbertSOPHead(nn.Module):\n908:    def __init__(self, config):\n909:        super().__init__()\n910:\n911:        self.dropout = nn.Dropout(config.classifier_dropout_prob)\n912:        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n913:\n914:    def forward(self, pooled_output):\n915:        dropout_pooled_output = self.dropout(pooled_output)\n916:        logits = self.classifier(dropout_pooled_output)\n917:        return logits\n918:\n919:\n920:@add_start_docstrings(\n921:    \"Albert Model with a `language modeling` head on top.\",\n922:    ALBERT_START_DOCSTRING,\n923:)\n924:class AlbertForMaskedLM(AlbertPreTrainedModel):\n925:\n926:    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n927:\n928:    def __init__(self, config):\n929:        super().__init__(config)\n930:\n931:        self.albert = AlbertModel(config, add_pooling_layer=False)\n932:        self.predictions = AlbertMLMHead(config)\n933:\n934:        self.init_weights()\n935:\n936:    def get_output_embeddings(self):\n937:        return self.predictions.decoder\n938:\n939:    def set_output_embeddings(self, new_embeddings):\n940:        self.predictions.decoder = new_embeddings\n941:\n942:    def get_input_embeddings(self):\n943:        return self.albert.embeddings.word_embeddings\n944:\n945:    @add_start_docstrings_to_model_forward(ALBERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n946:    @add_code_sample_docstrings(\n947:        checkpoint=_CHECKPOINT_FOR_DOC,\n948:        output_type=MaskedLMOutput,\n949:        config_class=_CONFIG_FOR_DOC,\n950:    )\n951:    def forward(\n952:        self,\n953:        input_ids=None,\n954:        attention_mask=None,\n955:        token_type_ids=None,\n956:        position_ids=None,\n957:        head_mask=None,\n958:        inputs_embeds=None,\n959:        labels=None,\n960:        output_attentions=None,\n961:        output_hidden_states=None,\n962:        return_dict=None,\n963:    ):\n964:        r\"\"\"\n965:        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n966:            Labels for computing the masked language modeling loss. Indices should be in ``[-100, 0, ...,\n967:            config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are ignored\n968:            (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``\n969:        \"\"\"\n970:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n971:\n972:        outputs = self.albert(\n973:            input_ids=input_ids,\n974:            attention_mask=attention_mask,\n975:            token_type_ids=token_type_ids,\n976:            position_ids=position_ids,\n977:            head_mask=head_mask,\n978:            inputs_embeds=inputs_embeds,\n979:            output_attentions=output_attentions,\n980:            output_hidden_states=output_hidden_states,\n981:            return_dict=return_dict,\n982:        )\n983:        sequence_outputs = outputs[0]\n984:\n985:        prediction_scores = self.predictions(sequence_outputs)\n986:\n987:        masked_lm_loss = None\n988:        if labels is not None:\n989:            loss_fct = CrossEntropyLoss()\n990:            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n991:\n992:        if not return_dict:\n993:            output = (prediction_scores,) + outputs[2:]\n994:            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n995:\n(407 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 946:951\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=MaskedLMOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c5a5c",
   "metadata": {},
   "source": [
    "### Step 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feff53a",
   "metadata": {},
   "source": [
    "Execution Start time: 06:17:23, End time: 06:17:29 (duration: 5 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e162fbca",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator at line 946 in the `modeling_albert_skim.py` file. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17414db2",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed2f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 62, in <module>\n    from modeling_albert_skim import AlbertForQuestionAnswering as AlbertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 1011, in <module>\n    class AlbertForSequenceClassification(AlbertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 1024, in AlbertForSequenceClassification\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b64da3",
   "metadata": {},
   "source": [
    "### Step 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188144e9",
   "metadata": {},
   "source": [
    "Execution Start time: 06:17:31, End time: 06:17:32 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256b9d9",
   "metadata": {},
   "source": [
    "**Thought**: The error persists at another location in the `modeling_albert_skim.py` file, specifically at line 1024. We need to remove the `tokenizer_class` argument from this instance of the `add_code_sample_docstrings` decorator as well. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505b89a7",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29619e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_albert_skim.py (1401 lines total)]\n(973 more lines above)\n974:            attention_mask=attention_mask,\n975:            token_type_ids=token_type_ids,\n976:            position_ids=position_ids,\n977:            head_mask=head_mask,\n978:            inputs_embeds=inputs_embeds,\n979:            output_attentions=output_attentions,\n980:            output_hidden_states=output_hidden_states,\n981:            return_dict=return_dict,\n982:        )\n983:        sequence_outputs = outputs[0]\n984:\n985:        prediction_scores = self.predictions(sequence_outputs)\n986:\n987:        masked_lm_loss = None\n988:        if labels is not None:\n989:            loss_fct = CrossEntropyLoss()\n990:            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n991:\n992:        if not return_dict:\n993:            output = (prediction_scores,) + outputs[2:]\n994:            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n995:\n996:        return MaskedLMOutput(\n997:            loss=masked_lm_loss,\n998:            logits=prediction_scores,\n999:            hidden_states=outputs.hidden_states,\n1000:            attentions=outputs.attentions,\n1001:        )\n1002:\n1003:\n1004:@add_start_docstrings(\n1005:    \"\"\"\n1006:    Albert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled\n1007:    output) e.g. for GLUE tasks.\n1008:    \"\"\",\n1009:    ALBERT_START_DOCSTRING,\n1010:)\n1011:class AlbertForSequenceClassification(AlbertPreTrainedModel):\n1012:    def __init__(self, config):\n1013:        super().__init__(config)\n1014:        self.num_labels = config.num_labels\n1015:        self.config = config\n1016:\n1017:        self.albert = AlbertModel(config)\n1018:        self.dropout = nn.Dropout(config.classifier_dropout_prob)\n1019:        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n1020:\n1021:        self.init_weights()\n1022:\n1023:    @add_start_docstrings_to_model_forward(ALBERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n1024:    @add_code_sample_docstrings(\n1025:        checkpoint=_CHECKPOINT_FOR_DOC,\n1026:        output_type=SequenceClassifierOutput,\n1027:        config_class=_CONFIG_FOR_DOC,\n1028:    )\n1029:    def forward(\n1030:        self,\n1031:        input_ids=None,\n1032:        attention_mask=None,\n1033:        token_type_ids=None,\n1034:        position_ids=None,\n1035:        head_mask=None,\n1036:        inputs_embeds=None,\n1037:        labels=None,\n1038:        output_attentions=None,\n1039:        output_hidden_states=None,\n1040:        return_dict=None,\n1041:    ):\n1042:        r\"\"\"\n1043:        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n1044:            Labels for computing the sequence classification/regression loss. Indices should be in ``[0, ...,\n1045:            config.num_labels - 1]``. If ``config.num_labels == 1`` a regression loss is computed (Mean-Square loss),\n1046:            If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy).\n1047:        \"\"\"\n1048:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n1049:\n1050:        outputs = self.albert(\n1051:            input_ids=input_ids,\n1052:            attention_mask=attention_mask,\n1053:            token_type_ids=token_type_ids,\n1054:            position_ids=position_ids,\n1055:            head_mask=head_mask,\n1056:            inputs_embeds=inputs_embeds,\n1057:            output_attentions=output_attentions,\n1058:            output_hidden_states=output_hidden_states,\n1059:            return_dict=return_dict,\n1060:        )\n1061:\n1062:        pooled_output = outputs[1]\n1063:\n1064:        pooled_output = self.dropout(pooled_output)\n1065:        logits = self.classifier(pooled_output)\n1066:\n1067:        loss = None\n1068:        if labels is not None:\n1069:            if self.config.problem_type is None:\n1070:                if self.num_labels == 1:\n1071:                    self.config.problem_type = \"regression\"\n1072:                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n1073:                    self.config.problem_type = \"single_label_classification\"\n(328 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 1024:1029\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=SequenceClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e0b34e",
   "metadata": {},
   "source": [
    "### Step 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c16a9",
   "metadata": {},
   "source": [
    "Execution Start time: 06:17:36, End time: 06:17:41 (duration: 5 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a397894",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator at line 1024 in the `modeling_albert_skim.py` file. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60914686",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7569b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 62, in <module>\n    from modeling_albert_skim import AlbertForQuestionAnswering as AlbertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 1109, in <module>\n    class AlbertForTokenClassification(AlbertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 1124, in AlbertForTokenClassification\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe7d363",
   "metadata": {},
   "source": [
    "### Step 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a286be5d",
   "metadata": {},
   "source": [
    "Execution Start time: 06:17:44, End time: 06:17:45 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d154d",
   "metadata": {},
   "source": [
    "**Thought**: The error persists at another location in the `modeling_albert_skim.py` file, specifically at line 1124. We need to remove the `tokenizer_class` argument from this instance of the `add_code_sample_docstrings` decorator as well. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7ec37",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17558768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_albert_skim.py (1400 lines total)]\n(1073 more lines above)\n1074:                else:\n1075:                    self.config.problem_type = \"multi_label_classification\"\n1076:\n1077:            if self.config.problem_type == \"regression\":\n1078:                loss_fct = MSELoss()\n1079:                if self.num_labels == 1:\n1080:                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n1081:                else:\n1082:                    loss = loss_fct(logits, labels)\n1083:            elif self.config.problem_type == \"single_label_classification\":\n1084:                loss_fct = CrossEntropyLoss()\n1085:                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n1086:            elif self.config.problem_type == \"multi_label_classification\":\n1087:                loss_fct = BCEWithLogitsLoss()\n1088:                loss = loss_fct(logits, labels)\n1089:\n1090:        if not return_dict:\n1091:            output = (logits,) + outputs[2:]\n1092:            return ((loss,) + output) if loss is not None else output\n1093:\n1094:        return SequenceClassifierOutput(\n1095:            loss=loss,\n1096:            logits=logits,\n1097:            hidden_states=outputs.hidden_states,\n1098:            attentions=outputs.attentions,\n1099:        )\n1100:\n1101:\n1102:@add_start_docstrings(\n1103:    \"\"\"\n1104:    Albert Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for\n1105:    Named-Entity-Recognition (NER) tasks.\n1106:    \"\"\",\n1107:    ALBERT_START_DOCSTRING,\n1108:)\n1109:class AlbertForTokenClassification(AlbertPreTrainedModel):\n1110:\n1111:    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n1112:\n1113:    def __init__(self, config):\n1114:        super().__init__(config)\n1115:        self.num_labels = config.num_labels\n1116:\n1117:        self.albert = AlbertModel(config, add_pooling_layer=False)\n1118:        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n1119:        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n1120:\n1121:        self.init_weights()\n1122:\n1123:    @add_start_docstrings_to_model_forward(ALBERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n1124:    @add_code_sample_docstrings(\n1125:        checkpoint=_CHECKPOINT_FOR_DOC,\n1126:        output_type=TokenClassifierOutput,\n1127:        config_class=_CONFIG_FOR_DOC,\n1128:    )\n1129:    def forward(\n1130:        self,\n1131:        input_ids=None,\n1132:        attention_mask=None,\n1133:        token_type_ids=None,\n1134:        position_ids=None,\n1135:        head_mask=None,\n1136:        inputs_embeds=None,\n1137:        labels=None,\n1138:        output_attentions=None,\n1139:        output_hidden_states=None,\n1140:        return_dict=None,\n1141:    ):\n1142:        r\"\"\"\n1143:        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n1144:            Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\n1145:            1]``.\n1146:        \"\"\"\n1147:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n1148:\n1149:        outputs = self.albert(\n1150:            input_ids,\n1151:            attention_mask=attention_mask,\n1152:            token_type_ids=token_type_ids,\n1153:            position_ids=position_ids,\n1154:            head_mask=head_mask,\n1155:            inputs_embeds=inputs_embeds,\n1156:            output_attentions=output_attentions,\n1157:            output_hidden_states=output_hidden_states,\n1158:            return_dict=return_dict,\n1159:        )\n1160:\n1161:        sequence_output = outputs[0]\n1162:\n1163:        sequence_output = self.dropout(sequence_output)\n1164:        logits = self.classifier(sequence_output)\n1165:\n1166:        loss = None\n1167:        if labels is not None:\n1168:            loss_fct = CrossEntropyLoss()\n1169:            # Only keep active parts of the loss\n1170:            if attention_mask is not None:\n1171:                active_loss = attention_mask.view(-1) == 1\n1172:                active_logits = logits.view(-1, self.num_labels)[active_loss]\n1173:                active_labels = labels.view(-1)[active_loss]\n(227 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 1124:1129\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=TokenClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f8b7a",
   "metadata": {},
   "source": [
    "### Step 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ecc3f",
   "metadata": {},
   "source": [
    "Execution Start time: 06:17:48, End time: 06:17:53 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9855f",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator at line 1124 in the `modeling_albert_skim.py` file. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8927782",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45415677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 62, in <module>\n    from modeling_albert_skim import AlbertForQuestionAnswering as AlbertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 1197, in <module>\n    class AlbertForQuestionAnswering(AlbertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 1211, in AlbertForQuestionAnswering\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b5c76b",
   "metadata": {},
   "source": [
    "### Step 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8886deeb",
   "metadata": {},
   "source": [
    "Execution Start time: 06:17:55, End time: 06:17:56 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c537bbf",
   "metadata": {},
   "source": [
    "**Thought**: The error persists at another location in the `modeling_albert_skim.py` file, specifically at line 1211. We need to remove the `tokenizer_class` argument from this instance of the `add_code_sample_docstrings` decorator as well. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd27567a",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058346ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_albert_skim.py (1399 lines total)]\n(1160 more lines above)\n1161:        sequence_output = outputs[0]\n1162:\n1163:        sequence_output = self.dropout(sequence_output)\n1164:        logits = self.classifier(sequence_output)\n1165:\n1166:        loss = None\n1167:        if labels is not None:\n1168:            loss_fct = CrossEntropyLoss()\n1169:            # Only keep active parts of the loss\n1170:            if attention_mask is not None:\n1171:                active_loss = attention_mask.view(-1) == 1\n1172:                active_logits = logits.view(-1, self.num_labels)[active_loss]\n1173:                active_labels = labels.view(-1)[active_loss]\n1174:                loss = loss_fct(active_logits, active_labels)\n1175:            else:\n1176:                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n1177:\n1178:        if not return_dict:\n1179:            output = (logits,) + outputs[2:]\n1180:            return ((loss,) + output) if loss is not None else output\n1181:\n1182:        return TokenClassifierOutput(\n1183:            loss=loss,\n1184:            logits=logits,\n1185:            hidden_states=outputs.hidden_states,\n1186:            attentions=outputs.attentions,\n1187:        )\n1188:\n1189:\n1190:@add_start_docstrings(\n1191:    \"\"\"\n1192:    Albert Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear\n1193:    layers on top of the hidden-states output to compute `span start logits` and `span end logits`).\n1194:    \"\"\",\n1195:    ALBERT_START_DOCSTRING,\n1196:)\n1197:class AlbertForQuestionAnswering(AlbertPreTrainedModel):\n1198:\n1199:    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n1200:\n1201:    def __init__(self, config):\n1202:        super().__init__(config)\n1203:        self.num_labels = config.num_labels\n1204:\n1205:        self.albert = AlbertModel(config, add_pooling_layer=False)\n1206:        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n1207:\n1208:        self.init_weights()\n1209:\n1210:    @add_start_docstrings_to_model_forward(ALBERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n1211:    @add_code_sample_docstrings(\n1212:        checkpoint=_CHECKPOINT_FOR_DOC,\n1213:        output_type=QuestionAnsweringModelOutput,\n1214:        config_class=_CONFIG_FOR_DOC,\n1215:    )\n1216:    def forward(\n1217:        self,\n1218:        input_ids=None,\n1219:        attention_mask=None,\n1220:        token_type_ids=None,\n1221:        position_ids=None,\n1222:        head_mask=None,\n1223:        inputs_embeds=None,\n1224:        start_positions=None,\n1225:        end_positions=None,\n1226:        output_attentions=None,\n1227:        output_hidden_states=None,\n1228:        return_dict=None,\n1229:    ):\n1230:        r\"\"\"\n1231:        start_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n1232:            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n1233:            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n1234:            sequence are not taken into account for computing the loss.\n1235:        end_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n1236:            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n1237:            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n1238:            sequence are not taken into account for computing the loss.\n1239:        \"\"\"\n1240:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n1241:\n1242:        outputs = self.albert(\n1243:            input_ids=input_ids,\n1244:            attention_mask=attention_mask,\n1245:            token_type_ids=token_type_ids,\n1246:            position_ids=position_ids,\n1247:            head_mask=head_mask,\n1248:            inputs_embeds=inputs_embeds,\n1249:            output_attentions=output_attentions,\n1250:            output_hidden_states=output_hidden_states,\n1251:            return_dict=return_dict,\n1252:        )\n1253:\n1254:        sequence_output = outputs[0]\n1255:\n1256:        logits = self.qa_outputs(sequence_output)\n1257:        start_logits, end_logits = logits.split(1, dim=-1)\n1258:        start_logits = start_logits.squeeze(-1).contiguous()\n1259:        end_logits = end_logits.squeeze(-1).contiguous()\n1260:\n(139 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 1211:1216\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=QuestionAnsweringModelOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b503ed9",
   "metadata": {},
   "source": [
    "### Step 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a5728",
   "metadata": {},
   "source": [
    "Execution Start time: 06:18:00, End time: 06:18:07 (duration: 6 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beaddb5",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator at line 1211 in the `modeling_albert_skim.py` file. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f1513b",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651072f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 62, in <module>\n    from modeling_albert_skim import AlbertForQuestionAnswering as AlbertForQuestionAnsweringWithSkim\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 1299, in <module>\n    class AlbertForMultipleChoice(AlbertPreTrainedModel):\n  File \"/content/blockskim/src/modeling_albert_skim.py\", line 1310, in AlbertForMultipleChoice\n    @add_code_sample_docstrings(\nTypeError: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d89b16",
   "metadata": {},
   "source": [
    "### Step 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574ecc3",
   "metadata": {},
   "source": [
    "Execution Start time: 06:18:09, End time: 06:18:10 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83894099",
   "metadata": {},
   "source": [
    "**Thought**: The error persists at another location in the `modeling_albert_skim.py` file, specifically at line 1310. We need to remove the `tokenizer_class` argument from this instance of the `add_code_sample_docstrings` decorator as well. Let's edit the file to fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b08a8",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db99d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/modeling_albert_skim.py (1398 lines total)]\n(1259 more lines above)\n1260:\n1261:        total_loss = None\n1262:        if start_positions is not None and end_positions is not None:\n1263:            # If we are on multi-GPU, split add a dimension\n1264:            if len(start_positions.size()) > 1:\n1265:                start_positions = start_positions.squeeze(-1)\n1266:            if len(end_positions.size()) > 1:\n1267:                end_positions = end_positions.squeeze(-1)\n1268:            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n1269:            ignored_index = start_logits.size(1)\n1270:            start_positions = start_positions.clamp(0, ignored_index)\n1271:            end_positions = end_positions.clamp(0, ignored_index)\n1272:\n1273:            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n1274:            start_loss = loss_fct(start_logits, start_positions)\n1275:            end_loss = loss_fct(end_logits, end_positions)\n1276:            total_loss = (start_loss + end_loss) / 2\n1277:\n1278:        if not return_dict:\n1279:            output = (start_logits, end_logits) + outputs[2:]\n1280:            return ((total_loss,) + output) if total_loss is not None else output\n1281:\n1282:        return QuestionAnsweringModelOutputWithSkim(\n1283:            loss=total_loss,\n1284:            start_logits=start_logits,\n1285:            end_logits=end_logits,\n1286:            hidden_states=outputs.hidden_states,\n1287:            attentions=outputs.attentions,\n1288:            all_skim_mask=outputs.all_skim_mask,\n1289:        )\n1290:\n1291:\n1292:@add_start_docstrings(\n1293:    \"\"\"\n1294:    Albert Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a\n1295:    softmax) e.g. for RocStories/SWAG tasks.\n1296:    \"\"\",\n1297:    ALBERT_START_DOCSTRING,\n1298:)\n1299:class AlbertForMultipleChoice(AlbertPreTrainedModel):\n1300:    def __init__(self, config):\n1301:        super().__init__(config)\n1302:\n1303:        self.albert = AlbertModel(config)\n1304:        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n1305:        self.classifier = nn.Linear(config.hidden_size, 1)\n1306:\n1307:        self.init_weights()\n1308:\n1309:    @add_start_docstrings_to_model_forward(ALBERT_INPUTS_DOCSTRING.format(\"batch_size, num_choices, sequence_length\"))\n1310:    @add_code_sample_docstrings(\n1311:        checkpoint=_CHECKPOINT_FOR_DOC,\n1312:        output_type=MultipleChoiceModelOutput,\n1313:        config_class=_CONFIG_FOR_DOC,\n1314:    )\n1315:    def forward(\n1316:        self,\n1317:        input_ids=None,\n1318:        attention_mask=None,\n1319:        token_type_ids=None,\n1320:        position_ids=None,\n1321:        head_mask=None,\n1322:        inputs_embeds=None,\n1323:        labels=None,\n1324:        output_attentions=None,\n1325:        output_hidden_states=None,\n1326:        return_dict=None,\n1327:    ):\n1328:        r\"\"\"\n1329:        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n1330:            Labels for computing the multiple choice classification loss. Indices should be in ``[0, ...,\n1331:            num_choices-1]`` where `num_choices` is the size of the second dimension of the input tensors. (see\n1332:            `input_ids` above)\n1333:        \"\"\"\n1334:        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n1335:        num_choices = input_ids.shape[1] if input_ids is not None else inputs_embeds.shape[1]\n1336:\n1337:        input_ids = input_ids.view(-1, input_ids.size(-1)) if input_ids is not None else None\n1338:        attention_mask = attention_mask.view(-1, attention_mask.size(-1)) if attention_mask is not None else None\n1339:        token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1)) if token_type_ids is not None else None\n1340:        position_ids = position_ids.view(-1, position_ids.size(-1)) if position_ids is not None else None\n1341:        inputs_embeds = (\n1342:            inputs_embeds.view(-1, inputs_embeds.size(-2), inputs_embeds.size(-1))\n1343:            if inputs_embeds is not None\n1344:            else None\n1345:        )\n1346:        outputs = self.albert(\n1347:            input_ids,\n1348:            attention_mask=attention_mask,\n1349:            token_type_ids=token_type_ids,\n1350:            position_ids=position_ids,\n1351:            head_mask=head_mask,\n1352:            inputs_embeds=inputs_embeds,\n1353:            output_attentions=output_attentions,\n1354:            output_hidden_states=output_hidden_states,\n1355:            return_dict=return_dict,\n1356:        )\n1357:\n1358:        pooled_output = outputs[1]\n1359:\n(39 more lines below)\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 1310:1315\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=MultipleChoiceModelOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc97ef3",
   "metadata": {},
   "source": [
    "### Step 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18630281",
   "metadata": {},
   "source": [
    "Execution Start time: 06:18:14, End time: 06:19:50 (duration: 95 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a873b",
   "metadata": {},
   "source": [
    "**Thought**: The `tokenizer_class` argument has been removed from the `add_code_sample_docstrings` decorator at line 1310 in the `modeling_albert_skim.py` file. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efeaeaa",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4ea25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "08/25/2024 06:18:19 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n\nconfig.json:   0%|                                    | 0.00/570 [00:00<?, ?B/s]\n\n[INFO|configuration_utils.py:726] 2024-08-25 06:18:19,890 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n[INFO|configuration_utils.py:789] 2024-08-25 06:18:19,891 >> Model config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.40.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n\ntokenizer_config.json:   0%|                         | 0.00/48.0 [00:00<?, ?B/s]\ntokenizer_config.json: 100%|██████████████████| 48.0/48.0 [00:00<00:00, 371kB/s]\n[INFO|configuration_utils.py:726] 2024-08-25 06:18:20,622 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n[INFO|configuration_utils.py:789] 2024-08-25 06:18:20,623 >> Model config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.40.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n\nvocab.txt:   0%|                                     | 0.00/232k [00:00<?, ?B/s]\n\n\n\ntokenizer.json:   0%|                                | 0.00/466k [00:00<?, ?B/s]\n\n\n[INFO|tokenization_utils_base.py:2087] 2024-08-25 06:18:21,851 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n[INFO|tokenization_utils_base.py:2087] 2024-08-25 06:18:21,851 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2087] 2024-08-25 06:18:21,851 >> loading file special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:2087] 2024-08-25 06:18:21,851 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2087] 2024-08-25 06:18:21,852 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n[INFO|configuration_utils.py:726] 2024-08-25 06:18:21,852 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n[INFO|configuration_utils.py:789] 2024-08-25 06:18:21,853 >> Model config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.40.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n\nmodel.safetensors:   0%|                             | 0.00/440M [00:00<?, ?B/s]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[INFO|modeling_utils.py:3429] 2024-08-25 06:19:40,378 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[WARNING|modeling_utils.py:4172] 2024-08-25 06:19:47,290 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n08/25/2024 06:19:47 - INFO - __main__ - Training/evaluation parameters Namespace(model_type='bert', model_name_or_path='bert-base-uncased', output_dir='./output', data_dir='dataset', train_file='train-v1.1.json', predict_file='dev-v1.1.json', config_name='', tokenizer_name='', cache_dir='', version_2_with_negative=False, null_score_diff_threshold=0.0, max_seq_length=512, doc_stride=128, max_query_length=64, do_train=True, do_eval=True, evaluate_during_training=False, do_lower_case=True, per_gpu_train_batch_size=16, per_gpu_eval_batch_size=16, learning_rate=3e-05, gradient_accumulation_steps=1, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, n_best_size=20, max_answer_length=30, verbose_logging=False, lang_id=0, logging_steps=500, save_steps=500, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, local_rank=-1, fp16=False, fp16_opt_level='O1', server_ip='', server_port='', threads=1, block_skim=False, actual_skim=False, block_size=32, skim_factor=0.1, balance_factor=20.0, cache_name=None, augment_layers=None, skim_threshold=0.001, num_eval_examples=10, num_train_examples=10, n_gpu=0, device=device(type='cpu'))\n08/25/2024 06:19:47 - INFO - __main__ - Creating features from dataset file at dataset\nloading train examples from dataset grom train-v1.1.json , dev-v1.1.json\n\n  0%|                                                   | 0/442 [00:00<?, ?it/s]\n  0%|                                                   | 0/442 [00:00<?, ?it/s]\nTraceback (most recent call last):\n  File \"/content/blockskim/src/run_squad.py\", line 981, in <module>\n    main()\n  File \"/content/blockskim/src/run_squad.py\", line 906, in main\n    train_dataset = load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False)\n  File \"/content/blockskim/src/run_squad.py\", line 548, in load_and_cache_examples\n    examples = processor.get_train_examples(args.data_dir, filename=args.train_file)\n  File \"/usr/local/lib/python3.10/site-packages/transformers/data/processors/squad.py\", line 627, in get_train_examples\n    return self._create_examples(input_data, \"train\")\n  File \"/content/blockskim/src/squad/transformer_squad_processor.py\", line 97, in _create_examples\n    supporting_facts = [(fact[\"fact_start\"], fact[\"text\"]) for fact in  qa[\"supporting_facts\"]]\nKeyError: 'supporting_facts'\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c40f77",
   "metadata": {},
   "source": [
    "### Step 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f9e26c",
   "metadata": {},
   "source": [
    "Execution Start time: 06:19:53, End time: 06:19:53 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85843e6a",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the code is trying to access a key `'supporting_facts'` which does not exist in the dataset. This suggests that the dataset format expected by the code does not match the actual format of the SQuAD dataset. We need to adjust the code to handle the dataset correctly.\n",
    "\n",
    "Let's open the `transformer_squad_processor.py` file around line 97 to inspect the `_create_examples` function and modify it to handle the dataset format properly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6910dd5",
   "metadata": {},
   "source": [
    "**Action (open)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28173e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/squad/transformer_squad_processor.py (121 lines total)]\n(21 more lines above)\n22:        question_text,\n23:        context_text,\n24:        answer_text,\n25:        start_position_character,\n26:        title,\n27:        answers=[],\n28:        is_impossible=False,\n29:        supporting_fact_position=[],\n30:    ):\n31:        self.qas_id = qas_id\n32:        self.question_text = question_text\n33:        self.context_text = context_text\n34:        self.answer_text = answer_text\n35:        self.title = title\n36:        self.is_impossible = is_impossible\n37:        self.answers = answers\n38:\n39:        self.start_position, self.end_position = 0, 0\n40:\n41:        doc_tokens = []\n42:        char_to_word_offset = []\n43:        prev_is_whitespace = True\n44:\n45:        # Split on whitespace so that different tokens may be attributed to their original position.\n46:        for c in self.context_text:\n47:            if _is_whitespace(c):\n48:                prev_is_whitespace = True\n49:            else:\n50:                if prev_is_whitespace:\n51:                    doc_tokens.append(c)\n52:                else:\n53:                    doc_tokens[-1] += c\n54:                prev_is_whitespace = False\n55:            char_to_word_offset.append(len(doc_tokens) - 1)\n56:\n57:        self.doc_tokens = doc_tokens\n58:        self.char_to_word_offset = char_to_word_offset\n59:\n60:        # Start and end positions only has a value during evaluation.\n61:        if start_position_character is not None and not is_impossible:\n62:            self.start_position = char_to_word_offset[start_position_character]\n63:            self.end_position = char_to_word_offset[\n64:                min(start_position_character + len(answer_text) - 1, len(char_to_word_offset) - 1)\n65:            ]\n66:\n67:        self.supporting_fact_position = []\n68:        for fact in supporting_fact_position:\n69:            fact_start_position = char_to_word_offset[fact[0]]\n70:            fact_end_position = char_to_word_offset[\n71:                min(fact[0] + len(fact[1]) - 1, len(char_to_word_offset) - 1)\n72:            ]\n73:            self.supporting_fact_position.append((fact_start_position, fact_end_position))\n74:class SquadProcessorForMask(SquadProcessor):\n75:    def _create_examples(self, input_data, set_type):\n76:        is_training = set_type == \"train\"\n77:        examples = []\n78:        for entry in tqdm(input_data):\n79:            title = entry[\"title\"]\n80:            for paragraph in entry[\"paragraphs\"]:\n81:                context_text = paragraph[\"context\"]\n82:                for qa in paragraph[\"qas\"]:\n83:                    qas_id = qa[\"id\"]\n84:                    question_text = qa[\"question\"]\n85:                    start_position_character = None\n86:                    answer_text = None\n87:                    answers = []\n88:\n89:                    is_impossible = qa.get(\"is_impossible\", False)\n90:                    if not is_impossible:\n91:\n92:                        answer = qa[\"answers\"][0]\n93:                        answer_text = answer[\"text\"]\n94:                        start_position_character = answer[\"answer_start\"]\n95:                        answers = qa[\"answers\"]\n96:\n97:                    supporting_facts = [(fact[\"fact_start\"], fact[\"text\"]) for fact in  qa[\"supporting_facts\"]]\n98:\n99:                    example = SquadExample(\n100:                        qas_id=qas_id,\n101:                        question_text=question_text,\n102:                        context_text=context_text,\n103:                        answer_text=answer_text,\n104:                        start_position_character=start_position_character,\n105:                        title=title,\n106:                        is_impossible=is_impossible,\n107:                        answers=answers,\n108:                        supporting_fact_position=supporting_facts\n109:                    )\n110:                    examples.append(example)\n111:        return examples\n112:\n113:\n114:class SquadV1Processor(SquadProcessorForMask):\n115:    train_file = \"train-v1.1.json\"\n116:    dev_file = \"dev-v1.1.json\"\n117:\n118:\n119:class SquadV2Processor(SquadProcessorForMask):\n120:    train_file = \"train-v2.0.json\"\n121:    dev_file = \"dev-v2.0.json\"\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open src/squad/transformer_squad_processor.py 97"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee1ca3",
   "metadata": {},
   "source": [
    "### Step 44"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9605750",
   "metadata": {},
   "source": [
    "Execution Start time: 06:19:55, End time: 06:19:56 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3022d29",
   "metadata": {},
   "source": [
    "**Thought**: The error is due to the code attempting to access a `'supporting_facts'` key, which is not present in the SQuAD dataset. We need to modify the `_create_examples` function to handle the dataset format correctly by removing the handling of `'supporting_facts'`.\n",
    "\n",
    "Let's edit the file to remove the lines related to `'supporting_facts'`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5548711",
   "metadata": {},
   "source": [
    "**Action (edit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26482730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File: /content/blockskim/src/squad/transformer_squad_processor.py (120 lines total)]\n(20 more lines above)\n21:        qas_id,\n22:        question_text,\n23:        context_text,\n24:        answer_text,\n25:        start_position_character,\n26:        title,\n27:        answers=[],\n28:        is_impossible=False,\n29:        supporting_fact_position=[],\n30:    ):\n31:        self.qas_id = qas_id\n32:        self.question_text = question_text\n33:        self.context_text = context_text\n34:        self.answer_text = answer_text\n35:        self.title = title\n36:        self.is_impossible = is_impossible\n37:        self.answers = answers\n38:\n39:        self.start_position, self.end_position = 0, 0\n40:\n41:        doc_tokens = []\n42:        char_to_word_offset = []\n43:        prev_is_whitespace = True\n44:\n45:        # Split on whitespace so that different tokens may be attributed to their original position.\n46:        for c in self.context_text:\n47:            if _is_whitespace(c):\n48:                prev_is_whitespace = True\n49:            else:\n50:                if prev_is_whitespace:\n51:                    doc_tokens.append(c)\n52:                else:\n53:                    doc_tokens[-1] += c\n54:                prev_is_whitespace = False\n55:            char_to_word_offset.append(len(doc_tokens) - 1)\n56:\n57:        self.doc_tokens = doc_tokens\n58:        self.char_to_word_offset = char_to_word_offset\n59:\n60:        # Start and end positions only has a value during evaluation.\n61:        if start_position_character is not None and not is_impossible:\n62:            self.start_position = char_to_word_offset[start_position_character]\n63:            self.end_position = char_to_word_offset[\n64:                min(start_position_character + len(answer_text) - 1, len(char_to_word_offset) - 1)\n65:            ]\n66:\n67:        self.supporting_fact_position = []\n68:        for fact in supporting_fact_position:\n69:            fact_start_position = char_to_word_offset[fact[0]]\n70:            fact_end_position = char_to_word_offset[\n71:                min(fact[0] + len(fact[1]) - 1, len(char_to_word_offset) - 1)\n72:            ]\n73:            self.supporting_fact_position.append((fact_start_position, fact_end_position))\n74:class SquadProcessorForMask(SquadProcessor):\n75:    def _create_examples(self, input_data, set_type):\n76:        is_training = set_type == \"train\"\n77:        examples = []\n78:        for entry in tqdm(input_data):\n79:            title = entry[\"title\"]\n80:            for paragraph in entry[\"paragraphs\"]:\n81:                context_text = paragraph[\"context\"]\n82:                for qa in paragraph[\"qas\"]:\n83:                    qas_id = qa[\"id\"]\n84:                    question_text = qa[\"question\"]\n85:                    start_position_character = None\n86:                    answer_text = None\n87:                    answers = []\n88:\n89:                    is_impossible = qa.get(\"is_impossible\", False)\n90:                    if not is_impossible:\n91:\n92:                        answer = qa[\"answers\"][0]\n93:                        answer_text = answer[\"text\"]\n94:                        start_position_character = answer[\"answer_start\"]\n95:                        answers = qa[\"answers\"]\n96:\n97:                    supporting_facts = []\n98:                    example = SquadExample(\n99:                        qas_id=qas_id,\n100:                        question_text=question_text,\n101:                        context_text=context_text,\n102:                        answer_text=answer_text,\n103:                        start_position_character=start_position_character,\n104:                        title=title,\n105:                        is_impossible=is_impossible,\n106:                        answers=answers,\n107:                        supporting_fact_position=supporting_facts\n108:                    )\n109:                    examples.append(example)\n110:        return examples\n111:\n112:\n113:class SquadV1Processor(SquadProcessorForMask):\n114:    train_file = \"train-v1.1.json\"\n115:    dev_file = \"dev-v1.1.json\"\n116:\n117:\n118:class SquadV2Processor(SquadProcessorForMask):\n119:    train_file = \"train-v2.0.json\"\n120:    dev_file = \"dev-v2.0.json\"\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit 97:98\n",
    "                    supporting_facts = []\n",
    "end_of_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20bf0ad",
   "metadata": {},
   "source": [
    "### Step 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e386569",
   "metadata": {},
   "source": [
    "Execution Start time: 06:20:01, End time: 06:21:58 (duration: 116 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe27e784",
   "metadata": {},
   "source": [
    "**Thought**: The handling of `supporting_facts` has been removed from the `_create_examples` function. Let's attempt to run the training and evaluation script once more to see if the issue is resolved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e6646",
   "metadata": {},
   "source": [
    "**Action (None)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69954b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "08/25/2024 06:20:07 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n/usr/local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n[INFO|configuration_utils.py:726] 2024-08-25 06:20:07,787 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n[INFO|configuration_utils.py:789] 2024-08-25 06:20:07,788 >> Model config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.40.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n[INFO|configuration_utils.py:726] 2024-08-25 06:20:07,918 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n[INFO|configuration_utils.py:789] 2024-08-25 06:20:07,919 >> Model config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.40.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n[INFO|tokenization_utils_base.py:2087] 2024-08-25 06:20:07,920 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n[INFO|tokenization_utils_base.py:2087] 2024-08-25 06:20:07,920 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2087] 2024-08-25 06:20:07,920 >> loading file special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:2087] 2024-08-25 06:20:07,920 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2087] 2024-08-25 06:20:07,920 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n[INFO|configuration_utils.py:726] 2024-08-25 06:20:07,921 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n[INFO|configuration_utils.py:789] 2024-08-25 06:20:07,921 >> Model config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.40.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n[INFO|modeling_utils.py:3429] 2024-08-25 06:20:08,080 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[WARNING|modeling_utils.py:4172] 2024-08-25 06:20:09,372 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n08/25/2024 06:20:09 - INFO - __main__ - Training/evaluation parameters Namespace(model_type='bert', model_name_or_path='bert-base-uncased', output_dir='./output', data_dir='dataset', train_file='train-v1.1.json', predict_file='dev-v1.1.json', config_name='', tokenizer_name='', cache_dir='', version_2_with_negative=False, null_score_diff_threshold=0.0, max_seq_length=512, doc_stride=128, max_query_length=64, do_train=True, do_eval=True, evaluate_during_training=False, do_lower_case=True, per_gpu_train_batch_size=16, per_gpu_eval_batch_size=16, learning_rate=3e-05, gradient_accumulation_steps=1, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, n_best_size=20, max_answer_length=30, verbose_logging=False, lang_id=0, logging_steps=500, save_steps=500, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, local_rank=-1, fp16=False, fp16_opt_level='O1', server_ip='', server_port='', threads=1, block_skim=False, actual_skim=False, block_size=32, skim_factor=0.1, balance_factor=20.0, cache_name=None, augment_layers=None, skim_threshold=0.001, num_eval_examples=10, num_train_examples=10, n_gpu=0, device=device(type='cpu'))\n08/25/2024 06:20:10 - INFO - __main__ - Creating features from dataset file at dataset\nloading train examples from dataset grom train-v1.1.json , dev-v1.1.json\n\n  0%|                                                   | 0/442 [00:00<?, ?it/s]\n  0%|                                           | 1/442 [00:00<00:52,  8.35it/s]\n  0%|▏                                          | 2/442 [00:00<01:44,  4.21it/s]\n  1%|▍                                          | 4/442 [00:00<00:53,  8.18it/s]\n  1%|▌                                          | 6/442 [00:00<00:59,  7.29it/s]\n  2%|▋                                          | 7/442 [00:00<00:56,  7.74it/s]\n  2%|▉                                          | 9/442 [00:01<00:46,  9.24it/s]\n  2%|█                                         | 11/442 [00:01<00:48,  8.92it/s]\n  3%|█▏                                        | 12/442 [00:01<00:59,  7.23it/s]\n  3%|█▎                                        | 14/442 [00:01<00:50,  8.49it/s]\n  4%|█▌                                        | 16/442 [00:01<00:41, 10.17it/s]\n  4%|█▋                                        | 18/442 [00:02<00:49,  8.57it/s]\n  4%|█▊                                        | 19/442 [00:02<00:52,  8.00it/s]\n  5%|█▉                                        | 20/442 [00:02<00:59,  7.13it/s]\n  5%|█▉                                        | 21/442 [00:02<00:55,  7.62it/s]\n  5%|██                                        | 22/442 [00:02<01:02,  6.69it/s]\n  5%|██▏                                       | 23/442 [00:02<00:57,  7.24it/s]\n  5%|██▎                                       | 24/442 [00:03<00:57,  7.25it/s]\n  6%|██▋                                       | 28/442 [00:03<00:29, 13.96it/s]\n  7%|███                                       | 32/442 [00:03<00:20, 19.91it/s]\n  8%|███▍                                      | 36/442 [00:03<00:17, 23.87it/s]\n  9%|███▋                                      | 39/442 [00:03<00:16, 24.97it/s]\n 10%|████                                      | 43/442 [00:03<00:15, 26.48it/s]\n 10%|████▎                                     | 46/442 [00:03<00:16, 24.63it/s]\n 11%|████▋                                     | 49/442 [00:03<00:17, 22.04it/s]\n 12%|█████                                     | 53/442 [00:04<00:15, 25.31it/s]\n 13%|█████▎                                    | 56/442 [00:04<00:15, 25.06it/s]\n 13%|█████▌                                    | 59/442 [00:05<00:46,  8.22it/s]\n 14%|█████▉                                    | 62/442 [00:05<00:37, 10.16it/s]\n 15%|██████▏                                   | 65/442 [00:05<00:32, 11.67it/s]\n 15%|██████▍                                   | 68/442 [00:05<00:27, 13.80it/s]\n 16%|██████▋                                   | 71/442 [00:05<00:23, 15.81it/s]\n 17%|███████                                   | 74/442 [00:05<00:20, 18.17it/s]\n 17%|███████▎                                  | 77/442 [00:06<00:21, 16.74it/s]\n 18%|███████▋                                  | 81/442 [00:06<00:17, 20.59it/s]\n 19%|███████▉                                  | 84/442 [00:06<00:32, 11.05it/s]\n 19%|████████▏                                 | 86/442 [00:06<00:32, 11.08it/s]\n 20%|████████▎                                 | 88/442 [00:07<00:31, 11.13it/s]\n 20%|████████▌                                 | 90/442 [00:07<00:30, 11.41it/s]\n 21%|████████▋                                 | 92/442 [00:07<00:31, 11.28it/s]\n 21%|████████▉                                 | 94/442 [00:07<00:28, 12.28it/s]\n 22%|█████████                                 | 96/442 [00:07<00:26, 13.04it/s]\n 22%|█████████▎                                | 98/442 [00:07<00:26, 13.16it/s]\n 23%|█████████▎                               | 101/442 [00:08<00:23, 14.76it/s]\n 23%|█████████▌                               | 103/442 [00:08<00:32, 10.29it/s]\n 24%|█████████▋                               | 105/442 [00:08<00:28, 11.71it/s]\n 24%|█████████▉                               | 107/442 [00:08<00:29, 11.52it/s]\n 25%|██████████                               | 109/442 [00:08<00:25, 13.06it/s]\n 25%|██████████▎                              | 111/442 [00:08<00:26, 12.52it/s]\n 26%|██████████▍                              | 113/442 [00:09<00:24, 13.30it/s]\n 26%|██████████▊                              | 116/442 [00:09<00:26, 12.11it/s]\n 27%|███████████                              | 119/442 [00:09<00:23, 13.61it/s]\n 27%|███████████▏                             | 121/442 [00:09<00:22, 14.06it/s]\n 28%|███████████▌                             | 125/442 [00:09<00:17, 17.84it/s]\n 29%|███████████▊                             | 128/442 [00:09<00:16, 18.73it/s]\n 29%|████████████                             | 130/442 [00:10<00:16, 18.91it/s]\n 30%|████████████▏                            | 132/442 [00:10<00:16, 19.13it/s]\n 30%|████████████▍                            | 134/442 [00:10<00:17, 18.06it/s]\n 31%|████████████▌                            | 136/442 [00:10<00:19, 15.82it/s]\n 31%|████████████▊                            | 138/442 [00:10<00:18, 16.12it/s]\n 32%|█████████████▏                           | 142/442 [00:10<00:14, 20.44it/s]\n 33%|█████████████▍                           | 145/442 [00:10<00:15, 19.20it/s]\n 33%|█████████████▋                           | 148/442 [00:11<00:14, 20.93it/s]\n 34%|██████████████                           | 151/442 [00:11<00:14, 20.22it/s]\n 35%|██████████████▎                          | 154/442 [00:11<00:20, 14.13it/s]\n 35%|██████████████▍                          | 156/442 [00:11<00:21, 13.24it/s]\n 36%|██████████████▋                          | 158/442 [00:11<00:24, 11.50it/s]\n 36%|██████████████▊                          | 160/442 [00:12<00:24, 11.39it/s]\n 37%|███████████████                          | 162/442 [00:12<00:23, 11.92it/s]\n 37%|███████████████▏                         | 164/442 [00:12<00:24, 11.51it/s]\n 38%|███████████████▍                         | 166/442 [00:12<00:23, 11.98it/s]\n 38%|███████████████▌                         | 168/442 [00:13<00:42,  6.42it/s]\n 38%|███████████████▊                         | 170/442 [00:13<00:34,  7.83it/s]\n 39%|███████████████▉                         | 172/442 [00:13<00:32,  8.20it/s]\n 39%|████████████████▏                        | 174/442 [00:13<00:30,  8.75it/s]\n 40%|████████████████▎                        | 176/442 [00:13<00:28,  9.38it/s]\n 40%|████████████████▌                        | 178/442 [00:14<00:26,  9.80it/s]\n 41%|████████████████▋                        | 180/442 [00:14<00:29,  8.79it/s]\n 41%|████████████████▉                        | 182/442 [00:14<00:26,  9.78it/s]\n 42%|█████████████████                        | 184/442 [00:15<00:34,  7.50it/s]\n 42%|█████████████████▏                       | 185/442 [00:15<00:34,  7.34it/s]\n 42%|█████████████████▎                       | 186/442 [00:15<00:40,  6.37it/s]\n 42%|█████████████████▎                       | 187/442 [00:16<01:20,  3.19it/s]\n 43%|█████████████████▌                       | 189/442 [00:16<00:55,  4.53it/s]\n 43%|█████████████████▋                       | 191/442 [00:16<00:42,  5.97it/s]\n 44%|█████████████████▉                       | 193/442 [00:16<00:33,  7.39it/s]\n 44%|██████████████████                       | 195/442 [00:16<00:29,  8.30it/s]\n 45%|██████████████████▎                      | 197/442 [00:16<00:24, 10.06it/s]\n 45%|██████████████████▍                      | 199/442 [00:17<00:22, 10.89it/s]\n 45%|██████████████████▋                      | 201/442 [00:17<00:22, 10.95it/s]\n 46%|██████████████████▊                      | 203/442 [00:17<00:24,  9.65it/s]\n 47%|███████████████████                      | 206/442 [00:17<00:18, 12.61it/s]\n 47%|███████████████████▎                     | 208/442 [00:17<00:17, 13.14it/s]\n 48%|███████████████████▍                     | 210/442 [00:18<00:20, 11.44it/s]\n 48%|███████████████████▋                     | 212/442 [00:18<00:24,  9.37it/s]\n 49%|███████████████████▉                     | 215/442 [00:18<00:18, 12.35it/s]\n 49%|████████████████████▏                    | 217/442 [00:18<00:18, 12.13it/s]\n 50%|████████████████████▎                    | 219/442 [00:19<00:34,  6.38it/s]\n 50%|████████████████████▌                    | 221/442 [00:19<00:28,  7.82it/s]\n 50%|████████████████████▋                    | 223/442 [00:19<00:27,  7.99it/s]\n 51%|████████████████████▊                    | 225/442 [00:20<00:29,  7.37it/s]\n 51%|█████████████████████                    | 227/442 [00:20<00:26,  8.14it/s]\n 52%|█████████████████████▏                   | 229/442 [00:20<00:21,  9.69it/s]\n 52%|█████████████████████▍                   | 231/442 [00:20<00:18, 11.18it/s]\n 53%|█████████████████████▌                   | 233/442 [00:20<00:17, 11.83it/s]\n 53%|█████████████████████▊                   | 235/442 [00:20<00:18, 11.19it/s]\n 54%|█████████████████████▉                   | 237/442 [00:20<00:16, 12.56it/s]\n 54%|██████████████████████▏                  | 239/442 [00:21<00:15, 13.33it/s]\n 55%|██████████████████████▍                  | 242/442 [00:21<00:12, 16.04it/s]\n 55%|██████████████████████▋                  | 244/442 [00:21<00:12, 16.31it/s]\n 56%|██████████████████████▊                  | 246/442 [00:21<00:13, 14.66it/s]\n 56%|███████████████████████                  | 248/442 [00:21<00:15, 12.32it/s]\n 57%|███████████████████████▎                 | 251/442 [00:21<00:12, 14.78it/s]\n 57%|███████████████████████▍                 | 253/442 [00:22<00:22,  8.52it/s]\n 58%|███████████████████████▋                 | 255/442 [00:22<00:18,  9.93it/s]\n 58%|███████████████████████▊                 | 257/442 [00:22<00:16, 10.90it/s]\n 59%|████████████████████████                 | 259/442 [00:22<00:15, 12.00it/s]\n 59%|████████████████████████▏                | 261/442 [00:22<00:14, 12.31it/s]\n 60%|████████████████████████▍                | 263/442 [00:23<00:15, 11.59it/s]\n 60%|████████████████████████▌                | 265/442 [00:23<00:13, 13.18it/s]\n 61%|████████████████████████▊                | 268/442 [00:23<00:11, 15.43it/s]\n 61%|█████████████████████████                | 270/442 [00:23<00:11, 14.61it/s]\n 62%|█████████████████████████▎               | 273/442 [00:23<00:10, 16.90it/s]\n 62%|█████████████████████████▌               | 275/442 [00:23<00:11, 14.27it/s]\n 63%|█████████████████████████▋               | 277/442 [00:24<00:20,  8.07it/s]\n 63%|█████████████████████████▉               | 279/442 [00:24<00:18,  8.97it/s]\n 64%|██████████████████████████               | 281/442 [00:24<00:15, 10.45it/s]\n 64%|██████████████████████████▎              | 283/442 [00:24<00:15, 10.13it/s]\n 65%|██████████████████████████▌              | 286/442 [00:24<00:11, 13.14it/s]\n 65%|██████████████████████████▋              | 288/442 [00:25<00:10, 14.13it/s]\n 66%|██████████████████████████▉              | 290/442 [00:25<00:09, 15.23it/s]\n 66%|███████████████████████████              | 292/442 [00:25<00:09, 15.31it/s]\n 67%|███████████████████████████▎             | 294/442 [00:25<00:09, 16.35it/s]\n 67%|███████████████████████████▌             | 297/442 [00:25<00:08, 16.52it/s]\n 68%|███████████████████████████▊             | 300/442 [00:25<00:07, 19.44it/s]\n 69%|████████████████████████████             | 303/442 [00:25<00:07, 19.44it/s]\n 69%|████████████████████████████▍            | 306/442 [00:26<00:10, 12.94it/s]\n 70%|████████████████████████████▋            | 309/442 [00:26<00:08, 15.20it/s]\n 70%|████████████████████████████▊            | 311/442 [00:26<00:08, 14.66it/s]\n 71%|█████████████████████████████            | 313/442 [00:26<00:08, 15.32it/s]\n 71%|█████████████████████████████▏           | 315/442 [00:27<00:17,  7.42it/s]\n 72%|█████████████████████████████▍           | 317/442 [00:27<00:14,  8.39it/s]\n 72%|█████████████████████████████▌           | 319/442 [00:27<00:12,  9.82it/s]\n 73%|█████████████████████████████▊           | 321/442 [00:27<00:11, 10.99it/s]\n 73%|██████████████████████████████           | 324/442 [00:27<00:09, 12.88it/s]\n 74%|██████████████████████████████▏          | 326/442 [00:28<00:10, 11.37it/s]\n 74%|██████████████████████████████▍          | 328/442 [00:28<00:11,  9.82it/s]\n 75%|██████████████████████████████▌          | 330/442 [00:28<00:09, 11.30it/s]\n 75%|██████████████████████████████▉          | 333/442 [00:28<00:08, 13.22it/s]\n 76%|███████████████████████████████▏         | 336/442 [00:28<00:06, 15.79it/s]\n 77%|███████████████████████████████▍         | 339/442 [00:28<00:05, 18.00it/s]\n 77%|███████████████████████████████▋         | 342/442 [00:28<00:04, 20.54it/s]\n 78%|████████████████████████████████         | 345/442 [00:29<00:05, 18.88it/s]\n 79%|████████████████████████████████▎        | 348/442 [00:29<00:04, 19.90it/s]\n 79%|████████████████████████████████▌        | 351/442 [00:29<00:05, 16.21it/s]\n 80%|████████████████████████████████▊        | 354/442 [00:29<00:05, 17.58it/s]\n 81%|█████████████████████████████████        | 357/442 [00:29<00:04, 17.17it/s]\n 81%|█████████████████████████████████▎       | 359/442 [00:29<00:04, 17.29it/s]\n 82%|█████████████████████████████████▍       | 361/442 [00:30<00:05, 14.83it/s]\n 82%|█████████████████████████████████▋       | 363/442 [00:30<00:07, 11.13it/s]\n 83%|█████████████████████████████████▊       | 365/442 [00:30<00:07, 10.98it/s]\n 83%|██████████████████████████████████       | 367/442 [00:30<00:06, 11.82it/s]\n 83%|██████████████████████████████████▏      | 369/442 [00:30<00:05, 12.81it/s]\n 84%|██████████████████████████████████▍      | 371/442 [00:31<00:06, 11.21it/s]\n 85%|██████████████████████████████████▋      | 374/442 [00:31<00:05, 12.35it/s]\n 85%|██████████████████████████████████▉      | 376/442 [00:31<00:05, 12.16it/s]\n 86%|███████████████████████████████████▏     | 379/442 [00:31<00:04, 15.33it/s]\n 86%|███████████████████████████████████▎     | 381/442 [00:31<00:04, 13.66it/s]\n 87%|███████████████████████████████████▌     | 383/442 [00:31<00:04, 13.62it/s]\n 87%|███████████████████████████████████▋     | 385/442 [00:32<00:04, 13.26it/s]\n 88%|███████████████████████████████████▉     | 388/442 [00:32<00:03, 16.10it/s]\n 88%|████████████████████████████████████▏    | 390/442 [00:32<00:03, 16.95it/s]\n 89%|████████████████████████████████████▎    | 392/442 [00:32<00:03, 14.16it/s]\n 89%|████████████████████████████████████▌    | 394/442 [00:32<00:03, 13.80it/s]\n 90%|████████████████████████████████████▋    | 396/442 [00:32<00:04, 11.07it/s]\n 90%|████████████████████████████████████▉    | 398/442 [00:33<00:04,  9.71it/s]\n 90%|█████████████████████████████████████    | 400/442 [00:34<00:11,  3.58it/s]\n 91%|█████████████████████████████████████▎   | 402/442 [00:34<00:08,  4.48it/s]\n 92%|█████████████████████████████████████▌   | 405/442 [00:34<00:05,  6.62it/s]\n 92%|█████████████████████████████████████▊   | 407/442 [00:35<00:04,  7.99it/s]\n 93%|██████████████████████████████████████   | 410/442 [00:35<00:03, 10.53it/s]\n 93%|██████████████████████████████████████▎  | 413/442 [00:35<00:02, 11.80it/s]\n 94%|██████████████████████████████████████▍  | 415/442 [00:35<00:02, 13.02it/s]\n 94%|██████████████████████████████████████▋  | 417/442 [00:35<00:01, 13.63it/s]\n 95%|██████████████████████████████████████▊  | 419/442 [00:35<00:01, 13.26it/s]\n 95%|███████████████████████████████████████  | 421/442 [00:36<00:01, 11.15it/s]\n 96%|███████████████████████████████████████▏ | 423/442 [00:36<00:01, 11.18it/s]\n 96%|███████████████████████████████████████▍ | 425/442 [00:36<00:01, 10.51it/s]\n 97%|███████████████████████████████████████▌ | 427/442 [00:36<00:01, 11.53it/s]\n 97%|███████████████████████████████████████▊ | 429/442 [00:36<00:01, 11.73it/s]\n 98%|████████████████████████████████████████ | 432/442 [00:36<00:00, 14.70it/s]\n 98%|████████████████████████████████████████▎| 434/442 [00:37<00:00, 12.03it/s]\n 99%|████████████████████████████████████████▍| 436/442 [00:37<00:00, 12.62it/s]\n 99%|████████████████████████████████████████▋| 438/442 [00:37<00:00, 14.01it/s]\n100%|████████████████████████████████████████▊| 440/442 [00:37<00:00, 15.22it/s]\n100%|█████████████████████████████████████████| 442/442 [00:37<00:00, 12.85it/s]\n100%|█████████████████████████████████████████| 442/442 [00:37<00:00, 11.73it/s]\n\nconvert squad examples to features:   0%|                | 0/10 [00:00<?, ?it/s]actual_text: Saint Bernadette Soubirous\nanswer_text: Saint Bernadette Soubirous\nactual_text: a copper statue of Christ\nanswer_text: a copper statue of Christ\nactual_text: the Main Building\nanswer_text: the Main Building\nactual_text: a Marian place of prayer and reflection.\nanswer_text: a Marian place of prayer and reflection\nactual_text: a golden statue of the Virgin Mary.\nanswer_text: a golden statue of the Virgin Mary\nactual_text: September 1876,\nanswer_text: September 1876\nactual_text: twice\nanswer_text: twice\nactual_text: The Observer\nanswer_text: The Observer\nactual_text: three\nanswer_text: three\nactual_text: 1987,\nanswer_text: 1987\n\nconvert squad examples to features:  10%|▊       | 1/10 [00:00<00:01,  6.70it/s]\nconvert squad examples to features: 100%|███████| 10/10 [00:00<00:00, 65.77it/s]\n\nadd example index and unique id:   0%|                   | 0/10 [00:00<?, ?it/s]\nadd example index and unique id: 100%|██████| 10/10 [00:00<00:00, 262144.00it/s]\n/content/blockskim/src/squad/squad.py:441: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n  all_answer_mask = torch.tensor([f.answer_mask for f in features], dtype=torch.float)\n08/25/2024 06:20:49 - INFO - __main__ - Saving features into cached file dataset/cached_train_bert-base-uncased_512\n/usr/local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n08/25/2024 06:20:51 - INFO - __main__ - ***** Running training *****\n08/25/2024 06:20:51 - INFO - __main__ -   Num examples = 10\n08/25/2024 06:20:51 - INFO - __main__ -   Num Epochs = 1\n08/25/2024 06:20:51 - INFO - __main__ -   Instantaneous batch size per GPU = 16\n08/25/2024 06:20:51 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n08/25/2024 06:20:51 - INFO - __main__ -   Gradient Accumulation steps = 1\n08/25/2024 06:20:51 - INFO - __main__ -   Total optimization steps = 1\n\nEpoch:   0%|                                              | 0/1 [00:00<?, ?it/s]\n\nIteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[A\n\nIteration: 100%|██████████████████████████████████| 1/1 [00:51<00:00, 51.13s/it]\u001b[A\nIteration: 100%|██████████████████████████████████| 1/1 [00:51<00:00, 51.13s/it]\n\nEpoch: 100%|██████████████████████████████████████| 1/1 [00:51<00:00, 51.13s/it]\nEpoch: 100%|██████████████████████████████████████| 1/1 [00:51<00:00, 51.13s/it]\n08/25/2024 06:21:42 - INFO - __main__ -  global_step = 2, average loss = 3.0821452140808105\n08/25/2024 06:21:42 - INFO - __main__ - Saving model checkpoint to ./output\n[INFO|configuration_utils.py:471] 2024-08-25 06:21:42,157 >> Configuration saved in ./output/config.json\n[INFO|modeling_utils.py:2590] 2024-08-25 06:21:42,507 >> Model weights saved in ./output/model.safetensors\n[INFO|tokenization_utils_base.py:2488] 2024-08-25 06:21:42,517 >> tokenizer config file saved in ./output/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2497] 2024-08-25 06:21:42,517 >> Special tokens file saved in ./output/special_tokens_map.json\n[INFO|configuration_utils.py:724] 2024-08-25 06:21:42,537 >> loading configuration file ./output/config.json\n[INFO|configuration_utils.py:789] 2024-08-25 06:21:42,538 >> Model config BertConfig {\n  \"_name_or_path\": \"./output\",\n  \"architectures\": [\n    \"BertForQuestionAnswering\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.40.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n[INFO|modeling_utils.py:3426] 2024-08-25 06:21:42,539 >> loading weights file ./output/model.safetensors\n[INFO|modeling_utils.py:4170] 2024-08-25 06:21:42,695 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n\n[INFO|modeling_utils.py:4178] 2024-08-25 06:21:42,696 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at ./output.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n[INFO|tokenization_utils_base.py:2085] 2024-08-25 06:21:42,717 >> loading file vocab.txt\n[INFO|tokenization_utils_base.py:2085] 2024-08-25 06:21:42,717 >> loading file added_tokens.json\n[INFO|tokenization_utils_base.py:2085] 2024-08-25 06:21:42,717 >> loading file special_tokens_map.json\n[INFO|tokenization_utils_base.py:2085] 2024-08-25 06:21:42,717 >> loading file tokenizer_config.json\n[INFO|tokenization_utils_base.py:2085] 2024-08-25 06:21:42,717 >> loading file tokenizer.json\n---------------- EVALUATION ------------------\n08/25/2024 06:21:42 - INFO - __main__ - Loading checkpoints saved during training for evaluation\n08/25/2024 06:21:42 - INFO - __main__ - Evaluate the following checkpoints: ['./output']\n[INFO|configuration_utils.py:724] 2024-08-25 06:21:42,753 >> loading configuration file ./output/config.json\n[INFO|configuration_utils.py:789] 2024-08-25 06:21:42,754 >> Model config BertConfig {\n  \"_name_or_path\": \"./output\",\n  \"architectures\": [\n    \"BertForQuestionAnswering\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.40.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n[INFO|modeling_utils.py:3426] 2024-08-25 06:21:42,754 >> loading weights file ./output/model.safetensors\n[INFO|modeling_utils.py:4170] 2024-08-25 06:21:42,908 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n\n[INFO|modeling_utils.py:4178] 2024-08-25 06:21:42,909 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at ./output.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n---------------- Getting Result ------------------\n\n-------Namespace(model_type='bert', model_name_or_path='bert-base-uncased', output_dir='./output', data_dir='dataset', train_file='train-v1.1.json', predict_file='dev-v1.1.json', config_name='', tokenizer_name='', cache_dir='', version_2_with_negative=False, null_score_diff_threshold=0.0, max_seq_length=512, doc_stride=128, max_query_length=64, do_train=True, do_eval=True, evaluate_during_training=False, do_lower_case=True, per_gpu_train_batch_size=16, per_gpu_eval_batch_size=16, learning_rate=3e-05, gradient_accumulation_steps=1, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, n_best_size=20, max_answer_length=30, verbose_logging=False, lang_id=0, logging_steps=500, save_steps=500, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, local_rank=-1, fp16=False, fp16_opt_level='O1', server_ip='', server_port='', threads=1, block_skim=False, actual_skim=False, block_size=32, skim_factor=0.1, balance_factor=20.0, cache_name=None, augment_layers=None, skim_threshold=0.001, num_eval_examples=10, num_train_examples=10, n_gpu=0, device=device(type='cpu'), train_batch_size=16)-----------\n\n08/25/2024 06:21:42 - INFO - __main__ - Creating features from dataset file at dataset\n\n  0%|                                                    | 0/48 [00:00<?, ?it/s]\n  2%|▉                                           | 1/48 [00:00<00:10,  4.44it/s]\n  6%|██▊                                         | 3/48 [00:00<00:04,  9.94it/s]\n 10%|████▌                                       | 5/48 [00:00<00:04, 10.36it/s]\n 15%|██████▍                                     | 7/48 [00:00<00:04,  9.96it/s]\n 21%|████████▉                                  | 10/48 [00:00<00:02, 14.36it/s]\n 25%|██████████▊                                | 12/48 [00:00<00:02, 14.03it/s]\n 29%|████████████▌                              | 14/48 [00:01<00:02, 15.13it/s]\n 33%|██████████████▎                            | 16/48 [00:01<00:02, 11.78it/s]\n 38%|████████████████▏                          | 18/48 [00:01<00:02, 12.66it/s]\n 44%|██████████████████▊                        | 21/48 [00:01<00:01, 15.21it/s]\n 48%|████████████████████▌                      | 23/48 [00:01<00:01, 15.37it/s]\n 52%|██████████████████████▍                    | 25/48 [00:02<00:01, 11.73it/s]\n 56%|████████████████████████▏                  | 27/48 [00:02<00:01, 12.71it/s]\n 60%|█████████████████████████▉                 | 29/48 [00:02<00:01, 12.41it/s]\n 67%|████████████████████████████▋              | 32/48 [00:02<00:01, 15.71it/s]\n 71%|██████████████████████████████▍            | 34/48 [00:02<00:00, 15.14it/s]\n 75%|████████████████████████████████▎          | 36/48 [00:02<00:00, 13.87it/s]\n 79%|██████████████████████████████████         | 38/48 [00:02<00:00, 12.94it/s]\n 83%|███████████████████████████████████▊       | 40/48 [00:03<00:00, 13.64it/s]\n 88%|█████████████████████████████████████▋     | 42/48 [00:03<00:00, 14.02it/s]\n 92%|███████████████████████████████████████▍   | 44/48 [00:03<00:00, 14.49it/s]\n 96%|█████████████████████████████████████████▏ | 46/48 [00:03<00:00, 14.17it/s]\n100%|███████████████████████████████████████████| 48/48 [00:03<00:00, 14.32it/s]\n100%|███████████████████████████████████████████| 48/48 [00:03<00:00, 13.32it/s]\n\nconvert squad examples to features:   0%|                | 0/10 [00:00<?, ?it/s]actual_text: Denver Broncos\nanswer_text: Denver Broncos\nactual_text: Carolina Panthers\nanswer_text: Carolina Panthers\nactual_text: Santa Clara, California.\nanswer_text: Santa Clara, California\nactual_text: Denver Broncos\nanswer_text: Denver Broncos\nactual_text: \"golden\nanswer_text: gold\nactual_text: \"golden anniversary\"\nanswer_text: \"golden anniversary\"\nactual_text: February 7, 2016,\nanswer_text: February 7, 2016\nactual_text: American Football Conference\nanswer_text: American Football Conference\nactual_text: \"golden anniversary\"\nanswer_text: \"golden anniversary\"\nactual_text: American Football Conference\nanswer_text: American Football Conference\n\nconvert squad examples to features:  10%|▊       | 1/10 [00:00<00:01,  8.25it/s]\nconvert squad examples to features: 100%|███████| 10/10 [00:00<00:00, 80.34it/s]\n\nadd example index and unique id:   0%|                   | 0/10 [00:00<?, ?it/s]\nadd example index and unique id: 100%|██████| 10/10 [00:00<00:00, 173318.35it/s]\n08/25/2024 06:21:47 - INFO - __main__ - Saving features into cached file dataset/cached_dev_bert-base-uncased_512\n08/25/2024 06:21:47 - INFO - __main__ - ***** Running evaluation  *****\n08/25/2024 06:21:47 - INFO - __main__ -   Num examples = 10\n08/25/2024 06:21:47 - INFO - __main__ -   Batch size = 16\n\nEvaluating:   0%|                                         | 0/1 [00:00<?, ?it/s]\nEvaluating: 100%|█████████████████████████████████| 1/1 [00:09<00:00,  9.79s/it]\nEvaluating: 100%|█████████████████████████████████| 1/1 [00:09<00:00,  9.79s/it]\n08/25/2024 06:21:56 - INFO - __main__ -   Evaluation done in total 9.792695 secs (0.979270 sec per example)\n[INFO|squad_metrics.py:401] 2024-08-25 06:21:56,839 >> Writing predictions to: ./output/predictions_.json\n[INFO|squad_metrics.py:403] 2024-08-25 06:21:56,839 >> Writing nbest to: ./output/nbest_predictions_.json\n08/25/2024 06:21:56 - INFO - __main__ - Results: {'exact': 0.0, 'f1': 1.7391304347826089, 'total': 10, 'HasAns_exact': 0.0, 'HasAns_f1': 1.7391304347826089, 'HasAns_total': 10, 'best_exact': 0.0, 'best_exact_thresh': 0.0, 'best_f1': 1.7391304347826089, 'best_f1_thresh': 0.0}\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python src/run_squad.py \\\n",
    "  --model_type bert \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --do_lower_case \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file train-v1.1.json \\\n",
    "  --predict_file dev-v1.1.json \\\n",
    "  --data_dir dataset \\\n",
    "  --per_gpu_train_batch_size 16 \\\n",
    "  --per_gpu_eval_batch_size 16 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 1.0 \\\n",
    "  --max_seq_length 512 \\\n",
    "  --output_dir ./output \\\n",
    "  --overwrite_output_dir \\\n",
    "  --skim_factor 0.1 \\\n",
    "  --balance_factor 20 \\\n",
    "  --num_train_examples 10 \\\n",
    "  --num_eval_examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47edc1da",
   "metadata": {},
   "source": [
    "### Step 46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133ae00",
   "metadata": {},
   "source": [
    "Execution Start time: 06:22:02, End time: 06:22:02 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7df82",
   "metadata": {},
   "source": [
    "**Thought**: The training and evaluation have completed successfully. The results show an exact match score of 0.0 and an F1 score of 1.7391. Let's format these results into the required JSON structure and submit the answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db22c71",
   "metadata": {},
   "source": [
    "**Action (submit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f53b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{exact_match: 0.0, f1: 1.7391}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit {\"exact_match\": 0.0, \"f1\": 1.7391}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
