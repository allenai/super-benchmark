{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0035b760",
   "metadata": {},
   "source": [
    "### Query\n",
    "Train a teacher model on the iwslt14-de-en dataset (available from the download script in the repo), then train a teacher model and evaluate it. Report loss and nll_loss on the validation set for the teacher model training as a json structured as follows: {\"teacher_loss\": 0.0, \"teacher_nll_loss\": 0.0} (replace 0.0 with the actual values).\n",
    "\n",
    "Additional instructions:\n",
    "1. Once loaded/tokenized, keep only the first 10 rows of each set in the dataset.\n",
    "2. Train for only one epoch and with batch_size=1.\n",
    "3. To evaluate the teacher model, generate predictions on the test set using `generate.py` with beam_size=5. Then take the evaluation score with the `score.py` script, with `--ignore-case --sacrebleu`.\n",
    "\n",
    "Git repository: https://github.com/ncsoft/Align-to-Distill\n",
    "\n",
    "I have already executed some of the required steps. Now, you should install all required dependencies. Once dependencies are installed, you can re-run any of the pre-executed steps, and finally should successfully run\n",
    "```\n",
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --arch transformer_teacher --share-decoder-input-output-embed \\\n",
    "    --user-dir custom/ --cpu \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt\n",
    "# checkpoints\n",
    "!ls data/de-en/ckpt/\n",
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --alpha 0.5 \\\n",
    "    --decay 0.9 \\\n",
    "    --arch transformer_student_4heads_A2D --share-decoder-input-output-embed \\\n",
    "    --teacher-checkpoint-path data/de-en/ckpt/checkpoint_best.pt \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --task kd_translation --criterion kd_label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --keep-last-epochs 2 --patience 10 \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt/student_model/ \\\n",
    "    --user-dir custom/\n",
    "\n",
    "# student checkpoints\n",
    "!ls data/de-en/ckpt/student_model/\n",
    "%pwd\n",
    "%%bash\n",
    "CKPT=data/de-en/ckpt/student_model/checkpoint_best.pt\n",
    "mkdir -p data/de-en/tmp/\n",
    "\n",
    "python fairseq_cli/generate.py data-bin \\\n",
    "      --path data/de-en/ckpt/student_model/checkpoint_best.pt \\\n",
    "      --beam 5 --batch-size 1 \\\n",
    "      --sacrebleu --remove-bpe \\\n",
    "      --user-dir custom/ > data/de-en/tmp/gen.out\n",
    "!tail data/de-en/tmp/gen.out\n",
    "# Post-process to separate hypothesis and target\n",
    "!grep ^H data/de-en/tmp/gen.out | cut -f3 > data/de-en/tmp/gen.out.tok.sys\n",
    "!grep ^T data/de-en/tmp/gen.out | cut -f2 > data/de-en/tmp/gen.out.tok.ref\n",
    "\n",
    "!wc -l data/de-en/tmp/gen.out.tok.sys\n",
    "!wc -l data/de-en/tmp/gen.out.tok.ref\n",
    "# The generated test translations\n",
    "!head data/de-en/tmp/gen.out.tok.sys\n",
    "# the actual (reference) translations (before de-tokenization)\n",
    "!head data/de-en/tmp/gen.out.tok.ref\n",
    "# De-tokenize (spm decode) using sed\n",
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.ref | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.ref\n",
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.sys | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.sys\n",
    "\n",
    "# the actual (reference) translations\n",
    "!head data/de-en/tmp/gen.out.ref\n",
    "# Score the translations\n",
    "!python fairseq_cli/score.py -s data/de-en/tmp/gen.out.sys -r data/de-en/tmp/gen.out.ref --ignore-case --sacrebleu\n",
    "\n",
    "```\n",
    "to submit the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cdd60c",
   "metadata": {},
   "source": [
    "### Prompt\n",
    "<details>\n",
    "[{'role': 'system', 'content': 'Interact in a jupyter notebook to solve the request.\\nOutput a thought and an action.\\nThought can reason about the current situation, and action allows you to interact with the Jupyter notebook. There are three types of actions:\\n(1) execute, which executes a notebook cell with the command under the \"content\" field. This could be a bash command (beginning with !), a python command, or magic command (beginning with %).\\n(2) edit, which allows you to replace existing lines in a file with new lines. To replace lines, you will need to provide the lines as they appear before the replacement, and the lines to replace them with.\\nIn the \"content\" field, format should be ```{filename}\\n<<<BEFORE_EDIT>>>\\nlines before edit\\nlines before edit\\n<<<AFTER_EDIT>>>\\nlines after edit\\nlines after edit```\\n  - Include the entire lines WITH indentation. After editing, make sure indentation is correct.\\n(3) submit, which submits the final answer (or null if there\\'s no answer to submit), formatted as JSON (make sure to use double quotes for keys and values).\\nAlways output exactly one \"thought\" and one \"action\", and encapsulate the content with <content>...</content> tags.\\nI will provide the cell output (observation) for you.\\n\\nTips:\\n- When a github repository is given, you should start by cloning it. You can read the readme file and browse the repo for installation and usage instructions.\\n- Avoid using conda, instead use pip for package management.\\n- Each execution has a 5-minute timeout. After this period, you can decide whether to interrupt the kernel or continue waiting.\\n  You should interrupt if: (1) you are prompted with an interactive message (e.g., \"Do you want to continue? [Y/n]\"). In that case, you can bypass it by executing echo \"y\" | command, or (2) the execution is taking longer than expected because the wrong task is being executed, such as a different model or incorrect number of epochs.\\n  You should continue to wait if the current execution is correct and proceeding as expected.\\n\\nHere are some examples.\\nGit repository: EleutherAI/lm-evaluation-harness\\nQuery: Evaluate EleutherAI/gpt-j-6B on hellaswag. What\\'s the score?\\nThought: First, I need to clone the GitHub repository \\'EleutherAI/lm-evaluation-harness\\'.\\nAction: execute\\n<content>\\n!git clone https://github.com/EleutherAI/lm-evaluation-harness.git\\n</content>\\nObservation: ```\\nCloning into \\'lm-evaluation-harness\\'...\\n```\\nThought: The repository has been cloned. Next, I should check the README file for installation and usage instructions to proceed with evaluating EleutherAI/gpt-j-6B on hellaswag.\\nAction: execute\\n<content>\\n!cat lm-evaluation-harness/README.md\\n</content>\\nObservation: ```# Language Model Evaluation Harness ... truncated ...\\n```\\nThought: The README provides detailed instructions for installing the `lm-eval` package and evaluating models like GPT-J-6B on tasks like hellaswag. I need to install the package and its dependencies first.\\nAction: execute\\n<content>\\n!pip install -e lm-evaluation-harness/.\\n</content>\\nObservation: ```\\nObtaining file:///home/nora/lm-evaluation-harness\\n  Installing build dependencies ... truncated ...\\n```\\nThought: The `lm-eval` package and its dependencies have been installed successfully. Now, I can proceed with evaluating the EleutherAI/gpt-j-6B model on the hellaswag task as per the instructions in the README.\\nAction: execute\\n<content>\\n!lm_eval --model hf --model_args pretrained=EleutherAI/gpt-j-6B --tasks hellaswag --device cuda:0 --batch_size 8\\n</content>\\nObservation: ```\\n{\\n  \"hellaswag\": {\\n    \"acc\": 0.24603658536585363,\\n    \"acc_norm\": 0.34436059706446426,\\n  },  ... truncated ...\\n```\\nThought: The `lm-eval` was executed successfully, providing the metrics I needed. The `acc` metric is 0.2460. The `acc_norm` metric is 0.3444\\nAction: submit\\n<content>\\n{\"acc\": 0.2460, \"acc_norm\": 0.3444}\\n</content>\\n\\nQuery: use pandas to read the file \\'data.csv\\' and display the first 2 rows.\\nThought: First, I need to read the file \\'data.csv\\' using the pandas library.\\nAction: execute\\n<content>\\nimport pandas as pd\\npd.read_csv(\\'data.csv\\').head()\\n</content>\\nObservation: ```\\n    name\\n  0  Alice\\n   1    Bob\\n  2  Charlie\\n```\\nThought: The file \\'data.csv\\' has been read successfully and the first 2 rows have been displayed.\\nAction: submit\\n<content>\\n[\"Alice\", \"Bob\"]\\n</content>\\n\\nQuery: Change the model name in the \\'config.json\\' file from \\'roberta-base\\' to \\'roberta-large\\'.\\nThought: First, I need to read the \\'config.json\\' file to find the location where I can replace the model name.\\nAction: execute\\n<content>\\n!cat config.json\\n</content>\\nObservation: ```\\n{\\n    \"model\": \"roberta-base\",\\n    \"batch_size\": 8,\\n    \"epochs\": 10\\n}\\n```\\nThought: The file has been read successfully. Now, I can replace the model name in the \\'config.json\\' file.\\nAction: edit\\n<content>\\nconfig.json\\n<<<BEFORE_EDIT>>>\\n{\\n    \"model\": \"roberta-base\",\\n    \"batch_size\": 8,\\n<<<AFTER_EDIT>>>\\n{\\n    \"model\": \"roberta-large\",\\n    \"batch_size\": 8,\\n</content>\\nObservation: \"editing file config.json\"\\nThought: The model name has been replaced in the \\'config.json\\' file.\\nAction: submit\\n<content>\\nnull\\n</content>\\n'}, {'role': 'user', 'content': 'Query: Train a teacher model on the iwslt14-de-en dataset (available from the download script in the repo), then train a teacher model and evaluate it. Report loss and nll_loss on the validation set for the teacher model training as a json structured as follows: {\"teacher_loss\": 0.0, \"teacher_nll_loss\": 0.0} (replace 0.0 with the actual values).\\n\\nAdditional instructions:\\n1. Once loaded/tokenized, keep only the first 10 rows of each set in the dataset.\\n2. Train for only one epoch and with batch_size=1.\\n3. To evaluate the teacher model, generate predictions on the test set using `generate.py` with beam_size=5. Then take the evaluation score with the `score.py` script, with `--ignore-case --sacrebleu`.\\n\\nGit repository: https://github.com/ncsoft/Align-to-Distill\\n\\nI have already executed some of the required steps. Now, you should install all required dependencies. Once dependencies are installed, you can re-run any of the pre-executed steps, and finally should successfully run\\n```\\n%%bash\\npython fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n# checkpoints\\n!ls data/de-en/ckpt/\\n%%bash\\npython fairseq_cli/train.py data-bin \\\\\\n    --alpha 0.5 \\\\\\n    --decay 0.9 \\\\\\n    --arch transformer_student_4heads_A2D --share-decoder-input-output-embed \\\\\\n    --teacher-checkpoint-path data/de-en/ckpt/checkpoint_best.pt \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --task kd_translation --criterion kd_label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --keep-last-epochs 2 --patience 10 \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt/student_model/ \\\\\\n    --user-dir custom/\\n\\n# student checkpoints\\n!ls data/de-en/ckpt/student_model/\\n%pwd\\n%%bash\\nCKPT=data/de-en/ckpt/student_model/checkpoint_best.pt\\nmkdir -p data/de-en/tmp/\\n\\npython fairseq_cli/generate.py data-bin \\\\\\n      --path data/de-en/ckpt/student_model/checkpoint_best.pt \\\\\\n      --beam 5 --batch-size 1 \\\\\\n      --sacrebleu --remove-bpe \\\\\\n      --user-dir custom/ > data/de-en/tmp/gen.out\\n!tail data/de-en/tmp/gen.out\\n# Post-process to separate hypothesis and target\\n!grep ^H data/de-en/tmp/gen.out | cut -f3 > data/de-en/tmp/gen.out.tok.sys\\n!grep ^T data/de-en/tmp/gen.out | cut -f2 > data/de-en/tmp/gen.out.tok.ref\\n\\n!wc -l data/de-en/tmp/gen.out.tok.sys\\n!wc -l data/de-en/tmp/gen.out.tok.ref\\n# The generated test translations\\n!head data/de-en/tmp/gen.out.tok.sys\\n# the actual (reference) translations (before de-tokenization)\\n!head data/de-en/tmp/gen.out.tok.ref\\n# De-tokenize (spm decode) using sed\\n!sed \\'s/ //g\\' data/de-en/tmp/gen.out.tok.ref | sed \\'s/▁/ /g\\' | sed \\'s/^ //g\\' > data/de-en/tmp/gen.out.ref\\n!sed \\'s/ //g\\' data/de-en/tmp/gen.out.tok.sys | sed \\'s/▁/ /g\\' | sed \\'s/^ //g\\' > data/de-en/tmp/gen.out.sys\\n\\n# the actual (reference) translations\\n!head data/de-en/tmp/gen.out.ref\\n# Score the translations\\n!python fairseq_cli/score.py -s data/de-en/tmp/gen.out.sys -r data/de-en/tmp/gen.out.ref --ignore-case --sacrebleu\\n\\n```\\nto submit the answer.'}]\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490aa4de",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a453bc",
   "metadata": {},
   "source": [
    "Execution Start time: 00:08:24, End time: 00:08:24 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa30be",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4795de9",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ff70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Repository Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2202c94c",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f48e7",
   "metadata": {},
   "source": [
    "Execution Start time: 00:08:24, End time: 00:08:28 (duration: 3 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c2609",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2beda7d",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloning into 'Align-to-Distill'...\nremote: Enumerating objects: 579, done.\u001b[K\nremote: Counting objects: 100% (579/579)\u001b[K\nremote: Counting objects: 100% (579/579), done.\u001b[K\nremote: Compressing objects: 100% (457/457)\u001b[K\nremote: Compressing objects: 100% (457/457), done.\u001b[K\nremote: Total 579 (delta 116), reused 579 (delta 116), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (579/579)\nReceiving objects: 100% (579/579), 932.36 KiB | 2.72 MiB/s, done.\nResolving deltas: 100% (116/116)\nResolving deltas: 100% (116/116), done.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/ncsoft/Align-to-Distill.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd09fb1",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b5690",
   "metadata": {},
   "source": [
    "Execution Start time: 00:08:28, End time: 00:08:28 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd4314",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8872401",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5821968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd Align-to-Distill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c38af",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da84953d",
   "metadata": {},
   "source": [
    "Execution Start time: 00:08:28, End time: 00:08:29 (duration: 1 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e06da",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc3f3d0",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16505b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CODE_OF_CONDUCT.md*  RELEASE.md    hubconf.py*        setup.py*\nCONTRIBUTING.md*     custom/       pyproject.toml*    test.sh*\nLICENSE*             examples/     release_utils.py*  train.py*\nMANIFEST.in*         fairseq/      scripts/           train_student.sh*\nREADME.md*           fairseq_cli/  setup.cfg*         train_teacher.sh\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a3570",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7196815b",
   "metadata": {},
   "source": [
    "Execution Start time: 00:08:29, End time: 00:13:29 (duration: 299 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5728d6",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab8471d",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41542b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Requirement already satisfied: pip<24.1 in /usr/local/lib/python3.10/site-packages (24.0)\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\nCollecting fairseq==0.12.2\n  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/9.6 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n\u001b[?25hCollecting omegaconf==2.0.6\n  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: cffi in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (1.16.0)\nRequirement already satisfied: cython in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (3.0.10)\nCollecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\n  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (2023.12.25)\nCollecting sacrebleu>=1.4.12 (from fairseq==0.12.2)\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/51.8 kB ? eta -:--:--\n\n\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (2.2.1+cpu)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (4.66.4)\nCollecting bitarray (from fairseq==0.12.2)\n  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\nCollecting torchaudio>=0.8.0 (from fairseq==0.12.2)\n  Downloading torchaudio-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from fairseq==0.12.2) (1.25.2)\nRequirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/site-packages (from omegaconf==2.0.6) (6.0.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from omegaconf==2.0.6) (4.12.2)\nCollecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\n  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/112.4 kB ? eta -:--:--\n\n\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\n\u001b[?25hCollecting portalocker (from sacrebleu>=1.4.12->fairseq==0.12.2)\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\nCollecting tabulate>=0.8.9 (from sacrebleu>=1.4.12->fairseq==0.12.2)\n  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\nCollecting colorama (from sacrebleu>=1.4.12->fairseq==0.12.2)\n  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\nCollecting lxml (from sacrebleu>=1.4.12->fairseq==0.12.2)\n  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\nCollecting torch (from fairseq==0.12.2)\n  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (3.15.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (1.12)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch->fairseq==0.12.2) (2023.6.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->fairseq==0.12.2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->fairseq==0.12.2)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->fairseq==0.12.2)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->fairseq==0.12.2)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->fairseq==0.12.2)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->fairseq==0.12.2)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch->fairseq==0.12.2)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->fairseq==0.12.2)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->fairseq==0.12.2)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch->fairseq==0.12.2)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch->fairseq==0.12.2)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==3.0.0 (from torch->fairseq==0.12.2)\n  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq==0.12.2)\n  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi->fairseq==0.12.2) (2.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch->fairseq==0.12.2) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch->fairseq==0.12.2) (1.3.0)\nDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\nDownloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/123.8 kB ? eta -:--:--\n\n\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/104.0 kB ? eta -:--:--\n\n\u001b[?25hDownloading torchaudio-2.4.0-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/3.4 MB ? eta -:--:--\n\n\n\n\n\u001b[?25hDownloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/797.2 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/410.6 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/14.1 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/23.7 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/823.6 kB ? eta -:--:--\n\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/664.8 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/121.6 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/56.5 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/124.2 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/196.0 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/176.2 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/99.1 kB ? eta -:--:--\n\n\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/209.4 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hDownloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/288.3 kB ? eta -:--:--\n\n\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\nDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/5.0 MB ? eta -:--:--\n\n\n\n\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\nDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/19.7 MB ? eta -:--:--\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[?25hBuilding wheels for collected packages: fairseq, antlr4-python3-runtime\n  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10854413 sha256=66680b50adf3b2c60c3f403534255fcdfac1af41e5489acdce9a20158a3faf3c\n  Stored in directory: /tmp/pip-ephem-wheel-cache-278p274u/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n  Building wheel for antlr4-python3-runtime (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=2e2bdf79b9fbea8554a350e190b1f3701ff6716ba711c186b428f8ffce0b77ff\n  Stored in directory: /tmp/pip-ephem-wheel-cache-278p274u/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\nSuccessfully built fairseq antlr4-python3-runtime\nDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\nInstalling collected packages: bitarray, antlr4-python3-runtime, triton, tabulate, portalocker, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lxml, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, torch, torchaudio, fairseq\n  WARNING: The scripts proton and proton-viewer are installed in '/root/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n  WARNING: The script tabulate is installed in '/root/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n  WARNING: The script sacrebleu is installed in '/root/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/root/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n  WARNING: The scripts fairseq-eval-lm, fairseq-generate, fairseq-hydra-train, fairseq-interactive, fairseq-preprocess, fairseq-score, fairseq-train and fairseq-validate are installed in '/root/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\nSuccessfully installed antlr4-python3-runtime-4.8 bitarray-2.9.2 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 lxml-5.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 omegaconf-2.0.6 portalocker-2.10.1 sacrebleu-2.4.3 tabulate-0.9.0 torch-2.4.0 torchaudio-2.4.0 triton-3.0.0\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempt 3: fairseq from pip\n",
    "# Installation of fairseq through pip works!\n",
    "!pip install \"pip<24.1\"\n",
    "!pip install fairseq==0.12.2 omegaconf==2.0.6 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183726e",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e953b3",
   "metadata": {},
   "source": [
    "Execution Start time: 00:13:29, End time: 00:13:29 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad4d4e",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289fe28d",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3065b524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e233ff",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc7814e",
   "metadata": {},
   "source": [
    "Execution Start time: 00:13:29, End time: 00:15:08 (duration: 98 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7227b4",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d148f9",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ecf0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill/examples/translation\nCloning Moses github repository (for tokenization scripts)...\nCloning into 'mosesdecoder'...\nremote: Enumerating objects: 148459, done.\u001b[K\nremote: Counting objects: 100% (887/887)\u001b[K\nremote: Counting objects: 100% (887/887), done.\u001b[K\nremote: Compressing objects: 100% (366/366)\u001b[K\nremote: Compressing objects: 100% (366/366), done.\u001b[K\nremote: Total 148459 (delta 565), reused 797 (delta 517), pack-reused 147572 (from 1)\u001b[K\nReceiving objects: 100% (148459/148459), 129.93 MiB | 25.88 MiB/s\nReceiving objects: 100% (148459/148459), 129.99 MiB | 23.60 MiB/s, done.\nResolving deltas: 100% (114591/114591)\nResolving deltas: 100% (114591/114591), done.\nCloning Subword NMT repository (for BPE pre-processing)...\nCloning into 'subword-nmt'...\nremote: Enumerating objects: 622, done.\u001b[K\nremote: Counting objects: 100% (46/46)\u001b[K\nremote: Counting objects: 100% (46/46), done.\u001b[K\nremote: Compressing objects: 100% (30/30)\u001b[K\nremote: Compressing objects: 100% (30/30), done.\u001b[K\nremote: Total 622 (delta 25), reused 31 (delta 16), pack-reused 576 (from 1)\u001b[K\nReceiving objects: 100% (622/622)\nReceiving objects: 100% (622/622), 261.27 KiB | 6.37 MiB/s, done.\nResolving deltas: 100% (374/374)\nResolving deltas: 100% (374/374), done.\nDownloading data from http://dl.fbaipublicfiles.com/fairseq/data/iwslt14/de-en.tgz...\n--2024-08-21 00:13:39--  http://dl.fbaipublicfiles.com/fairseq/data/iwslt14/de-en.tgz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.156.184.78, 108.156.184.129, 108.156.184.22, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.156.184.78|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 19982877 (19M) [application/x-tar]\nSaving to: ‘de-en.tgz’\n\n\nde-en.tgz             0%[                    ]       0  --.-KB/s               \nde-en.tgz           100%[===================>]  19.06M  --.-KB/s    in 0.1s    \n\n\n\nData successfully downloaded.\nde-en/\nde-en/IWSLT14.TED.dev2010.de-en.de.xml\nde-en/IWSLT14.TED.dev2010.de-en.en.xml\nde-en/IWSLT14.TED.tst2010.de-en.de.xml\nde-en/IWSLT14.TED.tst2010.de-en.en.xml\nde-en/IWSLT14.TED.tst2011.de-en.de.xml\nde-en/IWSLT14.TED.tst2011.de-en.en.xml\nde-en/IWSLT14.TED.tst2012.de-en.de.xml\nde-en/IWSLT14.TED.tst2012.de-en.en.xml\nde-en/IWSLT14.TEDX.dev2012.de-en.de.xml\nde-en/IWSLT14.TEDX.dev2012.de-en.en.xml\nde-en/README\nde-en/train.en\nde-en/train.tags.de-en.de\nde-en/train.tags.de-en.en\npre-processing train data...\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\nclean-corpus.perl: processing iwslt14.tokenized.de-en/tmp/train.tags.de-en.tok.de & .en to iwslt14.tokenized.de-en/tmp/train.tags.de-en.clean, cutoff 1-175, ratio 1.5\n..........(100000).......\nInput sentences: 174443  Output sentences:  167522\npre-processing valid/test data...\norig/de-en/IWSLT14.TED.dev2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.de\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.de\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2011.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.de\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.de\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\norig/de-en/IWSLT14.TEDX.dev2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.de\nTokenizer Version 1.1\nLanguage: de\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.dev2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.en\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.en\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2011.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.en\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\norig/de-en/IWSLT14.TED.tst2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.en\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\norig/de-en/IWSLT14.TEDX.dev2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.en\nTokenizer Version 1.1\nLanguage: en\nNumber of threads: 8\n\ncreating train, valid, test...\nlearn_bpe.py on iwslt14.tokenized.de-en/tmp/train.en-de...\n\n  0%|                                                 | 0/10000 [00:00<?, ?it/s]\n  0%|                                         | 1/10000 [00:00<32:28,  5.13it/s]\n  0%|                                         | 3/10000 [00:00<23:44,  7.02it/s]\n  0%|                                         | 4/10000 [00:00<33:32,  4.97it/s]\n  0%|                                         | 5/10000 [00:00<29:21,  5.67it/s]\n  0%|                                         | 6/10000 [00:01<34:37,  4.81it/s]\n  0%|                                         | 8/10000 [00:01<29:33,  5.63it/s]\n  0%|                                         | 9/10000 [00:01<27:41,  6.01it/s]\n  0%|                                        | 11/10000 [00:01<21:58,  7.58it/s]\n  0%|                                        | 13/10000 [00:01<20:06,  8.28it/s]\n  0%|                                        | 15/10000 [00:02<17:05,  9.74it/s]\n  0%|                                        | 18/10000 [00:02<14:01, 11.86it/s]\n  0%|                                        | 20/10000 [00:02<16:36, 10.02it/s]\n  0%|1                                       | 25/10000 [00:02<11:04, 15.02it/s]\n  0%|1                                       | 27/10000 [00:02<11:36, 14.31it/s]\n  0%|1                                       | 30/10000 [00:03<10:01, 16.59it/s]\n  0%|1                                       | 32/10000 [00:03<10:09, 16.35it/s]\n  0%|1                                       | 37/10000 [00:03<07:24, 22.39it/s]\n  0%|1                                       | 40/10000 [00:03<06:58, 23.81it/s]\n  0%|2                                       | 50/10000 [00:03<04:20, 38.23it/s]\n  1%|2                                       | 54/10000 [00:03<06:08, 27.02it/s]\n  1%|2                                       | 58/10000 [00:03<06:39, 24.91it/s]\n  1%|2                                       | 63/10000 [00:04<05:45, 28.79it/s]\n  1%|2                                       | 67/10000 [00:04<05:25, 30.52it/s]\n  1%|2                                       | 73/10000 [00:04<04:30, 36.73it/s]\n  1%|3                                       | 79/10000 [00:04<03:58, 41.61it/s]\n  1%|3                                       | 84/10000 [00:04<03:59, 41.47it/s]\n  1%|3                                       | 96/10000 [00:04<02:47, 59.16it/s]\n  1%|4                                      | 105/10000 [00:04<02:34, 64.12it/s]\n  1%|4                                      | 112/10000 [00:04<02:38, 62.51it/s]\n  1%|4                                      | 119/10000 [00:05<03:07, 52.56it/s]\n  1%|4                                      | 125/10000 [00:05<03:08, 52.26it/s]\n  1%|5                                      | 132/10000 [00:05<02:55, 56.18it/s]\n  1%|5                                      | 142/10000 [00:05<02:29, 65.97it/s]\n  2%|6                                      | 157/10000 [00:05<01:55, 85.13it/s]\n  2%|6                                      | 171/10000 [00:05<01:41, 96.82it/s]\n  2%|7                                      | 181/10000 [00:05<01:43, 94.71it/s]\n  2%|7                                      | 191/10000 [00:05<01:46, 92.41it/s]\n  2%|7                                      | 201/10000 [00:05<01:52, 86.73it/s]\n  2%|8                                      | 212/10000 [00:06<01:53, 86.11it/s]\n  2%|8                                      | 223/10000 [00:06<01:46, 92.01it/s]\n  2%|8                                     | 236/10000 [00:06<01:37, 100.40it/s]\n  2%|9                                      | 247/10000 [00:06<01:38, 98.97it/s]\n  3%|9                                     | 261/10000 [00:06<01:29, 109.42it/s]\n  3%|#                                     | 273/10000 [00:06<01:32, 105.26it/s]\n  3%|#                                     | 284/10000 [00:06<01:33, 103.53it/s]\n  3%|#1                                    | 297/10000 [00:06<01:27, 110.33it/s]\n  3%|#1                                    | 309/10000 [00:07<01:31, 105.53it/s]\n  3%|#2                                    | 324/10000 [00:07<01:22, 117.30it/s]\n  3%|#2                                    | 336/10000 [00:07<01:32, 104.06it/s]\n  3%|#3                                    | 349/10000 [00:07<01:27, 110.21it/s]\n  4%|#3                                    | 364/10000 [00:07<01:19, 120.57it/s]\n  4%|#4                                    | 377/10000 [00:07<01:26, 111.85it/s]\n  4%|#4                                    | 390/10000 [00:07<01:22, 116.43it/s]\n  4%|#5                                    | 402/10000 [00:07<01:30, 106.64it/s]\n  4%|#6                                    | 432/10000 [00:07<01:00, 157.25it/s]\n  4%|#7                                    | 449/10000 [00:08<00:59, 160.53it/s]\n  5%|#7                                    | 468/10000 [00:08<00:56, 168.10it/s]\n  5%|#8                                    | 487/10000 [00:08<00:54, 173.64it/s]\n  5%|#9                                    | 510/10000 [00:08<00:50, 187.87it/s]\n  5%|##                                    | 530/10000 [00:08<00:51, 182.35it/s]\n  6%|##1                                   | 557/10000 [00:08<00:45, 206.34it/s]\n  6%|##1                                   | 578/10000 [00:08<00:50, 187.26it/s]\n  6%|##2                                   | 598/10000 [00:08<00:49, 189.74it/s]\n  6%|##3                                   | 622/10000 [00:08<00:46, 203.32it/s]\n  7%|##5                                   | 658/10000 [00:09<00:38, 243.31it/s]\n  7%|##5                                   | 683/10000 [00:09<00:39, 234.58it/s]\n  7%|##6                                   | 707/10000 [00:09<00:53, 173.53it/s]\n  7%|##7                                   | 732/10000 [00:09<00:48, 190.16it/s]\n  8%|##8                                   | 761/10000 [00:09<00:43, 214.25it/s]\n  8%|##9                                   | 785/10000 [00:09<00:44, 208.56it/s]\n  8%|###                                   | 808/10000 [00:09<00:49, 187.47it/s]\n  8%|###1                                  | 840/10000 [00:09<00:41, 218.44it/s]\n  9%|###3                                  | 872/10000 [00:10<00:37, 243.41it/s]\n  9%|###4                                  | 898/10000 [00:10<00:38, 239.31it/s]\n  9%|###5                                  | 933/10000 [00:10<00:33, 268.21it/s]\n 10%|###6                                  | 965/10000 [00:10<00:31, 282.57it/s]\n 10%|###7                                  | 995/10000 [00:10<00:31, 283.92it/s]\n 10%|###7                                 | 1027/10000 [00:10<00:30, 294.05it/s]\n 11%|###9                                 | 1064/10000 [00:10<00:28, 316.01it/s]\n 11%|####                                 | 1096/10000 [00:10<00:29, 299.33it/s]\n 11%|####1                                | 1127/10000 [00:10<00:34, 258.65it/s]\n 12%|####2                                | 1162/10000 [00:11<00:31, 279.36it/s]\n 12%|####4                                | 1192/10000 [00:11<00:31, 276.32it/s]\n 12%|####5                                | 1221/10000 [00:11<00:31, 278.30it/s]\n 13%|####6                                | 1258/10000 [00:11<00:28, 302.34it/s]\n 13%|####7                                | 1292/10000 [00:11<00:28, 309.31it/s]\n 13%|####9                                | 1337/10000 [00:11<00:25, 346.32it/s]\n 14%|#####                                | 1373/10000 [00:11<00:24, 347.04it/s]\n 14%|#####2                               | 1408/10000 [00:11<00:25, 336.11it/s]\n 14%|#####3                               | 1450/10000 [00:11<00:23, 358.75it/s]\n 15%|#####5                               | 1487/10000 [00:11<00:23, 358.37it/s]\n 15%|#####6                               | 1524/10000 [00:12<00:24, 344.39it/s]\n 16%|#####7                               | 1559/10000 [00:12<00:24, 340.09it/s]\n 16%|#####8                               | 1594/10000 [00:12<00:24, 340.08it/s]\n 16%|######                               | 1637/10000 [00:12<00:22, 365.57it/s]\n 17%|######2                              | 1678/10000 [00:12<00:22, 375.26it/s]\n 17%|######3                              | 1716/10000 [00:12<00:26, 309.64it/s]\n 18%|######5                              | 1772/10000 [00:12<00:22, 370.22it/s]\n 18%|######7                              | 1813/10000 [00:12<00:21, 380.72it/s]\n 19%|######8                              | 1860/10000 [00:12<00:20, 403.62it/s]\n 19%|#######                              | 1902/10000 [00:13<00:20, 404.30it/s]\n 20%|#######2                             | 1960/10000 [00:13<00:17, 452.98it/s]\n 20%|#######4                             | 2007/10000 [00:13<00:19, 420.57it/s]\n 21%|#######6                             | 2069/10000 [00:13<00:16, 474.77it/s]\n 21%|#######8                             | 2118/10000 [00:13<00:16, 470.17it/s]\n 22%|########                             | 2172/10000 [00:13<00:16, 487.34it/s]\n 22%|########2                            | 2222/10000 [00:13<00:15, 486.25it/s]\n 23%|########4                            | 2272/10000 [00:13<00:15, 489.67it/s]\n 23%|########5                            | 2322/10000 [00:13<00:16, 471.00it/s]\n 24%|########8                            | 2387/10000 [00:14<00:14, 519.53it/s]\n 25%|#########                            | 2453/10000 [00:14<00:13, 558.46it/s]\n 25%|#########2                           | 2513/10000 [00:14<00:13, 570.33it/s]\n 26%|#########5                           | 2572/10000 [00:14<00:12, 573.43it/s]\n 26%|#########7                           | 2630/10000 [00:14<00:13, 564.45it/s]\n 27%|#########9                           | 2695/10000 [00:14<00:12, 588.46it/s]\n 28%|##########1                          | 2755/10000 [00:14<00:15, 475.83it/s]\n 28%|##########3                          | 2807/10000 [00:14<00:15, 475.24it/s]\n 29%|##########6                          | 2878/10000 [00:14<00:13, 535.35it/s]\n 29%|##########8                          | 2935/10000 [00:15<00:13, 537.85it/s]\n 30%|###########1                         | 3006/10000 [00:15<00:11, 585.15it/s]\n 31%|###########4                         | 3094/10000 [00:15<00:10, 667.78it/s]\n 32%|###########7                         | 3177/10000 [00:15<00:09, 713.76it/s]\n 33%|############                         | 3267/10000 [00:15<00:08, 767.88it/s]\n 34%|############4                        | 3356/10000 [00:15<00:08, 801.00it/s]\n 34%|############7                        | 3445/10000 [00:15<00:07, 827.11it/s]\n 35%|#############                        | 3531/10000 [00:15<00:07, 835.95it/s]\n 36%|#############4                       | 3624/10000 [00:15<00:07, 862.39it/s]\n 37%|#############7                       | 3715/10000 [00:15<00:07, 876.34it/s]\n 38%|##############1                      | 3827/10000 [00:16<00:06, 948.78it/s]\n 39%|##############5                      | 3938/10000 [00:16<00:06, 996.38it/s]\n 40%|##############9                      | 4038/10000 [00:17<00:21, 281.08it/s]\n 41%|###############2                     | 4112/10000 [00:17<00:19, 300.43it/s]\n 42%|###############4                     | 4175/10000 [00:17<00:18, 319.60it/s]\n 42%|###############6                     | 4232/10000 [00:17<00:17, 328.12it/s]\n 43%|###############8                     | 4283/10000 [00:17<00:16, 336.33it/s]\n 43%|################                     | 4330/10000 [00:18<00:19, 284.80it/s]\n 44%|################1                    | 4368/10000 [00:18<00:21, 265.33it/s]\n 44%|################2                    | 4401/10000 [00:18<00:23, 237.98it/s]\n 44%|################4                    | 4436/10000 [00:18<00:21, 257.26it/s]\n 45%|################5                    | 4467/10000 [00:18<00:23, 239.66it/s]\n 45%|################6                    | 4494/10000 [00:18<00:25, 219.87it/s]\n 45%|################7                    | 4518/10000 [00:18<00:25, 215.51it/s]\n 45%|################8                    | 4541/10000 [00:19<00:25, 211.78it/s]\n 46%|################8                    | 4563/10000 [00:19<00:28, 188.11it/s]\n 46%|################9                    | 4593/10000 [00:19<00:25, 213.36it/s]\n 46%|#################1                   | 4635/10000 [00:19<00:20, 262.50it/s]\n 47%|#################2                   | 4674/10000 [00:19<00:18, 293.77it/s]\n 47%|#################4                   | 4706/10000 [00:19<00:18, 290.59it/s]\n 47%|#################5                   | 4747/10000 [00:19<00:16, 321.25it/s]\n 48%|#################7                   | 4787/10000 [00:19<00:15, 342.96it/s]\n 48%|#################8                   | 4829/10000 [00:19<00:14, 363.61it/s]\n 49%|##################                   | 4871/10000 [00:20<00:13, 376.64it/s]\n 49%|##################1                  | 4913/10000 [00:20<00:13, 388.47it/s]\n 50%|##################3                  | 4962/10000 [00:20<00:12, 417.16it/s]\n 50%|##################5                  | 5005/10000 [00:20<00:12, 412.38it/s]\n 51%|##################7                  | 5057/10000 [00:20<00:11, 443.73it/s]\n 51%|##################8                  | 5102/10000 [00:20<00:11, 436.94it/s]\n 52%|###################                  | 5157/10000 [00:20<00:10, 467.71it/s]\n 52%|###################2                 | 5204/10000 [00:20<00:10, 460.02it/s]\n 53%|###################4                 | 5260/10000 [00:20<00:09, 486.87it/s]\n 53%|###################6                 | 5309/10000 [00:20<00:09, 483.45it/s]\n 54%|###################8                 | 5365/10000 [00:21<00:09, 503.92it/s]\n 54%|####################                 | 5416/10000 [00:21<00:09, 493.17it/s]\n 55%|####################2                | 5466/10000 [00:21<00:09, 488.86it/s]\n 55%|####################4                | 5515/10000 [00:21<00:09, 481.93it/s]\n 56%|####################6                | 5577/10000 [00:21<00:08, 519.84it/s]\n 56%|####################8                | 5631/10000 [00:21<00:08, 525.57it/s]\n 57%|#####################                | 5689/10000 [00:21<00:07, 541.36it/s]\n 58%|#####################2               | 5751/10000 [00:21<00:07, 563.46it/s]\n 58%|#####################4               | 5808/10000 [00:21<00:07, 563.14it/s]\n 59%|#####################7               | 5875/10000 [00:21<00:06, 594.18it/s]\n 59%|#####################9               | 5941/10000 [00:22<00:06, 611.46it/s]\n 60%|######################2              | 6003/10000 [00:22<00:06, 608.00it/s]\n 61%|######################4              | 6070/10000 [00:22<00:06, 624.39it/s]\n 61%|######################6              | 6133/10000 [00:22<00:06, 618.36it/s]\n 62%|######################9              | 6197/10000 [00:22<00:06, 623.25it/s]\n 63%|#######################1             | 6267/10000 [00:22<00:05, 644.85it/s]\n 63%|#######################4             | 6332/10000 [00:22<00:05, 642.59it/s]\n 64%|#######################6             | 6399/10000 [00:22<00:05, 649.80it/s]\n 65%|#######################9             | 6476/10000 [00:22<00:05, 683.42it/s]\n 66%|########################2            | 6551/10000 [00:22<00:04, 700.75it/s]\n 66%|########################5            | 6626/10000 [00:23<00:04, 714.85it/s]\n 67%|########################7            | 6698/10000 [00:23<00:04, 715.24it/s]\n 68%|#########################            | 6775/10000 [00:23<00:04, 730.49it/s]\n 69%|#########################3           | 6856/10000 [00:23<00:04, 752.94it/s]\n 69%|#########################6           | 6932/10000 [00:23<00:04, 742.93it/s]\n 70%|#########################9           | 7010/10000 [00:23<00:03, 752.30it/s]\n 71%|##########################2          | 7092/10000 [00:23<00:03, 771.56it/s]\n 72%|##########################5          | 7170/10000 [00:23<00:04, 588.42it/s]\n 73%|##########################8          | 7260/10000 [00:24<00:04, 663.83it/s]\n 74%|###########################2         | 7352/10000 [00:24<00:03, 729.77it/s]\n 74%|###########################4         | 7431/10000 [00:24<00:03, 723.82it/s]\n 75%|###########################7         | 7510/10000 [00:24<00:03, 739.62it/s]\n 76%|############################         | 7587/10000 [00:24<00:03, 724.43it/s]\n 77%|############################4        | 7679/10000 [00:24<00:02, 775.59it/s]\n 78%|############################7        | 7781/10000 [00:24<00:02, 844.89it/s]\n 79%|#############################1       | 7887/10000 [00:24<00:02, 905.62it/s]\n 80%|#############################5       | 7994/10000 [00:24<00:02, 950.90it/s]\n 81%|#############################2      | 8115/10000 [00:24<00:01, 1026.21it/s]\n 82%|#############################6      | 8234/10000 [00:25<00:01, 1074.11it/s]\n 84%|##############################1     | 8363/10000 [00:25<00:01, 1136.78it/s]\n 85%|##############################5     | 8491/10000 [00:25<00:01, 1176.68it/s]\n 86%|###############################     | 8626/10000 [00:25<00:01, 1227.23it/s]\n 88%|###############################6    | 8778/10000 [00:25<00:00, 1312.26it/s]\n 89%|################################1   | 8938/10000 [00:25<00:00, 1395.97it/s]\n 91%|################################7   | 9109/10000 [00:25<00:00, 1489.60it/s]\n 93%|#################################5  | 9331/10000 [00:25<00:00, 1706.68it/s]\n 95%|###################################1 | 9502/10000 [00:27<00:01, 371.40it/s]\n 96%|###################################6 | 9626/10000 [00:27<00:00, 386.64it/s]\n 97%|###################################9 | 9726/10000 [00:27<00:00, 396.54it/s]\n 98%|####################################2| 9810/10000 [00:27<00:00, 402.69it/s]\n 99%|####################################5| 9881/10000 [00:27<00:00, 405.68it/s]\n 99%|####################################7| 9944/10000 [00:28<00:00, 410.79it/s]\n100%|####################################| 10000/10000 [00:28<00:00, 354.75it/s]\napply_bpe.py to train.de...\napply_bpe.py to valid.de...\napply_bpe.py to test.de...\napply_bpe.py to train.en...\napply_bpe.py to valid.en...\napply_bpe.py to test.en...\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/Align-to-Distill/examples/translation/\n",
    "!bash prepare-iwslt14.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d72bf",
   "metadata": {},
   "source": [
    "### Step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ceaa4e",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:08, End time: 00:15:08 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dba8ac",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c999581",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e5185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill/examples/translation/iwslt14.tokenized.de-en\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/Align-to-Distill/examples/translation/iwslt14.tokenized.de-en/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f2724",
   "metadata": {},
   "source": [
    "### Step 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f9bce3",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:08, End time: 00:15:09 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164488a7",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7779451c",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ea504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001 code\n6750 test.de\n6750 test.en\n160239 train.de\n160239 train.en\n7283 valid.de\n7283 valid.en\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "# print the number of lines\n",
    "for file in *\n",
    "do\n",
    "  # Check if it is a file\n",
    "  if [ -f \"$file\" ]; then\n",
    "    # Print the number of lines\n",
    "    wc -l \"$file\"\n",
    "  fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d86611",
   "metadata": {},
   "source": [
    "### Step 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b5651",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:09, End time: 00:15:09 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0242f19c",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e9e903",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5f69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and it can be a very complicated thing , what human health is .\nand bringing those two together might seem a very da@@ un@@ ting task , but what i &apos;m going to try to say is that even in that complexity , there &apos;s some simple the@@ mes that i think , if we understand , we can really move forward .\nund was menschliche gesundheit ist , kann auch ziemlich kompliziert sein .\nund diese zwei zusammen zu bringen , erscheint vielleicht wie eine gewal@@ tige aufgabe . aber was ich ihnen zu sagen versuche ist , dass es trotz dieser komplexität einige einfache themen gibt , von denen ich denke , wenn wir diese verstehen , können wir uns wirklich weiter entwickeln .\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example parallel sentence\n",
    "!head -2 train.en\n",
    "!head -2 train.de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6317b7bb",
   "metadata": {},
   "source": [
    "### Step 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2600fd32",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:09, End time: 00:15:09 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbcc740",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0168514",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c71665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Extract First 10 Sentences Each\n",
    "# From each dataset, use only the first 10 sentences each!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb7895a",
   "metadata": {},
   "source": [
    "### Step 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf65d24",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:09, End time: 00:15:14 (duration: 4 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd278854",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225ff492",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd5f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10 train10.en\n10 test10.en\n10 valid10.en\n10 train10.de\n10 test10.de\n10 valid10.de\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!head -10 train.en > train10.en\n",
    "!head -10 test.en > test10.en\n",
    "!head -10 valid.en > valid10.en\n",
    "!head -10 train.de > train10.de\n",
    "!head -10 test.de > test10.de\n",
    "!head -10 valid.de > valid10.de\n",
    "\n",
    "!wc -l train10.en\n",
    "!wc -l test10.en\n",
    "!wc -l valid10.en\n",
    "!wc -l train10.de\n",
    "!wc -l test10.de\n",
    "!wc -l valid10.de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b638d4",
   "metadata": {},
   "source": [
    "### Step 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a2a254",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:14, End time: 00:15:14 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e099e",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b787ea",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b05de37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move these files to data/de-en\n",
    "!mkdir -p /content/Align-to-Distill/data/de-en\n",
    "!mv *.en /content/Align-to-Distill/data/de-en\n",
    "!mv *.de /content/Align-to-Distill/data/de-en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4530818d",
   "metadata": {},
   "source": [
    "### Step 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51854c3",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:14, End time: 00:15:15 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb0f069",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7512fa9",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc01c036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Preprocess/binarize the data\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720108c1",
   "metadata": {},
   "source": [
    "### Step 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13fcc4",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:15, End time: 00:15:15 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b7692",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b03b1c7",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f7b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Be in the root directory\n",
    "# %cd /content/Align-to-Distill/\n",
    "%cd /content/Align-to-Distill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4539f1cd",
   "metadata": {},
   "source": [
    "### Step 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f93d9",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:15, End time: 00:15:22 (duration: 7 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4cfd0",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb4ecef",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f2fd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-21 00:15:20 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\nTraceback (most recent call last):\n  File \"/content/Align-to-Distill/fairseq_cli/preprocess.py\", line 21, in <module>\n    from fairseq import options, tasks, utils\n  File \"/content/Align-to-Distill/fairseq/__init__.py\", line 36, in <module>\n    import fairseq.criterions  # noqa\n  File \"/content/Align-to-Distill/fairseq/criterions/__init__.py\", line 39, in <module>\n    importlib.import_module(\"fairseq.criterions.\" + file_name)\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/content/Align-to-Distill/fairseq/criterions/ctc.py\", line 22, in <module>\n    from fairseq.tasks import FairseqTask\n  File \"/content/Align-to-Distill/fairseq/tasks/__init__.py\", line 139, in <module>\n    import_tasks(tasks_dir, \"fairseq.tasks\")\n  File \"/content/Align-to-Distill/fairseq/tasks/__init__.py\", line 120, in import_tasks\n    importlib.import_module(namespace + \".\" + task_name)\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/content/Align-to-Distill/fairseq/tasks/multilingual_translation.py\", line 23, in <module>\n    from fairseq.models import FairseqMultiModel\n  File \"/content/Align-to-Distill/fairseq/models/__init__.py\", line 238, in <module>\n    import_models(models_dir, \"fairseq.models\")\n  File \"/content/Align-to-Distill/fairseq/models/__init__.py\", line 220, in import_models\n    importlib.import_module(namespace + \".\" + model_name)\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/content/Align-to-Distill/fairseq/models/bart/__init__.py\", line 10, in <module>\n    from .model import *  # noqa\n  File \"/content/Align-to-Distill/fairseq/models/bart/model.py\", line 20, in <module>\n    from fairseq.models.transformer import TransformerModel\n  File \"/content/Align-to-Distill/fairseq/models/transformer/__init__.py\", line 16, in <module>\n    from .transformer_decoder import TransformerDecoder, TransformerDecoderBase, Linear\n  File \"/content/Align-to-Distill/fairseq/models/transformer/transformer_decoder.py\", line 19, in <module>\n    from fairseq.modules import (\n  File \"/content/Align-to-Distill/fairseq/modules/__init__.py\", line 37, in <module>\n    from .multihead_attention import MultiheadAttention\n  File \"/content/Align-to-Distill/fairseq/modules/multihead_attention.py\", line 8, in <module>\n    from einops import rearrange\nModuleNotFoundError: No module named 'einops'\nError/Traceback: CalledProcessError: Command 'b'DATA_DIR=data/de-en\\nrm -rf data-bin/\\n# Add current directory to path\\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\\n\\npython fairseq_cli/preprocess.py --source-lang de --target-lang en \\\\\\n    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\\\\n    --destdir data-bin/ \\\\\\n    --cpu\\n'' returned non-zero exit status 1.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[18], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'DATA_DIR=data/de-en\\nrm -rf data-bin/\\n# Add current directory to path\\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\\n\\npython fairseq_cli/preprocess.py --source-lang de --target-lang en \\\\\\n    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\\\\n    --destdir data-bin/ \\\\\\n    --cpu\\n')\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b'DATA_DIR=data/de-en\\nrm -rf data-bin/\\n# Add current directory to path\\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\\n\\npython fairseq_cli/preprocess.py --source-lang de --target-lang en \\\\\\n    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\\\\n    --destdir data-bin/ \\\\\\n    --cpu\\n'' returned non-zero exit status 1."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=data/de-en\n",
    "rm -rf data-bin/\n",
    "# Add current directory to path\n",
    "export PYTHONPATH=$PYTHONPATH:$(pwd)\n",
    "\n",
    "python fairseq_cli/preprocess.py --source-lang de --target-lang en \\\n",
    "    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\n",
    "    --destdir data-bin/ \\\n",
    "    --cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1de389",
   "metadata": {},
   "source": [
    "### Step 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514340de",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:22, End time: 00:15:22 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ec447f",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6833cc1d",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019d631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/Align-to-Distill\n/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/Align-to-Distill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312d2085",
   "metadata": {},
   "source": [
    "### Step 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3822d0",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:23, End time: 00:15:23 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3938b9b",
   "metadata": {},
   "source": [
    "**Thought**: [pre-executed by user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee65477e",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd9acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Training a Teacher Model\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d16e7",
   "metadata": {},
   "source": [
    "### Step 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff9acac",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:26, End time: 00:15:41 (duration: 14 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee99257",
   "metadata": {},
   "source": [
    "**Thought**: Now that the data has been prepared and preprocessed, I will proceed to train the teacher model using the specified command. This will involve training for one epoch with a batch size of 1, as per the instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc2c85b",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a0749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-21 00:15:33 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n2024-08-21 00:15:39 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': True, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'custom/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 0, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'data/de-en/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=True, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='custom/', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=1, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=1, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_teacher', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='data/de-en/ckpt', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='data-bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, alignment_module=True, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_layers=6, encoder_attention_heads=4, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_teacher'), 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\nTraceback (most recent call last):\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 599, in <module>\n    cli_main()\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 592, in cli_main\n    distributed_utils.call_main(cfg, main)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/distributed/utils.py\", line 369, in call_main\n    main(cfg, **kwargs)\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 92, in main\n    task = tasks.setup_task(cfg.task)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/tasks/__init__.py\", line 46, in setup_task\n    return task.setup_task(cfg, **kwargs)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/tasks/translation.py\", line 301, in setup_task\n    cfg.source_lang, cfg.target_lang = data_utils.infer_language_pair(paths[0])\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/data/data_utils.py\", line 30, in infer_language_pair\n    for filename in PathManager.ls(path):\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/file_io.py\", line 100, in ls\n    return os.listdir(path)\nFileNotFoundError: [Errno 2] No such file or directory: 'data-bin'\nError/Traceback: CalledProcessError: Command 'b'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n'' returned non-zero exit status 1.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[21], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n')\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n'' returned non-zero exit status 1."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --arch transformer_teacher --share-decoder-input-output-embed \\\n",
    "    --user-dir custom/ --cpu \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797b8c0",
   "metadata": {},
   "source": [
    "### Step 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d597065",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:43, End time: 00:15:43 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c3d92",
   "metadata": {},
   "source": [
    "**Thought**: It seems that the `data-bin` directory is missing, which is causing the error. This directory should have been created during the preprocessing step. I will check if the preprocessing step was successful and if the `data-bin` directory exists. If not, I will attempt to preprocess the data again to ensure the directory is created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd92beea",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec602d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ls: cannot access 'data-bin': No such file or directory\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ls data-bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7bc8c1",
   "metadata": {},
   "source": [
    "### Step 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d8380f",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:45, End time: 00:15:52 (duration: 6 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfda47c",
   "metadata": {},
   "source": [
    "**Thought**: The `data-bin` directory does not exist, indicating that the preprocessing step did not complete successfully. I will attempt to preprocess the data again to ensure the directory is created and the data is properly prepared for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726974c1",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac07304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-21 00:15:51 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\nTraceback (most recent call last):\n  File \"/content/Align-to-Distill/fairseq_cli/preprocess.py\", line 21, in <module>\n    from fairseq import options, tasks, utils\n  File \"/content/Align-to-Distill/fairseq/__init__.py\", line 36, in <module>\n    import fairseq.criterions  # noqa\n  File \"/content/Align-to-Distill/fairseq/criterions/__init__.py\", line 39, in <module>\n    importlib.import_module(\"fairseq.criterions.\" + file_name)\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/content/Align-to-Distill/fairseq/criterions/ctc.py\", line 22, in <module>\n    from fairseq.tasks import FairseqTask\n  File \"/content/Align-to-Distill/fairseq/tasks/__init__.py\", line 139, in <module>\n    import_tasks(tasks_dir, \"fairseq.tasks\")\n  File \"/content/Align-to-Distill/fairseq/tasks/__init__.py\", line 120, in import_tasks\n    importlib.import_module(namespace + \".\" + task_name)\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/content/Align-to-Distill/fairseq/tasks/multilingual_translation.py\", line 23, in <module>\n    from fairseq.models import FairseqMultiModel\n  File \"/content/Align-to-Distill/fairseq/models/__init__.py\", line 238, in <module>\n    import_models(models_dir, \"fairseq.models\")\n  File \"/content/Align-to-Distill/fairseq/models/__init__.py\", line 220, in import_models\n    importlib.import_module(namespace + \".\" + model_name)\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/content/Align-to-Distill/fairseq/models/bart/__init__.py\", line 10, in <module>\n    from .model import *  # noqa\n  File \"/content/Align-to-Distill/fairseq/models/bart/model.py\", line 20, in <module>\n    from fairseq.models.transformer import TransformerModel\n  File \"/content/Align-to-Distill/fairseq/models/transformer/__init__.py\", line 16, in <module>\n    from .transformer_decoder import TransformerDecoder, TransformerDecoderBase, Linear\n  File \"/content/Align-to-Distill/fairseq/models/transformer/transformer_decoder.py\", line 19, in <module>\n    from fairseq.modules import (\n  File \"/content/Align-to-Distill/fairseq/modules/__init__.py\", line 37, in <module>\n    from .multihead_attention import MultiheadAttention\n  File \"/content/Align-to-Distill/fairseq/modules/multihead_attention.py\", line 8, in <module>\n    from einops import rearrange\nModuleNotFoundError: No module named 'einops'\nError/Traceback: CalledProcessError: Command 'b'DATA_DIR=data/de-en\\nrm -rf data-bin/\\n# Add current directory to path\\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\\n\\npython fairseq_cli/preprocess.py --source-lang de --target-lang en \\\\\\n    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\\\\n    --destdir data-bin/ \\\\\\n    --cpu\\n'' returned non-zero exit status 1.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[23], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'DATA_DIR=data/de-en\\nrm -rf data-bin/\\n# Add current directory to path\\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\\n\\npython fairseq_cli/preprocess.py --source-lang de --target-lang en \\\\\\n    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\\\\n    --destdir data-bin/ \\\\\\n    --cpu\\n')\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b'DATA_DIR=data/de-en\\nrm -rf data-bin/\\n# Add current directory to path\\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\\n\\npython fairseq_cli/preprocess.py --source-lang de --target-lang en \\\\\\n    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\\\\n    --destdir data-bin/ \\\\\\n    --cpu\\n'' returned non-zero exit status 1."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=data/de-en\n",
    "rm -rf data-bin/\n",
    "# Add current directory to path\n",
    "export PYTHONPATH=$PYTHONPATH:$(pwd)\n",
    "\n",
    "python fairseq_cli/preprocess.py --source-lang de --target-lang en \\\n",
    "    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\n",
    "    --destdir data-bin/ \\\n",
    "    --cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d81d6",
   "metadata": {},
   "source": [
    "### Step 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963cbb5",
   "metadata": {},
   "source": [
    "Execution Start time: 00:15:53, End time: 00:16:01 (duration: 7 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3744d98",
   "metadata": {},
   "source": [
    "**Thought**: \n",
    "Thought: The error indicates that the `einops` module is missing, which is required by the `fairseq` library. I need to install the `einops` package to resolve this issue and then attempt the preprocessing step again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b55b1",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d20d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/43.2 kB ? eta -:--:--\n\n\u001b[?25hDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\nInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install einops --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feea850",
   "metadata": {},
   "source": [
    "### Step 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abac779e",
   "metadata": {},
   "source": [
    "Execution Start time: 00:16:03, End time: 00:16:14 (duration: 10 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac4a34",
   "metadata": {},
   "source": [
    "**Thought**: The `einops` package has been successfully installed. I will now attempt the preprocessing step again to ensure the data is properly prepared for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d5e35",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea827971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-21 00:16:10 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=True, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='de', target_lang='en', trainpref='data/de-en/train10', validpref='data/de-en/valid10', testpref='data/de-en/test10', align_suffix=None, destdir='data-bin/', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=1, dict_only=False)\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [de] Dictionary: 128 types\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [de] data/de-en/train10.de: 10 sents, 207 tokens, 0.0% replaced (by <unk>)\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [de] Dictionary: 128 types\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [de] data/de-en/valid10.de: 10 sents, 174 tokens, 60.9% replaced (by <unk>)\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [de] Dictionary: 128 types\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [de] data/de-en/test10.de: 10 sents, 494 tokens, 63.6% replaced (by <unk>)\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [en] Dictionary: 120 types\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [en] data/de-en/train10.en: 10 sents, 234 tokens, 0.0% replaced (by <unk>)\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [en] Dictionary: 120 types\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [en] data/de-en/valid10.en: 10 sents, 175 tokens, 54.9% replaced (by <unk>)\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [en] Dictionary: 120 types\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | [en] data/de-en/test10.en: 10 sents, 474 tokens, 53.6% replaced (by <unk>)\n2024-08-21 00:16:13 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=data/de-en\n",
    "rm -rf data-bin/\n",
    "# Add current directory to path\n",
    "export PYTHONPATH=$PYTHONPATH:$(pwd)\n",
    "\n",
    "python fairseq_cli/preprocess.py --source-lang de --target-lang en \\\n",
    "    --trainpref $DATA_DIR/train10 --validpref $DATA_DIR/valid10 --testpref $DATA_DIR/test10 \\\n",
    "    --destdir data-bin/ \\\n",
    "    --cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c24f30",
   "metadata": {},
   "source": [
    "### Step 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665af126",
   "metadata": {},
   "source": [
    "Execution Start time: 00:16:19, End time: 00:16:33 (duration: 14 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af1223",
   "metadata": {},
   "source": [
    "**Thought**: The preprocessing step has completed successfully, and the `data-bin` directory has been created. I will now proceed to train the teacher model using the specified command. This will involve training for one epoch with a batch size of 1, as per the instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d07b91d",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864bc5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-21 00:16:26 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n2024-08-21 00:16:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': True, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'custom/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 0, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'data/de-en/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=True, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='custom/', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=1, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=1, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_teacher', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='data/de-en/ckpt', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='data-bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, alignment_module=True, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_layers=6, encoder_attention_heads=4, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_teacher'), 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n2024-08-21 00:16:30 | INFO | fairseq.tasks.translation | [de] dictionary: 128 types\n2024-08-21 00:16:30 | INFO | fairseq.tasks.translation | [en] dictionary: 120 types\nTraceback (most recent call last):\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/data/encoders/moses_tokenizer.py\", line 31, in __init__\n    from sacremoses import MosesTokenizer, MosesDetokenizer\nModuleNotFoundError: No module named 'sacremoses'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 599, in <module>\n    cli_main()\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 592, in cli_main\n    distributed_utils.call_main(cfg, main)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/distributed/utils.py\", line 369, in call_main\n    main(cfg, **kwargs)\n  File \"/content/Align-to-Distill/fairseq_cli/train.py\", line 98, in main\n    model = task.build_model(cfg.model)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/tasks/translation.py\", line 372, in build_model\n    self.tokenizer = encoders.build_tokenizer(\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/registry.py\", line 61, in build_x\n    return builder(cfg, *extra_args, **extra_kwargs)\n  File \"/root/.local/lib/python3.10/site-packages/fairseq/data/encoders/moses_tokenizer.py\", line 36, in __init__\n    raise ImportError(\nImportError: Please install Moses tokenizer with: pip install sacremoses\nError/Traceback: CalledProcessError: Command 'b'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n'' returned non-zero exit status 1.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[26], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n')\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b'python fairseq_cli/train.py data-bin \\\\\\n    --arch transformer_teacher --share-decoder-input-output-embed \\\\\\n    --user-dir custom/ --cpu \\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 4096 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\\\\n    --max-epoch 1 --batch-size 1 --cpu \\\\\\n    --save-dir data/de-en/ckpt\\n'' returned non-zero exit status 1."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --arch transformer_teacher --share-decoder-input-output-embed \\\n",
    "    --user-dir custom/ --cpu \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414ed601",
   "metadata": {},
   "source": [
    "### Step 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d267f8",
   "metadata": {},
   "source": [
    "Execution Start time: 00:16:35, End time: 00:16:41 (duration: 6 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d678376",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `sacremoses` module is missing, which is required for the Moses tokenizer. I need to install the `sacremoses` package to resolve this issue and then attempt the training step again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec521f05",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0adadf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/site-packages (from sacremoses) (2023.12.25)\nRequirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from sacremoses) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from sacremoses) (1.4.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from sacremoses) (4.66.4)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/897.5 kB ? eta -:--:--\n\n\n\n\u001b[?25hDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\nInstalling collected packages: sacremoses\n  WARNING: The script sacremoses is installed in '/root/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\nSuccessfully installed sacremoses-0.1.1\n\n[notice] A new release of pip is available: 24.0 -> 24.2\n[notice] To update, run: pip install --upgrade pip\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install sacremoses --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d0497",
   "metadata": {},
   "source": [
    "### Step 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc3b373",
   "metadata": {},
   "source": [
    "Execution Start time: 00:16:46, End time: 00:17:31 (duration: 45 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196263d2",
   "metadata": {},
   "source": [
    "**Thought**: The `sacremoses` package has been successfully installed. I will now attempt the training step again to train the teacher model for one epoch with a batch size of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1343e4",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefa90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-21 00:16:51 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n2024-08-21 00:16:56 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': True, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'custom/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 0, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'data/de-en/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=True, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='custom/', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=1, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=1, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_teacher', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='data/de-en/ckpt', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='data-bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, alignment_module=True, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_layers=6, encoder_attention_heads=4, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_teacher'), 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n2024-08-21 00:16:56 | INFO | fairseq.tasks.translation | [de] dictionary: 128 types\n2024-08-21 00:16:56 | INFO | fairseq.tasks.translation | [en] dictionary: 120 types\n2024-08-21 00:16:58 | INFO | fairseq_cli.train | TransformerModel(\n  (encoder): TransformerEncoderBase(\n    (dropout_module): FairseqDropout()\n    (embed_tokens): Embedding(128, 512, padding_idx=1)\n    (embed_positions): SinusoidalPositionalEmbedding()\n    (layers): ModuleList(\n      (0-5): 6 x TransformerEncoderLayerBase(\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n        (dropout_module): FairseqDropout()\n        (activation_dropout_module): FairseqDropout()\n      )\n    )\n  )\n  (decoder): TransformerDecoderBase(\n    (dropout_module): FairseqDropout()\n    (embed_tokens): Embedding(120, 512, padding_idx=1)\n    (embed_positions): SinusoidalPositionalEmbedding()\n    (layers): ModuleList(\n      (0-5): 6 x TransformerDecoderLayerBase(\n        (dropout_module): FairseqDropout()\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n        (activation_dropout_module): FairseqDropout()\n        (encoder_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n        )\n      )\n    )\n  )\n)\n2024-08-21 00:16:58 | INFO | fairseq_cli.train | task: TranslationTask\n2024-08-21 00:16:58 | INFO | fairseq_cli.train | model: TransformerModel\n2024-08-21 00:16:58 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n2024-08-21 00:16:58 | INFO | fairseq_cli.train | num. shared model params: 44,274,688 (num. trained: 44,274,688)\n2024-08-21 00:16:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n2024-08-21 00:16:58 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/valid.de-en.de\n2024-08-21 00:16:58 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/valid.de-en.en\n2024-08-21 00:16:58 | INFO | fairseq.tasks.translation | data-bin valid de-en 10 examples\n2024-08-21 00:16:58 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n2024-08-21 00:16:58 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n2024-08-21 00:16:58 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = 1\n2024-08-21 00:16:58 | INFO | fairseq.trainer | Preparing to load checkpoint data/de-en/ckpt/checkpoint_last.pt\n2024-08-21 00:16:58 | INFO | fairseq.trainer | No existing checkpoint found data/de-en/ckpt/checkpoint_last.pt\n2024-08-21 00:16:58 | INFO | fairseq.trainer | loading train data for epoch 1\n2024-08-21 00:16:58 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/train.de-en.de\n2024-08-21 00:16:58 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/train.de-en.en\n2024-08-21 00:16:58 | INFO | fairseq.tasks.translation | data-bin train de-en 10 examples\n2024-08-21 00:16:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 10\n2024-08-21 00:16:59 | INFO | fairseq.trainer | begin training epoch 1\n2024-08-21 00:16:59 | INFO | fairseq_cli.train | Start iterating over samples\n/root/.local/lib/python3.10/site-packages/fairseq/tasks/fairseq_task.py:514: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):\n2024-08-21 00:17:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n2024-08-21 00:17:19 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together\n2024-08-21 00:17:19 | INFO | fairseq.tasks.translation | example reference: in UNKNOWNTOKENINREF's UNKNOWNTOKENINREF.\n2024-08-21 00:17:20 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together\n2024-08-21 00:17:20 | INFO | fairseq.tasks.translation | example reference: it's that UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n2024-08-21 00:17:20 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together things things things things things things things things things things things things things things\n2024-08-21 00:17:20 | INFO | fairseq.tasks.translation | example reference: i really UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n2024-08-21 00:17:20 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together things things things things things things things things things things things things things things things things\n2024-08-21 00:17:20 | INFO | fairseq.tasks.translation | example reference: and UNKNOWNTOKENINREF we UNKNOWNTOKENINREF UNKNOWNTOKENINREF to UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF to UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n2024-08-21 00:17:21 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-21 00:17:21 | INFO | fairseq.tasks.translation | example reference: UNKNOWNTOKENINREF what UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF is UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n2024-08-21 00:17:22 | INFO | fairseq.tasks.translation | example hypothesis: complex complex together together together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-21 00:17:22 | INFO | fairseq.tasks.translation | example reference: UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF: UNKNOWNTOKENINREF the UNKNOWNTOKENINREF UNKNOWNTOKENINREF y UNKNOWNTOKENINREF UNKNOWNTOKENINREF\n2024-08-21 00:17:22 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-21 00:17:22 | INFO | fairseq.tasks.translation | example reference: what UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF this UNKNOWNTOKENINREF of UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF?\n2024-08-21 00:17:23 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-21 00:17:23 | INFO | fairseq.tasks.translation | example reference: UNKNOWNTOKENINREF UNKNOWNTOKENINREF: and UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF, in UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF, the UNKNOWNTOKENINREF to move the UNKNOWNTOKENINREF from UNKNOWNTOKENINREF to right, and UNKNOWNTOKENINREF and UNKNOWNTOKENINREF with the UNKNOWNTOKENINREF UNKNOWNTOKENINREF.\n2024-08-21 00:17:24 | INFO | fairseq.tasks.translation | example hypothesis: together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-21 00:17:24 | INFO | fairseq.tasks.translation | example reference: it had UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF the UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF the UNKNOWNTOKENINREF a.\n2024-08-21 00:17:25 | INFO | fairseq.tasks.translation | example hypothesis: complex together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together together\n2024-08-21 00:17:25 | INFO | fairseq.tasks.translation | example reference: but we UNKNOWNTOKENINREF't UNKNOWNTOKENINREF at the time that we UNKNOWNTOKENINREF UNKNOWNTOKENINREF a UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF UNKNOWNTOKENINREF, UNKNOWNTOKENINREF we UNKNOWNTOKENINREF't UNKNOWNTOKENINREF UNKNOWNTOKENINREF the UNKNOWNTOKENINREF UNKNOWNTOKENINREF from UNKNOWNTOKENINREF and UNKNOWNTOKENINREF the UNKNOWNTOKENINREF at the UNKNOWNTOKENINREF time.\n2024-08-21 00:17:25 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.245 | nll_loss 6.084 | ppl 67.83 | bleu 0 | wps 28.1 | wpb 17.5 | bsz 1 | num_updates 10\n2024-08-21 00:17:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 10 updates\n2024-08-21 00:17:25 | INFO | fairseq.trainer | Saving checkpoint to /content/Align-to-Distill/data/de-en/ckpt/checkpoint1.pt\n2024-08-21 00:17:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/Align-to-Distill/data/de-en/ckpt/checkpoint1.pt\n2024-08-21 00:17:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint data/de-en/ckpt/checkpoint1.pt (epoch 1 @ 10 updates, score 0.0) (writing took 3.8438655380000455 seconds)\n2024-08-21 00:17:29 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n2024-08-21 00:17:29 | INFO | train | epoch 001 | loss 7.822 | nll_loss 7.837 | ppl 228.63 | wps 9.3 | ups 0.38 | wpb 23.4 | bsz 1 | num_updates 10 | lr 1.25e-06 | gnorm 20.127 | train_wall 17 | wall 31\n2024-08-21 00:17:29 | INFO | fairseq_cli.train | done training in 30.1 seconds\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "python fairseq_cli/train.py data-bin \\\n",
    "    --arch transformer_teacher --share-decoder-input-output-embed \\\n",
    "    --user-dir custom/ --cpu \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --max-epoch 1 --batch-size 1 --cpu \\\n",
    "    --save-dir data/de-en/ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f815a364",
   "metadata": {},
   "source": [
    "### Step 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c315ec",
   "metadata": {},
   "source": [
    "Execution Start time: 00:17:39, End time: 00:18:29 (duration: 50 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72399e90",
   "metadata": {},
   "source": [
    "**Thought**: The teacher model has been successfully trained for one epoch. The validation loss and nll_loss for the teacher model are 6.245 and 6.084, respectively. I will now proceed to evaluate the teacher model by generating predictions on the test set and scoring them using the specified scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b66db",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b27f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-21 00:17:43 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n2024-08-21 00:17:46 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'custom/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data/de-en/ckpt/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': True, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n2024-08-21 00:17:46 | INFO | fairseq.tasks.translation | [de] dictionary: 128 types\n2024-08-21 00:17:46 | INFO | fairseq.tasks.translation | [en] dictionary: 120 types\n2024-08-21 00:17:46 | INFO | fairseq_cli.generate | loading model(s) from data/de-en/ckpt/checkpoint_best.pt\n/root/.local/lib/python3.10/site-packages/fairseq/checkpoint_utils.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(f, map_location=torch.device(\"cpu\"))\n2024-08-21 00:17:47 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/test.de-en.de\n2024-08-21 00:17:47 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/test.de-en.en\n2024-08-21 00:17:47 | INFO | fairseq.tasks.translation | data-bin test de-en 10 examples\n/root/.local/lib/python3.10/site-packages/fairseq/models/transformer/transformer_encoder.py:281: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n  x = torch._nested_tensor_from_mask(\n2024-08-21 00:18:26 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n2024-08-21 00:18:26 | INFO | fairseq_cli.generate | Translated 10 sentences (2,010 tokens) in 38.9s (0.26 sentences/s, 51.66 tokens/s)\nbash: line 9: !tail: command not found\nbash: line 11: !grep: command not found\nbash: line 12: !grep: command not found\nbash: line 14: !wc: command not found\nbash: line 15: !wc: command not found\nbash: line 17: !head: command not found\nbash: line 19: !head: command not found\nbash: line 21: !sed: command not found\nbash: line 22: !sed: command not found\nbash: line 25: !head: command not found\nbash: line 27: !python: command not found\nError/Traceback: CalledProcessError: Command 'b\"CKPT=data/de-en/ckpt/checkpoint_best.pt\\nmkdir -p data/de-en/tmp/\\n\\npython fairseq_cli/generate.py data-bin \\\\\\n      --path data/de-en/ckpt/checkpoint_best.pt \\\\\\n      --beam 5 --batch-size 1 \\\\\\n      --sacrebleu --remove-bpe \\\\\\n      --user-dir custom/ > data/de-en/tmp/gen.out\\n!tail data/de-en/tmp/gen.out\\n# Post-process to separate hypothesis and target\\n!grep ^H data/de-en/tmp/gen.out | cut -f3 > data/de-en/tmp/gen.out.tok.sys\\n!grep ^T data/de-en/tmp/gen.out | cut -f2 > data/de-en/tmp/gen.out.tok.ref\\n\\n!wc -l data/de-en/tmp/gen.out.tok.sys\\n!wc -l data/de-en/tmp/gen.out.tok.ref\\n# The generated test translations\\n!head data/de-en/tmp/gen.out.tok.sys\\n# the actual (reference) translations (before de-tokenization)\\n!head data/de-en/tmp/gen.out.tok.ref\\n# De-tokenize (spm decode) using sed\\n!sed 's/ //g' data/de-en/tmp/gen.out.tok.ref | sed 's/\\xe2\\x96\\x81/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.ref\\n!sed 's/ //g' data/de-en/tmp/gen.out.tok.sys | sed 's/\\xe2\\x96\\x81/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.sys\\n\\n# the actual (reference) translations\\n!head data/de-en/tmp/gen.out.ref\\n# Score the translations\\n!python fairseq_cli/score.py -s data/de-en/tmp/gen.out.sys -r data/de-en/tmp/gen.out.ref --ignore-case --sacrebleu\\n\"' returned non-zero exit status 127.---------------------------------------------------------------------------CalledProcessError                        Traceback (most recent call last)Cell In[29], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', \"CKPT=data/de-en/ckpt/checkpoint_best.pt\\nmkdir -p data/de-en/tmp/\\n\\npython fairseq_cli/generate.py data-bin \\\\\\n      --path data/de-en/ckpt/checkpoint_best.pt \\\\\\n      --beam 5 --batch-size 1 \\\\\\n      --sacrebleu --remove-bpe \\\\\\n      --user-dir custom/ > data/de-en/tmp/gen.out\\n!tail data/de-en/tmp/gen.out\\n# Post-process to separate hypothesis and target\\n!grep ^H data/de-en/tmp/gen.out | cut -f3 > data/de-en/tmp/gen.out.tok.sys\\n!grep ^T data/de-en/tmp/gen.out | cut -f2 > data/de-en/tmp/gen.out.tok.ref\\n\\n!wc -l data/de-en/tmp/gen.out.tok.sys\\n!wc -l data/de-en/tmp/gen.out.tok.ref\\n# The generated test translations\\n!head data/de-en/tmp/gen.out.tok.sys\\n# the actual (reference) translations (before de-tokenization)\\n!head data/de-en/tmp/gen.out.tok.ref\\n# De-tokenize (spm decode) using sed\\n!sed 's/ //g' data/de-en/tmp/gen.out.tok.ref | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.ref\\n!sed 's/ //g' data/de-en/tmp/gen.out.tok.sys | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.sys\\n\\n# the actual (reference) translations\\n!head data/de-en/tmp/gen.out.ref\\n# Score the translations\\n!python fairseq_cli/score.py -s data/de-en/tmp/gen.out.sys -r data/de-en/tmp/gen.out.ref --ignore-case --sacrebleu\\n\")\nFile /usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-> 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:155, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell)\n    153 else:\n    154     line = script\n--> 155 return self.shebang(line, cell)\nFile /usr/local/lib/python3.10/site-packages/IPython/core/magics/script.py:315, in ScriptMagics.shebang(self, line, cell)\n    310 if args.raise_error and p.returncode != 0:\n    311     # If we get here and p.returncode is still None, we must have\n    312     # killed it but not yet seen its return code. We don't wait for it,\n    313     # in case it's stuck in uninterruptible sleep. -9 = SIGKILL\n    314     rc = p.returncode or -9\n--> 315     raise CalledProcessError(rc, cell)\nCalledProcessError: Command 'b\"CKPT=data/de-en/ckpt/checkpoint_best.pt\\nmkdir -p data/de-en/tmp/\\n\\npython fairseq_cli/generate.py data-bin \\\\\\n      --path data/de-en/ckpt/checkpoint_best.pt \\\\\\n      --beam 5 --batch-size 1 \\\\\\n      --sacrebleu --remove-bpe \\\\\\n      --user-dir custom/ > data/de-en/tmp/gen.out\\n!tail data/de-en/tmp/gen.out\\n# Post-process to separate hypothesis and target\\n!grep ^H data/de-en/tmp/gen.out | cut -f3 > data/de-en/tmp/gen.out.tok.sys\\n!grep ^T data/de-en/tmp/gen.out | cut -f2 > data/de-en/tmp/gen.out.tok.ref\\n\\n!wc -l data/de-en/tmp/gen.out.tok.sys\\n!wc -l data/de-en/tmp/gen.out.tok.ref\\n# The generated test translations\\n!head data/de-en/tmp/gen.out.tok.sys\\n# the actual (reference) translations (before de-tokenization)\\n!head data/de-en/tmp/gen.out.tok.ref\\n# De-tokenize (spm decode) using sed\\n!sed 's/ //g' data/de-en/tmp/gen.out.tok.ref | sed 's/\\xe2\\x96\\x81/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.ref\\n!sed 's/ //g' data/de-en/tmp/gen.out.tok.sys | sed 's/\\xe2\\x96\\x81/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.sys\\n\\n# the actual (reference) translations\\n!head data/de-en/tmp/gen.out.ref\\n# Score the translations\\n!python fairseq_cli/score.py -s data/de-en/tmp/gen.out.sys -r data/de-en/tmp/gen.out.ref --ignore-case --sacrebleu\\n\"' returned non-zero exit status 127."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "CKPT=data/de-en/ckpt/checkpoint_best.pt\n",
    "mkdir -p data/de-en/tmp/\n",
    "\n",
    "python fairseq_cli/generate.py data-bin \\\n",
    "      --path data/de-en/ckpt/checkpoint_best.pt \\\n",
    "      --beam 5 --batch-size 1 \\\n",
    "      --sacrebleu --remove-bpe \\\n",
    "      --user-dir custom/ > data/de-en/tmp/gen.out\n",
    "!tail data/de-en/tmp/gen.out\n",
    "# Post-process to separate hypothesis and target\n",
    "!grep ^H data/de-en/tmp/gen.out | cut -f3 > data/de-en/tmp/gen.out.tok.sys\n",
    "!grep ^T data/de-en/tmp/gen.out | cut -f2 > data/de-en/tmp/gen.out.tok.ref\n",
    "\n",
    "!wc -l data/de-en/tmp/gen.out.tok.sys\n",
    "!wc -l data/de-en/tmp/gen.out.tok.ref\n",
    "# The generated test translations\n",
    "!head data/de-en/tmp/gen.out.tok.sys\n",
    "# the actual (reference) translations (before de-tokenization)\n",
    "!head data/de-en/tmp/gen.out.tok.ref\n",
    "# De-tokenize (spm decode) using sed\n",
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.ref | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.ref\n",
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.sys | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.sys\n",
    "\n",
    "# the actual (reference) translations\n",
    "!head data/de-en/tmp/gen.out.ref\n",
    "# Score the translations\n",
    "!python fairseq_cli/score.py -s data/de-en/tmp/gen.out.sys -r data/de-en/tmp/gen.out.ref --ignore-case --sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6491ac",
   "metadata": {},
   "source": [
    "### Step 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f80d2d",
   "metadata": {},
   "source": [
    "Execution Start time: 00:18:31, End time: 00:18:31 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8505e315",
   "metadata": {},
   "source": [
    "**Thought**: The error indicates that the `bash` commands are not being recognized within the cell. This is likely due to the use of `%%bash` magic, which does not support inline shell commands prefixed with `!`. I will separate the shell commands into individual cells and execute them sequentially to ensure they are recognized and executed properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6cd793",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078655e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir -p data/de-en/tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656367a",
   "metadata": {},
   "source": [
    "### Step 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce3755",
   "metadata": {},
   "source": [
    "Execution Start time: 00:18:34, End time: 00:19:20 (duration: 46 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245f16a",
   "metadata": {},
   "source": [
    "**Thought**: The directory for storing temporary files has been created. I will now proceed to generate predictions using the trained teacher model and save the output to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2169187",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01c556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-21 00:18:37 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n2024-08-21 00:18:40 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'custom/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data/de-en/ckpt/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': True, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n2024-08-21 00:18:40 | INFO | fairseq.tasks.translation | [de] dictionary: 128 types\n2024-08-21 00:18:40 | INFO | fairseq.tasks.translation | [en] dictionary: 120 types\n2024-08-21 00:18:40 | INFO | fairseq_cli.generate | loading model(s) from data/de-en/ckpt/checkpoint_best.pt\n/root/.local/lib/python3.10/site-packages/fairseq/checkpoint_utils.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(f, map_location=torch.device(\"cpu\"))\n2024-08-21 00:18:40 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/test.de-en.de\n2024-08-21 00:18:40 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin/test.de-en.en\n2024-08-21 00:18:40 | INFO | fairseq.tasks.translation | data-bin test de-en 10 examples\n\n  0%|                                                    | 0/10 [00:00<?, ?it/s]/root/.local/lib/python3.10/site-packages/fairseq/models/transformer/transformer_encoder.py:281: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n  x = torch._nested_tensor_from_mask(\n\n 10%|███▌                                | 1/10 [00:03<00:31,  3.54s/it, wps=57]\n 20%|███████▏                            | 2/10 [00:06<00:27,  3.47s/it, wps=58]\n 30%|██████████▊                         | 3/10 [00:11<00:27,  3.91s/it, wps=53]\n 40%|██████████████▍                     | 4/10 [00:15<00:22,  3.83s/it, wps=53]\n 50%|██████████████████                  | 5/10 [00:18<00:19,  3.81s/it, wps=53]\n 60%|█████████████████████▌              | 6/10 [00:23<00:15,  3.92s/it, wps=52]\n 70%|█████████████████████████▏          | 7/10 [00:26<00:11,  3.83s/it, wps=53]\n 80%|████████████████████████████▊       | 8/10 [00:30<00:07,  3.71s/it, wps=53]\n 90%|████████████████████████████████▍   | 9/10 [00:33<00:03,  3.73s/it, wps=53]\n100%|███████████████████████████████████| 10/10 [00:37<00:00,  3.74s/it, wps=53]\n                                                                                \n2024-08-21 00:19:18 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n2024-08-21 00:19:18 | INFO | fairseq_cli.generate | Translated 10 sentences (2,010 tokens) in 37.4s (0.27 sentences/s, 53.81 tokens/s)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python fairseq_cli/generate.py data-bin \\\n",
    "      --path data/de-en/ckpt/checkpoint_best.pt \\\n",
    "      --beam 5 --batch-size 1 \\\n",
    "      --sacrebleu --remove-bpe \\\n",
    "      --user-dir custom/ > data/de-en/tmp/gen.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c78523",
   "metadata": {},
   "source": [
    "### Step 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bfb4b1",
   "metadata": {},
   "source": [
    "Execution Start time: 00:19:22, End time: 00:19:23 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9bca4",
   "metadata": {},
   "source": [
    "**Thought**: The predictions have been generated successfully using the trained teacher model. I will now proceed to post-process the output to separate the hypothesis and target translations, and then score the translations using the `score.py` script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e75b2d",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c44b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!grep ^H data/de-en/tmp/gen.out | cut -f3 > data/de-en/tmp/gen.out.tok.sys\n",
    "!grep ^T data/de-en/tmp/gen.out | cut -f2 > data/de-en/tmp/gen.out.tok.ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bf5a9",
   "metadata": {},
   "source": [
    "### Step 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5455a8b",
   "metadata": {},
   "source": [
    "Execution Start time: 00:19:25, End time: 00:19:26 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc00af48",
   "metadata": {},
   "source": [
    "**Thought**: The hypothesis and target translations have been successfully separated into their respective files. I will now proceed to de-tokenize the translations and then score them using the `score.py` script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326b029b",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0ce25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.ref | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.ref\n",
    "!sed 's/ //g' data/de-en/tmp/gen.out.tok.sys | sed 's/▁/ /g' | sed 's/^ //g' > data/de-en/tmp/gen.out.sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7546d",
   "metadata": {},
   "source": [
    "### Step 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6691e3",
   "metadata": {},
   "source": [
    "Execution Start time: 00:19:28, End time: 00:19:35 (duration: 6 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a86713",
   "metadata": {},
   "source": [
    "**Thought**: The translations have been successfully de-tokenized. I will now proceed to score the translations using the `score.py` script with the specified options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5308d6e",
   "metadata": {},
   "source": [
    "**Action (execute)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52733f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-08-21 00:19:33 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\nNamespace(sys='data/de-en/tmp/gen.out.sys', ref='data/de-en/tmp/gen.out.ref', order=4, ignore_case=True, sacrebleu=True, sentence_bleu=False)\nBLEU = 0.00 0.0/0.0/0.0/0.0 (BP = 0.000 ratio = 0.007 hyp_len = 10 ref_len = 1422)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python fairseq_cli/score.py -s data/de-en/tmp/gen.out.sys -r data/de-en/tmp/gen.out.ref --ignore-case --sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fdd18a",
   "metadata": {},
   "source": [
    "### Step 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d7cebb",
   "metadata": {},
   "source": [
    "Execution Start time: 00:19:37, End time: 00:19:37 (duration: 0 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a73ca4",
   "metadata": {},
   "source": [
    "**Thought**: The evaluation of the teacher model has been completed, and the BLEU score is 0.00. This is expected given the limited data (only 10 sentences) and the short training duration (one epoch). I will now submit the results for the teacher model's validation loss and nll_loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bdb816",
   "metadata": {},
   "source": [
    "**Action (submit)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf24280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'teacher_loss': 7.822, 'teacher_nll_loss': 7.837}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
